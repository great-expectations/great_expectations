# This file is responsible for configuring the `dev` pipeline (https://dev.azure.com/great-expectations/great_expectations/_build)
#
# The pipeline is run under the following conditions:
#   - On the develop branch whenever a commit is made to an open PR
#
# `dev` runs unit tests for any directories that have sufficient coverage and integration tests for those that don't.
# The pipeline aims to balance both performance and safety to improve the developer experience but is innately less thorough than `great_expectations`.

trigger:
  branches:
    include:
    - pre_pr-* # Can be used to test both `great_expectations` and `dependency_graph` pipelines
    - develop
    exclude:
    - main

resources:
  containers:
  - container: postgres
    image: postgres:11
    ports:
    - 5432:5432
    env:
      POSTGRES_DB: "test_ci"
      POSTGRES_HOST_AUTH_METHOD: "trust"
  - container: mysql
    image: mysql:8.0.20
    ports:
      - 3306:3306
    env:
      MYSQL_ALLOW_EMPTY_PASSWORD: "yes"
      MYSQL_DATABASE: test_ci
  - container: mssql
    image: mcr.microsoft.com/mssql/server:2019-latest
    env:
      ACCEPT_EULA: Y
      MSSQL_SA_PASSWORD: ReallyStrongPwd1234%^&*
      MSSQL_DB: test_ci
      MSSQL_PID: Developer
    ports:
      - 1433:1433
  - container: trino
    image: trinodb/trino:400
    ports:
      - 8088:8080

variables:
  GE_USAGE_STATISTICS_URL: "https://qa.stats.greatexpectations.io/great_expectations/v1/usage_statistics"


stages:
  - stage: scope_check
    pool:
      vmImage: 'ubuntu-latest'
    jobs:
      - job: changes
        steps:
          - task: ChangedFiles@1
            name: CheckChanges
            inputs:
              verbose: true
              rules: |
                [DocsChanged]
                docs/**
                tests/integration/docusaurus/**
                tests/integration/fixtures/**
                tests/test_sets/**
                examples/expectations/*.py
                static/_redirects
                static/index.html
                /*.js
                /*.json
                yarn.lock

                [GXChanged]
                great_expectations/**/*.py
                pyproject.toml
                setup.cfg
                setup.py
                MANIFEST.in
                tests/**
                docs/**/*.py
                /*.txt
                /*.yml
                requirements*
                reqs/*.txt
                ci/**/*.yml
                assets/scripts/**
                scripts/*.py
                scripts/*.sh

  - stage: lint
    dependsOn: scope_check
    pool:
      vmImage: 'ubuntu-latest'

    jobs:
      - job: lint
        condition: eq(stageDependencies.scope_check.changes.outputs['CheckChanges.GXChanged'], true)
        steps:
          - task: UsePythonVersion@0
            inputs:
              versionSpec: 3.8
            displayName: 'Use Python 3.8'

          - script: |
              pip install $(grep -E '^(black|invoke|ruff)' reqs/requirements-dev-contrib.txt)
              EXIT_STATUS=0
              invoke fmt --check || EXIT_STATUS=$?
              invoke lint || EXIT_STATUS=$?
              exit $EXIT_STATUS

  - stage: unit_tests
    dependsOn: scope_check
    pool:
      vmImage: 'ubuntu-latest'

    jobs:
      - job: run_unit_tests
        condition: eq(stageDependencies.scope_check.changes.outputs['CheckChanges.GXChanged'], true)
        steps:
          - task: UsePythonVersion@0
            inputs:
              versionSpec: '3.8'
            displayName: 'Use Python 3.8'

          - bash: python -m pip install --upgrade pip
            displayName: 'Update pip'

          - script: |
              pip install --constraint constraints-dev.txt ".[test]" pytest-azurepipelines
            displayName: 'Install dependencies'

          - script: |
              invoke tests --cloud --unit --timeout=3.0
            displayName: 'Unit Tests'
            env:
              GE_USAGE_STATISTICS_URL: ${{ variables.GE_USAGE_STATISTICS_URL }}
              SQLALCHEMY_WARN_20: true

  - stage: custom_checks
    dependsOn: scope_check
    pool:
      vmImage: 'ubuntu-latest'

    jobs:
    - job: static_type_check
      condition: eq(stageDependencies.scope_check.changes.outputs['CheckChanges.GXChanged'], true)
      variables:
        python.version: '3.8'
      steps:
      - task: UsePythonVersion@0
        inputs:
          versionSpec: $(python.version)
        displayName: 'Use Python $(python.version)'
      - script: |
          python -m pip install --upgrade pip
          pip install --requirement requirements-types.txt
        name: InstallDependencies
      - script: |
          invoke type-check --ci --pretty --python-version $(python.version)
        name: StaticTypeCheck
      - script: |
          # initial run doesn't check `.pyi` source files
          invoke type-check --ci --pretty --check-stub-sources --python-version $(python.version)
        name: TypeCheckStubSourceFiles
    - job: docstring_linter
      condition: eq(stageDependencies.scope_check.changes.outputs['CheckChanges.GXChanged'], true)
      steps:
      - script: |
          pip install --requirement reqs/requirements-dev-test.txt
          invoke docstrings
        name: DocstringLinter
    - job: unused_import_checker
      condition: eq(stageDependencies.scope_check.changes.outputs['CheckChanges.GXChanged'], true)
      steps:
      - script: |
          pip install $(grep -E '^(ruff)' reqs/requirements-dev-contrib.txt)
          # https://www.flake8rules.com/rules/F401.html
          ruff --select F401 great_expectations tests
        name: UnusedImportChecker
    - job: check_repo_root_size
      steps:
        - script: ./ci/checks/check_repo_root_size.sh
          name: CheckRepoRootSize
    - job: public_api_report
      condition: eq(stageDependencies.scope_check.changes.outputs['CheckChanges.GXChanged'], true)
      steps:
        - script: |
            pip install --requirement reqs/requirements-dev-test.txt
            invoke public-api
          name: PublicAPIReport


  - stage: import_ge
    dependsOn: scope_check
    pool:
      vmImage: 'ubuntu-20.04'

    jobs:
      - job: import_ge

        steps:
         - task: UsePythonVersion@0
           inputs:
             versionSpec: '3.8'
           displayName: 'Use Python 3.8'

         - bash: python -m pip install --upgrade pip
           displayName: 'Update pip'

         - script: |
             pip install  .
           displayName: 'Install GX and required dependencies (i.e. not sqlalchemy)'

         - script: |
             python -c "import great_expectations as gx; print('Successfully imported GX Version:', gx.__version__)"
           displayName: 'Import Great Expectations'
  - stage: required
    dependsOn: [scope_check, lint, import_ge, custom_checks, unit_tests]
    pool:
      vmImage: 'ubuntu-20.04'

    jobs:
      # Runs pytest without any additional flags
      - job: minimal
        condition: eq(stageDependencies.scope_check.changes.outputs['CheckChanges.GXChanged'], true)
        strategy:
          # This matrix is intended to split up our sizeable test suite into two distinct components.
          # By splitting up slow tests from the remainder of the suite, we can parallelize test runs
          # at the cost of an additional Azure worker.
          #
          # To work as intended, "standard" and "slow" should be equally performant.
          matrix:
            standard:
              pytest_args: 'tests --ignore "tests/rule_based_profiler" --ignore "tests/integration"'
            slow:
              pytest_args: 'tests/rule_based_profiler tests/integration'

        steps:
          - task: UsePythonVersion@0
            inputs:
              versionSpec: '3.8'
            displayName: 'Use Python 3.8'

          - bash: python -m pip install --upgrade pip
            displayName: 'Update pip'

          - script: |
              pip install --constraint constraints-dev.txt ".[test]" pytest-azurepipelines
            displayName: 'Install dependencies'

          - script: |
              # Run pytest
              pytest $(pytest_args) \
                --no-sqlalchemy \
                --ignore 'tests/cli' \
                --ignore 'tests/integration/usage_statistics' \
                --napoleon-docstrings \
                --junitxml=junit/test-results.xml \
                --cov=. \
                --cov-report=xml \
                --cov-report=html \
                -m 'not unit and not e2e' \
                --durations=10

            displayName: 'pytest'
            env:
              GE_USAGE_STATISTICS_URL: ${{ variables.GE_USAGE_STATISTICS_URL }}
              SQLALCHEMY_WARN_20: true

          - task: PublishTestResults@2
            condition: succeededOrFailed()
            inputs:
              testResultsFiles: '**/test-*.xml'
              testRunTitle: 'Publish test results for Python $(python.version)'

          - task: PublishCodeCoverageResults@1
            inputs:
              codeCoverageTool: Cobertura
              summaryFileLocation: '$(System.DefaultWorkingDirectory)/**/coverage.xml'
              reportDirectory: '$(System.DefaultWorkingDirectory)/**/htmlcov'

      # Runs pytest with Spark and Postgres enabled
      - job: comprehensive
        timeoutInMinutes: 90
        condition: eq(stageDependencies.scope_check.changes.outputs['CheckChanges.GXChanged'], true)
        strategy:
          # This matrix is intended to split up our sizeable test suite into two distinct components.
          # By splitting up slow tests from the remainder of the suite, we can parallelize test runs
          # at the cost of an additional Azure worker.
          #
          # To work as intended, "standard" and "slow" should be equally performant.
          matrix:
            standard:
              pytest_args: 'tests --ignore "tests/rule_based_profiler" --ignore "tests/integration"'
            slow:
              pytest_args: 'tests/rule_based_profiler tests/integration'

        services:
          postgres: postgres

        steps:
          - task: UsePythonVersion@0
            inputs:
              versionSpec: '3.8'
            displayName: 'Use Python 3.8'

          - bash: python -m pip install --upgrade pip
            displayName: 'Update pip'

          - script: |
              pip install --constraint constraints-dev.txt ".[test, postgresql, spark]" pytest-azurepipelines
            displayName: 'Install dependencies'

          - script: |
              # Run pytest
              pytest $(pytest_args) \
                --postgresql \
                --spark \
                --ignore 'tests/cli' \
                --ignore 'tests/integration/usage_statistics' \
                --napoleon-docstrings \
                --junitxml=junit/test-results.xml \
                --cov=. \
                --cov-report=xml \
                --cov-report=html \
                -m 'not unit and not e2e'

            displayName: 'pytest'
            env:
              GE_USAGE_STATISTICS_URL: ${{ variables.GE_USAGE_STATISTICS_URL }}
              SQLALCHEMY_WARN_20: true

          - task: PublishTestResults@2
            condition: succeededOrFailed()
            inputs:
              testResultsFiles: '**/test-*.xml'
              testRunTitle: 'Publish test results for Python $(python.version)'

          - task: PublishCodeCoverageResults@1
            inputs:
              codeCoverageTool: Cobertura
              summaryFileLocation: '$(System.DefaultWorkingDirectory)/**/coverage.xml'
              reportDirectory: '$(System.DefaultWorkingDirectory)/**/htmlcov'

  - stage: usage_stats_integration
    dependsOn: [scope_check, lint, import_ge, custom_checks, unit_tests]
    pool:
      vmImage: 'ubuntu-latest'

    jobs:
      - job: test_usage_stats_messages
        condition: eq(stageDependencies.scope_check.changes.outputs['CheckChanges.GXChanged'], true)
        variables:
          python.version: '3.8'

        steps:
          - task: UsePythonVersion@0
            inputs:
              versionSpec: '$(python.version)'
            displayName: 'Use Python $(python.version)'

          - bash: python -m pip install --upgrade pip
            displayName: 'Update pip'

          - script: |
              pip install --constraint constraints-dev.txt ".[test]" pytest-azurepipelines
            displayName: 'Install dependencies'

          # Due to the relatively small number of usage_stats tests, we deem it appropriate to test them in their entirely through pytest
          - script: |
              pytest --no-sqlalchemy --aws-integration -v tests/integration/usage_statistics

            displayName: 'pytest'
            env:
              GE_USAGE_STATISTICS_URL: ${{ variables.GE_USAGE_STATISTICS_URL }}

  - stage: db_integration
    pool:
      vmImage: 'ubuntu-latest'

    dependsOn: [scope_check, lint, import_ge, custom_checks, unit_tests]

    jobs:
      - job: mysql
        condition: eq(stageDependencies.scope_check.changes.outputs['CheckChanges.GXChanged'], true)

        services:
          mysql: mysql

        variables:
          python.version: '3.8'

        steps:
          - task: UsePythonVersion@0
            inputs:
              versionSpec: '$(python.version)'
            displayName: 'Use Python $(python.version)'

          - bash: python -m pip install --upgrade pip
            displayName: 'Update pip'

          - script: |
              printf 'Waiting for MySQL database to accept connections'
              until mysql --host=localhost --protocol=TCP --port=3306 --user=root --password='' --execute "SHOW DATABASES"; do
                printf '.'
                sleep 1;
              done;
            displayName: Wait for database to initialise

          - script: |
              echo "SET GLOBAL sql_mode=(SELECT REPLACE(@@sql_mode,'ONLY_FULL_GROUP_BY',''));" > mysql_setup_script.sql
              mysql --host=localhost --protocol=TCP --port=3306 --user=root --password='' --reconnect < mysql_setup_script.sql
            displayName: 'Configure mysql'

          - script: |
              pip install --constraint constraints-dev.txt ".[test, mysql]" pytest-azurepipelines
            displayName: 'Install dependencies'

          - script: |
              # Run pytest
              pytest tests/test_definitions tests/expectations \
                --mysql \
                --napoleon-docstrings \
                --junitxml=junit/test-results.xml \
                --cov=. \
                --cov-report=xml \
                --cov-report=html

            displayName: 'pytest'
            env:
              GE_USAGE_STATISTICS_URL: ${{ variables.GE_USAGE_STATISTICS_URL }}
              SQLALCHEMY_WARN_20: true

      - job: mssql
        condition: eq(stageDependencies.scope_check.changes.outputs['CheckChanges.GXChanged'], true)

        services:
          mssql: mssql

        variables:
          python.version: '3.8'

        steps:
          - task: UsePythonVersion@0
            inputs:
              versionSpec: '$(python.version)'
            displayName: 'Use Python $(python.version)'

          - bash: python -m pip install --upgrade pip
            displayName: 'Update pip'

          - script: |
              sqlcmd -U sa -P "ReallyStrongPwd1234%^&*" -Q "CREATE DATABASE test_ci;" -o create_db_output.txt

          - script: |
              pip install --constraint constraints-dev.txt ".[test, mssql]" pytest-azurepipelines
            displayName: 'Install dependencies'

          - script: |
              # Run pytest
              pytest tests/test_definitions tests/expectations \
                --mssql \
                --napoleon-docstrings \
                --junitxml=junit/test-results.xml \
                --cov=. \
                --cov-report=xml \
                --cov-report=html

            displayName: 'pytest'
            env:
              GE_USAGE_STATISTICS_URL: ${{ variables.GE_USAGE_STATISTICS_URL }}
              SQLALCHEMY_WARN_20: true

      - job: trino
        condition: eq(stageDependencies.scope_check.changes.outputs['CheckChanges.GXChanged'], true)

        services:
          trino: trino

        variables:
          python.version: '3.8'

        steps:
          - task: UsePythonVersion@0
            inputs:
              versionSpec: '$(python.version)'
            displayName: 'Use Python $(python.version)'

          - bash: python -m pip install --upgrade pip
            displayName: 'Update pip'

          - script: |
              printf 'Waiting for Trino database to accept connections'
              sleep 30
#             until trino --execute "SHOW CATALOGS"; do
#               printf '.'
#               sleep 1;
#             done;
            displayName: Wait for database to initialise

          - script: |
              pip install --constraint constraints-dev.txt ".[test, trino]" pytest-azurepipelines
            displayName: 'Install dependencies'

          - script: |
              # Run pytest
              pytest tests/test_definitions tests/expectations \
                --trino \
                --napoleon-docstrings \
                --junitxml=junit/test-results.xml \
                --cov=. \
                --cov-report=xml \
                --cov-report=html

            displayName: 'pytest'
            env:
              GE_USAGE_STATISTICS_URL: ${{ variables.GE_USAGE_STATISTICS_URL }}
              SQLALCHEMY_WARN_20: true

  - stage: cli_integration
    dependsOn: [scope_check, lint, import_ge, custom_checks, unit_tests]
    pool:
      vmImage: 'ubuntu-latest'

    jobs:
      - job: test_cli
        condition: eq(stageDependencies.scope_check.changes.outputs['CheckChanges.GXChanged'], true)

        services:
          postgres: postgres

        variables:
          python.version: '3.8'

        steps:
          - task: UsePythonVersion@0
            inputs:
              versionSpec: '$(python.version)'
            displayName: 'Use Python $(python.version)'

          - bash: python -m pip install --upgrade pip
            displayName: 'Update pip'

          - script: |
              pip install --constraint constraints-dev.txt ".[test, postgresql, spark, athena]" pytest-azurepipelines
            displayName: 'Install dependencies'

          - script: |
              # Run pytest
              pytest --postgresql --spark --aws-integration tests/cli

            displayName: 'pytest'
            env:
              GE_USAGE_STATISTICS_URL: ${{ variables.GE_USAGE_STATISTICS_URL }}
              SQLALCHEMY_WARN_20: true

  - stage: airflow_provider
    dependsOn: [scope_check, lint, import_ge, custom_checks, unit_tests]
    pool:
      vmImage: 'ubuntu-latest'

    jobs:
      - job: run_airflow_provider_tests
        steps:
          - task: UsePythonVersion@0
            inputs:
              versionSpec: '3.8'
            displayName: 'Use Python 3.8'

          - script: ./ci/checks/check_min_airflow_dependency_compatibility.sh
            name: CheckMinAirflowDependencyCompatibility

          - script: ./ci/checks/run_gx_airflow_operator_tests.sh
            name: RunAirflowProviderTests
