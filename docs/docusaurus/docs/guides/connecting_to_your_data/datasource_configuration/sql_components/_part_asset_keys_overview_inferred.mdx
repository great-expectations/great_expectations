import NoteOptionalDataConnectorKeys from './_note_optional_data_connector_keys.mdx'

In an Inferred Asset Data Connector for SQL data, all the behaviour for how Data Assets are inferred, how they are split into Batches, and how those Batches are sampled for data are configured in the Data Connector dictionary.  To alter any of these behaviours from the default, you will simply set your desired behaviour by defining one of the following optional key/value pairs.

#### Optional Data Connector configuration keys for inferring Data Assets

A Data Asset in an Inferred Asset Data Connector for SQL data will consist of a single table in the database you have connected to.  You can modify the way that the Data Connector infers which tables to utilize as Data Assets by defining the following key/value pairs in your Data Connector's dictionary in the Datasource configuration:

<NoteOptionalDataConnectorKeys inferred={true} />

#### Optional Data Connector configuration keys for splitting Data Assets into Batches

Next is the matter of how (or even if) your Data Connector splits Data Assets into Batches.  By default, each Data Asset will provide a single Batch consisting of the entire table that it corresponds to.  You can change this behaviour by specifying the following key/value pairs:

<NoteOptionalDataConnectorKeys splitting={true} />

For example, imagine that you have one or more tables containing the NYC taxi data in your database.  You could instruct your Data Connector to infer Data Assets that return each table as a single Batch by simply not including a `splitter_method`.  Such a configuration would be identical to the data connector `name_of_my_inferred_data_connector` that was defined in the example at the end of step 7, so let's rename that `data_connector` entry `inferred_data_connector_single_batch_asset` since that is more meaningful.  Your configuration for a single Batch Data Asset would now look like:

```python name="inferred sql data asset single batch"
```

Alternatively, you could define a Data Asset that is split into Batches based on the year and month by defining the `splitter_method` to be `split_on_year_and_month` and providing a Datetime column. (In the case of the NYC taxi data, this would be the `pickup_datetime` column.)  Creating a Data Asset like this would result in your configuration being:

```python name="inferred sql data asset multi batch"
```

If you included both of these Data Assets, your complete configuration would look like:

```python name="full configuration for sql inferred Datasource"
```

:::note Reminder

If you are uncertain whether you should be splitting your Data Assets into Batches, please refer to our guide on [how to choose between working with a single or multiple Batches of data](../../how_to_choose_between_working_with_a_single_or_multiple_batches_of_data.md).

:::

:::tip

For more information on the available splitting methods, please see the [Splitting methods subsection under Additional notes](#splitting-methods) at the end of this guide.

:::

#### Optional Data Connector configuration keys for sampling data from returned Batches

Finally, you may wish to only sample a portion of the data that would be returned in your Data Asset's Batches.  To do this, you will need to define the optional keys `sampling_method` and `sampling_kwargs`.  As with `splitter_method` and `splitter_kwargs`, defining these key/value pairs in your Data Connector's dictionary will result in those values being applied to all Data Assets that are made available by the Data Connector.

The key/value pairs that are used for sampling data from a Data Asset are:

<NoteOptionalDataConnectorKeys sampling={true} />

:::tip

Although this guide will not use sampling in its examples, there is a list of the available sampling methods in [the Sampling methods subsection of the Additional notes section](#sampling-methods) at the end of this guide.

:::