---
title: Batch
id: batch
hoverText: A selection of records from a Data Asset.
---
import BatchesAndBatchRequests from './_batches_and_batch_requests.mdx';
import UniversalMap from '/docs/images/universal_map/_universal_map.mdx';
import ValidateHeader from '/docs/images/universal_map/_um_validate_header.mdx';
import CreateHeader from '/docs/images/universal_map/_um_create_header.mdx';

<UniversalMap setup='inactive' connect='inactive' create='active' validate='active'/> 

## Overview

### Definition

A Batch is a selection of records from a Data Asset.

### Features and promises

A Batch provides a consistent interface for describing specific data from any Datasource, to support building Metrics, Validation, and Profiling.

### Relationship to other objects

A Batch is generated by providing a Batch Request to a Datasource. It provides a reference to interact with the data through the Datasource and adds metadata to precisely identify the specific data included in the Batch.

Profilers use Batches to generate Metrics and potential Expectations based on the data. Batches make it possible for the Profiler to compare data over time and sample from large datasets to improve performance.

Metrics are always associated with a Batch of data. The identifier for the Batch is the primary way that Great Expectations identifies what data to use when computing a Metric and how to store that Metric.

## Use Cases

<CreateHeader/>

When creating Expectations interactively, a Validator needs access to a specific Batch of data against which to check Expectations. The [how to guide on interactively creating expectations](../guides/expectations/how_to_create_and_edit_expectations_with_instant_feedback_from_a_sample_batch_of_data.md) covers using a Batch in this use case.

Our in-depth guide on [how to create and edit expectations with a profiler](../guides/expectations/how_to_create_and_edit_expectations_with_a_profiler.md) covers how to specify which Batches of data should be used when using Great Expectations to generate statistics and candidate Expectations for your data.

<ValidateHeader/>

During Validation, a Checkpoint will check a Batch of data against Expectations from an Expectation Suite. You must specify a Batch Request or provide a Batch of data at runtime for the Checkpoint to run.

## Features

### Consistent Interface for Describing Specific Data from any Datasource

A Batch is always part of a Data Asset. The Data Asset is sliced into Batches to correspond to the specification you define in a Data Connector, allowing you to define Batches of a Data Asset based on times from the data, pipeline runs, or the time of a Validation.

A Batch is always built using a Batch Request. The Batch Request includes a "query" for the Data Connector to describe the data that will be included in the Batch. The query makes it possible to create a Batch Request for the most recent Batch of data without defining the specific timeframe, for example.

Once a Datasource identifies the specific data that will be included in a Batch based on the Batch Request, it creates a reference to the data, and adds metadata including a Batch Definition, Batch Spec, and Batch Markers. That additional metadata is how Great Expectations identifies the Batch when accessing or storing Metrics.

## API Basics

### How to access

You will typically not need to access a Batch directly.  Instead, you will pass it to a Great Expectations object such as a Profiler, Validator, or Checkpoint, which will then do something in response to the Batch's data.

### How to create

The `BatchRequest` object is the primary API used to construct Batches. It is provided to the `get_validator` method on DataContext.  

- For more information, see [our documentation on Batch Requests](./batch_request.md).

## More details

### Additional Notes

Instantiating a Batch does not necessarily “fetch” the data by immediately running a query or pulling data into memory. Instead, think of a Batch as a wrapper that includes the information that you will need to fetch the right data when it’s time to Validate.

You do not generally need to access the metadata that Great Expectations uses to define a Batch. You can read more about it in the API docs, but at a high level, the additional metadata works as follows:

- *Batch Definition* - A generic description of the Batch built directly from the Batch Request. It is not directly tied to the language of the source system, but it includes the specific parameters for identifying the data that may have been referenced in a relative way in the Batch Request.
- *Batch Spec* - The description of the data in the precise language of the source system or specific Execution Engine associated with the Batch.
- *Batch Markers* - (Advanced) Batch Markers are key-value pairs that can help to even more precisely identify data after Validation, such as the md5 hash of a Pandas DataFrame or the specific timestamp at which a Batch was accessed.


### Batches: Design Motivation

Batches are designed to be "MECE" -- mutually exclusive and collectively exhaustive partitions of Data Assets. However, in many cases the same *underlying data* could be present in multiple batches, for example if an analyst runs an analysis against an entire table of data each day, with only a fraction of new records being added.

Consequently, the best way to understand what "makes a batch a batch" is the act of attending to it. The batch is the fundamental unit that Great Expectations will validate and about which it will collect metrics.

<BatchesAndBatchRequests/>


## NOTES (Temporary)
:::caution API note

As part of the new modular expectations API in Great Expectations, Validation Operators are evolving into
Checkpoints. At some point in the future Validation Operators will be fully deprecated.
:::

The `batch.validate()` method evaluates one Batch of data against one Expectation Suite and returns a dictionary of
Validation Results. This is sufficient when you explore your data and get to know Great Expectations. When deploying
Great Expectations in a real data pipeline, you will typically discover additional needs:

* Validating a group of Batches that are logically related (for example, a Checkpoint for all staging tables).
* Validating a Batch against several Expectation Suites (for example, run three suites to protect a machine learning
  model `churn.critical`, `churn.warning`, `churn.drift`).
* Doing something with the Validation Results (for example, saving them for later review, sending notifications in case
  of failures, etc.).
