============================= test session starts ==============================
platform darwin -- Python 3.9.13, pytest-7.2.0, pluggy-1.0.0 -- /Users/work/Development/ENVs/supercon_ge/bin/python3
cachedir: .pytest_cache
Test order randomisation NOT enabled. Enable with --random-order or --random-order-bucket=<bucket_type>
benchmark: 4.0.0 (defaults: timer=time.perf_counter disable_gc=False min_rounds=5 min_time=0.000005 max_time=1.0 calibration_precision=10 warmup=False warmup_iterations=100000)
rootdir: /Users/work/Development/great_expectations, configfile: pyproject.toml
plugins: random-order-1.0.4, timeout-2.1.0, mock-3.10.0, pyfakefs-5.0.0, snapshottest-0.6.0, icdiff-0.6, order-1.0.1, cov-4.0.0, anyio-3.6.2, benchmark-4.0.0
collecting ... collected 1106 items

tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/multi_table_expectations/expect_table_row_count_to_equal_other_table:basic_positive] PASSED [  0%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/multi_table_expectations/expect_table_row_count_to_equal_other_table:basic_negative] PASSED [  0%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_lengths_to_equal:positive_test_string_one_character_length] PASSED [  0%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_lengths_to_equal:negative_test_string_value_is_1_too_high] PASSED [  0%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_lengths_to_equal:positive_test_with_missing_value_in_column_mostly] PASSED [  0%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_lengths_to_equal:negative_one_length_too_small] PASSED [  0%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_lengths_to_equal:positive_one_length_too_small_mostly] PASSED [  0%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_lengths_to_equal:test_conditional_expectation_passes] PASSED [  0%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_lengths_to_equal:test_conditional_expectation_fails] PASSED [  0%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_lengths_to_equal:test_conditional_expectation_parser_errors] PASSED [  0%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:basic_positive_now_test] PASSED [  0%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:basic_negative_now_test] PASSED [  1%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:basic_positive_now_timedelta_test] PASSED [  1%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:basic_negative_now_timedelta_test] PASSED [  1%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:basic_positive_datetime_test] PASSED [  1%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:basic_negative_datetime_test] PASSED [  1%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_json_parseable:basic_positive_test] PASSED [  1%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_json_parseable:positive_test_with_nulls] PASSED [  1%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_json_parseable:negative_test_integers] PASSED [  1%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_json_parseable:negative_test_string_only] PASSED [  1%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_json_parseable:negative_test_null_only] PASSED [  1%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:basic_positive_test_with_timestamps_tz_informed] PASSED [  1%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:basic_negative_test_with_timestamps_tz_informed] PASSED [  2%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_be_null:basic_positive_case_complete_result_format] PASSED [  2%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_be_null:negative_all_missing_values_pandas] PASSED [  2%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_be_null:positive_mostly_pandas] PASSED [  2%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_be_null:negative_no_mostly_one_missing_pandas] PASSED [  2%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_be_null:negative_mostly] PASSED [  2%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_be_null:positive_case_with_mostly_and_no_unexpected_values] PASSED [  2%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_be_null:negative_case_with_75percent_null_values_no_mostly] PASSED [  2%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_regex_list:basic_positive_test] PASSED [  2%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_regex_list:positive_test_with_multiple_regexes] PASSED [  2%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_regex_list:basic_negative_test] PASSED [  2%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_regex_list:negative_test_with_more_string-ish_strings] PASSED [  3%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_regex_list:positive_test_with_match_on__any] PASSED [  3%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_regex_list:positive_test_column_name_has_space_and_match_on__any] PASSED [  3%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_z_scores_to_be_less_than:basic_successful_test] PASSED [  3%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_z_scores_to_be_less_than:basic_unsuccessful_test] PASSED [  3%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_z_scores_to_be_less_than:basic_test_with_outlier] PASSED [  3%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_z_scores_to_be_less_than:basic_test_mostly_zero] PASSED [  3%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_z_scores_to_be_less_than:basic_test_with_missing] PASSED [  3%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:basic_positive_test0] PASSED [  3%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:another_basic_positive_test0] PASSED [  3%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:basic_positive_test_with_timestamps0] PASSED [  3%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:missing_min_value0] PASSED [  4%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:null_min_value0] PASSED [  4%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:missing_max_value0] PASSED [  4%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:null_max_value0] PASSED [  4%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:basic_negative_test0] PASSED [  4%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:another_negative_test0] PASSED [  4%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:basic_negative_test_with_timestamps0] PASSED [  4%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:positive_test_with_result_format__boolean_only0] PASSED [  4%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:another_positive_test_with_result_format__boolean_only0] PASSED [  4%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:negative_test_with_result_format__boolean_only0] PASSED [  4%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:another_negative_test_with_result_format__boolean_only0] PASSED [  4%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:positive_test_with_mostly0] PASSED [  5%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:2nd_positive_test_with_mostly0] PASSED [  5%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:3rd_positive_test_with_mostly0] PASSED [  5%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:negative_test_with_mostly0] PASSED [  5%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:error:_improperly_mixed_types0] PASSED [  5%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:error:_improperly_mixed_types_again0] PASSED [  5%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:error:_improperly_mixed_types_once_more0] PASSED [  5%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:error:_missing_both_min_value_and_max_value0] PASSED [  5%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:negative_test_to_verify_that_the_denominator_for_mostly_works_with_missing_values0] PASSED [  5%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:positive_test_to_verify_that_the_denominator_for_mostly_works_with_missing_values0] PASSED [  5%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:error_on_string-to-int_comparisons0] PASSED [  5%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:test_min_value_is_greater_than_max_value0] PASSED [  6%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:test_allow_cross_type_comparisons0] PASSED [  6%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:test_allow_cross_type_comparisons_again0] PASSED [  6%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:test_strict_min_failure0] PASSED [  6%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:test_strict_min_success0] PASSED [  6%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:test_strict_max_failure0] PASSED [  6%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:test_strict_max_success0] PASSED [  6%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:test_conditional_expectation_passes0] PASSED [  6%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:test_conditional_expectation_fails0] PASSED [  6%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:test_conditional_expectation_parser_errors0] PASSED [  6%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_regex:negative_test_insufficient_mostly_and_one_non_matching_value] PASSED [  6%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_regex:negative_test_insufficient_mostly_and_one_non_matching_value_summary_output] PASSED [  7%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_regex:positive_test_exact_mostly_w_one_non_matching_value] PASSED [  7%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_regex:positive_test_column_name_has_space] PASSED [  7%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_regex:positive_test_sufficient_mostly_w_one_non_matching_value] PASSED [  7%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_regex:negative_test_one_missing_value_and_insufficent_mostly] PASSED [  7%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_regex:positive_test_one_missing_value_and_exact_mostly] PASSED [  7%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_regex:positive_test_one_missing_value_and_sufficent_mostly] PASSED [  7%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_regex:positive_test_all_missing_values] PASSED [  7%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_regex:positive_test_all_missing_values_mostly] PASSED [  7%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_regex:positive_test_empty_regex] PASSED [  7%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_regex:positive_test_more_complicated_regex] PASSED [  7%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_regex:positive_test_match_characters_not_at_the_beginning_of_string] PASSED [  8%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:basic_positive_test1] PASSED [  8%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:another_basic_positive_test1] PASSED [  8%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:basic_positive_test_with_timestamps1] PASSED [  8%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:missing_min_value1] PASSED [  8%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:null_min_value1] PASSED [  8%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:missing_max_value1] PASSED [  8%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:null_max_value1] PASSED [  8%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:basic_negative_test1] PASSED [  8%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:another_negative_test1] PASSED [  8%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:basic_negative_test_with_timestamps1] PASSED [  8%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:positive_test_with_result_format__boolean_only1] PASSED [  9%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:another_positive_test_with_result_format__boolean_only1] PASSED [  9%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:negative_test_with_result_format__boolean_only1] PASSED [  9%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:another_negative_test_with_result_format__boolean_only1] PASSED [  9%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:positive_test_with_mostly1] PASSED [  9%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:2nd_positive_test_with_mostly1] PASSED [  9%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:3rd_positive_test_with_mostly1] PASSED [  9%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:negative_test_with_mostly1] PASSED [  9%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:error:_improperly_mixed_types1] PASSED [  9%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:error:_improperly_mixed_types_again1] PASSED [  9%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:error:_improperly_mixed_types_once_more1] PASSED [  9%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:error:_missing_both_min_value_and_max_value1] PASSED [ 10%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:negative_test_to_verify_that_the_denominator_for_mostly_works_with_missing_values1] PASSED [ 10%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:positive_test_to_verify_that_the_denominator_for_mostly_works_with_missing_values1] PASSED [ 10%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:error_on_string-to-int_comparisons1] PASSED [ 10%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:test_min_value_is_greater_than_max_value1] PASSED [ 10%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:test_allow_cross_type_comparisons1] PASSED [ 10%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:test_allow_cross_type_comparisons_again1] PASSED [ 10%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:test_strict_min_failure1] PASSED [ 10%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:test_strict_min_success1] PASSED [ 10%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:test_strict_max_failure1] PASSED [ 10%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:test_strict_max_success1] PASSED [ 10%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:test_conditional_expectation_passes1] PASSED [ 11%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:test_conditional_expectation_fails1] PASSED [ 11%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:test_conditional_expectation_parser_errors1] PASSED [ 11%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_be_in_set:basic_positive_test_case_single_value_not_in_column] PASSED [ 11%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_be_in_set:negative_test_case_include_one_existing_column_value] PASSED [ 11%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_be_in_set:positive_empty_values_set] PASSED [ 11%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_be_in_set:basic_negative_strings_set_all_character_values] PASSED [ 11%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_be_in_set:positive_test_strings_set_extra_value_in_column] PASSED [ 11%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_be_in_set:negative_test_float_set_two_out_of_three_column_values_included_mostly] PASSED [ 11%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_be_in_set:negative_test_float_set_two_out_of_three_column_values_included_mostly_summary_output] PASSED [ 11%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_be_in_set:positive_test_float_set_two_out_of_three_column_values_included_mostly] PASSED [ 11%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_be_in_set:positive_test_values_set_is_null] PASSED [ 12%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_be_in_set:raise_typeerror_when_values_set_is_missing] PASSED [ 12%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_of_type:basic_python_int_positive_test] PASSED [ 12%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_of_type:negative_test_python_ints_are_not_string] PASSED [ 12%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_of_type:positive_test_pandas_floats] PASSED [ 12%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_of_type:positive_test_pandas_strings] PASSED [ 12%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_of_type:negative_test_python_floats_are_not_python_bools] PASSED [ 12%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_of_type:dtype_object_and_type_object_still_has_aggregate_semantics] PASSED [ 12%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_of_type:dtype_object_and_type_object_still_has_aggregate_semantics_object_underscore] PASSED [ 12%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_of_type:dtype_object_and_type_object_still_has_aggregate_semantics_big_o] PASSED [ 12%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_of_type:positive_pandas_datetime_no_timezone] PASSED [ 12%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_of_type:positive_pandas_datetime_with_timezone] PASSED [ 13%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_of_type:negative_pandas_datetime_with_timezone] PASSED [ 13%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_of_type:negative_pandas_datetime_expected_int] PASSED [ 13%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_in_set:basic_positive_test_case_number_set] PASSED [ 13%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_in_set:vacuously_true_empty_value_set] PASSED [ 13%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_in_set:negative_test_case_exclude_existing_column_value] PASSED [ 13%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_in_set:negative_empty_values_set] PASSED [ 13%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_in_set:basic_positive_strings_set] PASSED [ 13%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_in_set:negative_test_strings_set_extra_value_in_column] PASSED [ 13%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_in_set:negative_test_numbers_set_no_matching_values] PASSED [ 13%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_in_set:positive_test_float_set] PASSED [ 13%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_in_set:negative_test_float_set] PASSED [ 14%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_in_set:test_conditional_expectation_passes] PASSED [ 14%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_in_set:test_conditional_expectation_fails] PASSED [ 14%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_in_set:test_conditional_expectation_parser_errors] PASSED [ 14%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_in_set:test_empty_column_should_be_vacuously_true] PASSED [ 14%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_in_set:basic_positive_test_case_datetime_set] PASSED [ 14%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_in_set:basic_negative_test_case_datetime_set] PASSED [ 14%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_decreasing:positive_test_with_mostly] PASSED [ 14%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_decreasing:basic_negative_test] PASSED [ 14%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_decreasing:basic_negative_test_with_strictly] PASSED [ 14%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_decreasing:basic_positive_test] PASSED [ 14%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_decreasing:test_empty_column_should_be_vacuously_true] PASSED [ 15%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_match_regex:negative_test_insufficient_mostly_and_one_non_matching_value] PASSED [ 15%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_match_regex:positive_test_exact_mostly_w_one_non_matching_value] PASSED [ 15%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_match_regex:positive_test_sufficient_mostly_w_one_non_matching_value] PASSED [ 15%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_match_regex:negative_test_one_missing_value_and_insufficent_mostly] PASSED [ 15%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_match_regex:positive_test_one_missing_value_no_exceptions] PASSED [ 15%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_match_regex:positive_test_all_missing_values] PASSED [ 15%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_match_regex:positive_test_all_missing_values_mostly] PASSED [ 15%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_match_regex:negative_test_empty_regex] PASSED [ 15%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_match_regex:negative_test_match_characters_not_at_the_beginning_of_string_exact_mostly] PASSED [ 15%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_dateutil_parseable:positive_test] PASSED [ 15%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_dateutil_parseable:positive_test_with_nulls] PASSED [ 16%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_dateutil_parseable:negative_test] PASSED [ 16%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_dateutil_parseable:test_raising_exception_for_wrong_input_data_type] PASSED [ 16%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_match_regex_list:basic_positive_test] PASSED [ 16%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_match_regex_list:positive_test_with_multiple_regexes] PASSED [ 16%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_match_regex_list:basic_negative_test] PASSED [ 16%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_match_regex_list:negative_test_with_more_string-ish_strings] PASSED [ 16%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_increasing:basic_positive_test] PASSED [ 16%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_increasing:2nd_basic_positive_test] PASSED [ 16%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_increasing:positive_test_with_strictly] PASSED [ 16%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_increasing:basic_negative_test] PASSED [ 16%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_increasing:positive_test_with_parse_strings_as_datetimes] PASSED [ 16%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_increasing:positive_test_with_interspersed_nulls] PASSED [ 17%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_increasing:negative_test_with_interspersed_nulls] PASSED [ 17%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_lengths_to_be_between:positive_test_exact_min_and_max] PASSED [ 17%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_lengths_to_be_between:negative_test_matching_min_max_too_small] PASSED [ 17%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_lengths_to_be_between:negative_test_matching_max_min_too_large] PASSED [ 17%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_lengths_to_be_between:positive_test_with_null_min_value] PASSED [ 17%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_lengths_to_be_between:positive_test_with_null_max_value] PASSED [ 17%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_lengths_to_be_between:negative_test_with_max_lt_min] PASSED [ 17%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_lengths_to_be_between:positive_test_with_missing_value_in_column] PASSED [ 17%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_lengths_to_be_between:test_error_handling_for_non_int_min_value] PASSED [ 17%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_lengths_to_be_between:test_error_handling_for_non_int_max_value] PASSED [ 17%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_lengths_to_be_between:test_error_handling_for_both_null_max_and_min_values] PASSED [ 18%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_lengths_to_be_between:test_error_handling_values_are_integers] PASSED [ 18%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_lengths_to_be_between:test_conditional_expectation_passes] PASSED [ 18%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_lengths_to_be_between:test_conditional_expectation_fails] PASSED [ 18%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_lengths_to_be_between:test_conditional_expectation_parser_errors] PASSED [ 18%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_strftime_format:simple_positive_test] PASSED [ 18%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_strftime_format:negative_test_wrong_format] PASSED [ 18%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_strftime_format:positive_test_w_nulls] PASSED [ 18%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_strftime_format:positive_test_w_mostly] PASSED [ 18%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_strftime_format:simple_negative_test] PASSED [ 18%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_strftime_format:negative_test_out_of_bounds_value_for_month] PASSED [ 18%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_strftime_format:negative_test_iso8601] PASSED [ 19%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_strftime_format:test_raising_exception_for_wrong_input_data_type] PASSED [ 19%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_strftime_format:test_raising_exception_for_wrong_format] PASSED [ 19%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_strftime_format:negative_test_input_already_datetimes] SKIPPED [ 19%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_unique:basic_positive_test_case] PASSED [ 19%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_unique:basic_negative_case_all_non_unique_character_values] PASSED [ 19%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_unique:multi_type_column_contains_2_and_quoted_2_suppressed_for_sqalchemy] PASSED [ 19%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_unique:positive_case_using_mostly] PASSED [ 19%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_unique:negative_case_using_mostly] PASSED [ 19%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_unique:positive_case_multiple_null_values] PASSED [ 19%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_unique:negative_case_non_unique_numeric_values] PASSED [ 19%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_unique:positive_case_all_null_values] PASSED [ 20%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_unique:negative_multiple_duplicate_values] PASSED [ 20%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_json_schema:basic_positive_test] PASSED [ 20%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_json_schema:positive_test_with_a_more_complex_schema] PASSED [ 20%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_json_schema:basic_negative_test] PASSED [ 20%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_null:basic_positive_case_basic_result_format] PASSED [ 20%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_null:negative_no_missing_values] PASSED [ 20%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_null:positive_mostly] PASSED [ 20%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_null:negative_mostly] PASSED [ 20%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_null:positive_case_with_mostly_and_no_unexpected_values] PASSED [ 20%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_null:negative_case_with_75percent_non_null_values_no_mostly] PASSED [ 20%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_in_type_list:positive_test_pandas_integer_column] PASSED [ 21%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_in_type_list:negative_test_pandas_float_values_are_not_strings] PASSED [ 21%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_in_type_list:positive_test_float_values] PASSED [ 21%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_in_type_list:positive_test_string_values] PASSED [ 21%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_in_type_list:positive_test_boolean_values] PASSED [ 21%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_in_type_list:positive_test_string_and_int_values] PASSED [ 21%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_in_type_list:negative_test_string_and_int_values_summary_output] PASSED [ 21%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_in_type_list:negative_test_string_and_int_values_complete_output] PASSED [ 21%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_in_type_list:positive_test_placeholder_expectation] PASSED [ 21%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_value_lengths_to_equal:positive_test_string_one_character_length] PASSED [ 21%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_value_lengths_to_equal:negative_test_string_value_is_1_too_high] PASSED [ 21%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_value_lengths_to_equal:positive_test_with_missing_value_in_column_mostly] PASSED [ 22%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_value_lengths_to_equal:negative_one_length_too_small] PASSED [ 22%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_value_lengths_to_equal:positive_one_length_too_small_mostly] PASSED [ 22%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:basic_positive_now_test] PASSED [ 22%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:basic_negative_now_test] FAILED [ 22%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:basic_positive_now_timedelta_test] PASSED [ 22%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:basic_negative_now_timedelta_test] FAILED [ 22%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:basic_positive_datetime_test] PASSED [ 22%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:basic_negative_datetime_test] FAILED [ 22%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_json_parseable:basic_positive_test] SKIPPED [ 22%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_json_parseable:positive_test_with_nulls] SKIPPED [ 22%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_json_parseable:negative_test_integers] SKIPPED [ 23%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_json_parseable:negative_test_string_only] SKIPPED [ 23%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_json_parseable:negative_test_null_only] SKIPPED [ 23%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:basic_positive_test_with_timestamps_tz_informed] PASSED [ 23%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:basic_negative_test_with_timestamps_tz_informed] FAILED [ 23%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_be_null:basic_positive_case_complete_result_format] PASSED [ 23%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_be_null:negative_mostly] PASSED [ 23%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_be_null:positive_case_with_mostly_and_no_unexpected_values] PASSED [ 23%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_be_null:negative_case_with_75percent_null_values_no_mostly] PASSED [ 23%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_regex_list:basic_positive_test] SKIPPED [ 23%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_regex_list:positive_test_with_multiple_regexes] SKIPPED [ 23%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_regex_list:basic_negative_test] SKIPPED [ 24%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_regex_list:negative_test_with_more_string-ish_strings] SKIPPED [ 24%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_regex_list:positive_test_with_match_on__any] SKIPPED [ 24%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_regex_list:positive_test_column_name_has_space_and_match_on__any] SKIPPED [ 24%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_value_z_scores_to_be_less_than:basic_successful_test] PASSED [ 24%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_value_z_scores_to_be_less_than:basic_unsuccessful_test] PASSED [ 24%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_value_z_scores_to_be_less_than:basic_test_with_outlier] PASSED [ 24%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_value_z_scores_to_be_less_than:basic_test_mostly_zero] PASSED [ 24%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_value_z_scores_to_be_less_than:basic_test_with_missing] PASSED [ 24%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:basic_positive_test0] PASSED [ 24%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:another_basic_positive_test0] PASSED [ 24%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:basic_positive_test_with_timestamps0] PASSED [ 25%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:missing_min_value0] PASSED [ 25%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:null_min_value0] PASSED [ 25%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:missing_max_value0] PASSED [ 25%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:null_max_value0] PASSED [ 25%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:basic_negative_test0] PASSED [ 25%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:another_negative_test0] PASSED [ 25%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:basic_negative_test_with_timestamps0] FAILED [ 25%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:positive_test_with_result_format__boolean_only0] PASSED [ 25%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:another_positive_test_with_result_format__boolean_only0] PASSED [ 25%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:negative_test_with_result_format__boolean_only0] PASSED [ 25%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:another_negative_test_with_result_format__boolean_only0] PASSED [ 26%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:positive_test_with_mostly0] PASSED [ 26%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:2nd_positive_test_with_mostly0] PASSED [ 26%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:3rd_positive_test_with_mostly0] PASSED [ 26%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:negative_test_with_mostly0] PASSED [ 26%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:error:_improperly_mixed_types0] PASSED [ 26%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:error:_improperly_mixed_types_again0] PASSED [ 26%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:error:_improperly_mixed_types_once_more0] PASSED [ 26%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:error:_missing_both_min_value_and_max_value0] PASSED [ 26%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:negative_test_to_verify_that_the_denominator_for_mostly_works_with_missing_values0] PASSED [ 26%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:positive_test_to_verify_that_the_denominator_for_mostly_works_with_missing_values0] PASSED [ 26%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:error_on_string-to-int_comparisons0] PASSED [ 27%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:test_min_value_is_greater_than_max_value0] PASSED [ 27%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:test_allow_cross_type_comparisons0] SKIPPED [ 27%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:test_allow_cross_type_comparisons_again0] SKIPPED [ 27%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:test_strict_min_failure0] PASSED [ 27%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:test_strict_min_success0] PASSED [ 27%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:test_strict_max_failure0] PASSED [ 27%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:test_strict_max_success0] PASSED [ 27%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_regex:negative_test_insufficient_mostly_and_one_non_matching_value] SKIPPED [ 27%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_regex:positive_test_exact_mostly_w_one_non_matching_value] SKIPPED [ 27%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_regex:positive_test_column_name_has_space] SKIPPED [ 27%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_regex:positive_test_sufficient_mostly_w_one_non_matching_value] SKIPPED [ 28%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_regex:negative_test_one_missing_value_and_insufficent_mostly] SKIPPED [ 28%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_regex:positive_test_one_missing_value_and_exact_mostly] SKIPPED [ 28%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_regex:positive_test_one_missing_value_and_sufficent_mostly] SKIPPED [ 28%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_regex:positive_test_all_missing_values] SKIPPED [ 28%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_regex:positive_test_all_missing_values_mostly] SKIPPED [ 28%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_regex:positive_test_empty_regex] SKIPPED [ 28%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_regex:positive_test_more_complicated_regex] SKIPPED [ 28%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_regex:positive_test_match_characters_not_at_the_beginning_of_string] SKIPPED [ 28%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:basic_positive_test1] PASSED [ 28%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:another_basic_positive_test1] PASSED [ 28%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:basic_positive_test_with_timestamps1] PASSED [ 29%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:missing_min_value1] PASSED [ 29%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:null_min_value1] PASSED [ 29%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:missing_max_value1] PASSED [ 29%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:null_max_value1] PASSED [ 29%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:basic_negative_test1] PASSED [ 29%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:another_negative_test1] PASSED [ 29%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:basic_negative_test_with_timestamps1] FAILED [ 29%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:positive_test_with_result_format__boolean_only1] PASSED [ 29%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:another_positive_test_with_result_format__boolean_only1] PASSED [ 29%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:negative_test_with_result_format__boolean_only1] PASSED [ 29%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:another_negative_test_with_result_format__boolean_only1] PASSED [ 30%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:positive_test_with_mostly1] PASSED [ 30%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:2nd_positive_test_with_mostly1] PASSED [ 30%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:3rd_positive_test_with_mostly1] PASSED [ 30%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:negative_test_with_mostly1] PASSED [ 30%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:error:_improperly_mixed_types1] PASSED [ 30%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:error:_improperly_mixed_types_again1] PASSED [ 30%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:error:_improperly_mixed_types_once_more1] PASSED [ 30%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:error:_missing_both_min_value_and_max_value1] PASSED [ 30%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:negative_test_to_verify_that_the_denominator_for_mostly_works_with_missing_values1] PASSED [ 30%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:positive_test_to_verify_that_the_denominator_for_mostly_works_with_missing_values1] PASSED [ 30%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:error_on_string-to-int_comparisons1] PASSED [ 31%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:test_min_value_is_greater_than_max_value1] PASSED [ 31%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:test_allow_cross_type_comparisons1] SKIPPED [ 31%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:test_allow_cross_type_comparisons_again1] SKIPPED [ 31%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:test_strict_min_failure1] PASSED [ 31%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:test_strict_min_success1] PASSED [ 31%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:test_strict_max_failure1] PASSED [ 31%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:test_strict_max_success1] PASSED [ 31%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_be_in_set:basic_positive_test_case_single_value_not_in_column] PASSED [ 31%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_be_in_set:negative_test_case_include_one_existing_column_value] PASSED [ 31%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_be_in_set:positive_empty_values_set] PASSED [ 31%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_be_in_set:basic_negative_strings_set_all_character_values] PASSED [ 32%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_be_in_set:positive_test_strings_set_extra_value_in_column] PASSED [ 32%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_be_in_set:negative_test_float_set_two_out_of_three_column_values_included_mostly] PASSED [ 32%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_be_in_set:positive_test_float_set_two_out_of_three_column_values_included_mostly] PASSED [ 32%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_be_in_set:positive_test_values_set_is_null] PASSED [ 32%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_be_in_set:raise_typeerror_when_values_set_is_missing] PASSED [ 32%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_of_type:basic_sqlalchemy_int_positive_test] PASSED [ 32%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_of_type:negative_sqlite_integer_is_not_varchar] PASSED [ 32%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_of_type:positive_test_sql_non_postgres_floats] PASSED [ 32%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_of_type:positive_test_sql_varchar] PASSED [ 32%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_of_type:negative_test_sqlalchemy_floats_are_not_boolean] PASSED [ 32%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_in_set:basic_positive_test_case_number_set] PASSED [ 33%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_in_set:vacuously_true_empty_value_set] PASSED [ 33%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_in_set:negative_test_case_exclude_existing_column_value] PASSED [ 33%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_in_set:negative_empty_values_set] PASSED [ 33%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_in_set:basic_positive_strings_set] PASSED [ 33%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_in_set:negative_test_strings_set_extra_value_in_column] PASSED [ 33%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_in_set:negative_test_numbers_set_no_matching_values] PASSED [ 33%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_in_set:positive_test_float_set] PASSED [ 33%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_in_set:negative_test_float_set] PASSED [ 33%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_in_set:test_empty_column_should_be_vacuously_true] PASSED [ 33%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_in_set:basic_positive_test_case_datetime_set] SKIPPED [ 33%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_in_set:basic_negative_test_case_datetime_set] SKIPPED [ 33%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_decreasing:positive_test_with_mostly] SKIPPED [ 34%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_decreasing:basic_negative_test] SKIPPED [ 34%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_decreasing:basic_negative_test_with_strictly] SKIPPED [ 34%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_decreasing:basic_positive_test] SKIPPED [ 34%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_decreasing:test_empty_column_should_be_vacuously_true] SKIPPED [ 34%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_match_regex:negative_test_insufficient_mostly_and_one_non_matching_value] SKIPPED [ 34%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_match_regex:positive_test_exact_mostly_w_one_non_matching_value] SKIPPED [ 34%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_match_regex:positive_test_sufficient_mostly_w_one_non_matching_value] SKIPPED [ 34%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_match_regex:negative_test_one_missing_value_and_insufficent_mostly] SKIPPED [ 34%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_match_regex:positive_test_one_missing_value_no_exceptions] SKIPPED [ 34%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_match_regex:positive_test_all_missing_values] SKIPPED [ 34%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_match_regex:positive_test_all_missing_values_mostly] SKIPPED [ 35%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_match_regex:negative_test_empty_regex] SKIPPED [ 35%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_match_regex:negative_test_match_characters_not_at_the_beginning_of_string_exact_mostly] SKIPPED [ 35%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_match_like_pattern_list:basic_positive_test] PASSED [ 35%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_match_like_pattern_list:positive_test_with_multiple_like_patternes] PASSED [ 35%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_match_like_pattern_list:negative_test_with_more_string-ish_strings] FAILED [ 35%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_match_like_pattern_list:basic_negative_test] FAILED [ 35%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_dateutil_parseable:positive_test] SKIPPED [ 35%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_dateutil_parseable:positive_test_with_nulls] SKIPPED [ 35%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_dateutil_parseable:negative_test] SKIPPED [ 35%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_dateutil_parseable:test_raising_exception_for_wrong_input_data_type] SKIPPED [ 35%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_match_like_pattern:negative_test_insufficient_mostly_and_one_non_matching_value] FAILED [ 36%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_match_like_pattern:positive_test_exact_mostly_w_one_non_matching_value] FAILED [ 36%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_match_like_pattern:positive_test_sufficient_mostly_w_one_non_matching_value] FAILED [ 36%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_match_like_pattern:negative_test_one_missing_value_and_insufficent_mostly] FAILED [ 36%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_match_like_pattern:positive_test_one_missing_value_no_exceptions] PASSED [ 36%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_match_like_pattern:positive_test_all_missing_values] PASSED [ 36%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_match_like_pattern:positive_test_all_missing_values_mostly] PASSED [ 36%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_match_like_pattern:negative_test_match_characters_not_at_the_beginning_of_string_exact_mostly] FAILED [ 36%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_match_regex_list:basic_positive_test] SKIPPED [ 36%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_match_regex_list:positive_test_with_multiple_regexes] SKIPPED [ 36%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_match_regex_list:basic_negative_test] SKIPPED [ 36%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_match_regex_list:negative_test_with_more_string-ish_strings] SKIPPED [ 37%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_increasing:basic_positive_test] SKIPPED [ 37%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_increasing:2nd_basic_positive_test] SKIPPED [ 37%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_increasing:positive_test_with_strictly] SKIPPED [ 37%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_increasing:positive_test_with_parse_strings_as_datetimes] SKIPPED [ 37%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_increasing:positive_test_with_interspersed_nulls] SKIPPED [ 37%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_increasing:negative_test_with_interspersed_nulls] SKIPPED [ 37%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_like_pattern:negative_test_insufficient_mostly_and_one_non_matching_value] FAILED [ 37%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_like_pattern:positive_test_exact_mostly_w_one_non_matching_value] FAILED [ 37%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_like_pattern:positive_test_column_name_has_space] FAILED [ 37%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_like_pattern:positive_test_sufficient_mostly_w_one_non_matching_value] FAILED [ 37%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_like_pattern:negative_test_one_missing_value_and_insufficent_mostly] FAILED [ 38%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_like_pattern:positive_test_one_missing_value_and_exact_mostly] FAILED [ 38%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_like_pattern:positive_test_one_missing_value_and_sufficent_mostly] FAILED [ 38%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_like_pattern:positive_test_all_missing_values] PASSED [ 38%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_like_pattern:positive_test_all_missing_values_mostly] PASSED [ 38%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_like_pattern:positive_test_match_characters_not_at_the_beginning_of_string] FAILED [ 38%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_value_lengths_to_be_between:positive_test_exact_min_and_max] PASSED [ 38%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_value_lengths_to_be_between:negative_test_matching_min_max_too_small] PASSED [ 38%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_value_lengths_to_be_between:negative_test_matching_max_min_too_large] PASSED [ 38%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_value_lengths_to_be_between:positive_test_with_null_min_value] PASSED [ 38%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_value_lengths_to_be_between:positive_test_with_null_max_value] PASSED [ 38%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_value_lengths_to_be_between:negative_test_with_max_lt_min] PASSED [ 39%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_value_lengths_to_be_between:positive_test_with_missing_value_in_column] PASSED [ 39%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_value_lengths_to_be_between:test_error_handling_for_non_int_min_value] PASSED [ 39%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_value_lengths_to_be_between:test_error_handling_for_non_int_max_value] PASSED [ 39%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_value_lengths_to_be_between:test_error_handling_for_both_null_max_and_min_values] PASSED [ 39%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_value_lengths_to_be_between:test_error_handling_values_are_integers] PASSED [ 39%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_strftime_format:simple_positive_test] SKIPPED [ 39%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_strftime_format:negative_test_wrong_format] SKIPPED [ 39%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_strftime_format:positive_test_w_nulls] SKIPPED [ 39%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_strftime_format:positive_test_w_mostly] SKIPPED [ 39%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_strftime_format:simple_negative_test] SKIPPED [ 39%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_strftime_format:negative_test_out_of_bounds_value_for_month] SKIPPED [ 40%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_strftime_format:negative_test_iso8601] SKIPPED [ 40%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_strftime_format:test_raising_exception_for_wrong_input_data_type] SKIPPED [ 40%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_strftime_format:test_raising_exception_for_wrong_format] SKIPPED [ 40%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_strftime_format:negative_test_input_already_datetimes] SKIPPED [ 40%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_like_pattern_list:basic_negative_test] FAILED [ 40%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_like_pattern_list:negative_test_with_more_string-ish_strings] FAILED [ 40%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_like_pattern_list:basic_positive_test] PASSED [ 40%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_like_pattern_list:positive_test_with_multiple_like_patternes] PASSED [ 40%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_like_pattern_list:positive_test_with_match_on__any] PASSED [ 40%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_like_pattern_list:positive_test_column_name_has_space_and_match_on__any] PASSED [ 40%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_unique:basic_positive_test_case] PASSED [ 41%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_unique:basic_negative_case_all_non_unique_character_values] PASSED [ 41%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_unique:multi_type_column_contains_2_and_quoted_2_suppressed_for_sqalchemy] SKIPPED [ 41%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_unique:positive_case_using_mostly] PASSED [ 41%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_unique:negative_case_using_mostly] PASSED [ 41%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_unique:positive_case_multiple_null_values] PASSED [ 41%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_unique:negative_case_non_unique_numeric_values] PASSED [ 41%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_unique:positive_case_all_null_values] PASSED [ 41%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_unique:negative_multiple_duplicate_values] PASSED [ 41%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_json_schema:basic_positive_test] SKIPPED [ 41%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_json_schema:positive_test_with_a_more_complex_schema] SKIPPED [ 41%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_json_schema:basic_negative_test] SKIPPED [ 42%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_null:basic_positive_case_basic_result_format] PASSED [ 42%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_null:negative_no_missing_values] PASSED [ 42%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_null:positive_mostly] PASSED [ 42%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_null:negative_mostly] PASSED [ 42%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_null:positive_case_with_mostly_and_no_unexpected_values] PASSED [ 42%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_null:negative_case_with_75percent_non_null_values_no_mostly] PASSED [ 42%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_in_type_list:positive_test_sqlalchemy_integer_column] PASSED [ 42%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_in_type_list:negative_test_sqlalchemy_float_values_are_not_text] PASSED [ 42%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_in_type_list:positive_test_float_values] PASSED [ 42%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_in_type_list:positive_test_text_values] PASSED [ 42%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_in_type_list:positive_test_boolean_values] PASSED [ 43%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_in_type_list:positive_test_text_and_integer_values] PASSED [ 43%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_in_type_list:positive_test_placeholder_expectation] PASSED [ 43%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_stdev_to_be_between:basic_positive_test] PASSED [ 43%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_stdev_to_be_between:vacuously_true] PASSED [ 43%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_stdev_to_be_between:positive_test__exact_min_and_max] PASSED [ 43%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_stdev_to_be_between:basic_negative_test] PASSED [ 43%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_stdev_to_be_between:positive_zero_stdev_exact_min_and_max] PASSED [ 43%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_stdev_to_be_between:positive_test_null_max_exact_min] PASSED [ 43%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_stdev_to_be_between:positive_test_null_min_exact_max] PASSED [ 43%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_stdev_to_be_between:negative_test_null_max] PASSED [ 43%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_stdev_to_be_between:negative_test_null_min] PASSED [ 44%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_stdev_to_be_between:positive_test_missing_value_in_column_complete_result_format] PASSED [ 44%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_be_in_set:basic_positive_test] PASSED [ 44%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_be_in_set:vacuously_true_universal_set] PASSED [ 44%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_be_in_set:positive_test_with_null_values_in_column] PASSED [ 44%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_be_in_set:positive_test_with_duplicate_values_in_column] PASSED [ 44%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_be_in_set:positive_test_duplicate_and_null_values] PASSED [ 44%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_be_in_set:basic_negative_test_no_set_intersection] PASSED [ 44%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_be_in_set:negative_test_some_set_intersection_and_extra] PASSED [ 44%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_be_in_set:negative_test_with_null_values_in_column] PASSED [ 44%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_be_in_set:negative_test_with_duplicate_values_in_column] PASSED [ 44%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_be_in_set:negative_test_duplicate_and_null_values] PASSED [ 45%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_most_common_value_to_be_in_set:negative_test_tie_for_most_common_with_missing_values_and_complete_result_format] PASSED [ 45%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_most_common_value_to_be_in_set:negative_test__tie_for_most_common__full_value_set__ties_okay__false] PASSED [ 45%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_most_common_value_to_be_in_set:positive_test__tie_for_most_common__ties_okay__true] PASSED [ 45%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_most_common_value_to_be_in_set:positive_test__tie_for_most_common_but_test_for_last_value__ties_okay__true] PASSED [ 45%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_most_common_value_to_be_in_set:negative_test__tie_for_most_common__value_set_does_not_match__ties_okay__false] PASSED [ 45%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_most_common_value_to_be_in_set:negative_test__tie_for_most_common__value_set_does_not_match__ties_okay__true] PASSED [ 45%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_most_common_value_to_be_in_set:positive_test_string_values_value_set_contains_more_than_actual_mode_list] PASSED [ 45%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_most_common_value_to_be_in_set:negative_test_string_values_value_set_contains_more_than_actual_mode_list] PASSED [ 45%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_quantile_values_to_be_between:basic_positive_test_extremes] PASSED [ 45%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_quantile_values_to_be_between:basic_positive_test_normal_quantiles] PASSED [ 45%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_quantile_values_to_be_between:basic_positive_test_uneven_spacing] PASSED [ 46%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_quantile_values_to_be_between:basic_negative_test_normal_quantiles_wrong_distribution] PASSED [ 46%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_quantile_values_to_be_between:basic_negative_test_disordered_quantile_ranges] PASSED [ 46%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_max_to_be_between:basic_positive_test_case] PASSED [ 46%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_max_to_be_between:basic_negative_test_case] PASSED [ 46%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_max_to_be_between:test_case_with_result_format_summary_also_verifies_that_max_value_is_inclusive] PASSED [ 46%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_max_to_be_between:test_case_with_only_a_lower_bound_and_a_missing_value] PASSED [ 46%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_max_to_be_between:negative_test_case_with_only_a_lower_bound] PASSED [ 46%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_max_to_be_between:datetime_except_sqlite] PASSED [ 46%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_max_to_be_between:datetime_with_evaluation_parameter_except_sqlite] PASSED [ 46%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_max_to_be_between:test_empty_column_should_be_false_no_observed_value_with_which_to_compare] PASSED [ 46%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_mean_to_be_between:simple_mean_positive_range] PASSED [ 47%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_mean_to_be_between:simple_mean_negative_range] PASSED [ 47%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_mean_to_be_between:simple_mean_positive_exact_match0] PASSED [ 47%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_mean_to_be_between:simple_mean_negative_exact_match] PASSED [ 47%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_mean_to_be_between:simple_mean_positive_exact_match1] PASSED [ 47%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_mean_to_be_between:simple_mean_negative_range_match] PASSED [ 47%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_mean_to_be_between:simple_mean_includes_null] PASSED [ 47%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_mean_to_be_between:vacuously_true_missing_min_and_max] PASSED [ 47%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_mean_to_be_between:type_mismatch_null_observed_value] PASSED [ 47%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_mean_to_be_between:coerced_types_true_false_values] PASSED [ 47%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_mean_to_be_between:coerced_types_true_false_and_null] PASSED [ 47%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_mean_to_be_between:catch_exceptions___non_number_min_value] PASSED [ 48%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_mean_to_be_between:catch_exceptions___non_number_max_value] PASSED [ 48%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_mean_to_be_between:test_empty_column_should_be_false_no_observed_value_with_which_to_compare] PASSED [ 48%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_equal_set:basic_positive_test] PASSED [ 48%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_equal_set:positive_test_with_null_values_in_column] PASSED [ 48%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_equal_set:positive_test_with_duplicate_values_in_column] PASSED [ 48%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_equal_set:positive_test_duplicate_and_null_values] PASSED [ 48%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_equal_set:basic_negative_test_set_contained] PASSED [ 48%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_equal_set:negative_test_some_set_intersection] PASSED [ 48%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_equal_set:negative_test_with_null_values_in_column] PASSED [ 48%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_equal_set:negative_test_with_duplicate_values_in_column] PASSED [ 48%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_equal_set:negative_test_duplicate_and_null_values] PASSED [ 49%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_sum_to_be_between:basic_positive_test_case] PASSED [ 49%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_sum_to_be_between:basic_negative_test_case] PASSED [ 49%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_sum_to_be_between:test_case_with_result_format_summary] PASSED [ 49%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_sum_to_be_between:test_case_with_only_a_lower_bound_and_a_missing_value] PASSED [ 49%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_sum_to_be_between:negative_test_case_with_only_a_lower_bound] PASSED [ 49%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_sum_to_be_between:negative_test_case_with_only_a_max] PASSED [ 49%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_sum_to_be_between:raise_valueerror_with_both_max_and_min_are_missing] PASSED [ 49%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_unique_value_count_to_be_between:basic_positive_test] PASSED [ 49%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_unique_value_count_to_be_between:positive_test_with_null_values_in_column] PASSED [ 49%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_unique_value_count_to_be_between:null_min_duplicate_values_in_column] PASSED [ 49%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_unique_value_count_to_be_between:null_max_duplicate_and_null_values] PASSED [ 50%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_unique_value_count_to_be_between:vacuously_true_null_min_and_max] PASSED [ 50%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_median_to_be_between:positive_test_min_equal_max] PASSED [ 50%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_median_to_be_between:positive_test_null_min] PASSED [ 50%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_median_to_be_between:positive_test_null_max] PASSED [ 50%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_median_to_be_between:negative_test_min_equal_max] PASSED [ 50%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_median_to_be_between:negative_test_null_min] PASSED [ 50%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_median_to_be_between:negative_test_null_max] PASSED [ 50%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_median_to_be_between:positive_test_missing_value_in_column_exact_min_and_max] PASSED [ 50%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_median_to_be_between:negative_test_missing_value_in_column_complete_result_format] PASSED [ 50%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_median_to_be_between:vacuously_true_both_min_and_max_null] PASSED [ 50%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_median_to_be_between:test_empty_column_should_be_false_no_observed_value_with_which_to_compare] PASSED [ 50%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_min_to_be_between:basic_positive_test_case] PASSED [ 51%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_min_to_be_between:negative_test_case_with_max_value_none] PASSED [ 51%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_min_to_be_between:test_case_with_result_format_summary_also_verifies_that_max_value_is_inclusive] PASSED [ 51%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_min_to_be_between:test_case_with_only_a_lower_bound_and_a_missing_value] PASSED [ 51%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_min_to_be_between:negative_test_case_with_only_a_lower_bound] PASSED [ 51%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_min_to_be_between:test_on_a_series_with_mostly_nulls] PASSED [ 51%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_min_to_be_between:negative_test_case_with_only_a_max] PASSED [ 51%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_min_to_be_between:raise_valueerror_with_both_max_and_min_are_missing] PASSED [ 51%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_proportion_of_unique_values_to_be_between:basic_positive_test] PASSED [ 51%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_proportion_of_unique_values_to_be_between:positive_test_with_null_values_in_column] PASSED [ 51%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_proportion_of_unique_values_to_be_between:duplicate_values_in_column] PASSED [ 51%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_proportion_of_unique_values_to_be_between:null_max_duplicate_and_null_values] PASSED [ 52%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_proportion_of_unique_values_to_be_between:vacuously_true_null_min_and_max] PASSED [ 52%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:basic_positive_test] PASSED [ 52%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:positive_test_with_null_values_in_column] PASSED [ 52%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:positive_test_with_duplicate_values_in_column] PASSED [ 52%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:positive_test_duplicate_and_null_values] PASSED [ 52%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:basic_negative_test_no_set_intersection] PASSED [ 52%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:negative_test_some_set_intersection] PASSED [ 52%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:negative_test_with_null_values_in_column] PASSED [ 52%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:negative_test_with_duplicate_values_in_column] PASSED [ 52%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:negative_test_duplicate_and_null_values] PASSED [ 52%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:positive_test_string_values] PASSED [ 53%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:negative_test_string_values] PASSED [ 53%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:basic_positive_test_case_date_set] PASSED [ 53%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:basic_negative_test_case_date_set] PASSED [ 53%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:basic_positive_test_case_datetime_set] PASSED [ 53%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:basic_negative_test_case_datetime_set] PASSED [ 53%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_pair_cramers_phi_value_to_be_less_than:basic_failure_test] SKIPPED [ 53%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_pair_cramers_phi_value_to_be_less_than:basic_pass_test] SKIPPED [ 53%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_pair_cramers_phi_value_to_be_less_than:basic_pass_int_string_test] SKIPPED [ 53%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_pair_cramers_phi_value_to_be_less_than:test_string_n_bins] SKIPPED [ 53%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_pair_cramers_phi_value_to_be_less_than:test_string_preconfigured_bins] SKIPPED [ 53%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_pair_cramers_phi_value_to_be_less_than:test_float_bins_preconfigured_bins] SKIPPED [ 54%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_pair_cramers_phi_value_to_be_less_than:test_float_with_missing] SKIPPED [ 54%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_pair_cramers_phi_value_to_be_less_than:test_float_and_string_with_missings] SKIPPED [ 54%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_stdev_to_be_between:basic_positive_test] PASSED [ 54%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_stdev_to_be_between:vacuously_true] PASSED [ 54%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_stdev_to_be_between:positive_test__exact_min_and_max] PASSED [ 54%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_stdev_to_be_between:positive_test__exact_min_and_max_sqlalchemy] SKIPPED [ 54%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_stdev_to_be_between:basic_negative_test] PASSED [ 54%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_stdev_to_be_between:positive_zero_stdev_exact_min_and_max] PASSED [ 54%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_stdev_to_be_between:positive_test_null_max_exact_min] PASSED [ 54%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_stdev_to_be_between:positive_test_null_min_exact_max] PASSED [ 54%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_stdev_to_be_between:negative_test_null_max] PASSED [ 55%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_stdev_to_be_between:negative_test_null_min] PASSED [ 55%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_stdev_to_be_between:positive_test_missing_value_in_column_complete_result_format] PASSED [ 55%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_be_in_set:basic_positive_test] PASSED [ 55%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_be_in_set:vacuously_true_universal_set] PASSED [ 55%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_be_in_set:positive_test_with_null_values_in_column] PASSED [ 55%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_be_in_set:positive_test_with_duplicate_values_in_column] PASSED [ 55%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_be_in_set:positive_test_duplicate_and_null_values] PASSED [ 55%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_be_in_set:basic_negative_test_no_set_intersection] PASSED [ 55%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_be_in_set:negative_test_some_set_intersection_and_extra] PASSED [ 55%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_be_in_set:negative_test_with_null_values_in_column] PASSED [ 55%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_be_in_set:negative_test_with_duplicate_values_in_column] PASSED [ 56%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_be_in_set:negative_test_duplicate_and_null_values] PASSED [ 56%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_most_common_value_to_be_in_set:negative_test_tie_for_most_common_with_missing_values_and_complete_result_format] PASSED [ 56%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_most_common_value_to_be_in_set:negative_test__tie_for_most_common__full_value_set__ties_okay__false] PASSED [ 56%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_most_common_value_to_be_in_set:positive_test__tie_for_most_common__ties_okay__true] PASSED [ 56%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_most_common_value_to_be_in_set:positive_test__tie_for_most_common_but_test_for_last_value__ties_okay__true] PASSED [ 56%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_most_common_value_to_be_in_set:negative_test__tie_for_most_common__value_set_does_not_match__ties_okay__false] PASSED [ 56%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_most_common_value_to_be_in_set:negative_test__tie_for_most_common__value_set_does_not_match__ties_okay__true] PASSED [ 56%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_most_common_value_to_be_in_set:positive_test_string_values_value_set_contains_more_than_actual_mode_list] PASSED [ 56%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_most_common_value_to_be_in_set:negative_test_string_values_value_set_contains_more_than_actual_mode_list] PASSED [ 56%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_quantile_values_to_be_between:basic_positive_test_extremes] PASSED [ 56%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_quantile_values_to_be_between:basic_positive_test_normal_quantiles] PASSED [ 57%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_quantile_values_to_be_between:basic_positive_test_uneven_spacing] PASSED [ 57%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_quantile_values_to_be_between:basic_negative_test_normal_quantiles_wrong_distribution] PASSED [ 57%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_quantile_values_to_be_between:basic_negative_test_disordered_quantile_ranges] PASSED [ 57%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_max_to_be_between:basic_positive_test_case] PASSED [ 57%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_max_to_be_between:basic_negative_test_case] PASSED [ 57%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_max_to_be_between:test_case_with_result_format_summary_also_verifies_that_max_value_is_inclusive] PASSED [ 57%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_max_to_be_between:test_case_with_only_a_lower_bound_and_a_missing_value] PASSED [ 57%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_max_to_be_between:negative_test_case_with_only_a_lower_bound] PASSED [ 57%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_max_to_be_between:datetime_except_sqlite] SKIPPED [ 57%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_max_to_be_between:datetime_sqlite] PASSED [ 57%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_max_to_be_between:datetime_with_evaluation_parameter_except_sqlite] SKIPPED [ 58%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_max_to_be_between:datetime_with_evaluation_parameter_sqlite] PASSED [ 58%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_max_to_be_between:test_empty_column_should_be_false_no_observed_value_with_which_to_compare] PASSED [ 58%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_mean_to_be_between:simple_mean_positive_range] PASSED [ 58%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_mean_to_be_between:simple_mean_negative_range] PASSED [ 58%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_mean_to_be_between:simple_mean_positive_exact_match0] PASSED [ 58%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_mean_to_be_between:simple_mean_negative_exact_match] PASSED [ 58%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_mean_to_be_between:simple_mean_positive_exact_match1] PASSED [ 58%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_mean_to_be_between:simple_mean_negative_range_match] PASSED [ 58%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_mean_to_be_between:simple_mean_includes_null] PASSED [ 58%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_mean_to_be_between:vacuously_true_missing_min_and_max] PASSED [ 58%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_mean_to_be_between:type_mismatch_null_observed_value] SKIPPED [ 59%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_mean_to_be_between:coerced_types_true_false_values] PASSED [ 59%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_mean_to_be_between:coerced_types_true_false_and_null] PASSED [ 59%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_mean_to_be_between:catch_exceptions___non_number_min_value] PASSED [ 59%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_mean_to_be_between:catch_exceptions___non_number_max_value] PASSED [ 59%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_mean_to_be_between:test_empty_column_should_be_false_no_observed_value_with_which_to_compare] PASSED [ 59%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_equal_set:basic_positive_test] PASSED [ 59%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_equal_set:positive_test_with_null_values_in_column] PASSED [ 59%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_equal_set:positive_test_with_duplicate_values_in_column] PASSED [ 59%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_equal_set:positive_test_duplicate_and_null_values] PASSED [ 59%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_equal_set:basic_negative_test_set_contained] PASSED [ 59%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_equal_set:negative_test_some_set_intersection] PASSED [ 60%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_equal_set:negative_test_with_null_values_in_column] PASSED [ 60%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_equal_set:negative_test_with_duplicate_values_in_column] PASSED [ 60%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_equal_set:negative_test_duplicate_and_null_values] PASSED [ 60%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_sum_to_be_between:basic_positive_test_case] PASSED [ 60%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_sum_to_be_between:basic_negative_test_case] PASSED [ 60%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_sum_to_be_between:test_case_with_result_format_summary] PASSED [ 60%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_sum_to_be_between:test_case_with_only_a_lower_bound_and_a_missing_value] PASSED [ 60%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_sum_to_be_between:negative_test_case_with_only_a_lower_bound] PASSED [ 60%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_sum_to_be_between:negative_test_case_with_only_a_max] PASSED [ 60%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_sum_to_be_between:raise_valueerror_with_both_max_and_min_are_missing] PASSED [ 60%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_unique_value_count_to_be_between:basic_positive_test] PASSED [ 61%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_unique_value_count_to_be_between:positive_test_with_null_values_in_column] PASSED [ 61%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_unique_value_count_to_be_between:null_min_duplicate_values_in_column] PASSED [ 61%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_unique_value_count_to_be_between:null_max_duplicate_and_null_values] PASSED [ 61%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_unique_value_count_to_be_between:vacuously_true_null_min_and_max] PASSED [ 61%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_median_to_be_between:positive_test_min_equal_max] PASSED [ 61%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_median_to_be_between:positive_test_null_min] PASSED [ 61%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_median_to_be_between:positive_test_null_max] PASSED [ 61%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_median_to_be_between:negative_test_min_equal_max] PASSED [ 61%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_median_to_be_between:negative_test_null_min] PASSED [ 61%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_median_to_be_between:negative_test_null_max] PASSED [ 61%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_median_to_be_between:positive_test_missing_value_in_column_exact_min_and_max] PASSED [ 62%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_median_to_be_between:negative_test_missing_value_in_column_complete_result_format] PASSED [ 62%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_median_to_be_between:vacuously_true_both_min_and_max_null] PASSED [ 62%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_median_to_be_between:test_empty_column_should_be_false_no_observed_value_with_which_to_compare] PASSED [ 62%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_min_to_be_between:basic_positive_test_case] PASSED [ 62%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_min_to_be_between:negative_test_case_with_max_value_none] PASSED [ 62%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_min_to_be_between:test_case_with_result_format_summary_also_verifies_that_max_value_is_inclusive] PASSED [ 62%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_min_to_be_between:test_case_with_only_a_lower_bound_and_a_missing_value] PASSED [ 62%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_min_to_be_between:negative_test_case_with_only_a_lower_bound] PASSED [ 62%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_min_to_be_between:test_on_a_series_with_mostly_nulls] PASSED [ 62%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_min_to_be_between:negative_test_case_with_only_a_max] PASSED [ 62%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_min_to_be_between:raise_valueerror_with_both_max_and_min_are_missing] PASSED [ 63%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_proportion_of_unique_values_to_be_between:basic_positive_test] PASSED [ 63%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_proportion_of_unique_values_to_be_between:positive_test_with_null_values_in_column] PASSED [ 63%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_proportion_of_unique_values_to_be_between:duplicate_values_in_column] PASSED [ 63%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_proportion_of_unique_values_to_be_between:null_max_duplicate_and_null_values] PASSED [ 63%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_proportion_of_unique_values_to_be_between:vacuously_true_null_min_and_max] PASSED [ 63%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:basic_positive_test] PASSED [ 63%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:positive_test_with_null_values_in_column] PASSED [ 63%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:positive_test_with_duplicate_values_in_column] PASSED [ 63%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:positive_test_duplicate_and_null_values] PASSED [ 63%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:basic_negative_test_no_set_intersection] PASSED [ 63%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:negative_test_some_set_intersection] PASSED [ 64%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:negative_test_with_null_values_in_column] PASSED [ 64%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:negative_test_with_duplicate_values_in_column] PASSED [ 64%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:negative_test_duplicate_and_null_values] PASSED [ 64%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:positive_test_string_values] PASSED [ 64%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:negative_test_string_values] PASSED [ 64%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:basic_positive_test_case_date_set] SKIPPED [ 64%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:basic_negative_test_case_date_set] SKIPPED [ 64%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:basic_positive_test_case_datetime_set] SKIPPED [ 64%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:basic_negative_test_case_datetime_set] SKIPPED [ 64%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_parameterized_distribution_ks_test_p_value_to_be_greater_than:positive_standard_norm_distribution] SKIPPED [ 64%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_parameterized_distribution_ks_test_p_value_to_be_greater_than:negative_standard_norm_distribution] SKIPPED [ 65%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_parameterized_distribution_ks_test_p_value_to_be_greater_than:positive_beta_distribution_params_is_a_dict] SKIPPED [ 65%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_parameterized_distribution_ks_test_p_value_to_be_greater_than:positive_beta_distribution_params_is_a_tuple] SKIPPED [ 65%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_parameterized_distribution_ks_test_p_value_to_be_greater_than:negative_beta_distribution_params_is_a_dict] SKIPPED [ 65%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_parameterized_distribution_ks_test_p_value_to_be_greater_than:negative_beta_distribution_params_is_a_tuple] SKIPPED [ 65%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_parameterized_distribution_ks_test_p_value_to_be_greater_than:positive_gamma_distribution_params_is_a_dict] SKIPPED [ 65%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_parameterized_distribution_ks_test_p_value_to_be_greater_than:positive_gamma_distribution_params_is_a_tuple] SKIPPED [ 65%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_parameterized_distribution_ks_test_p_value_to_be_greater_than:negative_gamma_distribution_params_is_a_dict] SKIPPED [ 65%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_parameterized_distribution_ks_test_p_value_to_be_greater_than:negative_gamma_distribution_params_is_a_tuple] SKIPPED [ 65%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_parameterized_distribution_ks_test_p_value_to_be_greater_than:positive_uniform_distribution_params_is_a_dict] SKIPPED [ 65%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_parameterized_distribution_ks_test_p_value_to_be_greater_than:positive_uniform_distribution_params_is_a_tuple] SKIPPED [ 65%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_parameterized_distribution_ks_test_p_value_to_be_greater_than:negative_uniform_distribution_params_is_a_dict] SKIPPED [ 66%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_parameterized_distribution_ks_test_p_value_to_be_greater_than:negative_uniform_distribution_params_is_a_tuple] SKIPPED [ 66%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_parameterized_distribution_ks_test_p_value_to_be_greater_than:positive_chi2_params_is_a_dict] SKIPPED [ 66%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_parameterized_distribution_ks_test_p_value_to_be_greater_than:positive_chi2_params_is_a_tuple] SKIPPED [ 66%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_parameterized_distribution_ks_test_p_value_to_be_greater_than:negative_chi2_params_is_a_dict] SKIPPED [ 66%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_parameterized_distribution_ks_test_p_value_to_be_greater_than:negative_chi2_params_is_a_tuple] SKIPPED [ 66%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_parameterized_distribution_ks_test_p_value_to_be_greater_than:positive_expon_distribution_params_is_a_dict] SKIPPED [ 66%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_parameterized_distribution_ks_test_p_value_to_be_greater_than:positive_expon_distribution_params_is_a_tuple] SKIPPED [ 66%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_parameterized_distribution_ks_test_p_value_to_be_greater_than:negative_expon_distribution_params_is_a_dict] SKIPPED [ 66%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_parameterized_distribution_ks_test_p_value_to_be_greater_than:negative_expon_distribution_params_is_a_tuple] SKIPPED [ 66%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:discrete_baseline_categorical_fixed_partition] PASSED [ 66%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:discrete_categorical_fixed_alternate_partition] PASSED [ 66%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:internal_holdout_with_categorical_partition] PASSED [ 67%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:holdout_0_1] PASSED [ 67%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:holdout_0_05] PASSED [ 67%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:missing_vals_no_holdout] PASSED [ 67%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:norm_0_1_auto_explicit_infinite_endpoints] PASSED [ 67%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:norm_0_1_auto_inf_partition_test_tail_weights] PASSED [ 67%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:norm_0_1_auto_inf_partition_should_fail_with_no_holdout] PASSED [ 67%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:norm_0_1_auto_inf_partition_null_threshold_should_always_succeed] PASSED [ 67%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:norm_0_1_auto_inf_partition_null_threshold_and_partition_object_supports_profiling] PASSED [ 67%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:norm_0_1_auto_inf_partition_tail_weights_should_fail_with_no_internal_holdout] PASSED [ 67%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:positive_norm_0_1_auto_partition] PASSED [ 67%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:positive_norm_0_1_uniform_partition] PASSED [ 68%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:positive_norm_0_1_ntile_partition] PASSED [ 68%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:positive_norm_0_1_kde_partition] PASSED [ 68%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:negative_norm_1_1_column_norm_0_1_auto_partition] PASSED [ 68%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:negative_norm_1_1_column_norm_0_1_uniform_partition] PASSED [ 68%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:negative_norm_1_1_column_norm_0_1_ntile_partition] PASSED [ 68%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:negative_norm_1_1_column_norm_0_1_kde_partition] PASSED [ 68%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:positive_bimodal_auto_partition] PASSED [ 68%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:negative_bimodal_column_norm_0_1_auto_partition] PASSED [ 68%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:negative_bimodal_column_norm_0_1_uniform_partition] PASSED [ 68%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_lower_inf_bound] PASSED [ 68%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_lower_inf_bound_tail_weights] PASSED [ 69%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_upper_inf_bound] PASSED [ 69%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_upper_inf_bound_tail_weights] PASSED [ 69%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_lower_and_upper_inf_bounds0] PASSED [ 69%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_lower_and_upper_inf_bounds1] PASSED [ 69%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:tail_weight_holdout_is_not_defined_for_partitions_already_extending_to_inifinity] PASSED [ 69%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:tail_weight_holdout_is_not_defined_for_partitions_already_extending_to_inifinity_tail_weight] PASSED [ 69%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:empty_partition] PASSED [ 69%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:too_big_tail_weight] PASSED [ 69%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:too_big_internal_weight] PASSED [ 69%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_undefined_infinite_kl_divergence0] PASSED [ 69%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_undefined_infinite_kl_divergence1] PASSED [ 70%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_undefined_infinite_kl_divergence_bins_do_not_cover_all_data] PASSED [ 70%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_return_partitions_should_have_tail_weights] PASSED [ 70%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_tail_weights_return_partitions_should_have_tail_weights] PASSED [ 70%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_bounded_endpoints_empty_tail_weights_in_return] PASSED [ 70%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_bounded_endpoints_observed_with_tail_weight_infinite_kl_divergence] PASSED [ 70%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_infinite_endpoints_non_zero_tail_hold_out] PASSED [ 70%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_upper_infinite_endpoint_non_zero_tail_hold_out] PASSED [ 70%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_lower_infinite_endpoint_non_zero_tail_hold_out] PASSED [ 70%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_bounded_endpoints_non_zero_tail_hold_out] PASSED [ 70%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_bootstrapped_ks_test_p_value_to_be_greater_than:positive_norm_0_1_auto_partition] SKIPPED [ 70%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_bootstrapped_ks_test_p_value_to_be_greater_than:positive_norm_0_1_uniform_partition] SKIPPED [ 71%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_bootstrapped_ks_test_p_value_to_be_greater_than:positive_norm_0_1_ntile_partition] SKIPPED [ 71%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_bootstrapped_ks_test_p_value_to_be_greater_than:positive_norm_0_1_kde_partition] SKIPPED [ 71%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_bootstrapped_ks_test_p_value_to_be_greater_than:negative_norm_0_1_auto_partition_norm_1_1_column] SKIPPED [ 71%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_bootstrapped_ks_test_p_value_to_be_greater_than:negative_norm_0_1_uniform_partition_norm_1_1_column] SKIPPED [ 71%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_bootstrapped_ks_test_p_value_to_be_greater_than:negative_norm_0_1_ntile_partition_norm_1_1_column] SKIPPED [ 71%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_bootstrapped_ks_test_p_value_to_be_greater_than:negative_norm_0_1_kde_partition_norm_1_1_column] SKIPPED [ 71%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_bootstrapped_ks_test_p_value_to_be_greater_than:positive_bimodal_auto_partition] SKIPPED [ 71%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_bootstrapped_ks_test_p_value_to_be_greater_than:positive_bimodal_kde_partition] SKIPPED [ 71%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_bootstrapped_ks_test_p_value_to_be_greater_than:negative_norm_0_1_auto_partition_bimodal_column] SKIPPED [ 71%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_bootstrapped_ks_test_p_value_to_be_greater_than:negative_norm_0_1_uniform_partition_bimodal_column] SKIPPED [ 71%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_bootstrapped_ks_test_p_value_to_be_greater_than:negative_norm_0_1_uniform_partition_detail] SKIPPED [ 72%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_bootstrapped_ks_test_p_value_to_be_greater_than:observed_above_and_below_partition] SKIPPED [ 72%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_bootstrapped_ks_test_p_value_to_be_greater_than:expected_extends_above_partition] SKIPPED [ 72%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_bootstrapped_ks_test_p_value_to_be_greater_than:partition_extends_above_data] SKIPPED [ 72%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_bootstrapped_ks_test_p_value_to_be_greater_than:partition_above_and_below_observed] SKIPPED [ 72%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_bootstrapped_ks_test_p_value_to_be_greater_than:bad_partition_infinite_endpoints_raise_error] SKIPPED [ 72%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_bootstrapped_ks_test_p_value_to_be_greater_than:bad_partition_tail_weights_raise_error] SKIPPED [ 72%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_bootstrapped_ks_test_p_value_to_be_greater_than:bad_partition_categorical_raise_error] SKIPPED [ 72%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_chisquare_test_p_value_to_be_greater_than:categorical_fixed_partition_object] SKIPPED [ 72%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_chisquare_test_p_value_to_be_greater_than:categorical_fixed_alternate_partition_object] SKIPPED [ 72%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_chisquare_test_p_value_to_be_greater_than:categorical_fixed_alternate_partition_object_exact_match] SKIPPED [ 72%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_chisquare_test_p_value_to_be_greater_than:categorical_fixed_alternate_new_categorical_vals_no_holdout] SKIPPED [ 73%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_chisquare_test_p_value_to_be_greater_than:categorical_fixed_alternate_new_categorical_vals_holdout] SKIPPED [ 73%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_chisquare_test_p_value_to_be_greater_than:categorical_fixed_missing_categorical_vals_no_holdout] SKIPPED [ 73%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_chisquare_test_p_value_to_be_greater_than:continuous_partition_should_fail] SKIPPED [ 73%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_parameterized_distribution_ks_test_p_value_to_be_greater_than:positive_standard_norm_distribution] SKIPPED [ 73%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_parameterized_distribution_ks_test_p_value_to_be_greater_than:negative_standard_norm_distribution] SKIPPED [ 73%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_parameterized_distribution_ks_test_p_value_to_be_greater_than:positive_beta_distribution_params_is_a_dict] SKIPPED [ 73%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_parameterized_distribution_ks_test_p_value_to_be_greater_than:positive_beta_distribution_params_is_a_tuple] SKIPPED [ 73%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_parameterized_distribution_ks_test_p_value_to_be_greater_than:negative_beta_distribution_params_is_a_dict] SKIPPED [ 73%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_parameterized_distribution_ks_test_p_value_to_be_greater_than:negative_beta_distribution_params_is_a_tuple] SKIPPED [ 73%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_parameterized_distribution_ks_test_p_value_to_be_greater_than:positive_gamma_distribution_params_is_a_dict] SKIPPED [ 73%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_parameterized_distribution_ks_test_p_value_to_be_greater_than:positive_gamma_distribution_params_is_a_tuple] SKIPPED [ 74%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_parameterized_distribution_ks_test_p_value_to_be_greater_than:negative_gamma_distribution_params_is_a_dict] SKIPPED [ 74%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_parameterized_distribution_ks_test_p_value_to_be_greater_than:negative_gamma_distribution_params_is_a_tuple] SKIPPED [ 74%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_parameterized_distribution_ks_test_p_value_to_be_greater_than:positive_uniform_distribution_params_is_a_dict] SKIPPED [ 74%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_parameterized_distribution_ks_test_p_value_to_be_greater_than:positive_uniform_distribution_params_is_a_tuple] SKIPPED [ 74%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_parameterized_distribution_ks_test_p_value_to_be_greater_than:negative_uniform_distribution_params_is_a_dict] SKIPPED [ 74%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_parameterized_distribution_ks_test_p_value_to_be_greater_than:negative_uniform_distribution_params_is_a_tuple] SKIPPED [ 74%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_parameterized_distribution_ks_test_p_value_to_be_greater_than:positive_chi2_params_is_a_dict] SKIPPED [ 74%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_parameterized_distribution_ks_test_p_value_to_be_greater_than:positive_chi2_params_is_a_tuple] SKIPPED [ 74%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_parameterized_distribution_ks_test_p_value_to_be_greater_than:negative_chi2_params_is_a_dict] SKIPPED [ 74%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_parameterized_distribution_ks_test_p_value_to_be_greater_than:negative_chi2_params_is_a_tuple] SKIPPED [ 74%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_parameterized_distribution_ks_test_p_value_to_be_greater_than:positive_expon_distribution_params_is_a_dict] SKIPPED [ 75%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_parameterized_distribution_ks_test_p_value_to_be_greater_than:positive_expon_distribution_params_is_a_tuple] SKIPPED [ 75%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_parameterized_distribution_ks_test_p_value_to_be_greater_than:negative_expon_distribution_params_is_a_dict] SKIPPED [ 75%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_parameterized_distribution_ks_test_p_value_to_be_greater_than:negative_expon_distribution_params_is_a_tuple] SKIPPED [ 75%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:discrete_baseline_categorical_fixed_partition] PASSED [ 75%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:discrete_categorical_fixed_alternate_partition] PASSED [ 75%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:internal_holdout_with_categorical_partition] PASSED [ 75%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:holdout_0_1] PASSED [ 75%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:holdout_0_05] PASSED [ 75%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:missing_vals_no_holdout] PASSED [ 75%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:norm_0_1_auto_explicit_infinite_endpoints] PASSED [ 75%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:norm_0_1_auto_inf_partition_test_tail_weights] PASSED [ 76%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:norm_0_1_auto_inf_partition_should_fail_with_no_holdout] PASSED [ 76%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:norm_0_1_auto_inf_partition_null_threshold_should_always_succeed] PASSED [ 76%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:norm_0_1_auto_inf_partition_null_threshold_and_partition_object_supports_profiling] SKIPPED [ 76%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:norm_0_1_auto_inf_partition_tail_weights_should_fail_with_no_internal_holdout] PASSED [ 76%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:positive_norm_0_1_auto_partition] PASSED [ 76%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:positive_norm_0_1_uniform_partition] PASSED [ 76%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:positive_norm_0_1_ntile_partition] PASSED [ 76%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:positive_norm_0_1_kde_partition] PASSED [ 76%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:negative_norm_1_1_column_norm_0_1_auto_partition] PASSED [ 76%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:negative_norm_1_1_column_norm_0_1_uniform_partition] PASSED [ 76%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:negative_norm_1_1_column_norm_0_1_ntile_partition] PASSED [ 77%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:negative_norm_1_1_column_norm_0_1_kde_partition] PASSED [ 77%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:positive_bimodal_auto_partition] PASSED [ 77%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:negative_bimodal_column_norm_0_1_auto_partition] PASSED [ 77%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:negative_bimodal_column_norm_0_1_uniform_partition] PASSED [ 77%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_lower_inf_bound] PASSED [ 77%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_lower_inf_bound_tail_weights] PASSED [ 77%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_upper_inf_bound] PASSED [ 77%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_upper_inf_bound_tail_weights] PASSED [ 77%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_lower_and_upper_inf_bounds0] PASSED [ 77%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_lower_and_upper_inf_bounds1] PASSED [ 77%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:tail_weight_holdout_is_not_defined_for_partitions_already_extending_to_inifinity] PASSED [ 78%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:tail_weight_holdout_is_not_defined_for_partitions_already_extending_to_inifinity_tail_weight] PASSED [ 78%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:empty_partition] PASSED [ 78%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:too_big_tail_weight] PASSED [ 78%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:too_big_internal_weight] PASSED [ 78%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_undefined_infinite_kl_divergence0] PASSED [ 78%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_undefined_infinite_kl_divergence1] PASSED [ 78%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_undefined_infinite_kl_divergence_bins_do_not_cover_all_data] PASSED [ 78%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_return_partitions_should_have_tail_weights] PASSED [ 78%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_tail_weights_return_partitions_should_have_tail_weights] PASSED [ 78%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_bounded_endpoints_empty_tail_weights_in_return] PASSED [ 78%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_bounded_endpoints_observed_with_tail_weight_infinite_kl_divergence] PASSED [ 79%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_infinite_endpoints_non_zero_tail_hold_out] PASSED [ 79%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_upper_infinite_endpoint_non_zero_tail_hold_out] PASSED [ 79%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_lower_infinite_endpoint_non_zero_tail_hold_out] PASSED [ 79%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_bounded_endpoints_non_zero_tail_hold_out] PASSED [ 79%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_bootstrapped_ks_test_p_value_to_be_greater_than:positive_norm_0_1_auto_partition] SKIPPED [ 79%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_bootstrapped_ks_test_p_value_to_be_greater_than:positive_norm_0_1_uniform_partition] SKIPPED [ 79%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_bootstrapped_ks_test_p_value_to_be_greater_than:positive_norm_0_1_ntile_partition] SKIPPED [ 79%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_bootstrapped_ks_test_p_value_to_be_greater_than:positive_norm_0_1_kde_partition] SKIPPED [ 79%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_bootstrapped_ks_test_p_value_to_be_greater_than:negative_norm_0_1_auto_partition_norm_1_1_column] SKIPPED [ 79%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_bootstrapped_ks_test_p_value_to_be_greater_than:negative_norm_0_1_uniform_partition_norm_1_1_column] SKIPPED [ 79%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_bootstrapped_ks_test_p_value_to_be_greater_than:negative_norm_0_1_ntile_partition_norm_1_1_column] SKIPPED [ 80%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_bootstrapped_ks_test_p_value_to_be_greater_than:negative_norm_0_1_kde_partition_norm_1_1_column] SKIPPED [ 80%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_bootstrapped_ks_test_p_value_to_be_greater_than:positive_bimodal_auto_partition] SKIPPED [ 80%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_bootstrapped_ks_test_p_value_to_be_greater_than:positive_bimodal_kde_partition] SKIPPED [ 80%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_bootstrapped_ks_test_p_value_to_be_greater_than:negative_norm_0_1_auto_partition_bimodal_column] SKIPPED [ 80%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_bootstrapped_ks_test_p_value_to_be_greater_than:negative_norm_0_1_uniform_partition_bimodal_column] SKIPPED [ 80%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_bootstrapped_ks_test_p_value_to_be_greater_than:negative_norm_0_1_uniform_partition_detail] SKIPPED [ 80%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_bootstrapped_ks_test_p_value_to_be_greater_than:observed_above_and_below_partition] SKIPPED [ 80%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_bootstrapped_ks_test_p_value_to_be_greater_than:expected_extends_above_partition] SKIPPED [ 80%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_bootstrapped_ks_test_p_value_to_be_greater_than:partition_extends_above_data] SKIPPED [ 80%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_bootstrapped_ks_test_p_value_to_be_greater_than:partition_above_and_below_observed] SKIPPED [ 80%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_bootstrapped_ks_test_p_value_to_be_greater_than:bad_partition_infinite_endpoints_raise_error] SKIPPED [ 81%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_bootstrapped_ks_test_p_value_to_be_greater_than:bad_partition_tail_weights_raise_error] SKIPPED [ 81%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_bootstrapped_ks_test_p_value_to_be_greater_than:bad_partition_categorical_raise_error] SKIPPED [ 81%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_chisquare_test_p_value_to_be_greater_than:categorical_fixed_partition_object] SKIPPED [ 81%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_chisquare_test_p_value_to_be_greater_than:categorical_fixed_alternate_partition_object] SKIPPED [ 81%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_chisquare_test_p_value_to_be_greater_than:categorical_fixed_alternate_partition_object_exact_match] SKIPPED [ 81%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_chisquare_test_p_value_to_be_greater_than:categorical_fixed_alternate_new_categorical_vals_no_holdout] SKIPPED [ 81%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_chisquare_test_p_value_to_be_greater_than:categorical_fixed_alternate_new_categorical_vals_holdout] SKIPPED [ 81%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_chisquare_test_p_value_to_be_greater_than:categorical_fixed_missing_categorical_vals_no_holdout] SKIPPED [ 81%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_chisquare_test_p_value_to_be_greater_than:continuous_partition_should_fail] SKIPPED [ 81%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_row_count_to_equal:basic_positive_case] PASSED [ 81%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_row_count_to_equal:basic_negative_case_upper_error] PASSED [ 82%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_row_count_to_equal:basic_negative_case_lower_error] PASSED [ 82%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_row_count_to_equal:basic_negative_case_kwargs_args] PASSED [ 82%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_row_count_to_equal:invalid_arguments_throws_exception] PASSED [ 82%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_column_to_exist:basic_positive_test] PASSED [ 82%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_column_to_exist:basic_negative_test] PASSED [ 82%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_column_to_exist:positive_test_with_column_order] PASSED [ 82%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_column_to_exist:column_exists_but_wrong_index] PASSED [ 82%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_column_to_exist:this_test_should_never_run] SKIPPED [ 82%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_row_count_to_be_between:basic_positive_test] PASSED [ 82%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_row_count_to_be_between:vacuously_true] PASSED [ 82%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_row_count_to_be_between:basic_negative_test] PASSED [ 83%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_row_count_to_be_between:positive_test_with_null_min_value] PASSED [ 83%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_row_count_to_be_between:test_error_handling_for_min_greater_than_max] PASSED [ 83%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_row_count_to_be_between:positive_test_with_null_min] PASSED [ 83%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_row_count_to_be_between:test_error_handling_for_non_int_min_value] PASSED [ 83%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_row_count_to_be_between:test_error_handling_for_non_int_max_value] PASSED [ 83%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_columns_to_match_ordered_list:basic_positive_test] PASSED [ 83%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_columns_to_match_ordered_list:negative_test_column_is_missing] PASSED [ 83%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_columns_to_match_ordered_list:negative_test_column_is_misnamed] PASSED [ 83%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_columns_to_match_ordered_list:negative_test_columns_are_right_but_ordering_wrong] PASSED [ 83%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_columns_to_match_ordered_list:negative_test_extra_column] PASSED [ 83%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_columns_to_match_ordered_list:null_list_provides_vacuously_true_expectation] PASSED [ 83%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_column_count_to_be_between:basic_positive_test] PASSED [ 84%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_column_count_to_be_between:vacuously_true] PASSED [ 84%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_column_count_to_be_between:basic_negative_test] PASSED [ 84%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_column_count_to_be_between:positive_test_with_null_min_value] PASSED [ 84%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_column_count_to_be_between:test_error_handling_for_max_lt_min] PASSED [ 84%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_column_count_to_be_between:positive_test_with_null_min] PASSED [ 84%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_column_count_to_be_between:test_error_handling_for_non_int_min_value] PASSED [ 84%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_column_count_to_be_between:test_error_handling_for_non_int_max_value] PASSED [ 84%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_columns_to_match_set:basic_positive_test_exact_match_true] PASSED [ 84%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_columns_to_match_set:basic_positive_test_exact_match_false] PASSED [ 84%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_columns_to_match_set:negative_test_column_is_missing_exact_match_true] PASSED [ 84%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_columns_to_match_set:positive_test_column_is_missing_exact_match_false] PASSED [ 85%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_columns_to_match_set:negative_test_column_is_misnamed_exact_match_true] PASSED [ 85%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_columns_to_match_set:negative_test_column_is_misnamed_exact_match_false] PASSED [ 85%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_columns_to_match_set:positive_test_columns_are_right_but_ordering_wrong_exact_match_true] PASSED [ 85%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_columns_to_match_set:positive_test_columns_are_right_but_ordering_wrong_exact_match_false] PASSED [ 85%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_columns_to_match_set:negative_test_extra_column_exact_match_true] PASSED [ 85%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_columns_to_match_set:negative_test_extra_column_exact_match_false] PASSED [ 85%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_columns_to_match_set:negative_test_null_set_exact_match_true] PASSED [ 85%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_columns_to_match_set:positive_test_vacuously_true_null_set_exact_match_false] PASSED [ 85%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_column_count_to_equal:basic_positive_case] PASSED [ 85%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_column_count_to_equal:basic_negative_case_upper_error] PASSED [ 85%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_column_count_to_equal:basic_negative_case_lower_error] PASSED [ 86%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_column_count_to_equal:basic_negative_case_kwargs_args] PASSED [ 86%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_column_count_to_equal:invalid_arguments_throws_exception] PASSED [ 86%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_row_count_to_equal:basic_positive_case] PASSED [ 86%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_row_count_to_equal:basic_negative_case_upper_error] PASSED [ 86%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_row_count_to_equal:basic_negative_case_lower_error] PASSED [ 86%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_row_count_to_equal:basic_negative_case_kwargs_args] PASSED [ 86%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_row_count_to_equal:invalid_arguments_throws_exception] PASSED [ 86%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_column_to_exist:basic_positive_test] PASSED [ 86%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_column_to_exist:basic_negative_test] PASSED [ 86%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_column_to_exist:positive_test_with_column_order] PASSED [ 86%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_column_to_exist:column_exists_but_wrong_index] PASSED [ 87%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_column_to_exist:this_test_should_never_run] SKIPPED [ 87%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_row_count_to_be_between:basic_positive_test] PASSED [ 87%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_row_count_to_be_between:vacuously_true] PASSED [ 87%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_row_count_to_be_between:basic_negative_test] PASSED [ 87%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_row_count_to_be_between:positive_test_with_null_min_value] PASSED [ 87%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_row_count_to_be_between:test_error_handling_for_min_greater_than_max] PASSED [ 87%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_row_count_to_be_between:positive_test_with_null_min] PASSED [ 87%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_row_count_to_be_between:test_error_handling_for_non_int_min_value] PASSED [ 87%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_row_count_to_be_between:test_error_handling_for_non_int_max_value] PASSED [ 87%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_columns_to_match_ordered_list:basic_positive_test] PASSED [ 87%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_columns_to_match_ordered_list:negative_test_column_is_missing] PASSED [ 88%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_columns_to_match_ordered_list:negative_test_column_is_misnamed] PASSED [ 88%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_columns_to_match_ordered_list:negative_test_columns_are_right_but_ordering_wrong] PASSED [ 88%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_columns_to_match_ordered_list:negative_test_extra_column] PASSED [ 88%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_columns_to_match_ordered_list:null_list_provides_vacuously_true_expectation] PASSED [ 88%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_column_count_to_be_between:basic_positive_test] PASSED [ 88%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_column_count_to_be_between:vacuously_true] PASSED [ 88%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_column_count_to_be_between:basic_negative_test] PASSED [ 88%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_column_count_to_be_between:positive_test_with_null_min_value] PASSED [ 88%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_column_count_to_be_between:test_error_handling_for_max_lt_min] PASSED [ 88%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_column_count_to_be_between:positive_test_with_null_min] PASSED [ 88%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_column_count_to_be_between:test_error_handling_for_non_int_min_value] PASSED [ 89%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_column_count_to_be_between:test_error_handling_for_non_int_max_value] PASSED [ 89%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_columns_to_match_set:basic_positive_test_exact_match_true] PASSED [ 89%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_columns_to_match_set:basic_positive_test_exact_match_false] PASSED [ 89%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_columns_to_match_set:negative_test_column_is_missing_exact_match_true] PASSED [ 89%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_columns_to_match_set:positive_test_column_is_missing_exact_match_false] PASSED [ 89%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_columns_to_match_set:negative_test_column_is_misnamed_exact_match_true] PASSED [ 89%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_columns_to_match_set:negative_test_column_is_misnamed_exact_match_false] PASSED [ 89%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_columns_to_match_set:positive_test_columns_are_right_but_ordering_wrong_exact_match_true] PASSED [ 89%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_columns_to_match_set:positive_test_columns_are_right_but_ordering_wrong_exact_match_false] PASSED [ 89%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_columns_to_match_set:negative_test_extra_column_exact_match_true] PASSED [ 89%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_columns_to_match_set:negative_test_extra_column_exact_match_false] PASSED [ 90%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_columns_to_match_set:negative_test_null_set_exact_match_true] PASSED [ 90%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_columns_to_match_set:positive_test_vacuously_true_null_set_exact_match_false] PASSED [ 90%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_column_count_to_equal:basic_positive_case] PASSED [ 90%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_column_count_to_equal:basic_negative_case_upper_error] PASSED [ 90%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_column_count_to_equal:basic_negative_case_lower_error] PASSED [ 90%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_column_count_to_equal:basic_negative_case_kwargs_args] PASSED [ 90%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_column_count_to_equal:invalid_arguments_throws_exception] PASSED [ 90%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_compound_columns_to_be_unique:mostly_default_successful_expectation] PASSED [ 90%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_compound_columns_to_be_unique:mostly_default_fails_expectation] PASSED [ 90%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_compound_columns_to_be_unique:mostly_set_successful_expectation] PASSED [ 90%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_compound_columns_to_be_unique:mostly_set_fails_expectation] PASSED [ 91%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_compound_columns_to_be_unique:mostly_set_incorrectly] PASSED [ 91%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_compound_columns_to_be_unique:basic_test_ignore_if_all_are_missing_the_default_behavior] PASSED [ 91%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_compound_columns_to_be_unique:basic_test_ignore_if_any_are_missing] PASSED [ 91%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_compound_columns_to_be_unique:row_condition_with_ignore_if_any_are_missing] PASSED [ 91%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_compound_columns_to_be_unique:unexpected_values_with_unexpected_index_list] PASSED [ 91%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_compound_columns_to_be_unique:unexpected_values_without_unexpected_index_list] PASSED [ 91%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_compound_columns_to_be_unique:unexpected_values_exact_match_out_without_unexpected_index_list] PASSED [ 91%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_select_column_values_to_be_unique_within_record:mostly_default_successful_expectation] PASSED [ 91%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_select_column_values_to_be_unique_within_record:mostly_default_fails_expectation] PASSED [ 91%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_select_column_values_to_be_unique_within_record:mostly_set_successful_expectation] PASSED [ 91%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_select_column_values_to_be_unique_within_record:mostly_set_fails_expectation] PASSED [ 92%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_select_column_values_to_be_unique_within_record:mostly_set_incorrectly] PASSED [ 92%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_select_column_values_to_be_unique_within_record:basic_test_ignore_if_all_are_missing_the_default_behavior] PASSED [ 92%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_select_column_values_to_be_unique_within_record:basic_test_ignore_if_any_are_missing] PASSED [ 92%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_select_column_values_to_be_unique_within_record:unexpected_values] PASSED [ 92%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_select_column_values_to_be_unique_within_record:unexpected_values_exact_match_out_no_index_list] SKIPPED [ 92%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_select_column_values_to_be_unique_within_record:unexpected_values_exact_match_out_without_unexpected_index_list] PASSED [ 92%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_multicolumn_sum_to_equal:mostly_default_successful_expectation] PASSED [ 92%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_multicolumn_sum_to_equal:mostly_default_fails_expectation] PASSED [ 92%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_multicolumn_sum_to_equal:mostly_set_successful_expectation] PASSED [ 92%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_multicolumn_sum_to_equal:mostly_set_fails_expectation] PASSED [ 92%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_multicolumn_sum_to_equal:mostly_set_incorrectly] PASSED [ 93%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_multicolumn_sum_to_equal:basic_positive_test] PASSED [ 93%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_multicolumn_sum_to_equal:basic_positive_test_more_than_2_columns] PASSED [ 93%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_multicolumn_sum_to_equal:row_condition_with_ignore_if_any_are_missing] PASSED [ 93%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_multicolumn_sum_to_equal:basic_negative_test] PASSED [ 93%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_multicolumn_sum_to_equal:negative_test_with_ignore_if_any_are_missing] PASSED [ 93%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_multicolumn_sum_to_equal:negative_test_different_value] PASSED [ 93%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_compound_columns_to_be_unique:mostly_default_successful_expectation] FAILED [ 93%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_compound_columns_to_be_unique:mostly_default_fails_expectation] FAILED [ 93%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_compound_columns_to_be_unique:mostly_set_successful_expectation] FAILED [ 93%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_compound_columns_to_be_unique:mostly_set_fails_expectation] FAILED [ 93%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_compound_columns_to_be_unique:mostly_set_incorrectly] PASSED [ 94%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_compound_columns_to_be_unique:basic_test_ignore_if_all_are_missing_the_default_behavior] FAILED [ 94%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_compound_columns_to_be_unique:basic_test_ignore_if_any_are_missing] FAILED [ 94%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_compound_columns_to_be_unique:unexpected_values_without_unexpected_index_list] FAILED [ 94%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_compound_columns_to_be_unique:unexpected_values_exact_match_out_with_unexpected_index_list_pandas_v3] FAILED [ 94%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_compound_columns_to_be_unique:unexpected_values_exact_match_out_without_unexpected_index_list] FAILED [ 94%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_select_column_values_to_be_unique_within_record:mostly_default_successful_expectation] PASSED [ 94%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_select_column_values_to_be_unique_within_record:mostly_default_fails_expectation] PASSED [ 94%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_select_column_values_to_be_unique_within_record:mostly_set_successful_expectation] PASSED [ 94%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_select_column_values_to_be_unique_within_record:mostly_set_fails_expectation] PASSED [ 94%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_select_column_values_to_be_unique_within_record:mostly_set_incorrectly] PASSED [ 94%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_select_column_values_to_be_unique_within_record:basic_test_ignore_if_all_are_missing_the_default_behavior] PASSED [ 95%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_select_column_values_to_be_unique_within_record:basic_test_ignore_if_any_are_missing] PASSED [ 95%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_select_column_values_to_be_unique_within_record:unexpected_values] PASSED [ 95%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_select_column_values_to_be_unique_within_record:unexpected_values_exact_match_out_with_index_list_pandas_v3_api] PASSED [ 95%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_select_column_values_to_be_unique_within_record:unexpected_values_exact_match_out_no_index_list] PASSED [ 95%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_select_column_values_to_be_unique_within_record:unexpected_values_exact_match_out_without_unexpected_index_list] PASSED [ 95%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_multicolumn_sum_to_equal:mostly_default_successful_expectation] PASSED [ 95%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_multicolumn_sum_to_equal:mostly_default_fails_expectation] PASSED [ 95%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_multicolumn_sum_to_equal:mostly_set_successful_expectation] PASSED [ 95%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_multicolumn_sum_to_equal:mostly_set_fails_expectation] PASSED [ 95%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_multicolumn_sum_to_equal:mostly_set_incorrectly] PASSED [ 95%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_multicolumn_sum_to_equal:basic_positive_test] PASSED [ 96%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_multicolumn_sum_to_equal:basic_positive_test_more_than_2_columns] PASSED [ 96%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_multicolumn_sum_to_equal:basic_negative_test] PASSED [ 96%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_multicolumn_sum_to_equal:negative_test_with_ignore_if_any_are_missing] PASSED [ 96%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_multicolumn_sum_to_equal:negative_test_different_value] PASSED [ 96%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_pair_map_expectations/expect_column_pair_values_to_be_equal:trivial_case:_x__x] PASSED [ 96%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_pair_map_expectations/expect_column_pair_values_to_be_equal:basic_negative_example_compare_number_to_text] PASSED [ 96%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_pair_map_expectations/expect_column_pair_values_to_be_equal:basic_negative_example_compare_numbers] PASSED [ 96%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_pair_map_expectations/expect_column_pair_values_to_be_equal:positive_example_with_mostly_compare_number_to_text] PASSED [ 96%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_pair_map_expectations/expect_column_pair_values_to_be_equal:positive_example_with_mostly_compare_numbers] PASSED [ 96%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_pair_map_expectations/expect_column_pair_values_to_be_equal:positive_example_with_mismatched_null_values_and_ignore_row_if__either_value_is_missing_compare_number_to_text] PASSED [ 96%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_pair_map_expectations/expect_column_pair_values_to_be_equal:positive_example_with_mismatched_null_values_and_ignore_row_if__either_value_is_missing_compare_numbers] PASSED [ 97%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_pair_map_expectations/expect_column_pair_values_to_be_equal:a_negative_example_with_mismatched_null_values_and_ignore_row_if__both_values_are_missing_set_explicitly] PASSED [ 97%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_pair_map_expectations/expect_column_pair_values_to_be_equal:a_negative_example_with_mismatched_null_values_and_ignore_row_if__both_values_are_missing_set_by_default] PASSED [ 97%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_pair_map_expectations/expect_column_pair_values_to_be_equal:a_negative_example] PASSED [ 97%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_pair_map_expectations/expect_column_pair_values_to_be_equal:a_positive_example_with_mostly] PASSED [ 97%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_pair_map_expectations/expect_column_pair_values_to_be_equal:a_positive_example_with_ignore_row_if__either_value_is_missing] PASSED [ 97%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_pair_map_expectations/expect_column_pair_values_to_be_in_set:basic_positive_test_without_nulls] PASSED [ 97%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_pair_map_expectations/expect_column_pair_values_to_be_in_set:positive_test_with_nulls_and_ignore_row_if_either_value_is_missing] PASSED [ 97%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_pair_map_expectations/expect_column_pair_values_to_be_in_set:negative_test_with_nulls] PASSED [ 97%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_pair_map_expectations/expect_column_pair_values_to_be_in_set:another_positive_test_with_nulls] PASSED [ 97%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_pair_map_expectations/expect_column_pair_values_A_to_be_greater_than_B:basic_positive_test] PASSED [ 97%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_pair_map_expectations/expect_column_pair_values_A_to_be_greater_than_B:basic_positive_test_with_missing_values_and_ignore_row_if__either_value_is_missing] PASSED [ 98%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_pair_map_expectations/expect_column_pair_values_A_to_be_greater_than_B:test_ties] PASSED [ 98%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_pair_map_expectations/expect_column_pair_values_A_to_be_greater_than_B:test_ties_with_or_equal] PASSED [ 98%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_pair_map_expectations/expect_column_pair_values_A_to_be_greater_than_B:test_parse_strings_as_datetimes_and_mostly] PASSED [ 98%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_pair_map_expectations/expect_column_pair_values_A_to_be_greater_than_B:test_mostly] PASSED [ 98%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_pair_map_expectations/expect_column_pair_values_to_be_equal:trivial_case:_x__x] PASSED [ 98%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_pair_map_expectations/expect_column_pair_values_to_be_equal:basic_negative_example_compare_numbers] PASSED [ 98%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_pair_map_expectations/expect_column_pair_values_to_be_equal:positive_example_with_mostly_compare_numbers] PASSED [ 98%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_pair_map_expectations/expect_column_pair_values_to_be_equal:positive_example_with_mismatched_null_values_and_ignore_row_if__either_value_is_missing_compare_numbers] PASSED [ 98%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_pair_map_expectations/expect_column_pair_values_to_be_equal:a_negative_example_with_mismatched_null_values_and_ignore_row_if__both_values_are_missing_set_explicitly] PASSED [ 98%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_pair_map_expectations/expect_column_pair_values_to_be_equal:a_negative_example_with_mismatched_null_values_and_ignore_row_if__both_values_are_missing_set_by_default] PASSED [ 98%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_pair_map_expectations/expect_column_pair_values_to_be_equal:a_negative_example] PASSED [ 99%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_pair_map_expectations/expect_column_pair_values_to_be_equal:a_positive_example_with_mostly] PASSED [ 99%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_pair_map_expectations/expect_column_pair_values_to_be_equal:a_positive_example_with_ignore_row_if__either_value_is_missing] PASSED [ 99%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_pair_map_expectations/expect_column_pair_values_to_be_in_set:basic_positive_test_without_nulls] PASSED [ 99%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_pair_map_expectations/expect_column_pair_values_to_be_in_set:positive_test_with_nulls_and_ignore_row_if_either_value_is_missing] PASSED [ 99%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_pair_map_expectations/expect_column_pair_values_to_be_in_set:negative_test_with_nulls] PASSED [ 99%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_pair_map_expectations/expect_column_pair_values_to_be_in_set:another_positive_test_with_nulls] PASSED [ 99%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_pair_map_expectations/expect_column_pair_values_A_to_be_greater_than_B:basic_positive_test] PASSED [ 99%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_pair_map_expectations/expect_column_pair_values_A_to_be_greater_than_B:basic_positive_test_with_missing_values_and_ignore_row_if__either_value_is_missing] PASSED [ 99%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_pair_map_expectations/expect_column_pair_values_A_to_be_greater_than_B:test_ties] PASSED [ 99%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_pair_map_expectations/expect_column_pair_values_A_to_be_greater_than_B:test_ties_with_or_equal] PASSED [ 99%]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_pair_map_expectations/expect_column_pair_values_A_to_be_greater_than_B:test_mostly] PASSED [100%]

=================================== FAILURES ===================================
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:basic_negative_now_test] _

test_case = {'expectation_type': 'expect_column_values_to_be_between', 'pk_column': True, 'skip': False, 'test': {'exact_match_out...ER': 'now()'}}, 'include_in_gallery': True, 'input': {'column': 'ts', 'min_value': {'$PARAMETER': 'now()'}}, ...}, ...}

    @pytest.mark.order(index=0)
    @pytest.mark.integration
    @pytest.mark.slow  # 12.68s
    def test_case_runner_v3_api(test_case):
        if test_case["skip"]:
            pytest.skip()

        # Note: this should never be done in practice, but we are wiping expectations to reuse batches during testing.
        # test_case["batch"]._initialize_expectations()
        if "parse_strings_as_datetimes" in test_case["test"]["in"]:
            with pytest.deprecated_call():
                evaluate_json_test_v3_api(
                    validator=test_case["validator_with_data"],
                    expectation_type=test_case["expectation_type"],
                    test=test_case["test"],
                    pk_column=test_case["pk_column"],
                )
        else:
>           evaluate_json_test_v3_api(
                validator=test_case["validator_with_data"],
                expectation_type=test_case["expectation_type"],
                test=test_case["test"],
                pk_column=test_case["pk_column"],
            )

tests/test_definitions/test_expectations_v3_api.py:428:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
great_expectations/self_check/util.py:2900: in evaluate_json_test_v3_api
    check_json_test_result(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

test = {'exact_match_out': False, 'in': {'column': 'ts', 'min_value': {'$PARAMETER': 'now()'}}, 'include_in_gallery': True, 'input': {'column': 'ts', 'min_value': {'$PARAMETER': 'now()'}}, ...}
result = {'exception_info': {'exception_message': None, 'exception_traceback': None, 'raised_exception': False}, 'expectation_c...2:00:01'}, {'count': 1, 'value': '2000-03-01 12:00:01'}, {'count': 1, 'value': '2000-04-01 12:00:01'}, ...], ...}, ...}
data_asset = <great_expectations.execution_engine.sqlalchemy_batch_data.SqlAlchemyBatchData object at 0x7fe2f24ba7c0>
pk_column = True

    def check_json_test_result(  # noqa: C901 - 52
        test, result, data_asset=None, pk_column=False
    ) -> None:

        # check for id_pk results in cases where pk_column is true and unexpected_index_list already exists
        # this will work for testing since result_format is COMPLETE
        if pk_column:
            if not result["success"]:
                if "unexpected_index_list" in result["result"]:
                    assert "unexpected_index_query" in result["result"]

        if "unexpected_list" in result["result"]:
            if ("result" in test["output"]) and (
                "unexpected_list" in test["output"]["result"]
            ):
                (
                    test["output"]["result"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["result"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                )
            elif "unexpected_list" in test["output"]:
                (
                    test["output"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                )

        if "partial_unexpected_list" in result["result"]:
            if ("result" in test["output"]) and (
                "partial_unexpected_list" in test["output"]["result"]
            ):
                (
                    test["output"]["result"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["result"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                )
            elif "partial_unexpected_list" in test["output"]:
                (
                    test["output"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                )

        # Determine if np.allclose(..) might be needed for float comparison
        try_allclose = False
        if "observed_value" in test["output"]:
            if RX_FLOAT.match(repr(test["output"]["observed_value"])):
                try_allclose = True

        # Check results
        if test["exact_match_out"] is True:
            if "result" in result and "observed_value" in result["result"]:
                if isinstance(result["result"]["observed_value"], (np.floating, float)):
                    assert np.allclose(
                        result["result"]["observed_value"],
                        expectationValidationResultSchema.load(test["output"])["result"][
                            "observed_value"
                        ],
                        rtol=RTOL,
                        atol=ATOL,
                    ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['result']['observed_value']} not np.allclose to {expectationValidationResultSchema.load(test['output'])['result']['observed_value']}"
                else:
                    assert result == expectationValidationResultSchema.load(
                        test["output"]
                    ), f"{result} != {expectationValidationResultSchema.load(test['output'])}"
            else:
                assert result == expectationValidationResultSchema.load(
                    test["output"]
                ), f"{result} != {expectationValidationResultSchema.load(test['output'])}"
        else:
            # Convert result to json since our tests are reading from json so cannot easily contain richer types (e.g. NaN)
            # NOTE - 20191031 - JPC - we may eventually want to change these tests as we update our view on how
            # representations, serializations, and objects should interact and how much of that is shown to the user.
            result = result.to_json_dict()
            for key, value in test["output"].items():
                if key == "success":
                    if isinstance(value, (np.floating, float)):
                        try:
                            assert np.allclose(
                                result["success"],
                                value,
                                rtol=RTOL,
                                atol=ATOL,
                            ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['success']} not np.allclose to {value}"
                        except TypeError:
                            assert (
                                result["success"] == value
                            ), f"{result['success']} != {value}"
                    else:
                        assert result["success"] == value, f"{result['success']} != {value}"

                elif key == "observed_value":
                    if "tolerance" in test:
                        if isinstance(value, dict):
                            assert set(result["result"]["observed_value"].keys()) == set(
                                value.keys()
                            ), f"{set(result['result']['observed_value'].keys())} != {set(value.keys())}"
                            for k, v in value.items():
                                assert np.allclose(
                                    result["result"]["observed_value"][k],
                                    v,
                                    rtol=test["tolerance"],
                                )
                        else:
                            assert np.allclose(
                                result["result"]["observed_value"],
                                value,
                                rtol=test["tolerance"],
                            )
                    else:
                        if isinstance(value, dict) and "values" in value:
                            try:
                                assert np.allclose(
                                    result["result"]["observed_value"]["values"],
                                    value["values"],
                                    rtol=RTOL,
                                    atol=ATOL,
                                ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['result']['observed_value']['values']} not np.allclose to {value['values']}"
                            except TypeError as e:
                                print(e)
                                assert (
                                    result["result"]["observed_value"] == value
                                ), f"{result['result']['observed_value']} != {value}"
                        elif try_allclose:
                            assert np.allclose(
                                result["result"]["observed_value"],
                                value,
                                rtol=RTOL,
                                atol=ATOL,
                            ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['result']['observed_value']} not np.allclose to {value}"
                        else:
                            assert (
                                result["result"]["observed_value"] == value
                            ), f"{result['result']['observed_value']} != {value}"

                # NOTE: This is a key used ONLY for testing cases where an expectation is legitimately allowed to return
                # any of multiple possible observed_values. expect_column_values_to_be_of_type is one such expectation.
                elif key == "observed_value_list":
                    assert result["result"]["observed_value"] in value

                elif key == "unexpected_index_list":
                    if pk_column:
>                       assert (
                            result["result"].get("unexpected_index_list") == value
                        ), f"{result['result'].get('unexpected_index_list')} != {value}"
E                       AssertionError: [{'pk_index': 0, 'ts': '1970-01-01 12:00:01'}, {'pk_index': 1, 'ts': '1999-12-31 12:00:01'}, {'pk_index': 2, 'ts': '2000-01-01 12:00:01'}, {'pk_index': 3, 'ts': '2000-02-01 12:00:01'}, {'pk_index': 4, 'ts': '2000-03-01 12:00:01'}, {'pk_index': 5, 'ts': '2000-04-01 12:00:01'}, {'pk_index': 6, 'ts': '2000-05-01 12:00:01'}, {'pk_index': 7, 'ts': '2000-06-01 12:00:01'}, {'pk_index': 9, 'ts': '2001-01-01 12:00:01'}] != [{'ts': '1970-01-01T12:00:01', 'pk_index': 0}, {'ts': '1999-12-31T12:00:01', 'pk_index': 1}, {'ts': '2000-01-01T12:00:01', 'pk_index': 2}, {'ts': '2000-02-01T12:00:01', 'pk_index': 3}, {'ts': '2000-03-01T12:00:01', 'pk_index': 4}, {'ts': '2000-04-01T12:00:01', 'pk_index': 5}, {'ts': '2000-05-01T12:00:01', 'pk_index': 6}, {'ts': '2000-06-01T12:00:01', 'pk_index': 7}, {'ts': '2001-01-01T12:00:01', 'pk_index': 9}]

great_expectations/self_check/util.py:3068: AssertionError
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2528.21it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 208.03it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 370.33it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 208.78it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 292.38it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 216.53it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 335.59it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 299.00it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 327.89it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 305.46it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 304.64it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 303.72it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:basic_negative_now_timedelta_test] _

test_case = {'expectation_type': 'expect_column_values_to_be_between', 'pk_column': True, 'skip': False, 'test': {'exact_match_out...:00:01'}, {'pk_index': 4, 'ts': '2000-03-01T12:00:01'}, {'pk_index': 5, 'ts': '2000-04-01T12:00:01'}, ...]}, ...}, ...}

    @pytest.mark.order(index=0)
    @pytest.mark.integration
    @pytest.mark.slow  # 12.68s
    def test_case_runner_v3_api(test_case):
        if test_case["skip"]:
            pytest.skip()

        # Note: this should never be done in practice, but we are wiping expectations to reuse batches during testing.
        # test_case["batch"]._initialize_expectations()
        if "parse_strings_as_datetimes" in test_case["test"]["in"]:
            with pytest.deprecated_call():
                evaluate_json_test_v3_api(
                    validator=test_case["validator_with_data"],
                    expectation_type=test_case["expectation_type"],
                    test=test_case["test"],
                    pk_column=test_case["pk_column"],
                )
        else:
>           evaluate_json_test_v3_api(
                validator=test_case["validator_with_data"],
                expectation_type=test_case["expectation_type"],
                test=test_case["test"],
                pk_column=test_case["pk_column"],
            )

tests/test_definitions/test_expectations_v3_api.py:428:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
great_expectations/self_check/util.py:2900: in evaluate_json_test_v3_api
    check_json_test_result(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

test = {'exact_match_out': False, 'in': {'column': 'ts', 'max_value': {'$PARAMETER': 'now() - timedelta(weeks=52*100)'}}, 'in...-01T12:00:01'}, {'pk_index': 4, 'ts': '2000-03-01T12:00:01'}, {'pk_index': 5, 'ts': '2000-04-01T12:00:01'}, ...]}, ...}
result = {'exception_info': {'exception_message': None, 'exception_traceback': None, 'raised_exception': False}, 'expectation_c...2:00:01'}, {'count': 1, 'value': '2000-03-01 12:00:01'}, {'count': 1, 'value': '2000-04-01 12:00:01'}, ...], ...}, ...}
data_asset = <great_expectations.execution_engine.sqlalchemy_batch_data.SqlAlchemyBatchData object at 0x7fe2f24ba7c0>
pk_column = True

    def check_json_test_result(  # noqa: C901 - 52
        test, result, data_asset=None, pk_column=False
    ) -> None:

        # check for id_pk results in cases where pk_column is true and unexpected_index_list already exists
        # this will work for testing since result_format is COMPLETE
        if pk_column:
            if not result["success"]:
                if "unexpected_index_list" in result["result"]:
                    assert "unexpected_index_query" in result["result"]

        if "unexpected_list" in result["result"]:
            if ("result" in test["output"]) and (
                "unexpected_list" in test["output"]["result"]
            ):
                (
                    test["output"]["result"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["result"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                )
            elif "unexpected_list" in test["output"]:
                (
                    test["output"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                )

        if "partial_unexpected_list" in result["result"]:
            if ("result" in test["output"]) and (
                "partial_unexpected_list" in test["output"]["result"]
            ):
                (
                    test["output"]["result"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["result"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                )
            elif "partial_unexpected_list" in test["output"]:
                (
                    test["output"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                )

        # Determine if np.allclose(..) might be needed for float comparison
        try_allclose = False
        if "observed_value" in test["output"]:
            if RX_FLOAT.match(repr(test["output"]["observed_value"])):
                try_allclose = True

        # Check results
        if test["exact_match_out"] is True:
            if "result" in result and "observed_value" in result["result"]:
                if isinstance(result["result"]["observed_value"], (np.floating, float)):
                    assert np.allclose(
                        result["result"]["observed_value"],
                        expectationValidationResultSchema.load(test["output"])["result"][
                            "observed_value"
                        ],
                        rtol=RTOL,
                        atol=ATOL,
                    ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['result']['observed_value']} not np.allclose to {expectationValidationResultSchema.load(test['output'])['result']['observed_value']}"
                else:
                    assert result == expectationValidationResultSchema.load(
                        test["output"]
                    ), f"{result} != {expectationValidationResultSchema.load(test['output'])}"
            else:
                assert result == expectationValidationResultSchema.load(
                    test["output"]
                ), f"{result} != {expectationValidationResultSchema.load(test['output'])}"
        else:
            # Convert result to json since our tests are reading from json so cannot easily contain richer types (e.g. NaN)
            # NOTE - 20191031 - JPC - we may eventually want to change these tests as we update our view on how
            # representations, serializations, and objects should interact and how much of that is shown to the user.
            result = result.to_json_dict()
            for key, value in test["output"].items():
                if key == "success":
                    if isinstance(value, (np.floating, float)):
                        try:
                            assert np.allclose(
                                result["success"],
                                value,
                                rtol=RTOL,
                                atol=ATOL,
                            ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['success']} not np.allclose to {value}"
                        except TypeError:
                            assert (
                                result["success"] == value
                            ), f"{result['success']} != {value}"
                    else:
                        assert result["success"] == value, f"{result['success']} != {value}"

                elif key == "observed_value":
                    if "tolerance" in test:
                        if isinstance(value, dict):
                            assert set(result["result"]["observed_value"].keys()) == set(
                                value.keys()
                            ), f"{set(result['result']['observed_value'].keys())} != {set(value.keys())}"
                            for k, v in value.items():
                                assert np.allclose(
                                    result["result"]["observed_value"][k],
                                    v,
                                    rtol=test["tolerance"],
                                )
                        else:
                            assert np.allclose(
                                result["result"]["observed_value"],
                                value,
                                rtol=test["tolerance"],
                            )
                    else:
                        if isinstance(value, dict) and "values" in value:
                            try:
                                assert np.allclose(
                                    result["result"]["observed_value"]["values"],
                                    value["values"],
                                    rtol=RTOL,
                                    atol=ATOL,
                                ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['result']['observed_value']['values']} not np.allclose to {value['values']}"
                            except TypeError as e:
                                print(e)
                                assert (
                                    result["result"]["observed_value"] == value
                                ), f"{result['result']['observed_value']} != {value}"
                        elif try_allclose:
                            assert np.allclose(
                                result["result"]["observed_value"],
                                value,
                                rtol=RTOL,
                                atol=ATOL,
                            ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['result']['observed_value']} not np.allclose to {value}"
                        else:
                            assert (
                                result["result"]["observed_value"] == value
                            ), f"{result['result']['observed_value']} != {value}"

                # NOTE: This is a key used ONLY for testing cases where an expectation is legitimately allowed to return
                # any of multiple possible observed_values. expect_column_values_to_be_of_type is one such expectation.
                elif key == "observed_value_list":
                    assert result["result"]["observed_value"] in value

                elif key == "unexpected_index_list":
                    if pk_column:
>                       assert (
                            result["result"].get("unexpected_index_list") == value
                        ), f"{result['result'].get('unexpected_index_list')} != {value}"
E                       AssertionError: [{'pk_index': 0, 'ts': '1970-01-01 12:00:01'}, {'pk_index': 1, 'ts': '1999-12-31 12:00:01'}, {'pk_index': 2, 'ts': '2000-01-01 12:00:01'}, {'pk_index': 3, 'ts': '2000-02-01 12:00:01'}, {'pk_index': 4, 'ts': '2000-03-01 12:00:01'}, {'pk_index': 5, 'ts': '2000-04-01 12:00:01'}, {'pk_index': 6, 'ts': '2000-05-01 12:00:01'}, {'pk_index': 7, 'ts': '2000-06-01 12:00:01'}, {'pk_index': 9, 'ts': '2001-01-01 12:00:01'}] != [{'ts': '1970-01-01T12:00:01', 'pk_index': 0}, {'ts': '1999-12-31T12:00:01', 'pk_index': 1}, {'ts': '2000-01-01T12:00:01', 'pk_index': 2}, {'ts': '2000-02-01T12:00:01', 'pk_index': 3}, {'ts': '2000-03-01T12:00:01', 'pk_index': 4}, {'ts': '2000-04-01T12:00:01', 'pk_index': 5}, {'ts': '2000-05-01T12:00:01', 'pk_index': 6}, {'ts': '2000-06-01T12:00:01', 'pk_index': 7}, {'ts': '2001-01-01T12:00:01', 'pk_index': 9}]

great_expectations/self_check/util.py:3068: AssertionError
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2430.07it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 210.33it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 373.24it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 206.47it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 273.51it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 142.64it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 207.57it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 176.82it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 200.17it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 191.03it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 190.60it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 190.20it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:basic_negative_datetime_test] _

test_case = {'expectation_type': 'expect_column_values_to_be_between', 'pk_column': True, 'skip': False, 'test': {'exact_match_out...:00:01'}, {'pk_index': 4, 'ts': '2000-03-01T12:00:01'}, {'pk_index': 5, 'ts': '2000-04-01T12:00:01'}, ...]}, ...}, ...}

    @pytest.mark.order(index=0)
    @pytest.mark.integration
    @pytest.mark.slow  # 12.68s
    def test_case_runner_v3_api(test_case):
        if test_case["skip"]:
            pytest.skip()

        # Note: this should never be done in practice, but we are wiping expectations to reuse batches during testing.
        # test_case["batch"]._initialize_expectations()
        if "parse_strings_as_datetimes" in test_case["test"]["in"]:
            with pytest.deprecated_call():
                evaluate_json_test_v3_api(
                    validator=test_case["validator_with_data"],
                    expectation_type=test_case["expectation_type"],
                    test=test_case["test"],
                    pk_column=test_case["pk_column"],
                )
        else:
>           evaluate_json_test_v3_api(
                validator=test_case["validator_with_data"],
                expectation_type=test_case["expectation_type"],
                test=test_case["test"],
                pk_column=test_case["pk_column"],
            )

tests/test_definitions/test_expectations_v3_api.py:428:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
great_expectations/self_check/util.py:2900: in evaluate_json_test_v3_api
    check_json_test_result(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

test = {'exact_match_out': False, 'in': {'column': 'ts', 'max_value': {'$PARAMETER': 'datetime(1969, 1, 1)'}}, 'input': {'col...-01T12:00:01'}, {'pk_index': 4, 'ts': '2000-03-01T12:00:01'}, {'pk_index': 5, 'ts': '2000-04-01T12:00:01'}, ...]}, ...}
result = {'exception_info': {'exception_message': None, 'exception_traceback': None, 'raised_exception': False}, 'expectation_c...2:00:01'}, {'count': 1, 'value': '2000-03-01 12:00:01'}, {'count': 1, 'value': '2000-04-01 12:00:01'}, ...], ...}, ...}
data_asset = <great_expectations.execution_engine.sqlalchemy_batch_data.SqlAlchemyBatchData object at 0x7fe2f24ba7c0>
pk_column = True

    def check_json_test_result(  # noqa: C901 - 52
        test, result, data_asset=None, pk_column=False
    ) -> None:

        # check for id_pk results in cases where pk_column is true and unexpected_index_list already exists
        # this will work for testing since result_format is COMPLETE
        if pk_column:
            if not result["success"]:
                if "unexpected_index_list" in result["result"]:
                    assert "unexpected_index_query" in result["result"]

        if "unexpected_list" in result["result"]:
            if ("result" in test["output"]) and (
                "unexpected_list" in test["output"]["result"]
            ):
                (
                    test["output"]["result"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["result"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                )
            elif "unexpected_list" in test["output"]:
                (
                    test["output"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                )

        if "partial_unexpected_list" in result["result"]:
            if ("result" in test["output"]) and (
                "partial_unexpected_list" in test["output"]["result"]
            ):
                (
                    test["output"]["result"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["result"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                )
            elif "partial_unexpected_list" in test["output"]:
                (
                    test["output"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                )

        # Determine if np.allclose(..) might be needed for float comparison
        try_allclose = False
        if "observed_value" in test["output"]:
            if RX_FLOAT.match(repr(test["output"]["observed_value"])):
                try_allclose = True

        # Check results
        if test["exact_match_out"] is True:
            if "result" in result and "observed_value" in result["result"]:
                if isinstance(result["result"]["observed_value"], (np.floating, float)):
                    assert np.allclose(
                        result["result"]["observed_value"],
                        expectationValidationResultSchema.load(test["output"])["result"][
                            "observed_value"
                        ],
                        rtol=RTOL,
                        atol=ATOL,
                    ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['result']['observed_value']} not np.allclose to {expectationValidationResultSchema.load(test['output'])['result']['observed_value']}"
                else:
                    assert result == expectationValidationResultSchema.load(
                        test["output"]
                    ), f"{result} != {expectationValidationResultSchema.load(test['output'])}"
            else:
                assert result == expectationValidationResultSchema.load(
                    test["output"]
                ), f"{result} != {expectationValidationResultSchema.load(test['output'])}"
        else:
            # Convert result to json since our tests are reading from json so cannot easily contain richer types (e.g. NaN)
            # NOTE - 20191031 - JPC - we may eventually want to change these tests as we update our view on how
            # representations, serializations, and objects should interact and how much of that is shown to the user.
            result = result.to_json_dict()
            for key, value in test["output"].items():
                if key == "success":
                    if isinstance(value, (np.floating, float)):
                        try:
                            assert np.allclose(
                                result["success"],
                                value,
                                rtol=RTOL,
                                atol=ATOL,
                            ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['success']} not np.allclose to {value}"
                        except TypeError:
                            assert (
                                result["success"] == value
                            ), f"{result['success']} != {value}"
                    else:
                        assert result["success"] == value, f"{result['success']} != {value}"

                elif key == "observed_value":
                    if "tolerance" in test:
                        if isinstance(value, dict):
                            assert set(result["result"]["observed_value"].keys()) == set(
                                value.keys()
                            ), f"{set(result['result']['observed_value'].keys())} != {set(value.keys())}"
                            for k, v in value.items():
                                assert np.allclose(
                                    result["result"]["observed_value"][k],
                                    v,
                                    rtol=test["tolerance"],
                                )
                        else:
                            assert np.allclose(
                                result["result"]["observed_value"],
                                value,
                                rtol=test["tolerance"],
                            )
                    else:
                        if isinstance(value, dict) and "values" in value:
                            try:
                                assert np.allclose(
                                    result["result"]["observed_value"]["values"],
                                    value["values"],
                                    rtol=RTOL,
                                    atol=ATOL,
                                ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['result']['observed_value']['values']} not np.allclose to {value['values']}"
                            except TypeError as e:
                                print(e)
                                assert (
                                    result["result"]["observed_value"] == value
                                ), f"{result['result']['observed_value']} != {value}"
                        elif try_allclose:
                            assert np.allclose(
                                result["result"]["observed_value"],
                                value,
                                rtol=RTOL,
                                atol=ATOL,
                            ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['result']['observed_value']} not np.allclose to {value}"
                        else:
                            assert (
                                result["result"]["observed_value"] == value
                            ), f"{result['result']['observed_value']} != {value}"

                # NOTE: This is a key used ONLY for testing cases where an expectation is legitimately allowed to return
                # any of multiple possible observed_values. expect_column_values_to_be_of_type is one such expectation.
                elif key == "observed_value_list":
                    assert result["result"]["observed_value"] in value

                elif key == "unexpected_index_list":
                    if pk_column:
>                       assert (
                            result["result"].get("unexpected_index_list") == value
                        ), f"{result['result'].get('unexpected_index_list')} != {value}"
E                       AssertionError: [{'pk_index': 0, 'ts': '1970-01-01 12:00:01'}, {'pk_index': 1, 'ts': '1999-12-31 12:00:01'}, {'pk_index': 2, 'ts': '2000-01-01 12:00:01'}, {'pk_index': 3, 'ts': '2000-02-01 12:00:01'}, {'pk_index': 4, 'ts': '2000-03-01 12:00:01'}, {'pk_index': 5, 'ts': '2000-04-01 12:00:01'}, {'pk_index': 6, 'ts': '2000-05-01 12:00:01'}, {'pk_index': 7, 'ts': '2000-06-01 12:00:01'}, {'pk_index': 9, 'ts': '2001-01-01 12:00:01'}] != [{'ts': '1970-01-01T12:00:01', 'pk_index': 0}, {'ts': '1999-12-31T12:00:01', 'pk_index': 1}, {'ts': '2000-01-01T12:00:01', 'pk_index': 2}, {'ts': '2000-02-01T12:00:01', 'pk_index': 3}, {'ts': '2000-03-01T12:00:01', 'pk_index': 4}, {'ts': '2000-04-01T12:00:01', 'pk_index': 5}, {'ts': '2000-05-01T12:00:01', 'pk_index': 6}, {'ts': '2000-06-01T12:00:01', 'pk_index': 7}, {'ts': '2001-01-01T12:00:01', 'pk_index': 9}]

great_expectations/self_check/util.py:3068: AssertionError
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2503.31it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 209.19it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 369.52it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 208.69it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 289.92it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 210.55it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 332.71it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 295.73it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 328.55it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 305.98it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 305.18it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 304.26it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:basic_negative_test_with_timestamps_tz_informed] _

test_case = {'expectation_type': 'expect_column_values_to_be_between', 'pk_column': True, 'skip': False, 'test': {'exact_match_out...: 8, 'ts': '2019-09-01T15:27:05.345678+09:00'}, {'pk_index': 9, 'ts': '2001-06-01T16:00:00.132678-08:00'}]}, ...}, ...}

    @pytest.mark.order(index=0)
    @pytest.mark.integration
    @pytest.mark.slow  # 12.68s
    def test_case_runner_v3_api(test_case):
        if test_case["skip"]:
            pytest.skip()

        # Note: this should never be done in practice, but we are wiping expectations to reuse batches during testing.
        # test_case["batch"]._initialize_expectations()
        if "parse_strings_as_datetimes" in test_case["test"]["in"]:
            with pytest.deprecated_call():
>               evaluate_json_test_v3_api(
                    validator=test_case["validator_with_data"],
                    expectation_type=test_case["expectation_type"],
                    test=test_case["test"],
                    pk_column=test_case["pk_column"],
                )

tests/test_definitions/test_expectations_v3_api.py:421:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
great_expectations/self_check/util.py:2900: in evaluate_json_test_v3_api
    check_json_test_result(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

test = {'exact_match_out': False, 'in': {'column': 'ts', 'max_value': '2001-02-01 12:00:01.001234 -1230', 'min_value': '1990-...index': 8, 'ts': '2019-09-01T15:27:05.345678+09:00'}, {'pk_index': 9, 'ts': '2001-06-01T16:00:00.132678-08:00'}]}, ...}
result = {'exception_info': {'exception_message': None, 'exception_traceback': None, 'raised_exception': False}, 'expectation_c..., {'count': 1, 'value': '2001-06-01 16:00:00.132678'}, {'count': 1, 'value': '2019-09-01 15:27:05.345678'}], ...}, ...}
data_asset = <great_expectations.execution_engine.sqlalchemy_batch_data.SqlAlchemyBatchData object at 0x7fe2f24f33a0>
pk_column = True

    def check_json_test_result(  # noqa: C901 - 52
        test, result, data_asset=None, pk_column=False
    ) -> None:

        # check for id_pk results in cases where pk_column is true and unexpected_index_list already exists
        # this will work for testing since result_format is COMPLETE
        if pk_column:
            if not result["success"]:
                if "unexpected_index_list" in result["result"]:
                    assert "unexpected_index_query" in result["result"]

        if "unexpected_list" in result["result"]:
            if ("result" in test["output"]) and (
                "unexpected_list" in test["output"]["result"]
            ):
                (
                    test["output"]["result"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["result"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                )
            elif "unexpected_list" in test["output"]:
                (
                    test["output"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                )

        if "partial_unexpected_list" in result["result"]:
            if ("result" in test["output"]) and (
                "partial_unexpected_list" in test["output"]["result"]
            ):
                (
                    test["output"]["result"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["result"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                )
            elif "partial_unexpected_list" in test["output"]:
                (
                    test["output"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                )

        # Determine if np.allclose(..) might be needed for float comparison
        try_allclose = False
        if "observed_value" in test["output"]:
            if RX_FLOAT.match(repr(test["output"]["observed_value"])):
                try_allclose = True

        # Check results
        if test["exact_match_out"] is True:
            if "result" in result and "observed_value" in result["result"]:
                if isinstance(result["result"]["observed_value"], (np.floating, float)):
                    assert np.allclose(
                        result["result"]["observed_value"],
                        expectationValidationResultSchema.load(test["output"])["result"][
                            "observed_value"
                        ],
                        rtol=RTOL,
                        atol=ATOL,
                    ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['result']['observed_value']} not np.allclose to {expectationValidationResultSchema.load(test['output'])['result']['observed_value']}"
                else:
                    assert result == expectationValidationResultSchema.load(
                        test["output"]
                    ), f"{result} != {expectationValidationResultSchema.load(test['output'])}"
            else:
                assert result == expectationValidationResultSchema.load(
                    test["output"]
                ), f"{result} != {expectationValidationResultSchema.load(test['output'])}"
        else:
            # Convert result to json since our tests are reading from json so cannot easily contain richer types (e.g. NaN)
            # NOTE - 20191031 - JPC - we may eventually want to change these tests as we update our view on how
            # representations, serializations, and objects should interact and how much of that is shown to the user.
            result = result.to_json_dict()
            for key, value in test["output"].items():
                if key == "success":
                    if isinstance(value, (np.floating, float)):
                        try:
                            assert np.allclose(
                                result["success"],
                                value,
                                rtol=RTOL,
                                atol=ATOL,
                            ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['success']} not np.allclose to {value}"
                        except TypeError:
                            assert (
                                result["success"] == value
                            ), f"{result['success']} != {value}"
                    else:
                        assert result["success"] == value, f"{result['success']} != {value}"

                elif key == "observed_value":
                    if "tolerance" in test:
                        if isinstance(value, dict):
                            assert set(result["result"]["observed_value"].keys()) == set(
                                value.keys()
                            ), f"{set(result['result']['observed_value'].keys())} != {set(value.keys())}"
                            for k, v in value.items():
                                assert np.allclose(
                                    result["result"]["observed_value"][k],
                                    v,
                                    rtol=test["tolerance"],
                                )
                        else:
                            assert np.allclose(
                                result["result"]["observed_value"],
                                value,
                                rtol=test["tolerance"],
                            )
                    else:
                        if isinstance(value, dict) and "values" in value:
                            try:
                                assert np.allclose(
                                    result["result"]["observed_value"]["values"],
                                    value["values"],
                                    rtol=RTOL,
                                    atol=ATOL,
                                ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['result']['observed_value']['values']} not np.allclose to {value['values']}"
                            except TypeError as e:
                                print(e)
                                assert (
                                    result["result"]["observed_value"] == value
                                ), f"{result['result']['observed_value']} != {value}"
                        elif try_allclose:
                            assert np.allclose(
                                result["result"]["observed_value"],
                                value,
                                rtol=RTOL,
                                atol=ATOL,
                            ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['result']['observed_value']} not np.allclose to {value}"
                        else:
                            assert (
                                result["result"]["observed_value"] == value
                            ), f"{result['result']['observed_value']} != {value}"

                # NOTE: This is a key used ONLY for testing cases where an expectation is legitimately allowed to return
                # any of multiple possible observed_values. expect_column_values_to_be_of_type is one such expectation.
                elif key == "observed_value_list":
                    assert result["result"]["observed_value"] in value

                elif key == "unexpected_index_list":
                    if pk_column:
>                       assert (
                            result["result"].get("unexpected_index_list") == value
                        ), f"{result['result'].get('unexpected_index_list')} != {value}"
E                       AssertionError: [{'pk_index': 0, 'ts': '1970-01-01 12:00:01.000000'}, {'pk_index': 8, 'ts': '2019-09-01 15:27:05.345678'}, {'pk_index': 9, 'ts': '2001-06-01 16:00:00.132678'}] != [{'ts': '1970-01-01T12:00:01+05:30', 'pk_index': 0}, {'ts': '2019-09-01T15:27:05.345678+09:00', 'pk_index': 8}, {'ts': '2001-06-01T16:00:00.132678-08:00', 'pk_index': 9}]

great_expectations/self_check/util.py:3068: AssertionError
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2613.27it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 217.56it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 369.92it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 207.74it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 283.89it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 208.99it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 322.28it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 289.97it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 318.87it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 299.01it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 298.27it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 297.38it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:basic_negative_test_with_timestamps0] _

test_case = {'expectation_type': 'expect_column_values_to_be_between', 'pk_column': True, 'skip': False, 'test': {'_notes': 'Suppr...ax_value': 'Jan 01 2001 12:00:00', 'min_value': 'Jan 01 1990 12:00:00', 'parse_strings_as_datetimes': True}, ...}, ...}

    @pytest.mark.order(index=0)
    @pytest.mark.integration
    @pytest.mark.slow  # 12.68s
    def test_case_runner_v3_api(test_case):
        if test_case["skip"]:
            pytest.skip()

        # Note: this should never be done in practice, but we are wiping expectations to reuse batches during testing.
        # test_case["batch"]._initialize_expectations()
        if "parse_strings_as_datetimes" in test_case["test"]["in"]:
            with pytest.deprecated_call():
>               evaluate_json_test_v3_api(
                    validator=test_case["validator_with_data"],
                    expectation_type=test_case["expectation_type"],
                    test=test_case["test"],
                    pk_column=test_case["pk_column"],
                )

tests/test_definitions/test_expectations_v3_api.py:421:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
great_expectations/self_check/util.py:2900: in evaluate_json_test_v3_api
    check_json_test_result(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

test = {'_notes': 'Suppressed for snowflake because these are not valid timestamp formats https://docs.snowflake.com/en/sql-r...s', 'max_value': 'Jan 01 2001 12:00:00', 'min_value': 'Jan 01 1990 12:00:00', 'parse_strings_as_datetimes': True}, ...}
result = {'exception_info': {'exception_message': None, 'exception_traceback': None, 'raised_exception': False}, 'expectation_c...ected_counts': [{'count': 1, 'value': '1970-01-01 12:00:01'}, {'count': 1, 'value': '2001-01-01 12:00:01'}], ...}, ...}
data_asset = <great_expectations.execution_engine.sqlalchemy_batch_data.SqlAlchemyBatchData object at 0x7fe2f216c2e0>
pk_column = True

    def check_json_test_result(  # noqa: C901 - 52
        test, result, data_asset=None, pk_column=False
    ) -> None:

        # check for id_pk results in cases where pk_column is true and unexpected_index_list already exists
        # this will work for testing since result_format is COMPLETE
        if pk_column:
            if not result["success"]:
                if "unexpected_index_list" in result["result"]:
                    assert "unexpected_index_query" in result["result"]

        if "unexpected_list" in result["result"]:
            if ("result" in test["output"]) and (
                "unexpected_list" in test["output"]["result"]
            ):
                (
                    test["output"]["result"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["result"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                )
            elif "unexpected_list" in test["output"]:
                (
                    test["output"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                )

        if "partial_unexpected_list" in result["result"]:
            if ("result" in test["output"]) and (
                "partial_unexpected_list" in test["output"]["result"]
            ):
                (
                    test["output"]["result"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["result"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                )
            elif "partial_unexpected_list" in test["output"]:
                (
                    test["output"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                )

        # Determine if np.allclose(..) might be needed for float comparison
        try_allclose = False
        if "observed_value" in test["output"]:
            if RX_FLOAT.match(repr(test["output"]["observed_value"])):
                try_allclose = True

        # Check results
        if test["exact_match_out"] is True:
            if "result" in result and "observed_value" in result["result"]:
                if isinstance(result["result"]["observed_value"], (np.floating, float)):
                    assert np.allclose(
                        result["result"]["observed_value"],
                        expectationValidationResultSchema.load(test["output"])["result"][
                            "observed_value"
                        ],
                        rtol=RTOL,
                        atol=ATOL,
                    ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['result']['observed_value']} not np.allclose to {expectationValidationResultSchema.load(test['output'])['result']['observed_value']}"
                else:
                    assert result == expectationValidationResultSchema.load(
                        test["output"]
                    ), f"{result} != {expectationValidationResultSchema.load(test['output'])}"
            else:
                assert result == expectationValidationResultSchema.load(
                    test["output"]
                ), f"{result} != {expectationValidationResultSchema.load(test['output'])}"
        else:
            # Convert result to json since our tests are reading from json so cannot easily contain richer types (e.g. NaN)
            # NOTE - 20191031 - JPC - we may eventually want to change these tests as we update our view on how
            # representations, serializations, and objects should interact and how much of that is shown to the user.
            result = result.to_json_dict()
            for key, value in test["output"].items():
                if key == "success":
                    if isinstance(value, (np.floating, float)):
                        try:
                            assert np.allclose(
                                result["success"],
                                value,
                                rtol=RTOL,
                                atol=ATOL,
                            ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['success']} not np.allclose to {value}"
                        except TypeError:
                            assert (
                                result["success"] == value
                            ), f"{result['success']} != {value}"
                    else:
                        assert result["success"] == value, f"{result['success']} != {value}"

                elif key == "observed_value":
                    if "tolerance" in test:
                        if isinstance(value, dict):
                            assert set(result["result"]["observed_value"].keys()) == set(
                                value.keys()
                            ), f"{set(result['result']['observed_value'].keys())} != {set(value.keys())}"
                            for k, v in value.items():
                                assert np.allclose(
                                    result["result"]["observed_value"][k],
                                    v,
                                    rtol=test["tolerance"],
                                )
                        else:
                            assert np.allclose(
                                result["result"]["observed_value"],
                                value,
                                rtol=test["tolerance"],
                            )
                    else:
                        if isinstance(value, dict) and "values" in value:
                            try:
                                assert np.allclose(
                                    result["result"]["observed_value"]["values"],
                                    value["values"],
                                    rtol=RTOL,
                                    atol=ATOL,
                                ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['result']['observed_value']['values']} not np.allclose to {value['values']}"
                            except TypeError as e:
                                print(e)
                                assert (
                                    result["result"]["observed_value"] == value
                                ), f"{result['result']['observed_value']} != {value}"
                        elif try_allclose:
                            assert np.allclose(
                                result["result"]["observed_value"],
                                value,
                                rtol=RTOL,
                                atol=ATOL,
                            ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['result']['observed_value']} not np.allclose to {value}"
                        else:
                            assert (
                                result["result"]["observed_value"] == value
                            ), f"{result['result']['observed_value']} != {value}"

                # NOTE: This is a key used ONLY for testing cases where an expectation is legitimately allowed to return
                # any of multiple possible observed_values. expect_column_values_to_be_of_type is one such expectation.
                elif key == "observed_value_list":
                    assert result["result"]["observed_value"] in value

                elif key == "unexpected_index_list":
                    if pk_column:
>                       assert (
                            result["result"].get("unexpected_index_list") == value
                        ), f"{result['result'].get('unexpected_index_list')} != {value}"
E                       AssertionError: [{'pk_index': 0, 'ts': '1970-01-01 12:00:01'}, {'pk_index': 9, 'ts': '2001-01-01 12:00:01'}] != [{'ts': '1970-01-01T12:00:01', 'pk_index': 0}, {'ts': '2001-01-01T12:00:01', 'pk_index': 9}]

great_expectations/self_check/util.py:3068: AssertionError
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2728.89it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 237.52it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 409.20it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 233.89it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 320.17it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 239.19it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 375.52it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 336.37it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 367.51it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 342.16it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 340.80it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 339.64it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:basic_negative_test_with_timestamps1] _

test_case = {'expectation_type': 'expect_column_values_to_be_between', 'pk_column': True, 'skip': False, 'test': {'exact_match_out..._index_list': [{'pk_index': 0, 'ts': '1970-01-01T12:00:01'}, {'pk_index': 9, 'ts': '2001-01-01T12:00:01'}]}, ...}, ...}

    @pytest.mark.order(index=0)
    @pytest.mark.integration
    @pytest.mark.slow  # 12.68s
    def test_case_runner_v3_api(test_case):
        if test_case["skip"]:
            pytest.skip()

        # Note: this should never be done in practice, but we are wiping expectations to reuse batches during testing.
        # test_case["batch"]._initialize_expectations()
        if "parse_strings_as_datetimes" in test_case["test"]["in"]:
            with pytest.deprecated_call():
>               evaluate_json_test_v3_api(
                    validator=test_case["validator_with_data"],
                    expectation_type=test_case["expectation_type"],
                    test=test_case["test"],
                    pk_column=test_case["pk_column"],
                )

tests/test_definitions/test_expectations_v3_api.py:421:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
great_expectations/self_check/util.py:2900: in evaluate_json_test_v3_api
    check_json_test_result(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

test = {'exact_match_out': False, 'in': {'column': 'ts', 'max_value': 'Jan 01 2001 12:00:00', 'min_value': 'Jan 01 1990 12:00...pected_index_list': [{'pk_index': 0, 'ts': '1970-01-01T12:00:01'}, {'pk_index': 9, 'ts': '2001-01-01T12:00:01'}]}, ...}
result = {'exception_info': {'exception_message': None, 'exception_traceback': None, 'raised_exception': False}, 'expectation_c...ected_counts': [{'count': 1, 'value': '1970-01-01 12:00:01'}, {'count': 1, 'value': '2001-01-01 12:00:01'}], ...}, ...}
data_asset = <great_expectations.execution_engine.sqlalchemy_batch_data.SqlAlchemyBatchData object at 0x7fe2f2035520>
pk_column = True

    def check_json_test_result(  # noqa: C901 - 52
        test, result, data_asset=None, pk_column=False
    ) -> None:

        # check for id_pk results in cases where pk_column is true and unexpected_index_list already exists
        # this will work for testing since result_format is COMPLETE
        if pk_column:
            if not result["success"]:
                if "unexpected_index_list" in result["result"]:
                    assert "unexpected_index_query" in result["result"]

        if "unexpected_list" in result["result"]:
            if ("result" in test["output"]) and (
                "unexpected_list" in test["output"]["result"]
            ):
                (
                    test["output"]["result"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["result"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                )
            elif "unexpected_list" in test["output"]:
                (
                    test["output"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                )

        if "partial_unexpected_list" in result["result"]:
            if ("result" in test["output"]) and (
                "partial_unexpected_list" in test["output"]["result"]
            ):
                (
                    test["output"]["result"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["result"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                )
            elif "partial_unexpected_list" in test["output"]:
                (
                    test["output"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                )

        # Determine if np.allclose(..) might be needed for float comparison
        try_allclose = False
        if "observed_value" in test["output"]:
            if RX_FLOAT.match(repr(test["output"]["observed_value"])):
                try_allclose = True

        # Check results
        if test["exact_match_out"] is True:
            if "result" in result and "observed_value" in result["result"]:
                if isinstance(result["result"]["observed_value"], (np.floating, float)):
                    assert np.allclose(
                        result["result"]["observed_value"],
                        expectationValidationResultSchema.load(test["output"])["result"][
                            "observed_value"
                        ],
                        rtol=RTOL,
                        atol=ATOL,
                    ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['result']['observed_value']} not np.allclose to {expectationValidationResultSchema.load(test['output'])['result']['observed_value']}"
                else:
                    assert result == expectationValidationResultSchema.load(
                        test["output"]
                    ), f"{result} != {expectationValidationResultSchema.load(test['output'])}"
            else:
                assert result == expectationValidationResultSchema.load(
                    test["output"]
                ), f"{result} != {expectationValidationResultSchema.load(test['output'])}"
        else:
            # Convert result to json since our tests are reading from json so cannot easily contain richer types (e.g. NaN)
            # NOTE - 20191031 - JPC - we may eventually want to change these tests as we update our view on how
            # representations, serializations, and objects should interact and how much of that is shown to the user.
            result = result.to_json_dict()
            for key, value in test["output"].items():
                if key == "success":
                    if isinstance(value, (np.floating, float)):
                        try:
                            assert np.allclose(
                                result["success"],
                                value,
                                rtol=RTOL,
                                atol=ATOL,
                            ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['success']} not np.allclose to {value}"
                        except TypeError:
                            assert (
                                result["success"] == value
                            ), f"{result['success']} != {value}"
                    else:
                        assert result["success"] == value, f"{result['success']} != {value}"

                elif key == "observed_value":
                    if "tolerance" in test:
                        if isinstance(value, dict):
                            assert set(result["result"]["observed_value"].keys()) == set(
                                value.keys()
                            ), f"{set(result['result']['observed_value'].keys())} != {set(value.keys())}"
                            for k, v in value.items():
                                assert np.allclose(
                                    result["result"]["observed_value"][k],
                                    v,
                                    rtol=test["tolerance"],
                                )
                        else:
                            assert np.allclose(
                                result["result"]["observed_value"],
                                value,
                                rtol=test["tolerance"],
                            )
                    else:
                        if isinstance(value, dict) and "values" in value:
                            try:
                                assert np.allclose(
                                    result["result"]["observed_value"]["values"],
                                    value["values"],
                                    rtol=RTOL,
                                    atol=ATOL,
                                ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['result']['observed_value']['values']} not np.allclose to {value['values']}"
                            except TypeError as e:
                                print(e)
                                assert (
                                    result["result"]["observed_value"] == value
                                ), f"{result['result']['observed_value']} != {value}"
                        elif try_allclose:
                            assert np.allclose(
                                result["result"]["observed_value"],
                                value,
                                rtol=RTOL,
                                atol=ATOL,
                            ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['result']['observed_value']} not np.allclose to {value}"
                        else:
                            assert (
                                result["result"]["observed_value"] == value
                            ), f"{result['result']['observed_value']} != {value}"

                # NOTE: This is a key used ONLY for testing cases where an expectation is legitimately allowed to return
                # any of multiple possible observed_values. expect_column_values_to_be_of_type is one such expectation.
                elif key == "observed_value_list":
                    assert result["result"]["observed_value"] in value

                elif key == "unexpected_index_list":
                    if pk_column:
>                       assert (
                            result["result"].get("unexpected_index_list") == value
                        ), f"{result['result'].get('unexpected_index_list')} != {value}"
E                       AssertionError: [{'pk_index': 0, 'ts': '1970-01-01 12:00:01'}, {'pk_index': 9, 'ts': '2001-01-01 12:00:01'}] != [{'ts': '1970-01-01T12:00:01', 'pk_index': 0}, {'ts': '2001-01-01T12:00:01', 'pk_index': 9}]

great_expectations/self_check/util.py:3068: AssertionError
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2691.24it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 244.97it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 419.01it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 240.37it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 329.94it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 247.50it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 390.71it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 349.24it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 383.15it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 357.58it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 356.63it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 355.52it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_match_like_pattern_list:negative_test_with_more_string-ish_strings] _

test_case = {'expectation_type': 'expect_column_values_to_not_match_like_pattern_list', 'pk_column': True, 'skip': False, 'test': ...']}, 'input': {'column': 'x', 'like_pattern_list': ['opatomus', 'ovat', 'h%t']}, 'only_for': ['sqlalchemy'], ...}, ...}

    @pytest.mark.order(index=0)
    @pytest.mark.integration
    @pytest.mark.slow  # 12.68s
    def test_case_runner_v3_api(test_case):
        if test_case["skip"]:
            pytest.skip()

        # Note: this should never be done in practice, but we are wiping expectations to reuse batches during testing.
        # test_case["batch"]._initialize_expectations()
        if "parse_strings_as_datetimes" in test_case["test"]["in"]:
            with pytest.deprecated_call():
                evaluate_json_test_v3_api(
                    validator=test_case["validator_with_data"],
                    expectation_type=test_case["expectation_type"],
                    test=test_case["test"],
                    pk_column=test_case["pk_column"],
                )
        else:
>           evaluate_json_test_v3_api(
                validator=test_case["validator_with_data"],
                expectation_type=test_case["expectation_type"],
                test=test_case["test"],
                pk_column=test_case["pk_column"],
            )

tests/test_definitions/test_expectations_v3_api.py:428:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
great_expectations/self_check/util.py:2900: in evaluate_json_test_v3_api
    check_json_test_result(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

test = {'exact_match_out': False, 'in': {'column': 'x', 'like_pattern_list': ['opatomus', 'ovat', 'h%t']}, 'input': {'column': 'x', 'like_pattern_list': ['opatomus', 'ovat', 'h%t']}, 'only_for': ['sqlalchemy'], ...}
result = {'exception_info': {'exception_message': None, 'exception_traceback': None, 'raised_exception': False}, 'expectation_c...10, 'missing_count': 0, 'missing_percent': 0.0, 'partial_unexpected_counts': [{'count': 1, 'value': 'hat'}], ...}, ...}
data_asset = <great_expectations.execution_engine.sqlalchemy_batch_data.SqlAlchemyBatchData object at 0x7fe2f28f5bb0>
pk_column = True

    def check_json_test_result(  # noqa: C901 - 52
        test, result, data_asset=None, pk_column=False
    ) -> None:

        # check for id_pk results in cases where pk_column is true and unexpected_index_list already exists
        # this will work for testing since result_format is COMPLETE
        if pk_column:
            if not result["success"]:
                if "unexpected_index_list" in result["result"]:
                    assert "unexpected_index_query" in result["result"]

        if "unexpected_list" in result["result"]:
            if ("result" in test["output"]) and (
                "unexpected_list" in test["output"]["result"]
            ):
                (
                    test["output"]["result"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["result"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                )
            elif "unexpected_list" in test["output"]:
                (
                    test["output"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                )

        if "partial_unexpected_list" in result["result"]:
            if ("result" in test["output"]) and (
                "partial_unexpected_list" in test["output"]["result"]
            ):
                (
                    test["output"]["result"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["result"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                )
            elif "partial_unexpected_list" in test["output"]:
                (
                    test["output"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                )

        # Determine if np.allclose(..) might be needed for float comparison
        try_allclose = False
        if "observed_value" in test["output"]:
            if RX_FLOAT.match(repr(test["output"]["observed_value"])):
                try_allclose = True

        # Check results
        if test["exact_match_out"] is True:
            if "result" in result and "observed_value" in result["result"]:
                if isinstance(result["result"]["observed_value"], (np.floating, float)):
                    assert np.allclose(
                        result["result"]["observed_value"],
                        expectationValidationResultSchema.load(test["output"])["result"][
                            "observed_value"
                        ],
                        rtol=RTOL,
                        atol=ATOL,
                    ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['result']['observed_value']} not np.allclose to {expectationValidationResultSchema.load(test['output'])['result']['observed_value']}"
                else:
                    assert result == expectationValidationResultSchema.load(
                        test["output"]
                    ), f"{result} != {expectationValidationResultSchema.load(test['output'])}"
            else:
                assert result == expectationValidationResultSchema.load(
                    test["output"]
                ), f"{result} != {expectationValidationResultSchema.load(test['output'])}"
        else:
            # Convert result to json since our tests are reading from json so cannot easily contain richer types (e.g. NaN)
            # NOTE - 20191031 - JPC - we may eventually want to change these tests as we update our view on how
            # representations, serializations, and objects should interact and how much of that is shown to the user.
            result = result.to_json_dict()
            for key, value in test["output"].items():
                if key == "success":
                    if isinstance(value, (np.floating, float)):
                        try:
                            assert np.allclose(
                                result["success"],
                                value,
                                rtol=RTOL,
                                atol=ATOL,
                            ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['success']} not np.allclose to {value}"
                        except TypeError:
                            assert (
                                result["success"] == value
                            ), f"{result['success']} != {value}"
                    else:
                        assert result["success"] == value, f"{result['success']} != {value}"

                elif key == "observed_value":
                    if "tolerance" in test:
                        if isinstance(value, dict):
                            assert set(result["result"]["observed_value"].keys()) == set(
                                value.keys()
                            ), f"{set(result['result']['observed_value'].keys())} != {set(value.keys())}"
                            for k, v in value.items():
                                assert np.allclose(
                                    result["result"]["observed_value"][k],
                                    v,
                                    rtol=test["tolerance"],
                                )
                        else:
                            assert np.allclose(
                                result["result"]["observed_value"],
                                value,
                                rtol=test["tolerance"],
                            )
                    else:
                        if isinstance(value, dict) and "values" in value:
                            try:
                                assert np.allclose(
                                    result["result"]["observed_value"]["values"],
                                    value["values"],
                                    rtol=RTOL,
                                    atol=ATOL,
                                ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['result']['observed_value']['values']} not np.allclose to {value['values']}"
                            except TypeError as e:
                                print(e)
                                assert (
                                    result["result"]["observed_value"] == value
                                ), f"{result['result']['observed_value']} != {value}"
                        elif try_allclose:
                            assert np.allclose(
                                result["result"]["observed_value"],
                                value,
                                rtol=RTOL,
                                atol=ATOL,
                            ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['result']['observed_value']} not np.allclose to {value}"
                        else:
                            assert (
                                result["result"]["observed_value"] == value
                            ), f"{result['result']['observed_value']} != {value}"

                # NOTE: This is a key used ONLY for testing cases where an expectation is legitimately allowed to return
                # any of multiple possible observed_values. expect_column_values_to_be_of_type is one such expectation.
                elif key == "observed_value_list":
                    assert result["result"]["observed_value"] in value

                elif key == "unexpected_index_list":
                    if pk_column:
>                       assert (
                            result["result"].get("unexpected_index_list") == value
                        ), f"{result['result'].get('unexpected_index_list')} != {value}"
E                       AssertionError: [{'pk_index': 4, 'x': 'hat'}] != [4]

great_expectations/self_check/util.py:3068: AssertionError
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 1638.08it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 33.60it/s]  Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 64.36it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 43.84it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 63.66it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 47.00it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 47.00it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 47.00it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 47.00it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 47.00it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 47.00it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 47.00it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 68.59it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_match_like_pattern_list:basic_negative_test] _

test_case = {'expectation_type': 'expect_column_values_to_not_match_like_pattern_list', 'pk_column': True, 'skip': False, 'test': ...'%2%', '%4%', '%5%']}, 'only_for': ['sqlite', 'postgresql', 'mysql', 'trino', 'bigquery', 'snowflake', ...], ...}, ...}

    @pytest.mark.order(index=0)
    @pytest.mark.integration
    @pytest.mark.slow  # 12.68s
    def test_case_runner_v3_api(test_case):
        if test_case["skip"]:
            pytest.skip()

        # Note: this should never be done in practice, but we are wiping expectations to reuse batches during testing.
        # test_case["batch"]._initialize_expectations()
        if "parse_strings_as_datetimes" in test_case["test"]["in"]:
            with pytest.deprecated_call():
                evaluate_json_test_v3_api(
                    validator=test_case["validator_with_data"],
                    expectation_type=test_case["expectation_type"],
                    test=test_case["test"],
                    pk_column=test_case["pk_column"],
                )
        else:
>           evaluate_json_test_v3_api(
                validator=test_case["validator_with_data"],
                expectation_type=test_case["expectation_type"],
                test=test_case["test"],
                pk_column=test_case["pk_column"],
            )

tests/test_definitions/test_expectations_v3_api.py:428:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
great_expectations/self_check/util.py:2900: in evaluate_json_test_v3_api
    check_json_test_result(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

test = {'exact_match_out': False, 'in': {'column': 'w', 'like_pattern_list': ['%1%', '%2%', '%4%', '%5%']}, 'input': {'column...%1%', '%2%', '%4%', '%5%']}, 'only_for': ['sqlite', 'postgresql', 'mysql', 'trino', 'bigquery', 'snowflake', ...], ...}
result = {'exception_info': {'exception_message': None, 'exception_traceback': None, 'raised_exception': False}, 'expectation_c...ue': '222'}, {'count': 1, 'value': '321'}, {'count': 1, 'value': '444'}, {'count': 1, 'value': '456'}, ...], ...}, ...}
data_asset = <great_expectations.execution_engine.sqlalchemy_batch_data.SqlAlchemyBatchData object at 0x7fe2f28f5bb0>
pk_column = True

    def check_json_test_result(  # noqa: C901 - 52
        test, result, data_asset=None, pk_column=False
    ) -> None:

        # check for id_pk results in cases where pk_column is true and unexpected_index_list already exists
        # this will work for testing since result_format is COMPLETE
        if pk_column:
            if not result["success"]:
                if "unexpected_index_list" in result["result"]:
                    assert "unexpected_index_query" in result["result"]

        if "unexpected_list" in result["result"]:
            if ("result" in test["output"]) and (
                "unexpected_list" in test["output"]["result"]
            ):
                (
                    test["output"]["result"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["result"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                )
            elif "unexpected_list" in test["output"]:
                (
                    test["output"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                )

        if "partial_unexpected_list" in result["result"]:
            if ("result" in test["output"]) and (
                "partial_unexpected_list" in test["output"]["result"]
            ):
                (
                    test["output"]["result"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["result"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                )
            elif "partial_unexpected_list" in test["output"]:
                (
                    test["output"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                )

        # Determine if np.allclose(..) might be needed for float comparison
        try_allclose = False
        if "observed_value" in test["output"]:
            if RX_FLOAT.match(repr(test["output"]["observed_value"])):
                try_allclose = True

        # Check results
        if test["exact_match_out"] is True:
            if "result" in result and "observed_value" in result["result"]:
                if isinstance(result["result"]["observed_value"], (np.floating, float)):
                    assert np.allclose(
                        result["result"]["observed_value"],
                        expectationValidationResultSchema.load(test["output"])["result"][
                            "observed_value"
                        ],
                        rtol=RTOL,
                        atol=ATOL,
                    ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['result']['observed_value']} not np.allclose to {expectationValidationResultSchema.load(test['output'])['result']['observed_value']}"
                else:
                    assert result == expectationValidationResultSchema.load(
                        test["output"]
                    ), f"{result} != {expectationValidationResultSchema.load(test['output'])}"
            else:
                assert result == expectationValidationResultSchema.load(
                    test["output"]
                ), f"{result} != {expectationValidationResultSchema.load(test['output'])}"
        else:
            # Convert result to json since our tests are reading from json so cannot easily contain richer types (e.g. NaN)
            # NOTE - 20191031 - JPC - we may eventually want to change these tests as we update our view on how
            # representations, serializations, and objects should interact and how much of that is shown to the user.
            result = result.to_json_dict()
            for key, value in test["output"].items():
                if key == "success":
                    if isinstance(value, (np.floating, float)):
                        try:
                            assert np.allclose(
                                result["success"],
                                value,
                                rtol=RTOL,
                                atol=ATOL,
                            ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['success']} not np.allclose to {value}"
                        except TypeError:
                            assert (
                                result["success"] == value
                            ), f"{result['success']} != {value}"
                    else:
                        assert result["success"] == value, f"{result['success']} != {value}"

                elif key == "observed_value":
                    if "tolerance" in test:
                        if isinstance(value, dict):
                            assert set(result["result"]["observed_value"].keys()) == set(
                                value.keys()
                            ), f"{set(result['result']['observed_value'].keys())} != {set(value.keys())}"
                            for k, v in value.items():
                                assert np.allclose(
                                    result["result"]["observed_value"][k],
                                    v,
                                    rtol=test["tolerance"],
                                )
                        else:
                            assert np.allclose(
                                result["result"]["observed_value"],
                                value,
                                rtol=test["tolerance"],
                            )
                    else:
                        if isinstance(value, dict) and "values" in value:
                            try:
                                assert np.allclose(
                                    result["result"]["observed_value"]["values"],
                                    value["values"],
                                    rtol=RTOL,
                                    atol=ATOL,
                                ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['result']['observed_value']['values']} not np.allclose to {value['values']}"
                            except TypeError as e:
                                print(e)
                                assert (
                                    result["result"]["observed_value"] == value
                                ), f"{result['result']['observed_value']} != {value}"
                        elif try_allclose:
                            assert np.allclose(
                                result["result"]["observed_value"],
                                value,
                                rtol=RTOL,
                                atol=ATOL,
                            ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['result']['observed_value']} not np.allclose to {value}"
                        else:
                            assert (
                                result["result"]["observed_value"] == value
                            ), f"{result['result']['observed_value']} != {value}"

                # NOTE: This is a key used ONLY for testing cases where an expectation is legitimately allowed to return
                # any of multiple possible observed_values. expect_column_values_to_be_of_type is one such expectation.
                elif key == "observed_value_list":
                    assert result["result"]["observed_value"] in value

                elif key == "unexpected_index_list":
                    if pk_column:
>                       assert (
                            result["result"].get("unexpected_index_list") == value
                        ), f"{result['result'].get('unexpected_index_list')} != {value}"
E                       AssertionError: [{'pk_index': 0, 'w': '111'}, {'pk_index': 1, 'w': '222'}, {'pk_index': 3, 'w': '123'}, {'pk_index': 4, 'w': '321'}, {'pk_index': 5, 'w': '444'}, {'pk_index': 6, 'w': '456'}, {'pk_index': 7, 'w': '654'}, {'pk_index': 8, 'w': '555'}] != [0, 1, 3, 4, 5, 6, 7, 8]

great_expectations/self_check/util.py:3068: AssertionError
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2064.13it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 54.18it/s]  Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 102.94it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 58.29it/s] Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 83.64it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 55.44it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 55.44it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 55.44it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 55.44it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 55.44it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 55.44it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 55.44it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 84.36it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_match_like_pattern:negative_test_insufficient_mostly_and_one_non_matching_value] _

test_case = {'expectation_type': 'expect_column_values_to_not_match_like_pattern', 'pk_column': True, 'skip': False, 'test': {'exa..., 'mostly': 0.3}, 'include_in_gallery': True, 'input': {'column': 'a', 'like_pattern': 'a%', 'mostly': 0.3}, ...}, ...}

    @pytest.mark.order(index=0)
    @pytest.mark.integration
    @pytest.mark.slow  # 12.68s
    def test_case_runner_v3_api(test_case):
        if test_case["skip"]:
            pytest.skip()

        # Note: this should never be done in practice, but we are wiping expectations to reuse batches during testing.
        # test_case["batch"]._initialize_expectations()
        if "parse_strings_as_datetimes" in test_case["test"]["in"]:
            with pytest.deprecated_call():
                evaluate_json_test_v3_api(
                    validator=test_case["validator_with_data"],
                    expectation_type=test_case["expectation_type"],
                    test=test_case["test"],
                    pk_column=test_case["pk_column"],
                )
        else:
>           evaluate_json_test_v3_api(
                validator=test_case["validator_with_data"],
                expectation_type=test_case["expectation_type"],
                test=test_case["test"],
                pk_column=test_case["pk_column"],
            )

tests/test_definitions/test_expectations_v3_api.py:428:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
great_expectations/self_check/util.py:2900: in evaluate_json_test_v3_api
    check_json_test_result(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

test = {'exact_match_out': False, 'in': {'column': 'a', 'like_pattern': 'a%', 'mostly': 0.3}, 'include_in_gallery': True, 'input': {'column': 'a', 'like_pattern': 'a%', 'mostly': 0.3}, ...}
result = {'exception_info': {'exception_message': None, 'exception_traceback': None, 'raised_exception': False}, 'expectation_c... 'value': 'aaa'}, {'count': 1, 'value': 'abb'}, {'count': 1, 'value': 'acc'}, {'count': 1, 'value': 'add'}], ...}, ...}
data_asset = <great_expectations.execution_engine.sqlalchemy_batch_data.SqlAlchemyBatchData object at 0x7fe2f2926610>
pk_column = True

    def check_json_test_result(  # noqa: C901 - 52
        test, result, data_asset=None, pk_column=False
    ) -> None:

        # check for id_pk results in cases where pk_column is true and unexpected_index_list already exists
        # this will work for testing since result_format is COMPLETE
        if pk_column:
            if not result["success"]:
                if "unexpected_index_list" in result["result"]:
                    assert "unexpected_index_query" in result["result"]

        if "unexpected_list" in result["result"]:
            if ("result" in test["output"]) and (
                "unexpected_list" in test["output"]["result"]
            ):
                (
                    test["output"]["result"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["result"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                )
            elif "unexpected_list" in test["output"]:
                (
                    test["output"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                )

        if "partial_unexpected_list" in result["result"]:
            if ("result" in test["output"]) and (
                "partial_unexpected_list" in test["output"]["result"]
            ):
                (
                    test["output"]["result"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["result"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                )
            elif "partial_unexpected_list" in test["output"]:
                (
                    test["output"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                )

        # Determine if np.allclose(..) might be needed for float comparison
        try_allclose = False
        if "observed_value" in test["output"]:
            if RX_FLOAT.match(repr(test["output"]["observed_value"])):
                try_allclose = True

        # Check results
        if test["exact_match_out"] is True:
            if "result" in result and "observed_value" in result["result"]:
                if isinstance(result["result"]["observed_value"], (np.floating, float)):
                    assert np.allclose(
                        result["result"]["observed_value"],
                        expectationValidationResultSchema.load(test["output"])["result"][
                            "observed_value"
                        ],
                        rtol=RTOL,
                        atol=ATOL,
                    ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['result']['observed_value']} not np.allclose to {expectationValidationResultSchema.load(test['output'])['result']['observed_value']}"
                else:
                    assert result == expectationValidationResultSchema.load(
                        test["output"]
                    ), f"{result} != {expectationValidationResultSchema.load(test['output'])}"
            else:
                assert result == expectationValidationResultSchema.load(
                    test["output"]
                ), f"{result} != {expectationValidationResultSchema.load(test['output'])}"
        else:
            # Convert result to json since our tests are reading from json so cannot easily contain richer types (e.g. NaN)
            # NOTE - 20191031 - JPC - we may eventually want to change these tests as we update our view on how
            # representations, serializations, and objects should interact and how much of that is shown to the user.
            result = result.to_json_dict()
            for key, value in test["output"].items():
                if key == "success":
                    if isinstance(value, (np.floating, float)):
                        try:
                            assert np.allclose(
                                result["success"],
                                value,
                                rtol=RTOL,
                                atol=ATOL,
                            ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['success']} not np.allclose to {value}"
                        except TypeError:
                            assert (
                                result["success"] == value
                            ), f"{result['success']} != {value}"
                    else:
                        assert result["success"] == value, f"{result['success']} != {value}"

                elif key == "observed_value":
                    if "tolerance" in test:
                        if isinstance(value, dict):
                            assert set(result["result"]["observed_value"].keys()) == set(
                                value.keys()
                            ), f"{set(result['result']['observed_value'].keys())} != {set(value.keys())}"
                            for k, v in value.items():
                                assert np.allclose(
                                    result["result"]["observed_value"][k],
                                    v,
                                    rtol=test["tolerance"],
                                )
                        else:
                            assert np.allclose(
                                result["result"]["observed_value"],
                                value,
                                rtol=test["tolerance"],
                            )
                    else:
                        if isinstance(value, dict) and "values" in value:
                            try:
                                assert np.allclose(
                                    result["result"]["observed_value"]["values"],
                                    value["values"],
                                    rtol=RTOL,
                                    atol=ATOL,
                                ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['result']['observed_value']['values']} not np.allclose to {value['values']}"
                            except TypeError as e:
                                print(e)
                                assert (
                                    result["result"]["observed_value"] == value
                                ), f"{result['result']['observed_value']} != {value}"
                        elif try_allclose:
                            assert np.allclose(
                                result["result"]["observed_value"],
                                value,
                                rtol=RTOL,
                                atol=ATOL,
                            ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['result']['observed_value']} not np.allclose to {value}"
                        else:
                            assert (
                                result["result"]["observed_value"] == value
                            ), f"{result['result']['observed_value']} != {value}"

                # NOTE: This is a key used ONLY for testing cases where an expectation is legitimately allowed to return
                # any of multiple possible observed_values. expect_column_values_to_be_of_type is one such expectation.
                elif key == "observed_value_list":
                    assert result["result"]["observed_value"] in value

                elif key == "unexpected_index_list":
                    if pk_column:
>                       assert (
                            result["result"].get("unexpected_index_list") == value
                        ), f"{result['result'].get('unexpected_index_list')} != {value}"
E                       AssertionError: [{'pk_index': 0, 'a': 'aaa'}, {'pk_index': 1, 'a': 'abb'}, {'pk_index': 2, 'a': 'acc'}, {'pk_index': 3, 'a': 'add'}] != [0, 1, 2, 3]

great_expectations/self_check/util.py:3068: AssertionError
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 1148.81it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 125.26it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 213.08it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 127.19it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 177.19it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 136.67it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 203.56it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 183.47it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 199.92it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 187.61it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 186.96it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 186.36it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_match_like_pattern:positive_test_exact_mostly_w_one_non_matching_value] _

test_case = {'expectation_type': 'expect_column_values_to_not_match_like_pattern', 'pk_column': True, 'skip': False, 'test': {'exa..., 'mostly': 0.2}, 'include_in_gallery': True, 'input': {'column': 'a', 'like_pattern': 'a%', 'mostly': 0.2}, ...}, ...}

    @pytest.mark.order(index=0)
    @pytest.mark.integration
    @pytest.mark.slow  # 12.68s
    def test_case_runner_v3_api(test_case):
        if test_case["skip"]:
            pytest.skip()

        # Note: this should never be done in practice, but we are wiping expectations to reuse batches during testing.
        # test_case["batch"]._initialize_expectations()
        if "parse_strings_as_datetimes" in test_case["test"]["in"]:
            with pytest.deprecated_call():
                evaluate_json_test_v3_api(
                    validator=test_case["validator_with_data"],
                    expectation_type=test_case["expectation_type"],
                    test=test_case["test"],
                    pk_column=test_case["pk_column"],
                )
        else:
>           evaluate_json_test_v3_api(
                validator=test_case["validator_with_data"],
                expectation_type=test_case["expectation_type"],
                test=test_case["test"],
                pk_column=test_case["pk_column"],
            )

tests/test_definitions/test_expectations_v3_api.py:428:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
great_expectations/self_check/util.py:2900: in evaluate_json_test_v3_api
    check_json_test_result(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

test = {'exact_match_out': False, 'in': {'column': 'a', 'like_pattern': 'a%', 'mostly': 0.2}, 'include_in_gallery': True, 'input': {'column': 'a', 'like_pattern': 'a%', 'mostly': 0.2}, ...}
result = {'exception_info': {'exception_message': None, 'exception_traceback': None, 'raised_exception': False}, 'expectation_c... 'value': 'aaa'}, {'count': 1, 'value': 'abb'}, {'count': 1, 'value': 'acc'}, {'count': 1, 'value': 'add'}], ...}, ...}
data_asset = <great_expectations.execution_engine.sqlalchemy_batch_data.SqlAlchemyBatchData object at 0x7fe2f2926610>
pk_column = True

    def check_json_test_result(  # noqa: C901 - 52
        test, result, data_asset=None, pk_column=False
    ) -> None:

        # check for id_pk results in cases where pk_column is true and unexpected_index_list already exists
        # this will work for testing since result_format is COMPLETE
        if pk_column:
            if not result["success"]:
                if "unexpected_index_list" in result["result"]:
                    assert "unexpected_index_query" in result["result"]

        if "unexpected_list" in result["result"]:
            if ("result" in test["output"]) and (
                "unexpected_list" in test["output"]["result"]
            ):
                (
                    test["output"]["result"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["result"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                )
            elif "unexpected_list" in test["output"]:
                (
                    test["output"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                )

        if "partial_unexpected_list" in result["result"]:
            if ("result" in test["output"]) and (
                "partial_unexpected_list" in test["output"]["result"]
            ):
                (
                    test["output"]["result"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["result"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                )
            elif "partial_unexpected_list" in test["output"]:
                (
                    test["output"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                )

        # Determine if np.allclose(..) might be needed for float comparison
        try_allclose = False
        if "observed_value" in test["output"]:
            if RX_FLOAT.match(repr(test["output"]["observed_value"])):
                try_allclose = True

        # Check results
        if test["exact_match_out"] is True:
            if "result" in result and "observed_value" in result["result"]:
                if isinstance(result["result"]["observed_value"], (np.floating, float)):
                    assert np.allclose(
                        result["result"]["observed_value"],
                        expectationValidationResultSchema.load(test["output"])["result"][
                            "observed_value"
                        ],
                        rtol=RTOL,
                        atol=ATOL,
                    ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['result']['observed_value']} not np.allclose to {expectationValidationResultSchema.load(test['output'])['result']['observed_value']}"
                else:
                    assert result == expectationValidationResultSchema.load(
                        test["output"]
                    ), f"{result} != {expectationValidationResultSchema.load(test['output'])}"
            else:
                assert result == expectationValidationResultSchema.load(
                    test["output"]
                ), f"{result} != {expectationValidationResultSchema.load(test['output'])}"
        else:
            # Convert result to json since our tests are reading from json so cannot easily contain richer types (e.g. NaN)
            # NOTE - 20191031 - JPC - we may eventually want to change these tests as we update our view on how
            # representations, serializations, and objects should interact and how much of that is shown to the user.
            result = result.to_json_dict()
            for key, value in test["output"].items():
                if key == "success":
                    if isinstance(value, (np.floating, float)):
                        try:
                            assert np.allclose(
                                result["success"],
                                value,
                                rtol=RTOL,
                                atol=ATOL,
                            ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['success']} not np.allclose to {value}"
                        except TypeError:
                            assert (
                                result["success"] == value
                            ), f"{result['success']} != {value}"
                    else:
                        assert result["success"] == value, f"{result['success']} != {value}"

                elif key == "observed_value":
                    if "tolerance" in test:
                        if isinstance(value, dict):
                            assert set(result["result"]["observed_value"].keys()) == set(
                                value.keys()
                            ), f"{set(result['result']['observed_value'].keys())} != {set(value.keys())}"
                            for k, v in value.items():
                                assert np.allclose(
                                    result["result"]["observed_value"][k],
                                    v,
                                    rtol=test["tolerance"],
                                )
                        else:
                            assert np.allclose(
                                result["result"]["observed_value"],
                                value,
                                rtol=test["tolerance"],
                            )
                    else:
                        if isinstance(value, dict) and "values" in value:
                            try:
                                assert np.allclose(
                                    result["result"]["observed_value"]["values"],
                                    value["values"],
                                    rtol=RTOL,
                                    atol=ATOL,
                                ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['result']['observed_value']['values']} not np.allclose to {value['values']}"
                            except TypeError as e:
                                print(e)
                                assert (
                                    result["result"]["observed_value"] == value
                                ), f"{result['result']['observed_value']} != {value}"
                        elif try_allclose:
                            assert np.allclose(
                                result["result"]["observed_value"],
                                value,
                                rtol=RTOL,
                                atol=ATOL,
                            ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['result']['observed_value']} not np.allclose to {value}"
                        else:
                            assert (
                                result["result"]["observed_value"] == value
                            ), f"{result['result']['observed_value']} != {value}"

                # NOTE: This is a key used ONLY for testing cases where an expectation is legitimately allowed to return
                # any of multiple possible observed_values. expect_column_values_to_be_of_type is one such expectation.
                elif key == "observed_value_list":
                    assert result["result"]["observed_value"] in value

                elif key == "unexpected_index_list":
                    if pk_column:
>                       assert (
                            result["result"].get("unexpected_index_list") == value
                        ), f"{result['result'].get('unexpected_index_list')} != {value}"
E                       AssertionError: [{'pk_index': 0, 'a': 'aaa'}, {'pk_index': 1, 'a': 'abb'}, {'pk_index': 2, 'a': 'acc'}, {'pk_index': 3, 'a': 'add'}] != [0, 1, 2, 3]

great_expectations/self_check/util.py:3068: AssertionError
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 1429.55it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 239.61it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 402.65it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 240.10it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 331.33it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 251.21it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 373.85it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 338.14it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 368.97it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 347.06it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 346.03it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 344.83it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_match_like_pattern:positive_test_sufficient_mostly_w_one_non_matching_value] _

test_case = {'expectation_type': 'expect_column_values_to_not_match_like_pattern', 'pk_column': True, 'skip': False, 'test': {'exa... 'a%', 'mostly': 0.1}, 'only_for': ['sqlite', 'postgresql', 'mysql', 'trino', 'bigquery', 'snowflake', ...], ...}, ...}

    @pytest.mark.order(index=0)
    @pytest.mark.integration
    @pytest.mark.slow  # 12.68s
    def test_case_runner_v3_api(test_case):
        if test_case["skip"]:
            pytest.skip()

        # Note: this should never be done in practice, but we are wiping expectations to reuse batches during testing.
        # test_case["batch"]._initialize_expectations()
        if "parse_strings_as_datetimes" in test_case["test"]["in"]:
            with pytest.deprecated_call():
                evaluate_json_test_v3_api(
                    validator=test_case["validator_with_data"],
                    expectation_type=test_case["expectation_type"],
                    test=test_case["test"],
                    pk_column=test_case["pk_column"],
                )
        else:
>           evaluate_json_test_v3_api(
                validator=test_case["validator_with_data"],
                expectation_type=test_case["expectation_type"],
                test=test_case["test"],
                pk_column=test_case["pk_column"],
            )

tests/test_definitions/test_expectations_v3_api.py:428:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
great_expectations/self_check/util.py:2900: in evaluate_json_test_v3_api
    check_json_test_result(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

test = {'exact_match_out': False, 'in': {'column': 'a', 'like_pattern': 'a%', 'mostly': 0.1}, 'input': {'column': 'a', 'like_pattern': 'a%', 'mostly': 0.1}, 'only_for': ['sqlite', 'postgresql', 'mysql', 'trino', 'bigquery', 'snowflake', ...], ...}
result = {'exception_info': {'exception_message': None, 'exception_traceback': None, 'raised_exception': False}, 'expectation_c... 'value': 'aaa'}, {'count': 1, 'value': 'abb'}, {'count': 1, 'value': 'acc'}, {'count': 1, 'value': 'add'}], ...}, ...}
data_asset = <great_expectations.execution_engine.sqlalchemy_batch_data.SqlAlchemyBatchData object at 0x7fe2f2926610>
pk_column = True

    def check_json_test_result(  # noqa: C901 - 52
        test, result, data_asset=None, pk_column=False
    ) -> None:

        # check for id_pk results in cases where pk_column is true and unexpected_index_list already exists
        # this will work for testing since result_format is COMPLETE
        if pk_column:
            if not result["success"]:
                if "unexpected_index_list" in result["result"]:
                    assert "unexpected_index_query" in result["result"]

        if "unexpected_list" in result["result"]:
            if ("result" in test["output"]) and (
                "unexpected_list" in test["output"]["result"]
            ):
                (
                    test["output"]["result"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["result"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                )
            elif "unexpected_list" in test["output"]:
                (
                    test["output"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                )

        if "partial_unexpected_list" in result["result"]:
            if ("result" in test["output"]) and (
                "partial_unexpected_list" in test["output"]["result"]
            ):
                (
                    test["output"]["result"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["result"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                )
            elif "partial_unexpected_list" in test["output"]:
                (
                    test["output"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                )

        # Determine if np.allclose(..) might be needed for float comparison
        try_allclose = False
        if "observed_value" in test["output"]:
            if RX_FLOAT.match(repr(test["output"]["observed_value"])):
                try_allclose = True

        # Check results
        if test["exact_match_out"] is True:
            if "result" in result and "observed_value" in result["result"]:
                if isinstance(result["result"]["observed_value"], (np.floating, float)):
                    assert np.allclose(
                        result["result"]["observed_value"],
                        expectationValidationResultSchema.load(test["output"])["result"][
                            "observed_value"
                        ],
                        rtol=RTOL,
                        atol=ATOL,
                    ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['result']['observed_value']} not np.allclose to {expectationValidationResultSchema.load(test['output'])['result']['observed_value']}"
                else:
                    assert result == expectationValidationResultSchema.load(
                        test["output"]
                    ), f"{result} != {expectationValidationResultSchema.load(test['output'])}"
            else:
                assert result == expectationValidationResultSchema.load(
                    test["output"]
                ), f"{result} != {expectationValidationResultSchema.load(test['output'])}"
        else:
            # Convert result to json since our tests are reading from json so cannot easily contain richer types (e.g. NaN)
            # NOTE - 20191031 - JPC - we may eventually want to change these tests as we update our view on how
            # representations, serializations, and objects should interact and how much of that is shown to the user.
            result = result.to_json_dict()
            for key, value in test["output"].items():
                if key == "success":
                    if isinstance(value, (np.floating, float)):
                        try:
                            assert np.allclose(
                                result["success"],
                                value,
                                rtol=RTOL,
                                atol=ATOL,
                            ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['success']} not np.allclose to {value}"
                        except TypeError:
                            assert (
                                result["success"] == value
                            ), f"{result['success']} != {value}"
                    else:
                        assert result["success"] == value, f"{result['success']} != {value}"

                elif key == "observed_value":
                    if "tolerance" in test:
                        if isinstance(value, dict):
                            assert set(result["result"]["observed_value"].keys()) == set(
                                value.keys()
                            ), f"{set(result['result']['observed_value'].keys())} != {set(value.keys())}"
                            for k, v in value.items():
                                assert np.allclose(
                                    result["result"]["observed_value"][k],
                                    v,
                                    rtol=test["tolerance"],
                                )
                        else:
                            assert np.allclose(
                                result["result"]["observed_value"],
                                value,
                                rtol=test["tolerance"],
                            )
                    else:
                        if isinstance(value, dict) and "values" in value:
                            try:
                                assert np.allclose(
                                    result["result"]["observed_value"]["values"],
                                    value["values"],
                                    rtol=RTOL,
                                    atol=ATOL,
                                ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['result']['observed_value']['values']} not np.allclose to {value['values']}"
                            except TypeError as e:
                                print(e)
                                assert (
                                    result["result"]["observed_value"] == value
                                ), f"{result['result']['observed_value']} != {value}"
                        elif try_allclose:
                            assert np.allclose(
                                result["result"]["observed_value"],
                                value,
                                rtol=RTOL,
                                atol=ATOL,
                            ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['result']['observed_value']} not np.allclose to {value}"
                        else:
                            assert (
                                result["result"]["observed_value"] == value
                            ), f"{result['result']['observed_value']} != {value}"

                # NOTE: This is a key used ONLY for testing cases where an expectation is legitimately allowed to return
                # any of multiple possible observed_values. expect_column_values_to_be_of_type is one such expectation.
                elif key == "observed_value_list":
                    assert result["result"]["observed_value"] in value

                elif key == "unexpected_index_list":
                    if pk_column:
>                       assert (
                            result["result"].get("unexpected_index_list") == value
                        ), f"{result['result'].get('unexpected_index_list')} != {value}"
E                       AssertionError: [{'pk_index': 0, 'a': 'aaa'}, {'pk_index': 1, 'a': 'abb'}, {'pk_index': 2, 'a': 'acc'}, {'pk_index': 3, 'a': 'add'}] != [0, 1, 2, 3]

great_expectations/self_check/util.py:3068: AssertionError
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2293.85it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 241.73it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 402.52it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 240.32it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 332.04it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 247.94it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 388.12it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 349.23it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 382.67it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 356.60it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 355.11it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 353.73it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_match_like_pattern:negative_test_one_missing_value_and_insufficent_mostly] _

test_case = {'expectation_type': 'expect_column_values_to_not_match_like_pattern', 'pk_column': True, 'skip': False, 'test': {'exa... 'a%', 'mostly': 0.5}, 'only_for': ['sqlite', 'postgresql', 'mysql', 'trino', 'bigquery', 'snowflake', ...], ...}, ...}

    @pytest.mark.order(index=0)
    @pytest.mark.integration
    @pytest.mark.slow  # 12.68s
    def test_case_runner_v3_api(test_case):
        if test_case["skip"]:
            pytest.skip()

        # Note: this should never be done in practice, but we are wiping expectations to reuse batches during testing.
        # test_case["batch"]._initialize_expectations()
        if "parse_strings_as_datetimes" in test_case["test"]["in"]:
            with pytest.deprecated_call():
                evaluate_json_test_v3_api(
                    validator=test_case["validator_with_data"],
                    expectation_type=test_case["expectation_type"],
                    test=test_case["test"],
                    pk_column=test_case["pk_column"],
                )
        else:
>           evaluate_json_test_v3_api(
                validator=test_case["validator_with_data"],
                expectation_type=test_case["expectation_type"],
                test=test_case["test"],
                pk_column=test_case["pk_column"],
            )

tests/test_definitions/test_expectations_v3_api.py:428:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
great_expectations/self_check/util.py:2900: in evaluate_json_test_v3_api
    check_json_test_result(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

test = {'exact_match_out': False, 'in': {'column': 'b', 'like_pattern': 'a%', 'mostly': 0.5}, 'input': {'column': 'b', 'like_pattern': 'a%', 'mostly': 0.5}, 'only_for': ['sqlite', 'postgresql', 'mysql', 'trino', 'bigquery', 'snowflake', ...], ...}
result = {'exception_info': {'exception_message': None, 'exception_traceback': None, 'raised_exception': False}, 'expectation_c...xpected_counts': [{'count': 1, 'value': 'aaa'}, {'count': 1, 'value': 'abb'}, {'count': 1, 'value': 'acc'}], ...}, ...}
data_asset = <great_expectations.execution_engine.sqlalchemy_batch_data.SqlAlchemyBatchData object at 0x7fe2f2926610>
pk_column = True

    def check_json_test_result(  # noqa: C901 - 52
        test, result, data_asset=None, pk_column=False
    ) -> None:

        # check for id_pk results in cases where pk_column is true and unexpected_index_list already exists
        # this will work for testing since result_format is COMPLETE
        if pk_column:
            if not result["success"]:
                if "unexpected_index_list" in result["result"]:
                    assert "unexpected_index_query" in result["result"]

        if "unexpected_list" in result["result"]:
            if ("result" in test["output"]) and (
                "unexpected_list" in test["output"]["result"]
            ):
                (
                    test["output"]["result"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["result"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                )
            elif "unexpected_list" in test["output"]:
                (
                    test["output"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                )

        if "partial_unexpected_list" in result["result"]:
            if ("result" in test["output"]) and (
                "partial_unexpected_list" in test["output"]["result"]
            ):
                (
                    test["output"]["result"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["result"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                )
            elif "partial_unexpected_list" in test["output"]:
                (
                    test["output"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                )

        # Determine if np.allclose(..) might be needed for float comparison
        try_allclose = False
        if "observed_value" in test["output"]:
            if RX_FLOAT.match(repr(test["output"]["observed_value"])):
                try_allclose = True

        # Check results
        if test["exact_match_out"] is True:
            if "result" in result and "observed_value" in result["result"]:
                if isinstance(result["result"]["observed_value"], (np.floating, float)):
                    assert np.allclose(
                        result["result"]["observed_value"],
                        expectationValidationResultSchema.load(test["output"])["result"][
                            "observed_value"
                        ],
                        rtol=RTOL,
                        atol=ATOL,
                    ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['result']['observed_value']} not np.allclose to {expectationValidationResultSchema.load(test['output'])['result']['observed_value']}"
                else:
                    assert result == expectationValidationResultSchema.load(
                        test["output"]
                    ), f"{result} != {expectationValidationResultSchema.load(test['output'])}"
            else:
                assert result == expectationValidationResultSchema.load(
                    test["output"]
                ), f"{result} != {expectationValidationResultSchema.load(test['output'])}"
        else:
            # Convert result to json since our tests are reading from json so cannot easily contain richer types (e.g. NaN)
            # NOTE - 20191031 - JPC - we may eventually want to change these tests as we update our view on how
            # representations, serializations, and objects should interact and how much of that is shown to the user.
            result = result.to_json_dict()
            for key, value in test["output"].items():
                if key == "success":
                    if isinstance(value, (np.floating, float)):
                        try:
                            assert np.allclose(
                                result["success"],
                                value,
                                rtol=RTOL,
                                atol=ATOL,
                            ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['success']} not np.allclose to {value}"
                        except TypeError:
                            assert (
                                result["success"] == value
                            ), f"{result['success']} != {value}"
                    else:
                        assert result["success"] == value, f"{result['success']} != {value}"

                elif key == "observed_value":
                    if "tolerance" in test:
                        if isinstance(value, dict):
                            assert set(result["result"]["observed_value"].keys()) == set(
                                value.keys()
                            ), f"{set(result['result']['observed_value'].keys())} != {set(value.keys())}"
                            for k, v in value.items():
                                assert np.allclose(
                                    result["result"]["observed_value"][k],
                                    v,
                                    rtol=test["tolerance"],
                                )
                        else:
                            assert np.allclose(
                                result["result"]["observed_value"],
                                value,
                                rtol=test["tolerance"],
                            )
                    else:
                        if isinstance(value, dict) and "values" in value:
                            try:
                                assert np.allclose(
                                    result["result"]["observed_value"]["values"],
                                    value["values"],
                                    rtol=RTOL,
                                    atol=ATOL,
                                ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['result']['observed_value']['values']} not np.allclose to {value['values']}"
                            except TypeError as e:
                                print(e)
                                assert (
                                    result["result"]["observed_value"] == value
                                ), f"{result['result']['observed_value']} != {value}"
                        elif try_allclose:
                            assert np.allclose(
                                result["result"]["observed_value"],
                                value,
                                rtol=RTOL,
                                atol=ATOL,
                            ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['result']['observed_value']} not np.allclose to {value}"
                        else:
                            assert (
                                result["result"]["observed_value"] == value
                            ), f"{result['result']['observed_value']} != {value}"

                # NOTE: This is a key used ONLY for testing cases where an expectation is legitimately allowed to return
                # any of multiple possible observed_values. expect_column_values_to_be_of_type is one such expectation.
                elif key == "observed_value_list":
                    assert result["result"]["observed_value"] in value

                elif key == "unexpected_index_list":
                    if pk_column:
>                       assert (
                            result["result"].get("unexpected_index_list") == value
                        ), f"{result['result'].get('unexpected_index_list')} != {value}"
E                       AssertionError: [{'pk_index': 0, 'b': 'aaa'}, {'pk_index': 1, 'b': 'abb'}, {'pk_index': 2, 'b': 'acc'}] != [0, 1, 2]

great_expectations/self_check/util.py:3068: AssertionError
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 1571.19it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 80.99it/s]  Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 147.14it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 83.31it/s] Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 98.65it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 79.39it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 116.47it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 105.48it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 105.48it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 105.48it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 105.48it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 105.48it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 94.07it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_match_like_pattern:negative_test_match_characters_not_at_the_beginning_of_string_exact_mostly] _

test_case = {'expectation_type': 'expect_column_values_to_not_match_like_pattern', 'pk_column': True, 'skip': False, 'test': {'exa...'%b%', 'mostly': 0.6}, 'only_for': ['sqlite', 'postgresql', 'mysql', 'trino', 'bigquery', 'snowflake', ...], ...}, ...}

    @pytest.mark.order(index=0)
    @pytest.mark.integration
    @pytest.mark.slow  # 12.68s
    def test_case_runner_v3_api(test_case):
        if test_case["skip"]:
            pytest.skip()

        # Note: this should never be done in practice, but we are wiping expectations to reuse batches during testing.
        # test_case["batch"]._initialize_expectations()
        if "parse_strings_as_datetimes" in test_case["test"]["in"]:
            with pytest.deprecated_call():
                evaluate_json_test_v3_api(
                    validator=test_case["validator_with_data"],
                    expectation_type=test_case["expectation_type"],
                    test=test_case["test"],
                    pk_column=test_case["pk_column"],
                )
        else:
>           evaluate_json_test_v3_api(
                validator=test_case["validator_with_data"],
                expectation_type=test_case["expectation_type"],
                test=test_case["test"],
                pk_column=test_case["pk_column"],
            )

tests/test_definitions/test_expectations_v3_api.py:428:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
great_expectations/self_check/util.py:2900: in evaluate_json_test_v3_api
    check_json_test_result(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

test = {'exact_match_out': False, 'in': {'column': 'a', 'like_pattern': '%b%', 'mostly': 0.6}, 'input': {'column': 'a', 'like...ern': '%b%', 'mostly': 0.6}, 'only_for': ['sqlite', 'postgresql', 'mysql', 'trino', 'bigquery', 'snowflake', ...], ...}
result = {'exception_info': {'exception_message': None, 'exception_traceback': None, 'raised_exception': False}, 'expectation_c...ng_percent': 0.0, 'partial_unexpected_counts': [{'count': 1, 'value': 'abb'}, {'count': 1, 'value': 'bee'}], ...}, ...}
data_asset = <great_expectations.execution_engine.sqlalchemy_batch_data.SqlAlchemyBatchData object at 0x7fe2f2926610>
pk_column = True

    def check_json_test_result(  # noqa: C901 - 52
        test, result, data_asset=None, pk_column=False
    ) -> None:

        # check for id_pk results in cases where pk_column is true and unexpected_index_list already exists
        # this will work for testing since result_format is COMPLETE
        if pk_column:
            if not result["success"]:
                if "unexpected_index_list" in result["result"]:
                    assert "unexpected_index_query" in result["result"]

        if "unexpected_list" in result["result"]:
            if ("result" in test["output"]) and (
                "unexpected_list" in test["output"]["result"]
            ):
                (
                    test["output"]["result"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["result"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                )
            elif "unexpected_list" in test["output"]:
                (
                    test["output"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                )

        if "partial_unexpected_list" in result["result"]:
            if ("result" in test["output"]) and (
                "partial_unexpected_list" in test["output"]["result"]
            ):
                (
                    test["output"]["result"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["result"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                )
            elif "partial_unexpected_list" in test["output"]:
                (
                    test["output"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                )

        # Determine if np.allclose(..) might be needed for float comparison
        try_allclose = False
        if "observed_value" in test["output"]:
            if RX_FLOAT.match(repr(test["output"]["observed_value"])):
                try_allclose = True

        # Check results
        if test["exact_match_out"] is True:
            if "result" in result and "observed_value" in result["result"]:
                if isinstance(result["result"]["observed_value"], (np.floating, float)):
                    assert np.allclose(
                        result["result"]["observed_value"],
                        expectationValidationResultSchema.load(test["output"])["result"][
                            "observed_value"
                        ],
                        rtol=RTOL,
                        atol=ATOL,
                    ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['result']['observed_value']} not np.allclose to {expectationValidationResultSchema.load(test['output'])['result']['observed_value']}"
                else:
                    assert result == expectationValidationResultSchema.load(
                        test["output"]
                    ), f"{result} != {expectationValidationResultSchema.load(test['output'])}"
            else:
                assert result == expectationValidationResultSchema.load(
                    test["output"]
                ), f"{result} != {expectationValidationResultSchema.load(test['output'])}"
        else:
            # Convert result to json since our tests are reading from json so cannot easily contain richer types (e.g. NaN)
            # NOTE - 20191031 - JPC - we may eventually want to change these tests as we update our view on how
            # representations, serializations, and objects should interact and how much of that is shown to the user.
            result = result.to_json_dict()
            for key, value in test["output"].items():
                if key == "success":
                    if isinstance(value, (np.floating, float)):
                        try:
                            assert np.allclose(
                                result["success"],
                                value,
                                rtol=RTOL,
                                atol=ATOL,
                            ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['success']} not np.allclose to {value}"
                        except TypeError:
                            assert (
                                result["success"] == value
                            ), f"{result['success']} != {value}"
                    else:
                        assert result["success"] == value, f"{result['success']} != {value}"

                elif key == "observed_value":
                    if "tolerance" in test:
                        if isinstance(value, dict):
                            assert set(result["result"]["observed_value"].keys()) == set(
                                value.keys()
                            ), f"{set(result['result']['observed_value'].keys())} != {set(value.keys())}"
                            for k, v in value.items():
                                assert np.allclose(
                                    result["result"]["observed_value"][k],
                                    v,
                                    rtol=test["tolerance"],
                                )
                        else:
                            assert np.allclose(
                                result["result"]["observed_value"],
                                value,
                                rtol=test["tolerance"],
                            )
                    else:
                        if isinstance(value, dict) and "values" in value:
                            try:
                                assert np.allclose(
                                    result["result"]["observed_value"]["values"],
                                    value["values"],
                                    rtol=RTOL,
                                    atol=ATOL,
                                ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['result']['observed_value']['values']} not np.allclose to {value['values']}"
                            except TypeError as e:
                                print(e)
                                assert (
                                    result["result"]["observed_value"] == value
                                ), f"{result['result']['observed_value']} != {value}"
                        elif try_allclose:
                            assert np.allclose(
                                result["result"]["observed_value"],
                                value,
                                rtol=RTOL,
                                atol=ATOL,
                            ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['result']['observed_value']} not np.allclose to {value}"
                        else:
                            assert (
                                result["result"]["observed_value"] == value
                            ), f"{result['result']['observed_value']} != {value}"

                # NOTE: This is a key used ONLY for testing cases where an expectation is legitimately allowed to return
                # any of multiple possible observed_values. expect_column_values_to_be_of_type is one such expectation.
                elif key == "observed_value_list":
                    assert result["result"]["observed_value"] in value

                elif key == "unexpected_index_list":
                    if pk_column:
>                       assert (
                            result["result"].get("unexpected_index_list") == value
                        ), f"{result['result'].get('unexpected_index_list')} != {value}"
E                       AssertionError: [{'pk_index': 1, 'a': 'abb'}, {'pk_index': 4, 'a': 'bee'}] != [1, 4]

great_expectations/self_check/util.py:3068: AssertionError
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2288.22it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 242.42it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 400.59it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 230.86it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 316.13it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 237.34it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 369.99it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 334.24it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 368.07it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 345.44it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 344.24it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 342.98it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_like_pattern:negative_test_insufficient_mostly_and_one_non_matching_value] _

test_case = {'expectation_type': 'expect_column_values_to_match_like_pattern', 'pk_column': True, 'skip': False, 'test': {'exact_m..., 'mostly': 0.9}, 'include_in_gallery': True, 'input': {'column': 'a', 'like_pattern': 'a%', 'mostly': 0.9}, ...}, ...}

    @pytest.mark.order(index=0)
    @pytest.mark.integration
    @pytest.mark.slow  # 12.68s
    def test_case_runner_v3_api(test_case):
        if test_case["skip"]:
            pytest.skip()

        # Note: this should never be done in practice, but we are wiping expectations to reuse batches during testing.
        # test_case["batch"]._initialize_expectations()
        if "parse_strings_as_datetimes" in test_case["test"]["in"]:
            with pytest.deprecated_call():
                evaluate_json_test_v3_api(
                    validator=test_case["validator_with_data"],
                    expectation_type=test_case["expectation_type"],
                    test=test_case["test"],
                    pk_column=test_case["pk_column"],
                )
        else:
>           evaluate_json_test_v3_api(
                validator=test_case["validator_with_data"],
                expectation_type=test_case["expectation_type"],
                test=test_case["test"],
                pk_column=test_case["pk_column"],
            )

tests/test_definitions/test_expectations_v3_api.py:428:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
great_expectations/self_check/util.py:2900: in evaluate_json_test_v3_api
    check_json_test_result(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

test = {'exact_match_out': False, 'in': {'column': 'a', 'like_pattern': 'a%', 'mostly': 0.9}, 'include_in_gallery': True, 'input': {'column': 'a', 'like_pattern': 'a%', 'mostly': 0.9}, ...}
result = {'exception_info': {'exception_message': None, 'exception_traceback': None, 'raised_exception': False}, 'expectation_c... 5, 'missing_count': 0, 'missing_percent': 0.0, 'partial_unexpected_counts': [{'count': 1, 'value': 'bee'}], ...}, ...}
data_asset = <great_expectations.execution_engine.sqlalchemy_batch_data.SqlAlchemyBatchData object at 0x7fe2f29b7220>
pk_column = True

    def check_json_test_result(  # noqa: C901 - 52
        test, result, data_asset=None, pk_column=False
    ) -> None:

        # check for id_pk results in cases where pk_column is true and unexpected_index_list already exists
        # this will work for testing since result_format is COMPLETE
        if pk_column:
            if not result["success"]:
                if "unexpected_index_list" in result["result"]:
                    assert "unexpected_index_query" in result["result"]

        if "unexpected_list" in result["result"]:
            if ("result" in test["output"]) and (
                "unexpected_list" in test["output"]["result"]
            ):
                (
                    test["output"]["result"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["result"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                )
            elif "unexpected_list" in test["output"]:
                (
                    test["output"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                )

        if "partial_unexpected_list" in result["result"]:
            if ("result" in test["output"]) and (
                "partial_unexpected_list" in test["output"]["result"]
            ):
                (
                    test["output"]["result"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["result"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                )
            elif "partial_unexpected_list" in test["output"]:
                (
                    test["output"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                )

        # Determine if np.allclose(..) might be needed for float comparison
        try_allclose = False
        if "observed_value" in test["output"]:
            if RX_FLOAT.match(repr(test["output"]["observed_value"])):
                try_allclose = True

        # Check results
        if test["exact_match_out"] is True:
            if "result" in result and "observed_value" in result["result"]:
                if isinstance(result["result"]["observed_value"], (np.floating, float)):
                    assert np.allclose(
                        result["result"]["observed_value"],
                        expectationValidationResultSchema.load(test["output"])["result"][
                            "observed_value"
                        ],
                        rtol=RTOL,
                        atol=ATOL,
                    ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['result']['observed_value']} not np.allclose to {expectationValidationResultSchema.load(test['output'])['result']['observed_value']}"
                else:
                    assert result == expectationValidationResultSchema.load(
                        test["output"]
                    ), f"{result} != {expectationValidationResultSchema.load(test['output'])}"
            else:
                assert result == expectationValidationResultSchema.load(
                    test["output"]
                ), f"{result} != {expectationValidationResultSchema.load(test['output'])}"
        else:
            # Convert result to json since our tests are reading from json so cannot easily contain richer types (e.g. NaN)
            # NOTE - 20191031 - JPC - we may eventually want to change these tests as we update our view on how
            # representations, serializations, and objects should interact and how much of that is shown to the user.
            result = result.to_json_dict()
            for key, value in test["output"].items():
                if key == "success":
                    if isinstance(value, (np.floating, float)):
                        try:
                            assert np.allclose(
                                result["success"],
                                value,
                                rtol=RTOL,
                                atol=ATOL,
                            ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['success']} not np.allclose to {value}"
                        except TypeError:
                            assert (
                                result["success"] == value
                            ), f"{result['success']} != {value}"
                    else:
                        assert result["success"] == value, f"{result['success']} != {value}"

                elif key == "observed_value":
                    if "tolerance" in test:
                        if isinstance(value, dict):
                            assert set(result["result"]["observed_value"].keys()) == set(
                                value.keys()
                            ), f"{set(result['result']['observed_value'].keys())} != {set(value.keys())}"
                            for k, v in value.items():
                                assert np.allclose(
                                    result["result"]["observed_value"][k],
                                    v,
                                    rtol=test["tolerance"],
                                )
                        else:
                            assert np.allclose(
                                result["result"]["observed_value"],
                                value,
                                rtol=test["tolerance"],
                            )
                    else:
                        if isinstance(value, dict) and "values" in value:
                            try:
                                assert np.allclose(
                                    result["result"]["observed_value"]["values"],
                                    value["values"],
                                    rtol=RTOL,
                                    atol=ATOL,
                                ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['result']['observed_value']['values']} not np.allclose to {value['values']}"
                            except TypeError as e:
                                print(e)
                                assert (
                                    result["result"]["observed_value"] == value
                                ), f"{result['result']['observed_value']} != {value}"
                        elif try_allclose:
                            assert np.allclose(
                                result["result"]["observed_value"],
                                value,
                                rtol=RTOL,
                                atol=ATOL,
                            ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['result']['observed_value']} not np.allclose to {value}"
                        else:
                            assert (
                                result["result"]["observed_value"] == value
                            ), f"{result['result']['observed_value']} != {value}"

                # NOTE: This is a key used ONLY for testing cases where an expectation is legitimately allowed to return
                # any of multiple possible observed_values. expect_column_values_to_be_of_type is one such expectation.
                elif key == "observed_value_list":
                    assert result["result"]["observed_value"] in value

                elif key == "unexpected_index_list":
                    if pk_column:
>                       assert (
                            result["result"].get("unexpected_index_list") == value
                        ), f"{result['result'].get('unexpected_index_list')} != {value}"
E                       AssertionError: [{'pk_index': 4, 'a': 'bee'}] != [4]

great_expectations/self_check/util.py:3068: AssertionError
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2255.61it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 243.49it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 399.76it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 229.69it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 315.44it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 242.19it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 365.52it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 321.73it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 344.90it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 322.73it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 320.84it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 318.57it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_like_pattern:positive_test_exact_mostly_w_one_non_matching_value] _

test_case = {'expectation_type': 'expect_column_values_to_match_like_pattern', 'pk_column': True, 'skip': False, 'test': {'exact_m..., 'mostly': 0.8}, 'include_in_gallery': True, 'input': {'column': 'a', 'like_pattern': 'a%', 'mostly': 0.8}, ...}, ...}

    @pytest.mark.order(index=0)
    @pytest.mark.integration
    @pytest.mark.slow  # 12.68s
    def test_case_runner_v3_api(test_case):
        if test_case["skip"]:
            pytest.skip()

        # Note: this should never be done in practice, but we are wiping expectations to reuse batches during testing.
        # test_case["batch"]._initialize_expectations()
        if "parse_strings_as_datetimes" in test_case["test"]["in"]:
            with pytest.deprecated_call():
                evaluate_json_test_v3_api(
                    validator=test_case["validator_with_data"],
                    expectation_type=test_case["expectation_type"],
                    test=test_case["test"],
                    pk_column=test_case["pk_column"],
                )
        else:
>           evaluate_json_test_v3_api(
                validator=test_case["validator_with_data"],
                expectation_type=test_case["expectation_type"],
                test=test_case["test"],
                pk_column=test_case["pk_column"],
            )

tests/test_definitions/test_expectations_v3_api.py:428:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
great_expectations/self_check/util.py:2900: in evaluate_json_test_v3_api
    check_json_test_result(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

test = {'exact_match_out': False, 'in': {'column': 'a', 'like_pattern': 'a%', 'mostly': 0.8}, 'include_in_gallery': True, 'input': {'column': 'a', 'like_pattern': 'a%', 'mostly': 0.8}, ...}
result = {'exception_info': {'exception_message': None, 'exception_traceback': None, 'raised_exception': False}, 'expectation_c... 5, 'missing_count': 0, 'missing_percent': 0.0, 'partial_unexpected_counts': [{'count': 1, 'value': 'bee'}], ...}, ...}
data_asset = <great_expectations.execution_engine.sqlalchemy_batch_data.SqlAlchemyBatchData object at 0x7fe2f29b7220>
pk_column = True

    def check_json_test_result(  # noqa: C901 - 52
        test, result, data_asset=None, pk_column=False
    ) -> None:

        # check for id_pk results in cases where pk_column is true and unexpected_index_list already exists
        # this will work for testing since result_format is COMPLETE
        if pk_column:
            if not result["success"]:
                if "unexpected_index_list" in result["result"]:
                    assert "unexpected_index_query" in result["result"]

        if "unexpected_list" in result["result"]:
            if ("result" in test["output"]) and (
                "unexpected_list" in test["output"]["result"]
            ):
                (
                    test["output"]["result"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["result"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                )
            elif "unexpected_list" in test["output"]:
                (
                    test["output"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                )

        if "partial_unexpected_list" in result["result"]:
            if ("result" in test["output"]) and (
                "partial_unexpected_list" in test["output"]["result"]
            ):
                (
                    test["output"]["result"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["result"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                )
            elif "partial_unexpected_list" in test["output"]:
                (
                    test["output"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                )

        # Determine if np.allclose(..) might be needed for float comparison
        try_allclose = False
        if "observed_value" in test["output"]:
            if RX_FLOAT.match(repr(test["output"]["observed_value"])):
                try_allclose = True

        # Check results
        if test["exact_match_out"] is True:
            if "result" in result and "observed_value" in result["result"]:
                if isinstance(result["result"]["observed_value"], (np.floating, float)):
                    assert np.allclose(
                        result["result"]["observed_value"],
                        expectationValidationResultSchema.load(test["output"])["result"][
                            "observed_value"
                        ],
                        rtol=RTOL,
                        atol=ATOL,
                    ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['result']['observed_value']} not np.allclose to {expectationValidationResultSchema.load(test['output'])['result']['observed_value']}"
                else:
                    assert result == expectationValidationResultSchema.load(
                        test["output"]
                    ), f"{result} != {expectationValidationResultSchema.load(test['output'])}"
            else:
                assert result == expectationValidationResultSchema.load(
                    test["output"]
                ), f"{result} != {expectationValidationResultSchema.load(test['output'])}"
        else:
            # Convert result to json since our tests are reading from json so cannot easily contain richer types (e.g. NaN)
            # NOTE - 20191031 - JPC - we may eventually want to change these tests as we update our view on how
            # representations, serializations, and objects should interact and how much of that is shown to the user.
            result = result.to_json_dict()
            for key, value in test["output"].items():
                if key == "success":
                    if isinstance(value, (np.floating, float)):
                        try:
                            assert np.allclose(
                                result["success"],
                                value,
                                rtol=RTOL,
                                atol=ATOL,
                            ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['success']} not np.allclose to {value}"
                        except TypeError:
                            assert (
                                result["success"] == value
                            ), f"{result['success']} != {value}"
                    else:
                        assert result["success"] == value, f"{result['success']} != {value}"

                elif key == "observed_value":
                    if "tolerance" in test:
                        if isinstance(value, dict):
                            assert set(result["result"]["observed_value"].keys()) == set(
                                value.keys()
                            ), f"{set(result['result']['observed_value'].keys())} != {set(value.keys())}"
                            for k, v in value.items():
                                assert np.allclose(
                                    result["result"]["observed_value"][k],
                                    v,
                                    rtol=test["tolerance"],
                                )
                        else:
                            assert np.allclose(
                                result["result"]["observed_value"],
                                value,
                                rtol=test["tolerance"],
                            )
                    else:
                        if isinstance(value, dict) and "values" in value:
                            try:
                                assert np.allclose(
                                    result["result"]["observed_value"]["values"],
                                    value["values"],
                                    rtol=RTOL,
                                    atol=ATOL,
                                ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['result']['observed_value']['values']} not np.allclose to {value['values']}"
                            except TypeError as e:
                                print(e)
                                assert (
                                    result["result"]["observed_value"] == value
                                ), f"{result['result']['observed_value']} != {value}"
                        elif try_allclose:
                            assert np.allclose(
                                result["result"]["observed_value"],
                                value,
                                rtol=RTOL,
                                atol=ATOL,
                            ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['result']['observed_value']} not np.allclose to {value}"
                        else:
                            assert (
                                result["result"]["observed_value"] == value
                            ), f"{result['result']['observed_value']} != {value}"

                # NOTE: This is a key used ONLY for testing cases where an expectation is legitimately allowed to return
                # any of multiple possible observed_values. expect_column_values_to_be_of_type is one such expectation.
                elif key == "observed_value_list":
                    assert result["result"]["observed_value"] in value

                elif key == "unexpected_index_list":
                    if pk_column:
>                       assert (
                            result["result"].get("unexpected_index_list") == value
                        ), f"{result['result'].get('unexpected_index_list')} != {value}"
E                       AssertionError: [{'pk_index': 4, 'a': 'bee'}] != [4]

great_expectations/self_check/util.py:3068: AssertionError
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 1888.90it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 226.40it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 380.66it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 209.98it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 292.06it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 224.47it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 349.54it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 309.00it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 335.25it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 315.11it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 313.96it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 312.88it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_like_pattern:positive_test_column_name_has_space] _

test_case = {'expectation_type': 'expect_column_values_to_match_like_pattern', 'pk_column': True, 'skip': False, 'test': {'exact_m...ern': 'a%', 'mostly': 0.8}, 'only_for': ['sqlite', 'postgresql', 'mysql', 'trino', 'snowflake', 'redshift'], ...}, ...}

    @pytest.mark.order(index=0)
    @pytest.mark.integration
    @pytest.mark.slow  # 12.68s
    def test_case_runner_v3_api(test_case):
        if test_case["skip"]:
            pytest.skip()

        # Note: this should never be done in practice, but we are wiping expectations to reuse batches during testing.
        # test_case["batch"]._initialize_expectations()
        if "parse_strings_as_datetimes" in test_case["test"]["in"]:
            with pytest.deprecated_call():
                evaluate_json_test_v3_api(
                    validator=test_case["validator_with_data"],
                    expectation_type=test_case["expectation_type"],
                    test=test_case["test"],
                    pk_column=test_case["pk_column"],
                )
        else:
>           evaluate_json_test_v3_api(
                validator=test_case["validator_with_data"],
                expectation_type=test_case["expectation_type"],
                test=test_case["test"],
                pk_column=test_case["pk_column"],
            )

tests/test_definitions/test_expectations_v3_api.py:428:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
great_expectations/self_check/util.py:2900: in evaluate_json_test_v3_api
    check_json_test_result(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

test = {'exact_match_out': False, 'in': {'column': 'column_name with space', 'like_pattern': 'a%', 'mostly': 0.8}, 'input': {...e_pattern': 'a%', 'mostly': 0.8}, 'only_for': ['sqlite', 'postgresql', 'mysql', 'trino', 'snowflake', 'redshift'], ...}
result = {'exception_info': {'exception_message': None, 'exception_traceback': None, 'raised_exception': False}, 'expectation_c... 5, 'missing_count': 0, 'missing_percent': 0.0, 'partial_unexpected_counts': [{'count': 1, 'value': 'bee'}], ...}, ...}
data_asset = <great_expectations.execution_engine.sqlalchemy_batch_data.SqlAlchemyBatchData object at 0x7fe2f29b7220>
pk_column = True

    def check_json_test_result(  # noqa: C901 - 52
        test, result, data_asset=None, pk_column=False
    ) -> None:

        # check for id_pk results in cases where pk_column is true and unexpected_index_list already exists
        # this will work for testing since result_format is COMPLETE
        if pk_column:
            if not result["success"]:
                if "unexpected_index_list" in result["result"]:
                    assert "unexpected_index_query" in result["result"]

        if "unexpected_list" in result["result"]:
            if ("result" in test["output"]) and (
                "unexpected_list" in test["output"]["result"]
            ):
                (
                    test["output"]["result"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["result"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                )
            elif "unexpected_list" in test["output"]:
                (
                    test["output"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                )

        if "partial_unexpected_list" in result["result"]:
            if ("result" in test["output"]) and (
                "partial_unexpected_list" in test["output"]["result"]
            ):
                (
                    test["output"]["result"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["result"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                )
            elif "partial_unexpected_list" in test["output"]:
                (
                    test["output"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                )

        # Determine if np.allclose(..) might be needed for float comparison
        try_allclose = False
        if "observed_value" in test["output"]:
            if RX_FLOAT.match(repr(test["output"]["observed_value"])):
                try_allclose = True

        # Check results
        if test["exact_match_out"] is True:
            if "result" in result and "observed_value" in result["result"]:
                if isinstance(result["result"]["observed_value"], (np.floating, float)):
                    assert np.allclose(
                        result["result"]["observed_value"],
                        expectationValidationResultSchema.load(test["output"])["result"][
                            "observed_value"
                        ],
                        rtol=RTOL,
                        atol=ATOL,
                    ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['result']['observed_value']} not np.allclose to {expectationValidationResultSchema.load(test['output'])['result']['observed_value']}"
                else:
                    assert result == expectationValidationResultSchema.load(
                        test["output"]
                    ), f"{result} != {expectationValidationResultSchema.load(test['output'])}"
            else:
                assert result == expectationValidationResultSchema.load(
                    test["output"]
                ), f"{result} != {expectationValidationResultSchema.load(test['output'])}"
        else:
            # Convert result to json since our tests are reading from json so cannot easily contain richer types (e.g. NaN)
            # NOTE - 20191031 - JPC - we may eventually want to change these tests as we update our view on how
            # representations, serializations, and objects should interact and how much of that is shown to the user.
            result = result.to_json_dict()
            for key, value in test["output"].items():
                if key == "success":
                    if isinstance(value, (np.floating, float)):
                        try:
                            assert np.allclose(
                                result["success"],
                                value,
                                rtol=RTOL,
                                atol=ATOL,
                            ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['success']} not np.allclose to {value}"
                        except TypeError:
                            assert (
                                result["success"] == value
                            ), f"{result['success']} != {value}"
                    else:
                        assert result["success"] == value, f"{result['success']} != {value}"

                elif key == "observed_value":
                    if "tolerance" in test:
                        if isinstance(value, dict):
                            assert set(result["result"]["observed_value"].keys()) == set(
                                value.keys()
                            ), f"{set(result['result']['observed_value'].keys())} != {set(value.keys())}"
                            for k, v in value.items():
                                assert np.allclose(
                                    result["result"]["observed_value"][k],
                                    v,
                                    rtol=test["tolerance"],
                                )
                        else:
                            assert np.allclose(
                                result["result"]["observed_value"],
                                value,
                                rtol=test["tolerance"],
                            )
                    else:
                        if isinstance(value, dict) and "values" in value:
                            try:
                                assert np.allclose(
                                    result["result"]["observed_value"]["values"],
                                    value["values"],
                                    rtol=RTOL,
                                    atol=ATOL,
                                ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['result']['observed_value']['values']} not np.allclose to {value['values']}"
                            except TypeError as e:
                                print(e)
                                assert (
                                    result["result"]["observed_value"] == value
                                ), f"{result['result']['observed_value']} != {value}"
                        elif try_allclose:
                            assert np.allclose(
                                result["result"]["observed_value"],
                                value,
                                rtol=RTOL,
                                atol=ATOL,
                            ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['result']['observed_value']} not np.allclose to {value}"
                        else:
                            assert (
                                result["result"]["observed_value"] == value
                            ), f"{result['result']['observed_value']} != {value}"

                # NOTE: This is a key used ONLY for testing cases where an expectation is legitimately allowed to return
                # any of multiple possible observed_values. expect_column_values_to_be_of_type is one such expectation.
                elif key == "observed_value_list":
                    assert result["result"]["observed_value"] in value

                elif key == "unexpected_index_list":
                    if pk_column:
>                       assert (
                            result["result"].get("unexpected_index_list") == value
                        ), f"{result['result'].get('unexpected_index_list')} != {value}"
E                       AssertionError: [{'pk_index': 4, 'column_name with space': 'bee'}] != [4]

great_expectations/self_check/util.py:3068: AssertionError
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2312.19it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 214.41it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 357.40it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 211.93it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 289.32it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 216.68it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 326.14it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 290.64it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 318.88it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 294.55it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 292.18it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 290.81it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_like_pattern:positive_test_sufficient_mostly_w_one_non_matching_value] _

test_case = {'expectation_type': 'expect_column_values_to_match_like_pattern', 'pk_column': True, 'skip': False, 'test': {'exact_m... 'a%', 'mostly': 0.7}, 'only_for': ['sqlite', 'postgresql', 'mysql', 'trino', 'bigquery', 'snowflake', ...], ...}, ...}

    @pytest.mark.order(index=0)
    @pytest.mark.integration
    @pytest.mark.slow  # 12.68s
    def test_case_runner_v3_api(test_case):
        if test_case["skip"]:
            pytest.skip()

        # Note: this should never be done in practice, but we are wiping expectations to reuse batches during testing.
        # test_case["batch"]._initialize_expectations()
        if "parse_strings_as_datetimes" in test_case["test"]["in"]:
            with pytest.deprecated_call():
                evaluate_json_test_v3_api(
                    validator=test_case["validator_with_data"],
                    expectation_type=test_case["expectation_type"],
                    test=test_case["test"],
                    pk_column=test_case["pk_column"],
                )
        else:
>           evaluate_json_test_v3_api(
                validator=test_case["validator_with_data"],
                expectation_type=test_case["expectation_type"],
                test=test_case["test"],
                pk_column=test_case["pk_column"],
            )

tests/test_definitions/test_expectations_v3_api.py:428:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
great_expectations/self_check/util.py:2900: in evaluate_json_test_v3_api
    check_json_test_result(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

test = {'exact_match_out': False, 'in': {'column': 'a', 'like_pattern': 'a%', 'mostly': 0.7}, 'input': {'column': 'a', 'like_pattern': 'a%', 'mostly': 0.7}, 'only_for': ['sqlite', 'postgresql', 'mysql', 'trino', 'bigquery', 'snowflake', ...], ...}
result = {'exception_info': {'exception_message': None, 'exception_traceback': None, 'raised_exception': False}, 'expectation_c... 5, 'missing_count': 0, 'missing_percent': 0.0, 'partial_unexpected_counts': [{'count': 1, 'value': 'bee'}], ...}, ...}
data_asset = <great_expectations.execution_engine.sqlalchemy_batch_data.SqlAlchemyBatchData object at 0x7fe2f29b7220>
pk_column = True

    def check_json_test_result(  # noqa: C901 - 52
        test, result, data_asset=None, pk_column=False
    ) -> None:

        # check for id_pk results in cases where pk_column is true and unexpected_index_list already exists
        # this will work for testing since result_format is COMPLETE
        if pk_column:
            if not result["success"]:
                if "unexpected_index_list" in result["result"]:
                    assert "unexpected_index_query" in result["result"]

        if "unexpected_list" in result["result"]:
            if ("result" in test["output"]) and (
                "unexpected_list" in test["output"]["result"]
            ):
                (
                    test["output"]["result"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["result"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                )
            elif "unexpected_list" in test["output"]:
                (
                    test["output"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                )

        if "partial_unexpected_list" in result["result"]:
            if ("result" in test["output"]) and (
                "partial_unexpected_list" in test["output"]["result"]
            ):
                (
                    test["output"]["result"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["result"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                )
            elif "partial_unexpected_list" in test["output"]:
                (
                    test["output"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                )

        # Determine if np.allclose(..) might be needed for float comparison
        try_allclose = False
        if "observed_value" in test["output"]:
            if RX_FLOAT.match(repr(test["output"]["observed_value"])):
                try_allclose = True

        # Check results
        if test["exact_match_out"] is True:
            if "result" in result and "observed_value" in result["result"]:
                if isinstance(result["result"]["observed_value"], (np.floating, float)):
                    assert np.allclose(
                        result["result"]["observed_value"],
                        expectationValidationResultSchema.load(test["output"])["result"][
                            "observed_value"
                        ],
                        rtol=RTOL,
                        atol=ATOL,
                    ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['result']['observed_value']} not np.allclose to {expectationValidationResultSchema.load(test['output'])['result']['observed_value']}"
                else:
                    assert result == expectationValidationResultSchema.load(
                        test["output"]
                    ), f"{result} != {expectationValidationResultSchema.load(test['output'])}"
            else:
                assert result == expectationValidationResultSchema.load(
                    test["output"]
                ), f"{result} != {expectationValidationResultSchema.load(test['output'])}"
        else:
            # Convert result to json since our tests are reading from json so cannot easily contain richer types (e.g. NaN)
            # NOTE - 20191031 - JPC - we may eventually want to change these tests as we update our view on how
            # representations, serializations, and objects should interact and how much of that is shown to the user.
            result = result.to_json_dict()
            for key, value in test["output"].items():
                if key == "success":
                    if isinstance(value, (np.floating, float)):
                        try:
                            assert np.allclose(
                                result["success"],
                                value,
                                rtol=RTOL,
                                atol=ATOL,
                            ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['success']} not np.allclose to {value}"
                        except TypeError:
                            assert (
                                result["success"] == value
                            ), f"{result['success']} != {value}"
                    else:
                        assert result["success"] == value, f"{result['success']} != {value}"

                elif key == "observed_value":
                    if "tolerance" in test:
                        if isinstance(value, dict):
                            assert set(result["result"]["observed_value"].keys()) == set(
                                value.keys()
                            ), f"{set(result['result']['observed_value'].keys())} != {set(value.keys())}"
                            for k, v in value.items():
                                assert np.allclose(
                                    result["result"]["observed_value"][k],
                                    v,
                                    rtol=test["tolerance"],
                                )
                        else:
                            assert np.allclose(
                                result["result"]["observed_value"],
                                value,
                                rtol=test["tolerance"],
                            )
                    else:
                        if isinstance(value, dict) and "values" in value:
                            try:
                                assert np.allclose(
                                    result["result"]["observed_value"]["values"],
                                    value["values"],
                                    rtol=RTOL,
                                    atol=ATOL,
                                ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['result']['observed_value']['values']} not np.allclose to {value['values']}"
                            except TypeError as e:
                                print(e)
                                assert (
                                    result["result"]["observed_value"] == value
                                ), f"{result['result']['observed_value']} != {value}"
                        elif try_allclose:
                            assert np.allclose(
                                result["result"]["observed_value"],
                                value,
                                rtol=RTOL,
                                atol=ATOL,
                            ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['result']['observed_value']} not np.allclose to {value}"
                        else:
                            assert (
                                result["result"]["observed_value"] == value
                            ), f"{result['result']['observed_value']} != {value}"

                # NOTE: This is a key used ONLY for testing cases where an expectation is legitimately allowed to return
                # any of multiple possible observed_values. expect_column_values_to_be_of_type is one such expectation.
                elif key == "observed_value_list":
                    assert result["result"]["observed_value"] in value

                elif key == "unexpected_index_list":
                    if pk_column:
>                       assert (
                            result["result"].get("unexpected_index_list") == value
                        ), f"{result['result'].get('unexpected_index_list')} != {value}"
E                       AssertionError: [{'pk_index': 4, 'a': 'bee'}] != [4]

great_expectations/self_check/util.py:3068: AssertionError
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 1865.79it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 215.20it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 365.46it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 213.26it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 295.16it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 225.55it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 342.20it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 307.73it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 339.22it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 318.53it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 317.18it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 315.42it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_like_pattern:negative_test_one_missing_value_and_insufficent_mostly] _

test_case = {'expectation_type': 'expect_column_values_to_match_like_pattern', 'pk_column': True, 'skip': False, 'test': {'exact_m... 'a%', 'mostly': 0.8}, 'only_for': ['sqlite', 'postgresql', 'mysql', 'trino', 'bigquery', 'snowflake', ...], ...}, ...}

    @pytest.mark.order(index=0)
    @pytest.mark.integration
    @pytest.mark.slow  # 12.68s
    def test_case_runner_v3_api(test_case):
        if test_case["skip"]:
            pytest.skip()

        # Note: this should never be done in practice, but we are wiping expectations to reuse batches during testing.
        # test_case["batch"]._initialize_expectations()
        if "parse_strings_as_datetimes" in test_case["test"]["in"]:
            with pytest.deprecated_call():
                evaluate_json_test_v3_api(
                    validator=test_case["validator_with_data"],
                    expectation_type=test_case["expectation_type"],
                    test=test_case["test"],
                    pk_column=test_case["pk_column"],
                )
        else:
>           evaluate_json_test_v3_api(
                validator=test_case["validator_with_data"],
                expectation_type=test_case["expectation_type"],
                test=test_case["test"],
                pk_column=test_case["pk_column"],
            )

tests/test_definitions/test_expectations_v3_api.py:428:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
great_expectations/self_check/util.py:2900: in evaluate_json_test_v3_api
    check_json_test_result(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

test = {'exact_match_out': False, 'in': {'column': 'b', 'like_pattern': 'a%', 'mostly': 0.8}, 'input': {'column': 'b', 'like_pattern': 'a%', 'mostly': 0.8}, 'only_for': ['sqlite', 'postgresql', 'mysql', 'trino', 'bigquery', 'snowflake', ...], ...}
result = {'exception_info': {'exception_message': None, 'exception_traceback': None, 'raised_exception': False}, 'expectation_c...5, 'missing_count': 1, 'missing_percent': 20.0, 'partial_unexpected_counts': [{'count': 1, 'value': 'bdd'}], ...}, ...}
data_asset = <great_expectations.execution_engine.sqlalchemy_batch_data.SqlAlchemyBatchData object at 0x7fe2f29b7220>
pk_column = True

    def check_json_test_result(  # noqa: C901 - 52
        test, result, data_asset=None, pk_column=False
    ) -> None:

        # check for id_pk results in cases where pk_column is true and unexpected_index_list already exists
        # this will work for testing since result_format is COMPLETE
        if pk_column:
            if not result["success"]:
                if "unexpected_index_list" in result["result"]:
                    assert "unexpected_index_query" in result["result"]

        if "unexpected_list" in result["result"]:
            if ("result" in test["output"]) and (
                "unexpected_list" in test["output"]["result"]
            ):
                (
                    test["output"]["result"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["result"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                )
            elif "unexpected_list" in test["output"]:
                (
                    test["output"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                )

        if "partial_unexpected_list" in result["result"]:
            if ("result" in test["output"]) and (
                "partial_unexpected_list" in test["output"]["result"]
            ):
                (
                    test["output"]["result"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["result"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                )
            elif "partial_unexpected_list" in test["output"]:
                (
                    test["output"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                )

        # Determine if np.allclose(..) might be needed for float comparison
        try_allclose = False
        if "observed_value" in test["output"]:
            if RX_FLOAT.match(repr(test["output"]["observed_value"])):
                try_allclose = True

        # Check results
        if test["exact_match_out"] is True:
            if "result" in result and "observed_value" in result["result"]:
                if isinstance(result["result"]["observed_value"], (np.floating, float)):
                    assert np.allclose(
                        result["result"]["observed_value"],
                        expectationValidationResultSchema.load(test["output"])["result"][
                            "observed_value"
                        ],
                        rtol=RTOL,
                        atol=ATOL,
                    ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['result']['observed_value']} not np.allclose to {expectationValidationResultSchema.load(test['output'])['result']['observed_value']}"
                else:
                    assert result == expectationValidationResultSchema.load(
                        test["output"]
                    ), f"{result} != {expectationValidationResultSchema.load(test['output'])}"
            else:
                assert result == expectationValidationResultSchema.load(
                    test["output"]
                ), f"{result} != {expectationValidationResultSchema.load(test['output'])}"
        else:
            # Convert result to json since our tests are reading from json so cannot easily contain richer types (e.g. NaN)
            # NOTE - 20191031 - JPC - we may eventually want to change these tests as we update our view on how
            # representations, serializations, and objects should interact and how much of that is shown to the user.
            result = result.to_json_dict()
            for key, value in test["output"].items():
                if key == "success":
                    if isinstance(value, (np.floating, float)):
                        try:
                            assert np.allclose(
                                result["success"],
                                value,
                                rtol=RTOL,
                                atol=ATOL,
                            ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['success']} not np.allclose to {value}"
                        except TypeError:
                            assert (
                                result["success"] == value
                            ), f"{result['success']} != {value}"
                    else:
                        assert result["success"] == value, f"{result['success']} != {value}"

                elif key == "observed_value":
                    if "tolerance" in test:
                        if isinstance(value, dict):
                            assert set(result["result"]["observed_value"].keys()) == set(
                                value.keys()
                            ), f"{set(result['result']['observed_value'].keys())} != {set(value.keys())}"
                            for k, v in value.items():
                                assert np.allclose(
                                    result["result"]["observed_value"][k],
                                    v,
                                    rtol=test["tolerance"],
                                )
                        else:
                            assert np.allclose(
                                result["result"]["observed_value"],
                                value,
                                rtol=test["tolerance"],
                            )
                    else:
                        if isinstance(value, dict) and "values" in value:
                            try:
                                assert np.allclose(
                                    result["result"]["observed_value"]["values"],
                                    value["values"],
                                    rtol=RTOL,
                                    atol=ATOL,
                                ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['result']['observed_value']['values']} not np.allclose to {value['values']}"
                            except TypeError as e:
                                print(e)
                                assert (
                                    result["result"]["observed_value"] == value
                                ), f"{result['result']['observed_value']} != {value}"
                        elif try_allclose:
                            assert np.allclose(
                                result["result"]["observed_value"],
                                value,
                                rtol=RTOL,
                                atol=ATOL,
                            ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['result']['observed_value']} not np.allclose to {value}"
                        else:
                            assert (
                                result["result"]["observed_value"] == value
                            ), f"{result['result']['observed_value']} != {value}"

                # NOTE: This is a key used ONLY for testing cases where an expectation is legitimately allowed to return
                # any of multiple possible observed_values. expect_column_values_to_be_of_type is one such expectation.
                elif key == "observed_value_list":
                    assert result["result"]["observed_value"] in value

                elif key == "unexpected_index_list":
                    if pk_column:
>                       assert (
                            result["result"].get("unexpected_index_list") == value
                        ), f"{result['result'].get('unexpected_index_list')} != {value}"
E                       AssertionError: [{'pk_index': 3, 'b': 'bdd'}] != [3]

great_expectations/self_check/util.py:3068: AssertionError
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 1831.57it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 201.29it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 353.11it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 212.90it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 295.68it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 220.92it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 341.10it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 308.81it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 332.44it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 312.70it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 311.49it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 310.46it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_like_pattern:positive_test_one_missing_value_and_exact_mostly] _

test_case = {'expectation_type': 'expect_column_values_to_match_like_pattern', 'pk_column': True, 'skip': False, 'test': {'exact_m...'a%', 'mostly': 0.75}, 'only_for': ['sqlite', 'postgresql', 'mysql', 'trino', 'bigquery', 'snowflake', ...], ...}, ...}

    @pytest.mark.order(index=0)
    @pytest.mark.integration
    @pytest.mark.slow  # 12.68s
    def test_case_runner_v3_api(test_case):
        if test_case["skip"]:
            pytest.skip()

        # Note: this should never be done in practice, but we are wiping expectations to reuse batches during testing.
        # test_case["batch"]._initialize_expectations()
        if "parse_strings_as_datetimes" in test_case["test"]["in"]:
            with pytest.deprecated_call():
                evaluate_json_test_v3_api(
                    validator=test_case["validator_with_data"],
                    expectation_type=test_case["expectation_type"],
                    test=test_case["test"],
                    pk_column=test_case["pk_column"],
                )
        else:
>           evaluate_json_test_v3_api(
                validator=test_case["validator_with_data"],
                expectation_type=test_case["expectation_type"],
                test=test_case["test"],
                pk_column=test_case["pk_column"],
            )

tests/test_definitions/test_expectations_v3_api.py:428:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
great_expectations/self_check/util.py:2900: in evaluate_json_test_v3_api
    check_json_test_result(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

test = {'exact_match_out': False, 'in': {'column': 'b', 'like_pattern': 'a%', 'mostly': 0.75}, 'input': {'column': 'b', 'like...ern': 'a%', 'mostly': 0.75}, 'only_for': ['sqlite', 'postgresql', 'mysql', 'trino', 'bigquery', 'snowflake', ...], ...}
result = {'exception_info': {'exception_message': None, 'exception_traceback': None, 'raised_exception': False}, 'expectation_c...5, 'missing_count': 1, 'missing_percent': 20.0, 'partial_unexpected_counts': [{'count': 1, 'value': 'bdd'}], ...}, ...}
data_asset = <great_expectations.execution_engine.sqlalchemy_batch_data.SqlAlchemyBatchData object at 0x7fe2f29b7220>
pk_column = True

    def check_json_test_result(  # noqa: C901 - 52
        test, result, data_asset=None, pk_column=False
    ) -> None:

        # check for id_pk results in cases where pk_column is true and unexpected_index_list already exists
        # this will work for testing since result_format is COMPLETE
        if pk_column:
            if not result["success"]:
                if "unexpected_index_list" in result["result"]:
                    assert "unexpected_index_query" in result["result"]

        if "unexpected_list" in result["result"]:
            if ("result" in test["output"]) and (
                "unexpected_list" in test["output"]["result"]
            ):
                (
                    test["output"]["result"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["result"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                )
            elif "unexpected_list" in test["output"]:
                (
                    test["output"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                )

        if "partial_unexpected_list" in result["result"]:
            if ("result" in test["output"]) and (
                "partial_unexpected_list" in test["output"]["result"]
            ):
                (
                    test["output"]["result"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["result"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                )
            elif "partial_unexpected_list" in test["output"]:
                (
                    test["output"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                )

        # Determine if np.allclose(..) might be needed for float comparison
        try_allclose = False
        if "observed_value" in test["output"]:
            if RX_FLOAT.match(repr(test["output"]["observed_value"])):
                try_allclose = True

        # Check results
        if test["exact_match_out"] is True:
            if "result" in result and "observed_value" in result["result"]:
                if isinstance(result["result"]["observed_value"], (np.floating, float)):
                    assert np.allclose(
                        result["result"]["observed_value"],
                        expectationValidationResultSchema.load(test["output"])["result"][
                            "observed_value"
                        ],
                        rtol=RTOL,
                        atol=ATOL,
                    ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['result']['observed_value']} not np.allclose to {expectationValidationResultSchema.load(test['output'])['result']['observed_value']}"
                else:
                    assert result == expectationValidationResultSchema.load(
                        test["output"]
                    ), f"{result} != {expectationValidationResultSchema.load(test['output'])}"
            else:
                assert result == expectationValidationResultSchema.load(
                    test["output"]
                ), f"{result} != {expectationValidationResultSchema.load(test['output'])}"
        else:
            # Convert result to json since our tests are reading from json so cannot easily contain richer types (e.g. NaN)
            # NOTE - 20191031 - JPC - we may eventually want to change these tests as we update our view on how
            # representations, serializations, and objects should interact and how much of that is shown to the user.
            result = result.to_json_dict()
            for key, value in test["output"].items():
                if key == "success":
                    if isinstance(value, (np.floating, float)):
                        try:
                            assert np.allclose(
                                result["success"],
                                value,
                                rtol=RTOL,
                                atol=ATOL,
                            ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['success']} not np.allclose to {value}"
                        except TypeError:
                            assert (
                                result["success"] == value
                            ), f"{result['success']} != {value}"
                    else:
                        assert result["success"] == value, f"{result['success']} != {value}"

                elif key == "observed_value":
                    if "tolerance" in test:
                        if isinstance(value, dict):
                            assert set(result["result"]["observed_value"].keys()) == set(
                                value.keys()
                            ), f"{set(result['result']['observed_value'].keys())} != {set(value.keys())}"
                            for k, v in value.items():
                                assert np.allclose(
                                    result["result"]["observed_value"][k],
                                    v,
                                    rtol=test["tolerance"],
                                )
                        else:
                            assert np.allclose(
                                result["result"]["observed_value"],
                                value,
                                rtol=test["tolerance"],
                            )
                    else:
                        if isinstance(value, dict) and "values" in value:
                            try:
                                assert np.allclose(
                                    result["result"]["observed_value"]["values"],
                                    value["values"],
                                    rtol=RTOL,
                                    atol=ATOL,
                                ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['result']['observed_value']['values']} not np.allclose to {value['values']}"
                            except TypeError as e:
                                print(e)
                                assert (
                                    result["result"]["observed_value"] == value
                                ), f"{result['result']['observed_value']} != {value}"
                        elif try_allclose:
                            assert np.allclose(
                                result["result"]["observed_value"],
                                value,
                                rtol=RTOL,
                                atol=ATOL,
                            ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['result']['observed_value']} not np.allclose to {value}"
                        else:
                            assert (
                                result["result"]["observed_value"] == value
                            ), f"{result['result']['observed_value']} != {value}"

                # NOTE: This is a key used ONLY for testing cases where an expectation is legitimately allowed to return
                # any of multiple possible observed_values. expect_column_values_to_be_of_type is one such expectation.
                elif key == "observed_value_list":
                    assert result["result"]["observed_value"] in value

                elif key == "unexpected_index_list":
                    if pk_column:
>                       assert (
                            result["result"].get("unexpected_index_list") == value
                        ), f"{result['result'].get('unexpected_index_list')} != {value}"
E                       AssertionError: [{'pk_index': 3, 'b': 'bdd'}] != [3]

great_expectations/self_check/util.py:3068: AssertionError
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2363.65it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 253.03it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 418.90it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 245.02it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 336.42it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 253.87it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 393.35it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 352.63it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 381.77it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 357.29it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 355.93it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 354.56it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_like_pattern:positive_test_one_missing_value_and_sufficent_mostly] _

test_case = {'expectation_type': 'expect_column_values_to_match_like_pattern', 'pk_column': True, 'skip': False, 'test': {'exact_m... 'a%', 'mostly': 0.7}, 'only_for': ['sqlite', 'postgresql', 'mysql', 'trino', 'bigquery', 'snowflake', ...], ...}, ...}

    @pytest.mark.order(index=0)
    @pytest.mark.integration
    @pytest.mark.slow  # 12.68s
    def test_case_runner_v3_api(test_case):
        if test_case["skip"]:
            pytest.skip()

        # Note: this should never be done in practice, but we are wiping expectations to reuse batches during testing.
        # test_case["batch"]._initialize_expectations()
        if "parse_strings_as_datetimes" in test_case["test"]["in"]:
            with pytest.deprecated_call():
                evaluate_json_test_v3_api(
                    validator=test_case["validator_with_data"],
                    expectation_type=test_case["expectation_type"],
                    test=test_case["test"],
                    pk_column=test_case["pk_column"],
                )
        else:
>           evaluate_json_test_v3_api(
                validator=test_case["validator_with_data"],
                expectation_type=test_case["expectation_type"],
                test=test_case["test"],
                pk_column=test_case["pk_column"],
            )

tests/test_definitions/test_expectations_v3_api.py:428:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
great_expectations/self_check/util.py:2900: in evaluate_json_test_v3_api
    check_json_test_result(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

test = {'exact_match_out': False, 'in': {'column': 'b', 'like_pattern': 'a%', 'mostly': 0.7}, 'input': {'column': 'b', 'like_pattern': 'a%', 'mostly': 0.7}, 'only_for': ['sqlite', 'postgresql', 'mysql', 'trino', 'bigquery', 'snowflake', ...], ...}
result = {'exception_info': {'exception_message': None, 'exception_traceback': None, 'raised_exception': False}, 'expectation_c...5, 'missing_count': 1, 'missing_percent': 20.0, 'partial_unexpected_counts': [{'count': 1, 'value': 'bdd'}], ...}, ...}
data_asset = <great_expectations.execution_engine.sqlalchemy_batch_data.SqlAlchemyBatchData object at 0x7fe2f29b7220>
pk_column = True

    def check_json_test_result(  # noqa: C901 - 52
        test, result, data_asset=None, pk_column=False
    ) -> None:

        # check for id_pk results in cases where pk_column is true and unexpected_index_list already exists
        # this will work for testing since result_format is COMPLETE
        if pk_column:
            if not result["success"]:
                if "unexpected_index_list" in result["result"]:
                    assert "unexpected_index_query" in result["result"]

        if "unexpected_list" in result["result"]:
            if ("result" in test["output"]) and (
                "unexpected_list" in test["output"]["result"]
            ):
                (
                    test["output"]["result"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["result"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                )
            elif "unexpected_list" in test["output"]:
                (
                    test["output"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                )

        if "partial_unexpected_list" in result["result"]:
            if ("result" in test["output"]) and (
                "partial_unexpected_list" in test["output"]["result"]
            ):
                (
                    test["output"]["result"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["result"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                )
            elif "partial_unexpected_list" in test["output"]:
                (
                    test["output"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                )

        # Determine if np.allclose(..) might be needed for float comparison
        try_allclose = False
        if "observed_value" in test["output"]:
            if RX_FLOAT.match(repr(test["output"]["observed_value"])):
                try_allclose = True

        # Check results
        if test["exact_match_out"] is True:
            if "result" in result and "observed_value" in result["result"]:
                if isinstance(result["result"]["observed_value"], (np.floating, float)):
                    assert np.allclose(
                        result["result"]["observed_value"],
                        expectationValidationResultSchema.load(test["output"])["result"][
                            "observed_value"
                        ],
                        rtol=RTOL,
                        atol=ATOL,
                    ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['result']['observed_value']} not np.allclose to {expectationValidationResultSchema.load(test['output'])['result']['observed_value']}"
                else:
                    assert result == expectationValidationResultSchema.load(
                        test["output"]
                    ), f"{result} != {expectationValidationResultSchema.load(test['output'])}"
            else:
                assert result == expectationValidationResultSchema.load(
                    test["output"]
                ), f"{result} != {expectationValidationResultSchema.load(test['output'])}"
        else:
            # Convert result to json since our tests are reading from json so cannot easily contain richer types (e.g. NaN)
            # NOTE - 20191031 - JPC - we may eventually want to change these tests as we update our view on how
            # representations, serializations, and objects should interact and how much of that is shown to the user.
            result = result.to_json_dict()
            for key, value in test["output"].items():
                if key == "success":
                    if isinstance(value, (np.floating, float)):
                        try:
                            assert np.allclose(
                                result["success"],
                                value,
                                rtol=RTOL,
                                atol=ATOL,
                            ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['success']} not np.allclose to {value}"
                        except TypeError:
                            assert (
                                result["success"] == value
                            ), f"{result['success']} != {value}"
                    else:
                        assert result["success"] == value, f"{result['success']} != {value}"

                elif key == "observed_value":
                    if "tolerance" in test:
                        if isinstance(value, dict):
                            assert set(result["result"]["observed_value"].keys()) == set(
                                value.keys()
                            ), f"{set(result['result']['observed_value'].keys())} != {set(value.keys())}"
                            for k, v in value.items():
                                assert np.allclose(
                                    result["result"]["observed_value"][k],
                                    v,
                                    rtol=test["tolerance"],
                                )
                        else:
                            assert np.allclose(
                                result["result"]["observed_value"],
                                value,
                                rtol=test["tolerance"],
                            )
                    else:
                        if isinstance(value, dict) and "values" in value:
                            try:
                                assert np.allclose(
                                    result["result"]["observed_value"]["values"],
                                    value["values"],
                                    rtol=RTOL,
                                    atol=ATOL,
                                ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['result']['observed_value']['values']} not np.allclose to {value['values']}"
                            except TypeError as e:
                                print(e)
                                assert (
                                    result["result"]["observed_value"] == value
                                ), f"{result['result']['observed_value']} != {value}"
                        elif try_allclose:
                            assert np.allclose(
                                result["result"]["observed_value"],
                                value,
                                rtol=RTOL,
                                atol=ATOL,
                            ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['result']['observed_value']} not np.allclose to {value}"
                        else:
                            assert (
                                result["result"]["observed_value"] == value
                            ), f"{result['result']['observed_value']} != {value}"

                # NOTE: This is a key used ONLY for testing cases where an expectation is legitimately allowed to return
                # any of multiple possible observed_values. expect_column_values_to_be_of_type is one such expectation.
                elif key == "observed_value_list":
                    assert result["result"]["observed_value"] in value

                elif key == "unexpected_index_list":
                    if pk_column:
>                       assert (
                            result["result"].get("unexpected_index_list") == value
                        ), f"{result['result'].get('unexpected_index_list')} != {value}"
E                       AssertionError: [{'pk_index': 3, 'b': 'bdd'}] != [3]

great_expectations/self_check/util.py:3068: AssertionError
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2336.66it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 228.16it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 383.92it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 222.03it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 306.67it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 234.45it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 356.87it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 322.26it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 347.63it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 321.02it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 319.61it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 318.41it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_like_pattern:positive_test_match_characters_not_at_the_beginning_of_string] _

test_case = {'expectation_type': 'expect_column_values_to_match_like_pattern', 'pk_column': True, 'skip': False, 'test': {'exact_m...'%b%', 'mostly': 0.4}, 'only_for': ['sqlite', 'postgresql', 'mysql', 'trino', 'bigquery', 'snowflake', ...], ...}, ...}

    @pytest.mark.order(index=0)
    @pytest.mark.integration
    @pytest.mark.slow  # 12.68s
    def test_case_runner_v3_api(test_case):
        if test_case["skip"]:
            pytest.skip()

        # Note: this should never be done in practice, but we are wiping expectations to reuse batches during testing.
        # test_case["batch"]._initialize_expectations()
        if "parse_strings_as_datetimes" in test_case["test"]["in"]:
            with pytest.deprecated_call():
                evaluate_json_test_v3_api(
                    validator=test_case["validator_with_data"],
                    expectation_type=test_case["expectation_type"],
                    test=test_case["test"],
                    pk_column=test_case["pk_column"],
                )
        else:
>           evaluate_json_test_v3_api(
                validator=test_case["validator_with_data"],
                expectation_type=test_case["expectation_type"],
                test=test_case["test"],
                pk_column=test_case["pk_column"],
            )

tests/test_definitions/test_expectations_v3_api.py:428:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
great_expectations/self_check/util.py:2900: in evaluate_json_test_v3_api
    check_json_test_result(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

test = {'exact_match_out': False, 'in': {'column': 'a', 'like_pattern': '%b%', 'mostly': 0.4}, 'input': {'column': 'a', 'like...ern': '%b%', 'mostly': 0.4}, 'only_for': ['sqlite', 'postgresql', 'mysql', 'trino', 'bigquery', 'snowflake', ...], ...}
result = {'exception_info': {'exception_message': None, 'exception_traceback': None, 'raised_exception': False}, 'expectation_c...xpected_counts': [{'count': 1, 'value': 'aaa'}, {'count': 1, 'value': 'acc'}, {'count': 1, 'value': 'add'}], ...}, ...}
data_asset = <great_expectations.execution_engine.sqlalchemy_batch_data.SqlAlchemyBatchData object at 0x7fe2f29b7220>
pk_column = True

    def check_json_test_result(  # noqa: C901 - 52
        test, result, data_asset=None, pk_column=False
    ) -> None:

        # check for id_pk results in cases where pk_column is true and unexpected_index_list already exists
        # this will work for testing since result_format is COMPLETE
        if pk_column:
            if not result["success"]:
                if "unexpected_index_list" in result["result"]:
                    assert "unexpected_index_query" in result["result"]

        if "unexpected_list" in result["result"]:
            if ("result" in test["output"]) and (
                "unexpected_list" in test["output"]["result"]
            ):
                (
                    test["output"]["result"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["result"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                )
            elif "unexpected_list" in test["output"]:
                (
                    test["output"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                )

        if "partial_unexpected_list" in result["result"]:
            if ("result" in test["output"]) and (
                "partial_unexpected_list" in test["output"]["result"]
            ):
                (
                    test["output"]["result"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["result"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                )
            elif "partial_unexpected_list" in test["output"]:
                (
                    test["output"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                )

        # Determine if np.allclose(..) might be needed for float comparison
        try_allclose = False
        if "observed_value" in test["output"]:
            if RX_FLOAT.match(repr(test["output"]["observed_value"])):
                try_allclose = True

        # Check results
        if test["exact_match_out"] is True:
            if "result" in result and "observed_value" in result["result"]:
                if isinstance(result["result"]["observed_value"], (np.floating, float)):
                    assert np.allclose(
                        result["result"]["observed_value"],
                        expectationValidationResultSchema.load(test["output"])["result"][
                            "observed_value"
                        ],
                        rtol=RTOL,
                        atol=ATOL,
                    ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['result']['observed_value']} not np.allclose to {expectationValidationResultSchema.load(test['output'])['result']['observed_value']}"
                else:
                    assert result == expectationValidationResultSchema.load(
                        test["output"]
                    ), f"{result} != {expectationValidationResultSchema.load(test['output'])}"
            else:
                assert result == expectationValidationResultSchema.load(
                    test["output"]
                ), f"{result} != {expectationValidationResultSchema.load(test['output'])}"
        else:
            # Convert result to json since our tests are reading from json so cannot easily contain richer types (e.g. NaN)
            # NOTE - 20191031 - JPC - we may eventually want to change these tests as we update our view on how
            # representations, serializations, and objects should interact and how much of that is shown to the user.
            result = result.to_json_dict()
            for key, value in test["output"].items():
                if key == "success":
                    if isinstance(value, (np.floating, float)):
                        try:
                            assert np.allclose(
                                result["success"],
                                value,
                                rtol=RTOL,
                                atol=ATOL,
                            ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['success']} not np.allclose to {value}"
                        except TypeError:
                            assert (
                                result["success"] == value
                            ), f"{result['success']} != {value}"
                    else:
                        assert result["success"] == value, f"{result['success']} != {value}"

                elif key == "observed_value":
                    if "tolerance" in test:
                        if isinstance(value, dict):
                            assert set(result["result"]["observed_value"].keys()) == set(
                                value.keys()
                            ), f"{set(result['result']['observed_value'].keys())} != {set(value.keys())}"
                            for k, v in value.items():
                                assert np.allclose(
                                    result["result"]["observed_value"][k],
                                    v,
                                    rtol=test["tolerance"],
                                )
                        else:
                            assert np.allclose(
                                result["result"]["observed_value"],
                                value,
                                rtol=test["tolerance"],
                            )
                    else:
                        if isinstance(value, dict) and "values" in value:
                            try:
                                assert np.allclose(
                                    result["result"]["observed_value"]["values"],
                                    value["values"],
                                    rtol=RTOL,
                                    atol=ATOL,
                                ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['result']['observed_value']['values']} not np.allclose to {value['values']}"
                            except TypeError as e:
                                print(e)
                                assert (
                                    result["result"]["observed_value"] == value
                                ), f"{result['result']['observed_value']} != {value}"
                        elif try_allclose:
                            assert np.allclose(
                                result["result"]["observed_value"],
                                value,
                                rtol=RTOL,
                                atol=ATOL,
                            ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['result']['observed_value']} not np.allclose to {value}"
                        else:
                            assert (
                                result["result"]["observed_value"] == value
                            ), f"{result['result']['observed_value']} != {value}"

                # NOTE: This is a key used ONLY for testing cases where an expectation is legitimately allowed to return
                # any of multiple possible observed_values. expect_column_values_to_be_of_type is one such expectation.
                elif key == "observed_value_list":
                    assert result["result"]["observed_value"] in value

                elif key == "unexpected_index_list":
                    if pk_column:
>                       assert (
                            result["result"].get("unexpected_index_list") == value
                        ), f"{result['result'].get('unexpected_index_list')} != {value}"
E                       AssertionError: [{'pk_index': 0, 'a': 'aaa'}, {'pk_index': 2, 'a': 'acc'}, {'pk_index': 3, 'a': 'add'}] != [0, 2, 3]

great_expectations/self_check/util.py:3068: AssertionError
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2463.61it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 253.55it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 421.19it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 248.54it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 343.96it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 258.98it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 403.74it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 362.52it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 399.81it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 373.66it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 372.44it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 370.93it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_like_pattern_list:basic_negative_test] _

test_case = {'expectation_type': 'expect_column_values_to_match_like_pattern_list', 'pk_column': True, 'skip': False, 'test': {'ex...e_in_gallery': True, 'input': {'column': 'w', 'like_pattern_list': ['[123]+', '[456]+'], 'match_on': 'all'}, ...}, ...}

    @pytest.mark.order(index=0)
    @pytest.mark.integration
    @pytest.mark.slow  # 12.68s
    def test_case_runner_v3_api(test_case):
        if test_case["skip"]:
            pytest.skip()

        # Note: this should never be done in practice, but we are wiping expectations to reuse batches during testing.
        # test_case["batch"]._initialize_expectations()
        if "parse_strings_as_datetimes" in test_case["test"]["in"]:
            with pytest.deprecated_call():
                evaluate_json_test_v3_api(
                    validator=test_case["validator_with_data"],
                    expectation_type=test_case["expectation_type"],
                    test=test_case["test"],
                    pk_column=test_case["pk_column"],
                )
        else:
>           evaluate_json_test_v3_api(
                validator=test_case["validator_with_data"],
                expectation_type=test_case["expectation_type"],
                test=test_case["test"],
                pk_column=test_case["pk_column"],
            )

tests/test_definitions/test_expectations_v3_api.py:428:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
great_expectations/self_check/util.py:2900: in evaluate_json_test_v3_api
    check_json_test_result(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

test = {'exact_match_out': False, 'in': {'column': 'w', 'like_pattern_list': ['[123]+', '[456]+'], 'match_on': 'all'}, 'include_in_gallery': True, 'input': {'column': 'w', 'like_pattern_list': ['[123]+', '[456]+'], 'match_on': 'all'}, ...}
result = {'exception_info': {'exception_message': None, 'exception_traceback': None, 'raised_exception': False}, 'expectation_c...ue': '222'}, {'count': 1, 'value': '321'}, {'count': 1, 'value': '333'}, {'count': 1, 'value': '444'}, ...], ...}, ...}
data_asset = <great_expectations.execution_engine.sqlalchemy_batch_data.SqlAlchemyBatchData object at 0x7fe2f2a9a9d0>
pk_column = True

    def check_json_test_result(  # noqa: C901 - 52
        test, result, data_asset=None, pk_column=False
    ) -> None:

        # check for id_pk results in cases where pk_column is true and unexpected_index_list already exists
        # this will work for testing since result_format is COMPLETE
        if pk_column:
            if not result["success"]:
                if "unexpected_index_list" in result["result"]:
                    assert "unexpected_index_query" in result["result"]

        if "unexpected_list" in result["result"]:
            if ("result" in test["output"]) and (
                "unexpected_list" in test["output"]["result"]
            ):
                (
                    test["output"]["result"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["result"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                )
            elif "unexpected_list" in test["output"]:
                (
                    test["output"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                )

        if "partial_unexpected_list" in result["result"]:
            if ("result" in test["output"]) and (
                "partial_unexpected_list" in test["output"]["result"]
            ):
                (
                    test["output"]["result"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["result"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                )
            elif "partial_unexpected_list" in test["output"]:
                (
                    test["output"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                )

        # Determine if np.allclose(..) might be needed for float comparison
        try_allclose = False
        if "observed_value" in test["output"]:
            if RX_FLOAT.match(repr(test["output"]["observed_value"])):
                try_allclose = True

        # Check results
        if test["exact_match_out"] is True:
            if "result" in result and "observed_value" in result["result"]:
                if isinstance(result["result"]["observed_value"], (np.floating, float)):
                    assert np.allclose(
                        result["result"]["observed_value"],
                        expectationValidationResultSchema.load(test["output"])["result"][
                            "observed_value"
                        ],
                        rtol=RTOL,
                        atol=ATOL,
                    ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['result']['observed_value']} not np.allclose to {expectationValidationResultSchema.load(test['output'])['result']['observed_value']}"
                else:
                    assert result == expectationValidationResultSchema.load(
                        test["output"]
                    ), f"{result} != {expectationValidationResultSchema.load(test['output'])}"
            else:
                assert result == expectationValidationResultSchema.load(
                    test["output"]
                ), f"{result} != {expectationValidationResultSchema.load(test['output'])}"
        else:
            # Convert result to json since our tests are reading from json so cannot easily contain richer types (e.g. NaN)
            # NOTE - 20191031 - JPC - we may eventually want to change these tests as we update our view on how
            # representations, serializations, and objects should interact and how much of that is shown to the user.
            result = result.to_json_dict()
            for key, value in test["output"].items():
                if key == "success":
                    if isinstance(value, (np.floating, float)):
                        try:
                            assert np.allclose(
                                result["success"],
                                value,
                                rtol=RTOL,
                                atol=ATOL,
                            ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['success']} not np.allclose to {value}"
                        except TypeError:
                            assert (
                                result["success"] == value
                            ), f"{result['success']} != {value}"
                    else:
                        assert result["success"] == value, f"{result['success']} != {value}"

                elif key == "observed_value":
                    if "tolerance" in test:
                        if isinstance(value, dict):
                            assert set(result["result"]["observed_value"].keys()) == set(
                                value.keys()
                            ), f"{set(result['result']['observed_value'].keys())} != {set(value.keys())}"
                            for k, v in value.items():
                                assert np.allclose(
                                    result["result"]["observed_value"][k],
                                    v,
                                    rtol=test["tolerance"],
                                )
                        else:
                            assert np.allclose(
                                result["result"]["observed_value"],
                                value,
                                rtol=test["tolerance"],
                            )
                    else:
                        if isinstance(value, dict) and "values" in value:
                            try:
                                assert np.allclose(
                                    result["result"]["observed_value"]["values"],
                                    value["values"],
                                    rtol=RTOL,
                                    atol=ATOL,
                                ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['result']['observed_value']['values']} not np.allclose to {value['values']}"
                            except TypeError as e:
                                print(e)
                                assert (
                                    result["result"]["observed_value"] == value
                                ), f"{result['result']['observed_value']} != {value}"
                        elif try_allclose:
                            assert np.allclose(
                                result["result"]["observed_value"],
                                value,
                                rtol=RTOL,
                                atol=ATOL,
                            ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['result']['observed_value']} not np.allclose to {value}"
                        else:
                            assert (
                                result["result"]["observed_value"] == value
                            ), f"{result['result']['observed_value']} != {value}"

                # NOTE: This is a key used ONLY for testing cases where an expectation is legitimately allowed to return
                # any of multiple possible observed_values. expect_column_values_to_be_of_type is one such expectation.
                elif key == "observed_value_list":
                    assert result["result"]["observed_value"] in value

                elif key == "unexpected_index_list":
                    if pk_column:
>                       assert (
                            result["result"].get("unexpected_index_list") == value
                        ), f"{result['result'].get('unexpected_index_list')} != {value}"
E                       AssertionError: [{'pk_index': 0, 'w': '111'}, {'pk_index': 1, 'w': '222'}, {'pk_index': 2, 'w': '333'}, {'pk_index': 3, 'w': '123'}, {'pk_index': 4, 'w': '321'}, {'pk_index': 5, 'w': '444'}, {'pk_index': 6, 'w': '456'}, {'pk_index': 7, 'w': '654'}, {'pk_index': 8, 'w': '555'}] != [0, 1, 2, 3, 4, 5, 6, 7, 8]

great_expectations/self_check/util.py:3068: AssertionError
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2157.56it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 226.53it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 365.56it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 195.81it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 261.39it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 196.20it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 300.37it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 271.99it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 294.63it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 277.87it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 276.88it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 275.99it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_like_pattern_list:negative_test_with_more_string-ish_strings] _

test_case = {'expectation_type': 'expect_column_values_to_match_like_pattern_list', 'pk_column': True, 'skip': False, 'test': {'ex...pattern_list': ['%a%']}, 'input': {'column': 'x', 'like_pattern_list': ['%a%']}, 'only_for': ['sqlalchemy'], ...}, ...}

    @pytest.mark.order(index=0)
    @pytest.mark.integration
    @pytest.mark.slow  # 12.68s
    def test_case_runner_v3_api(test_case):
        if test_case["skip"]:
            pytest.skip()

        # Note: this should never be done in practice, but we are wiping expectations to reuse batches during testing.
        # test_case["batch"]._initialize_expectations()
        if "parse_strings_as_datetimes" in test_case["test"]["in"]:
            with pytest.deprecated_call():
                evaluate_json_test_v3_api(
                    validator=test_case["validator_with_data"],
                    expectation_type=test_case["expectation_type"],
                    test=test_case["test"],
                    pk_column=test_case["pk_column"],
                )
        else:
>           evaluate_json_test_v3_api(
                validator=test_case["validator_with_data"],
                expectation_type=test_case["expectation_type"],
                test=test_case["test"],
                pk_column=test_case["pk_column"],
            )

tests/test_definitions/test_expectations_v3_api.py:428:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
great_expectations/self_check/util.py:2900: in evaluate_json_test_v3_api
    check_json_test_result(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

test = {'exact_match_out': False, 'in': {'column': 'x', 'like_pattern_list': ['%a%']}, 'input': {'column': 'x', 'like_pattern_list': ['%a%']}, 'only_for': ['sqlalchemy'], ...}
result = {'exception_info': {'exception_message': None, 'exception_traceback': None, 'raised_exception': False}, 'expectation_c... 'value': 'bet'}, {'count': 1, 'value': 'bit'}, {'count': 1, 'value': 'bot'}, {'count': 1, 'value': 'but'}], ...}, ...}
data_asset = <great_expectations.execution_engine.sqlalchemy_batch_data.SqlAlchemyBatchData object at 0x7fe2f2a9a9d0>
pk_column = True

    def check_json_test_result(  # noqa: C901 - 52
        test, result, data_asset=None, pk_column=False
    ) -> None:

        # check for id_pk results in cases where pk_column is true and unexpected_index_list already exists
        # this will work for testing since result_format is COMPLETE
        if pk_column:
            if not result["success"]:
                if "unexpected_index_list" in result["result"]:
                    assert "unexpected_index_query" in result["result"]

        if "unexpected_list" in result["result"]:
            if ("result" in test["output"]) and (
                "unexpected_list" in test["output"]["result"]
            ):
                (
                    test["output"]["result"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["result"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                )
            elif "unexpected_list" in test["output"]:
                (
                    test["output"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["unexpected_list"],
                    result["result"]["unexpected_list"],
                )

        if "partial_unexpected_list" in result["result"]:
            if ("result" in test["output"]) and (
                "partial_unexpected_list" in test["output"]["result"]
            ):
                (
                    test["output"]["result"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["result"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                )
            elif "partial_unexpected_list" in test["output"]:
                (
                    test["output"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                ) = sort_unexpected_values(
                    test["output"]["partial_unexpected_list"],
                    result["result"]["partial_unexpected_list"],
                )

        # Determine if np.allclose(..) might be needed for float comparison
        try_allclose = False
        if "observed_value" in test["output"]:
            if RX_FLOAT.match(repr(test["output"]["observed_value"])):
                try_allclose = True

        # Check results
        if test["exact_match_out"] is True:
            if "result" in result and "observed_value" in result["result"]:
                if isinstance(result["result"]["observed_value"], (np.floating, float)):
                    assert np.allclose(
                        result["result"]["observed_value"],
                        expectationValidationResultSchema.load(test["output"])["result"][
                            "observed_value"
                        ],
                        rtol=RTOL,
                        atol=ATOL,
                    ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['result']['observed_value']} not np.allclose to {expectationValidationResultSchema.load(test['output'])['result']['observed_value']}"
                else:
                    assert result == expectationValidationResultSchema.load(
                        test["output"]
                    ), f"{result} != {expectationValidationResultSchema.load(test['output'])}"
            else:
                assert result == expectationValidationResultSchema.load(
                    test["output"]
                ), f"{result} != {expectationValidationResultSchema.load(test['output'])}"
        else:
            # Convert result to json since our tests are reading from json so cannot easily contain richer types (e.g. NaN)
            # NOTE - 20191031 - JPC - we may eventually want to change these tests as we update our view on how
            # representations, serializations, and objects should interact and how much of that is shown to the user.
            result = result.to_json_dict()
            for key, value in test["output"].items():
                if key == "success":
                    if isinstance(value, (np.floating, float)):
                        try:
                            assert np.allclose(
                                result["success"],
                                value,
                                rtol=RTOL,
                                atol=ATOL,
                            ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['success']} not np.allclose to {value}"
                        except TypeError:
                            assert (
                                result["success"] == value
                            ), f"{result['success']} != {value}"
                    else:
                        assert result["success"] == value, f"{result['success']} != {value}"

                elif key == "observed_value":
                    if "tolerance" in test:
                        if isinstance(value, dict):
                            assert set(result["result"]["observed_value"].keys()) == set(
                                value.keys()
                            ), f"{set(result['result']['observed_value'].keys())} != {set(value.keys())}"
                            for k, v in value.items():
                                assert np.allclose(
                                    result["result"]["observed_value"][k],
                                    v,
                                    rtol=test["tolerance"],
                                )
                        else:
                            assert np.allclose(
                                result["result"]["observed_value"],
                                value,
                                rtol=test["tolerance"],
                            )
                    else:
                        if isinstance(value, dict) and "values" in value:
                            try:
                                assert np.allclose(
                                    result["result"]["observed_value"]["values"],
                                    value["values"],
                                    rtol=RTOL,
                                    atol=ATOL,
                                ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['result']['observed_value']['values']} not np.allclose to {value['values']}"
                            except TypeError as e:
                                print(e)
                                assert (
                                    result["result"]["observed_value"] == value
                                ), f"{result['result']['observed_value']} != {value}"
                        elif try_allclose:
                            assert np.allclose(
                                result["result"]["observed_value"],
                                value,
                                rtol=RTOL,
                                atol=ATOL,
                            ), f"(RTOL={RTOL}, ATOL={ATOL}) {result['result']['observed_value']} not np.allclose to {value}"
                        else:
                            assert (
                                result["result"]["observed_value"] == value
                            ), f"{result['result']['observed_value']} != {value}"

                # NOTE: This is a key used ONLY for testing cases where an expectation is legitimately allowed to return
                # any of multiple possible observed_values. expect_column_values_to_be_of_type is one such expectation.
                elif key == "observed_value_list":
                    assert result["result"]["observed_value"] in value

                elif key == "unexpected_index_list":
                    if pk_column:
>                       assert (
                            result["result"].get("unexpected_index_list") == value
                        ), f"{result['result'].get('unexpected_index_list')} != {value}"
E                       AssertionError: [{'pk_index': 6, 'x': 'bit'}, {'pk_index': 7, 'x': 'bot'}, {'pk_index': 8, 'x': 'but'}, {'pk_index': 9, 'x': 'bet'}] != [6, 7, 8, 9]

great_expectations/self_check/util.py:3068: AssertionError
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 1765.28it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 228.57it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 396.95it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 233.85it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 322.53it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 242.97it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 359.88it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 323.55it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 352.84it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 330.61it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 329.65it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 328.53it/s]
_ test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_compound_columns_to_be_unique:mostly_default_successful_expectation] _

self = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b9edf0>
dialect = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7fe2f3b9eaf0>
constructor = <bound method DefaultExecutionContext._init_compiled of <class 'sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext'>>
statement = 'SELECT pk_index, a, b \nFROM (SELECT original_table_clause.a AS a, original_table_clause.b AS b, original_table_claus...S NULL AND b IS NULL)) AS anon_2 \nWHERE records_with_grouped_column_counts_subquery._num_rows >= ?\n LIMIT ? OFFSET ?'
parameters = (2, 20, 0), execution_options = immutabledict({})
args = (<sqlalchemy.dialects.sqlite.base.SQLiteCompiler object at 0x7fe2f83eefd0>, [], <sqlalchemy.sql.selectable.Select obje...140612804243520 num_rows)s', 2, type_=Integer()), _OffsetLimitParam('%(140612804208096 param)s', 20, type_=Integer())])
kw = {'cache_hit': symbol('CACHE_MISS')}
branched = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b9edf0>
conn = <sqlalchemy.pool.base._ConnectionFairy object at 0x7fe2f3b9ee80>
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7fe2f84052e0>
cursor = <sqlite3.Cursor object at 0x7fe2f83c0730>, evt_handled = False

    def _execute_context(
        self,
        dialect,
        constructor,
        statement,
        parameters,
        execution_options,
        *args,
        **kw
    ):
        """Create an :class:`.ExecutionContext` and execute, returning
        a :class:`_engine.CursorResult`."""

        branched = self
        if self.__branch_from:
            # if this is a "branched" connection, do everything in terms
            # of the "root" connection, *except* for .close(), which is
            # the only feature that branching provides
            self = self.__branch_from

        try:
            conn = self._dbapi_connection
            if conn is None:
                conn = self._revalidate_connection()

            context = constructor(
                dialect, self, conn, execution_options, *args, **kw
            )
        except (exc.PendingRollbackError, exc.ResourceClosedError):
            raise
        except BaseException as e:
            self._handle_dbapi_exception(
                e, util.text_type(statement), parameters, None, None
            )

        if (
            self._transaction
            and not self._transaction.is_active
            or (
                self._nested_transaction
                and not self._nested_transaction.is_active
            )
        ):
            self._invalid_transaction()

        elif self._trans_context_manager:
            TransactionalContext._trans_ctx_check(self)

        if self._is_future and self._transaction is None:
            self._autobegin()

        context.pre_exec()

        if dialect.use_setinputsizes:
            context._set_input_sizes()

        cursor, statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )

        if not context.executemany:
            parameters = parameters[0]

        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                statement, parameters = fn(
                    self,
                    cursor,
                    statement,
                    parameters,
                    context,
                    context.executemany,
                )

        if self._echo:

            self._log_info(statement)

            stats = context._get_cache_stats()

            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        parameters, batches=10, ismulti=context.executemany
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]"
                    % (stats,)
                )

        evt_handled = False
        try:
            if context.executemany:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(cursor, statement, parameters, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor, statement, parameters, context
                    )
            elif not parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, statement, context
                    )
            else:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(cursor, statement, parameters, context):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, statement, parameters, context
                    )

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1802:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7fe2f3b9eaf0>
cursor = <sqlite3.Cursor object at 0x7fe2f83c0730>
statement = 'SELECT pk_index, a, b \nFROM (SELECT original_table_clause.a AS a, original_table_clause.b AS b, original_table_claus...S NULL AND b IS NULL)) AS anon_2 \nWHERE records_with_grouped_column_counts_subquery._num_rows >= ?\n LIMIT ? OFFSET ?'
parameters = (2, 20, 0)
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7fe2f84052e0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlite3.OperationalError: ambiguous column name: pk_index

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/engine/default.py:719: OperationalError

The above exception was the direct cause of the following exception:

self = <great_expectations.execution_engine.sqlalchemy_execution_engine.SqlAlchemyExecutionEngine object at 0x7fe2f3b9e2e0>
metric_fn_direct_configurations = [MetricComputationConfiguration(metric_configuration={
  "metric_name": "compound_columns.unique.unexpected_count",
  ...l_unexpected_count': 20, 'include_unexpected_rows': False}}}, compute_domain_kwargs=None, accessor_domain_kwargs=None)]
metric_fn_bundle_configurations = []

    def _process_direct_and_bundled_metric_computation_configurations(
        self,
        metric_fn_direct_configurations: List[MetricComputationConfiguration],
        metric_fn_bundle_configurations: List[MetricComputationConfiguration],
    ) -> Dict[Tuple[str, str, str], MetricValue]:
        """
        This method processes directly-computable and bundled "MetricComputationConfiguration" objects.

        Args:
            metric_fn_direct_configurations: directly-computable "MetricComputationConfiguration" objects
            metric_fn_bundle_configurations: bundled "MetricComputationConfiguration" objects (column aggregates)

        Returns:
            resolved_metrics (Dict): a dictionary with the values for the metrics that have just been resolved.
        """
        resolved_metrics: Dict[Tuple[str, str, str], MetricValue] = {}

        metric_computation_configuration: MetricComputationConfiguration

        for metric_computation_configuration in metric_fn_direct_configurations:
            try:
                resolved_metrics[
                    metric_computation_configuration.metric_configuration.id
>               ] = metric_computation_configuration.metric_fn(
                    **metric_computation_configuration.metric_provider_kwargs
                )

great_expectations/execution_engine/execution_engine.py:650:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

cls = <class 'great_expectations.expectations.metrics.multicolumn_map_metrics.compound_columns_unique.CompoundColumnsUnique'>
execution_engine = <great_expectations.execution_engine.sqlalchemy_execution_engine.SqlAlchemyExecutionEngine object at 0x7fe2f3b9e2e0>
metric_domain_kwargs = {'batch_id': 'b1ae3225b6aa3d6c44dce474d8b4e741', 'table': None, 'column_list': ['a', 'b'], 'row_condition': None, 'condition_parser': None, 'ignore_row_if': 'all_values_are_missing'}
metric_value_kwargs = {'result_format': {'result_format': 'COMPLETE', 'unexpected_index_column_names': ['pk_index'], 'partial_unexpected_count': 20, 'include_unexpected_rows': False}}
metrics = {'table.column_types': [{'autoincrement': 'auto', 'default': None, 'name': 'a', 'nullable': True, ...}, {'autoincremen...w_condition': None, 'condition_parser': None, 'ignore_row_if': 'all_values_are_missing'}, {'column_list': ['a', 'b']})}
kwargs = {'runtime_configuration': {'catch_exceptions': False, 'include_config': False, 'result_format': {'include_unexpected_rows': False, 'partial_unexpected_count': 20, 'result_format': 'COMPLETE', 'unexpected_index_column_names': ['pk_index']}}}
unexpected_condition = <sqlalchemy.sql.elements.BinaryExpression object at 0x7fe2f83f73d0>
compute_domain_kwargs = {'batch_id': 'b1ae3225b6aa3d6c44dce474d8b4e741', 'table': None, 'row_condition': None, 'condition_parser': None, 'ignore_row_if': 'all_values_are_missing'}
accessor_domain_kwargs = {'column_list': ['a', 'b']}
domain_column_name_list = ['a', 'b'], column_name = 'b'
column_list = ['a', 'b']
domain_kwargs = {'batch_id': 'b1ae3225b6aa3d6c44dce474d8b4e741', 'column_list': ['a', 'b'], 'condition_parser': None, 'ignore_row_if': 'all_values_are_missing', ...}

    def _sqlalchemy_map_condition_index(
        cls,
        execution_engine: SqlAlchemyExecutionEngine,
        metric_domain_kwargs: Dict,
        metric_value_kwargs: Dict,
        metrics: Dict[str, Any],
        **kwargs,
    ) -> List[Dict[str, Any]]:
        """
        Returns indices of the metric values which do not meet an expected Expectation condition for instances
        of ColumnMapExpectation.

        Requires `unexpected_index_column_names` to be part of `result_format` dict to specify primary_key columns
        to return.
        """
        (
            unexpected_condition,
            compute_domain_kwargs,
            accessor_domain_kwargs,
        ) = metrics.get("unexpected_condition")

        domain_column_name_list: List[str] = list()
        # column map expectations
        if "column" in accessor_domain_kwargs:
            column_name: Union[str, quoted_name] = accessor_domain_kwargs["column"]
            domain_column_name_list.append(column_name)
        # multi-column map expectations
        elif "column_list" in accessor_domain_kwargs:
            column_list: List[Union[str, quoted_name]] = accessor_domain_kwargs[
                "column_list"
            ]
            domain_column_name_list = column_list
        # column-map expectations
        elif "column_A" in accessor_domain_kwargs and "column_B" in accessor_domain_kwargs:
            column_list: List[Union[str, quoted_name]] = list()
            column_list.append(accessor_domain_kwargs["column_A"])
            column_list.append(accessor_domain_kwargs["column_B"])
            domain_column_name_list = column_list

        domain_kwargs: dict = dict(**compute_domain_kwargs, **accessor_domain_kwargs)
        result_format: dict = metric_value_kwargs["result_format"]

        all_table_columns: List[str] = metrics.get("table.columns")

        unexpected_index_column_names: Optional[List[str]] = result_format.get(
            "unexpected_index_column_names"
        )

        column_selector: List[sa.Column] = []
        for column_name in unexpected_index_column_names:
            if column_name not in all_table_columns:
                raise gx_exceptions.InvalidMetricAccessorDomainKwargsKeyError(
                    message=f'Error: The unexpected_index_column: "{column_name}" in does not exist in SQL Table. '
                    f"Please check your configuration and try again."
                )
            column_selector.append(sa.column(column_name))

        # expectation_domain_column_name: str = domain_kwargs["column"]

        # the last column we SELECT is the column the Expectation is being run on
        for column_name in domain_column_name_list:
            column_selector.append(sa.column(column_name))

        domain_records_as_selectable: sa.sql.Selectable = (
            execution_engine.get_domain_records(domain_kwargs=domain_kwargs)
        )
        unexpected_condition_query_with_selected_columns: sa.select = sa.select(
            column_selector
        ).where(unexpected_condition)

        if not MapMetricProvider.is_sqlalchemy_metric_selectable(map_metric_provider=cls):
            domain_records_as_selectable: Union[
                sa.Table, sa.Select
            ] = get_sqlalchemy_selectable(domain_records_as_selectable)

        # since SQL tables can be **very** large, truncate query_result values at 20, or at `partial_unexpected_count`
        final_query: sa.select = (
            unexpected_condition_query_with_selected_columns.select_from(
                domain_records_as_selectable
            ).limit(result_format["partial_unexpected_count"])
        )
>       query_result: List[tuple] = execution_engine.engine.execute(final_query).fetchall()

great_expectations/expectations/metrics/map_metric_provider.py:2662:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b9edf0>
statement = <sqlalchemy.sql.selectable.Select object at 0x7fe2f83ee070>
multiparams = (), params = {}
meth = <bound method ClauseElement._execute_on_connection of <sqlalchemy.sql.selectable.Select object at 0x7fe2f83ee070>>

    def execute(self, statement, *multiparams, **params):
        r"""Executes a SQL statement construct and returns a
        :class:`_engine.CursorResult`.

        :param statement: The statement to be executed.  May be
         one of:

         * a plain string (deprecated)
         * any :class:`_expression.ClauseElement` construct that is also
           a subclass of :class:`.Executable`, such as a
           :func:`_expression.select` construct
         * a :class:`.FunctionElement`, such as that generated
           by :data:`.func`, will be automatically wrapped in
           a SELECT statement, which is then executed.
         * a :class:`.DDLElement` object
         * a :class:`.DefaultGenerator` object
         * a :class:`.Compiled` object

         .. deprecated:: 2.0 passing a string to
            :meth:`_engine.Connection.execute` is
            deprecated and will be removed in version 2.0.  Use the
            :func:`_expression.text` construct with
            :meth:`_engine.Connection.execute`, or the
            :meth:`_engine.Connection.exec_driver_sql`
            method to invoke a driver-level
            SQL string.

        :param \*multiparams/\**params: represent bound parameter
         values to be used in the execution.   Typically,
         the format is either a collection of one or more
         dictionaries passed to \*multiparams::

             conn.execute(
                 table.insert(),
                 {"id":1, "value":"v1"},
                 {"id":2, "value":"v2"}
             )

         ...or individual key/values interpreted by \**params::

             conn.execute(
                 table.insert(), id=1, value="v1"
             )

         In the case that a plain SQL string is passed, and the underlying
         DBAPI accepts positional bind parameters, a collection of tuples
         or individual values in \*multiparams may be passed::

             conn.execute(
                 "INSERT INTO table (id, value) VALUES (?, ?)",
                 (1, "v1"), (2, "v2")
             )

             conn.execute(
                 "INSERT INTO table (id, value) VALUES (?, ?)",
                 1, "v1"
             )

         Note above, the usage of a question mark "?" or other
         symbol is contingent upon the "paramstyle" accepted by the DBAPI
         in use, which may be any of "qmark", "named", "pyformat", "format",
         "numeric".   See `pep-249
         <https://www.python.org/dev/peps/pep-0249/>`_ for details on
         paramstyle.

         To execute a textual SQL statement which uses bound parameters in a
         DBAPI-agnostic way, use the :func:`_expression.text` construct.

         .. deprecated:: 2.0 use of tuple or scalar positional parameters
            is deprecated. All params should be dicts or sequences of dicts.
            Use :meth:`.exec_driver_sql` to execute a plain string with
            tuple or scalar positional parameters.

        """

        if isinstance(statement, util.string_types):
            util.warn_deprecated_20(
                "Passing a string to Connection.execute() is "
                "deprecated and will be removed in version 2.0.  Use the "
                "text() construct, "
                "or the Connection.exec_driver_sql() method to invoke a "
                "driver-level SQL string."
            )

            return self._exec_driver_sql(
                statement,
                multiparams,
                params,
                _EMPTY_EXECUTION_OPTS,
                future=False,
            )

        try:
            meth = statement._execute_on_connection
        except AttributeError as err:
            util.raise_(
                exc.ObjectNotExecutableError(statement), replace_context=err
            )
        else:
>           return meth(self, multiparams, params, _EMPTY_EXECUTION_OPTS)

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1289:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.sql.selectable.Select object at 0x7fe2f83ee070>
connection = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b9edf0>
multiparams = (), params = {}, execution_options = immutabledict({})
_force = False

    def _execute_on_connection(
        self, connection, multiparams, params, execution_options, _force=False
    ):
        if _force or self.supports_execution:
>           return connection._execute_clauseelement(
                self, multiparams, params, execution_options
            )

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/sql/elements.py:325:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b9edf0>
elem = <sqlalchemy.sql.selectable.Select object at 0x7fe2f83ee070>
multiparams = (), params = {}, execution_options = immutabledict({})

    def _execute_clauseelement(
        self, elem, multiparams, params, execution_options
    ):
        """Execute a sql.ClauseElement object."""

        execution_options = elem._execution_options.merge_with(
            self._execution_options, execution_options
        )

        distilled_params = _distill_params(self, multiparams, params)

        has_events = self._has_events or self.engine._has_events
        if has_events:
            (
                elem,
                distilled_params,
                event_multiparams,
                event_params,
            ) = self._invoke_before_exec_event(
                elem, distilled_params, execution_options
            )

        if distilled_params:
            # ensure we don't retain a link to the view object for keys()
            # which links to the values, which we don't want to cache
            keys = sorted(distilled_params[0])
            for_executemany = len(distilled_params) > 1
        else:
            keys = []
            for_executemany = False

        dialect = self.dialect

        schema_translate_map = execution_options.get(
            "schema_translate_map", None
        )

        compiled_cache = execution_options.get(
            "compiled_cache", self.engine._compiled_cache
        )

        compiled_sql, extracted_params, cache_hit = elem._compile_w_cache(
            dialect=dialect,
            compiled_cache=compiled_cache,
            column_keys=keys,
            for_executemany=for_executemany,
            schema_translate_map=schema_translate_map,
            linting=self.dialect.compiler_linting | compiler.WARN_LINTING,
        )
>       ret = self._execute_context(
            dialect,
            dialect.execution_ctx_cls._init_compiled,
            compiled_sql,
            distilled_params,
            execution_options,
            compiled_sql,
            distilled_params,
            elem,
            extracted_params,
            cache_hit=cache_hit,
        )

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1481:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b9edf0>
dialect = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7fe2f3b9eaf0>
constructor = <bound method DefaultExecutionContext._init_compiled of <class 'sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext'>>
statement = 'SELECT pk_index, a, b \nFROM (SELECT original_table_clause.a AS a, original_table_clause.b AS b, original_table_claus...S NULL AND b IS NULL)) AS anon_2 \nWHERE records_with_grouped_column_counts_subquery._num_rows >= ?\n LIMIT ? OFFSET ?'
parameters = (2, 20, 0), execution_options = immutabledict({})
args = (<sqlalchemy.dialects.sqlite.base.SQLiteCompiler object at 0x7fe2f83eefd0>, [], <sqlalchemy.sql.selectable.Select obje...140612804243520 num_rows)s', 2, type_=Integer()), _OffsetLimitParam('%(140612804208096 param)s', 20, type_=Integer())])
kw = {'cache_hit': symbol('CACHE_MISS')}
branched = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b9edf0>
conn = <sqlalchemy.pool.base._ConnectionFairy object at 0x7fe2f3b9ee80>
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7fe2f84052e0>
cursor = <sqlite3.Cursor object at 0x7fe2f83c0730>, evt_handled = False

    def _execute_context(
        self,
        dialect,
        constructor,
        statement,
        parameters,
        execution_options,
        *args,
        **kw
    ):
        """Create an :class:`.ExecutionContext` and execute, returning
        a :class:`_engine.CursorResult`."""

        branched = self
        if self.__branch_from:
            # if this is a "branched" connection, do everything in terms
            # of the "root" connection, *except* for .close(), which is
            # the only feature that branching provides
            self = self.__branch_from

        try:
            conn = self._dbapi_connection
            if conn is None:
                conn = self._revalidate_connection()

            context = constructor(
                dialect, self, conn, execution_options, *args, **kw
            )
        except (exc.PendingRollbackError, exc.ResourceClosedError):
            raise
        except BaseException as e:
            self._handle_dbapi_exception(
                e, util.text_type(statement), parameters, None, None
            )

        if (
            self._transaction
            and not self._transaction.is_active
            or (
                self._nested_transaction
                and not self._nested_transaction.is_active
            )
        ):
            self._invalid_transaction()

        elif self._trans_context_manager:
            TransactionalContext._trans_ctx_check(self)

        if self._is_future and self._transaction is None:
            self._autobegin()

        context.pre_exec()

        if dialect.use_setinputsizes:
            context._set_input_sizes()

        cursor, statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )

        if not context.executemany:
            parameters = parameters[0]

        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                statement, parameters = fn(
                    self,
                    cursor,
                    statement,
                    parameters,
                    context,
                    context.executemany,
                )

        if self._echo:

            self._log_info(statement)

            stats = context._get_cache_stats()

            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        parameters, batches=10, ismulti=context.executemany
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]"
                    % (stats,)
                )

        evt_handled = False
        try:
            if context.executemany:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(cursor, statement, parameters, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor, statement, parameters, context
                    )
            elif not parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, statement, context
                    )
            else:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(cursor, statement, parameters, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute(
                        cursor, statement, parameters, context
                    )

            if self._has_events or self.engine._has_events:
                self.dispatch.after_cursor_execute(
                    self,
                    cursor,
                    statement,
                    parameters,
                    context,
                    context.executemany,
                )

            context.post_exec()

            result = context._setup_result_proxy()

            if not self._is_future:
                should_close_with_result = branched.should_close_with_result

                if not result._soft_closed and should_close_with_result:
                    result._autoclose_connection = True

                if (
                    # usually we're in a transaction so avoid relatively
                    # expensive / legacy should_autocommit call
                    self._transaction is None
                    and context.should_autocommit
                ):
                    self._commit_impl(autocommit=True)

                # for "connectionless" execution, we have to close this
                # Connection after the statement is complete.
                # legacy stuff.
                if should_close_with_result and context._soft_closed:
                    assert not self._is_future

                    # CursorResult already exhausted rows / has no rows.
                    # close us now
                    branched.close()

        except BaseException as e:
>           self._handle_dbapi_exception(
                e, statement, parameters, cursor, context
            )

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1845:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b9edf0>
e = OperationalError('ambiguous column name: pk_index')
statement = 'SELECT pk_index, a, b \nFROM (SELECT original_table_clause.a AS a, original_table_clause.b AS b, original_table_claus...S NULL AND b IS NULL)) AS anon_2 \nWHERE records_with_grouped_column_counts_subquery._num_rows >= ?\n LIMIT ? OFFSET ?'
parameters = (2, 20, 0), cursor = <sqlite3.Cursor object at 0x7fe2f83c0730>
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7fe2f84052e0>

    def _handle_dbapi_exception(
        self, e, statement, parameters, cursor, context
    ):
        exc_info = sys.exc_info()

        is_exit_exception = util.is_exit_exception(e)

        if not self._is_disconnect:
            self._is_disconnect = (
                isinstance(e, self.dialect.dbapi.Error)
                and not self.closed
                and self.dialect.is_disconnect(
                    e,
                    self._dbapi_connection if not self.invalidated else None,
                    cursor,
                )
            ) or (is_exit_exception and not self.closed)

        invalidate_pool_on_disconnect = not is_exit_exception

        if self._reentrant_error:
            util.raise_(
                exc.DBAPIError.instance(
                    statement,
                    parameters,
                    e,
                    self.dialect.dbapi.Error,
                    hide_parameters=self.engine.hide_parameters,
                    dialect=self.dialect,
                    ismulti=context.executemany
                    if context is not None
                    else None,
                ),
                with_traceback=exc_info[2],
                from_=e,
            )
        self._reentrant_error = True
        try:
            # non-DBAPI error - if we already got a context,
            # or there's no string statement, don't wrap it
            should_wrap = isinstance(e, self.dialect.dbapi.Error) or (
                statement is not None
                and context is None
                and not is_exit_exception
            )

            if should_wrap:
                sqlalchemy_exception = exc.DBAPIError.instance(
                    statement,
                    parameters,
                    e,
                    self.dialect.dbapi.Error,
                    hide_parameters=self.engine.hide_parameters,
                    connection_invalidated=self._is_disconnect,
                    dialect=self.dialect,
                    ismulti=context.executemany
                    if context is not None
                    else None,
                )
            else:
                sqlalchemy_exception = None

            newraise = None

            if (
                self._has_events or self.engine._has_events
            ) and not self._execution_options.get(
                "skip_user_error_events", False
            ):
                ctx = ExceptionContextImpl(
                    e,
                    sqlalchemy_exception,
                    self.engine,
                    self,
                    cursor,
                    statement,
                    parameters,
                    context,
                    self._is_disconnect,
                    invalidate_pool_on_disconnect,
                )

                for fn in self.dispatch.handle_error:
                    try:
                        # handler returns an exception;
                        # call next handler in a chain
                        per_fn = fn(ctx)
                        if per_fn is not None:
                            ctx.chained_exception = newraise = per_fn
                    except Exception as _raised:
                        # handler raises an exception - stop processing
                        newraise = _raised
                        break

                if self._is_disconnect != ctx.is_disconnect:
                    self._is_disconnect = ctx.is_disconnect
                    if sqlalchemy_exception:
                        sqlalchemy_exception.connection_invalidated = (
                            ctx.is_disconnect
                        )

                # set up potentially user-defined value for
                # invalidate pool.
                invalidate_pool_on_disconnect = (
                    ctx.invalidate_pool_on_disconnect
                )

            if should_wrap and context:
                context.handle_dbapi_exception(e)

            if not self._is_disconnect:
                if cursor:
                    self._safe_close_cursor(cursor)
                with util.safe_reraise(warn_only=True):
                    self._autorollback()

            if newraise:
                util.raise_(newraise, with_traceback=exc_info[2], from_=e)
            elif should_wrap:
>               util.raise_(
                    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
                )

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/engine/base.py:2026:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

    def raise_(
        exception, with_traceback=None, replace_context=None, from_=False
    ):
        r"""implement "raise" with cause support.

        :param exception: exception to raise
        :param with_traceback: will call exception.with_traceback()
        :param replace_context: an as-yet-unsupported feature.  This is
         an exception object which we are "replacing", e.g., it's our
         "cause" but we don't want it printed.    Basically just what
         ``__suppress_context__`` does but we don't want to suppress
         the enclosing context, if any.  So for now we make it the
         cause.
        :param from\_: the cause.  this actually sets the cause and doesn't
         hope to hide it someday.

        """
        if with_traceback is not None:
            exception = exception.with_traceback(with_traceback)

        if from_ is not False:
            exception.__cause__ = from_
        elif replace_context is not None:
            # no good solution here, we would like to have the exception
            # have only the context of replace_context.__context__ so that the
            # intermediary exception does not change, but we can't figure
            # that out.
            exception.__cause__ = replace_context

        try:
>           raise exception

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/util/compat.py:207:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b9edf0>
dialect = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7fe2f3b9eaf0>
constructor = <bound method DefaultExecutionContext._init_compiled of <class 'sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext'>>
statement = 'SELECT pk_index, a, b \nFROM (SELECT original_table_clause.a AS a, original_table_clause.b AS b, original_table_claus...S NULL AND b IS NULL)) AS anon_2 \nWHERE records_with_grouped_column_counts_subquery._num_rows >= ?\n LIMIT ? OFFSET ?'
parameters = (2, 20, 0), execution_options = immutabledict({})
args = (<sqlalchemy.dialects.sqlite.base.SQLiteCompiler object at 0x7fe2f83eefd0>, [], <sqlalchemy.sql.selectable.Select obje...140612804243520 num_rows)s', 2, type_=Integer()), _OffsetLimitParam('%(140612804208096 param)s', 20, type_=Integer())])
kw = {'cache_hit': symbol('CACHE_MISS')}
branched = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b9edf0>
conn = <sqlalchemy.pool.base._ConnectionFairy object at 0x7fe2f3b9ee80>
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7fe2f84052e0>
cursor = <sqlite3.Cursor object at 0x7fe2f83c0730>, evt_handled = False

    def _execute_context(
        self,
        dialect,
        constructor,
        statement,
        parameters,
        execution_options,
        *args,
        **kw
    ):
        """Create an :class:`.ExecutionContext` and execute, returning
        a :class:`_engine.CursorResult`."""

        branched = self
        if self.__branch_from:
            # if this is a "branched" connection, do everything in terms
            # of the "root" connection, *except* for .close(), which is
            # the only feature that branching provides
            self = self.__branch_from

        try:
            conn = self._dbapi_connection
            if conn is None:
                conn = self._revalidate_connection()

            context = constructor(
                dialect, self, conn, execution_options, *args, **kw
            )
        except (exc.PendingRollbackError, exc.ResourceClosedError):
            raise
        except BaseException as e:
            self._handle_dbapi_exception(
                e, util.text_type(statement), parameters, None, None
            )

        if (
            self._transaction
            and not self._transaction.is_active
            or (
                self._nested_transaction
                and not self._nested_transaction.is_active
            )
        ):
            self._invalid_transaction()

        elif self._trans_context_manager:
            TransactionalContext._trans_ctx_check(self)

        if self._is_future and self._transaction is None:
            self._autobegin()

        context.pre_exec()

        if dialect.use_setinputsizes:
            context._set_input_sizes()

        cursor, statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )

        if not context.executemany:
            parameters = parameters[0]

        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                statement, parameters = fn(
                    self,
                    cursor,
                    statement,
                    parameters,
                    context,
                    context.executemany,
                )

        if self._echo:

            self._log_info(statement)

            stats = context._get_cache_stats()

            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        parameters, batches=10, ismulti=context.executemany
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]"
                    % (stats,)
                )

        evt_handled = False
        try:
            if context.executemany:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(cursor, statement, parameters, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor, statement, parameters, context
                    )
            elif not parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, statement, context
                    )
            else:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(cursor, statement, parameters, context):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, statement, parameters, context
                    )

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1802:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7fe2f3b9eaf0>
cursor = <sqlite3.Cursor object at 0x7fe2f83c0730>
statement = 'SELECT pk_index, a, b \nFROM (SELECT original_table_clause.a AS a, original_table_clause.b AS b, original_table_claus...S NULL AND b IS NULL)) AS anon_2 \nWHERE records_with_grouped_column_counts_subquery._num_rows >= ?\n LIMIT ? OFFSET ?'
parameters = (2, 20, 0)
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7fe2f84052e0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) ambiguous column name: pk_index
E       [SQL: SELECT pk_index, a, b
E       FROM (SELECT original_table_clause.a AS a, original_table_clause.b AS b, original_table_clause.c AS c, original_table_clause.pk_index AS pk_index, group_counts_subquery._num_rows AS _num_rows
E       FROM (SELECT a, b, c, pk_index
E       FROM (SELECT *
E       FROM test_data_c5fncnz3
E       WHERE NOT (a IS NULL AND b IS NULL)) AS anon_1) AS original_table_clause JOIN (SELECT a, b, count(*) AS _num_rows
E       FROM (SELECT a, b, c, pk_index
E       FROM (SELECT *
E       FROM test_data_c5fncnz3
E       WHERE NOT (a IS NULL AND b IS NULL)) AS anon_1) AS original_table_clause GROUP BY a, b) AS group_counts_subquery ON group_counts_subquery.a = original_table_clause.a AND group_counts_subquery.b = original_table_clause.b) AS records_with_grouped_column_counts_subquery, (SELECT *
E       FROM test_data_c5fncnz3
E       WHERE NOT (a IS NULL AND b IS NULL)) AS anon_2
E       WHERE records_with_grouped_column_counts_subquery._num_rows >= ?
E        LIMIT ? OFFSET ?]
E       [parameters: (2, 20, 0)]
E       (Background on this error at: https://sqlalche.me/e/14/e3q8)

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/engine/default.py:719: OperationalError

The above exception was the direct cause of the following exception:

test_case = {'expectation_type': 'expect_compound_columns_to_be_unique', 'pk_column': True, 'skip': False, 'test': {'exact_match_o... False, 'in': {'column_list': ['a', 'b']}, 'include_in_gallery': True, 'input': {'column_list': ['a', 'b']}, ...}, ...}

    @pytest.mark.order(index=0)
    @pytest.mark.integration
    @pytest.mark.slow  # 12.68s
    def test_case_runner_v3_api(test_case):
        if test_case["skip"]:
            pytest.skip()

        # Note: this should never be done in practice, but we are wiping expectations to reuse batches during testing.
        # test_case["batch"]._initialize_expectations()
        if "parse_strings_as_datetimes" in test_case["test"]["in"]:
            with pytest.deprecated_call():
                evaluate_json_test_v3_api(
                    validator=test_case["validator_with_data"],
                    expectation_type=test_case["expectation_type"],
                    test=test_case["test"],
                    pk_column=test_case["pk_column"],
                )
        else:
>           evaluate_json_test_v3_api(
                validator=test_case["validator_with_data"],
                expectation_type=test_case["expectation_type"],
                test=test_case["test"],
                pk_column=test_case["pk_column"],
            )

tests/test_definitions/test_expectations_v3_api.py:428:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
great_expectations/self_check/util.py:2887: in evaluate_json_test_v3_api
    result = getattr(validator, expectation_type)(**runtime_kwargs)
great_expectations/validator/validator.py:595: in inst_expectation
    raise err
great_expectations/validator/validator.py:558: in inst_expectation
    validation_result = expectation.validate(
great_expectations/expectations/expectation.py:1265: in validate
    ] = validator.graph_validate(
great_expectations/validator/validator.py:1046: in graph_validate
    raise err
great_expectations/validator/validator.py:1025: in graph_validate
    ) = self._resolve_suite_level_graph_and_process_metric_evaluation_errors(
great_expectations/validator/validator.py:1184: in _resolve_suite_level_graph_and_process_metric_evaluation_errors
    ) = self._metrics_calculator.resolve_validation_graph(
great_expectations/validator/metrics_calculator.py:282: in resolve_validation_graph
    resolved_metrics, aborted_metrics_info = graph.resolve(
great_expectations/validator/validation_graph.py:196: in resolve
    ] = self._resolve(
great_expectations/validator/validation_graph.py:302: in _resolve
    raise err
great_expectations/validator/validation_graph.py:272: in _resolve
    self._execution_engine.resolve_metrics(
great_expectations/execution_engine/execution_engine.py:375: in resolve_metrics
    return self._process_direct_and_bundled_metric_computation_configurations(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <great_expectations.execution_engine.sqlalchemy_execution_engine.SqlAlchemyExecutionEngine object at 0x7fe2f3b9e2e0>
metric_fn_direct_configurations = [MetricComputationConfiguration(metric_configuration={
  "metric_name": "compound_columns.unique.unexpected_count",
  ...l_unexpected_count': 20, 'include_unexpected_rows': False}}}, compute_domain_kwargs=None, accessor_domain_kwargs=None)]
metric_fn_bundle_configurations = []

    def _process_direct_and_bundled_metric_computation_configurations(
        self,
        metric_fn_direct_configurations: List[MetricComputationConfiguration],
        metric_fn_bundle_configurations: List[MetricComputationConfiguration],
    ) -> Dict[Tuple[str, str, str], MetricValue]:
        """
        This method processes directly-computable and bundled "MetricComputationConfiguration" objects.

        Args:
            metric_fn_direct_configurations: directly-computable "MetricComputationConfiguration" objects
            metric_fn_bundle_configurations: bundled "MetricComputationConfiguration" objects (column aggregates)

        Returns:
            resolved_metrics (Dict): a dictionary with the values for the metrics that have just been resolved.
        """
        resolved_metrics: Dict[Tuple[str, str, str], MetricValue] = {}

        metric_computation_configuration: MetricComputationConfiguration

        for metric_computation_configuration in metric_fn_direct_configurations:
            try:
                resolved_metrics[
                    metric_computation_configuration.metric_configuration.id
                ] = metric_computation_configuration.metric_fn(
                    **metric_computation_configuration.metric_provider_kwargs
                )
            except Exception as e:
>               raise gx_exceptions.MetricResolutionError(
                    message=str(e),
                    failed_metrics=(
                        metric_computation_configuration.metric_configuration,
                    ),
                ) from e
E               great_expectations.exceptions.exceptions.MetricResolutionError: (sqlite3.OperationalError) ambiguous column name: pk_index
E               [SQL: SELECT pk_index, a, b
E               FROM (SELECT original_table_clause.a AS a, original_table_clause.b AS b, original_table_clause.c AS c, original_table_clause.pk_index AS pk_index, group_counts_subquery._num_rows AS _num_rows
E               FROM (SELECT a, b, c, pk_index
E               FROM (SELECT *
E               FROM test_data_c5fncnz3
E               WHERE NOT (a IS NULL AND b IS NULL)) AS anon_1) AS original_table_clause JOIN (SELECT a, b, count(*) AS _num_rows
E               FROM (SELECT a, b, c, pk_index
E               FROM (SELECT *
E               FROM test_data_c5fncnz3
E               WHERE NOT (a IS NULL AND b IS NULL)) AS anon_1) AS original_table_clause GROUP BY a, b) AS group_counts_subquery ON group_counts_subquery.a = original_table_clause.a AND group_counts_subquery.b = original_table_clause.b) AS records_with_grouped_column_counts_subquery, (SELECT *
E               FROM test_data_c5fncnz3
E               WHERE NOT (a IS NULL AND b IS NULL)) AS anon_2
E               WHERE records_with_grouped_column_counts_subquery._num_rows >= ?
E                LIMIT ? OFFSET ?]
E               [parameters: (2, 20, 0)]
E               (Background on this error at: https://sqlalche.me/e/14/e3q8)

great_expectations/execution_engine/execution_engine.py:654: MetricResolutionError
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:  18%|        | 2/11 [00:00<00:00, 1443.08it/s]Calculating Metrics:  18%|        | 2/11 [00:00<00:00, 124.55it/s] Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 168.13it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 89.78it/s] Calculating Metrics:  45%|     | 5/11 [00:00<00:00, 105.31it/s]Calculating Metrics:  45%|     | 5/11 [00:00<00:00, 79.42it/s] Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 91.57it/s]Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 83.42it/s]
_ test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_compound_columns_to_be_unique:mostly_default_fails_expectation] _

self = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b9edf0>
dialect = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7fe2f3b9eaf0>
constructor = <bound method DefaultExecutionContext._init_compiled of <class 'sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext'>>
statement = 'SELECT pk_index, b, c \nFROM (SELECT original_table_clause.a AS a, original_table_clause.b AS b, original_table_claus...S NULL AND c IS NULL)) AS anon_2 \nWHERE records_with_grouped_column_counts_subquery._num_rows >= ?\n LIMIT ? OFFSET ?'
parameters = (2, 20, 0), execution_options = immutabledict({})
args = (<sqlalchemy.dialects.sqlite.base.SQLiteCompiler object at 0x7fe2f8dbc250>, [], <sqlalchemy.sql.selectable.Select obje...140612814459568 num_rows)s', 2, type_=Integer()), _OffsetLimitParam('%(140612814488864 param)s', 20, type_=Integer())])
kw = {'cache_hit': symbol('CACHE_MISS')}
branched = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b9edf0>
conn = <sqlalchemy.pool.base._ConnectionFairy object at 0x7fe2f3b9ee80>
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7fe2f8dbc5e0>
cursor = <sqlite3.Cursor object at 0x7fe2f849dc00>, evt_handled = False

    def _execute_context(
        self,
        dialect,
        constructor,
        statement,
        parameters,
        execution_options,
        *args,
        **kw
    ):
        """Create an :class:`.ExecutionContext` and execute, returning
        a :class:`_engine.CursorResult`."""

        branched = self
        if self.__branch_from:
            # if this is a "branched" connection, do everything in terms
            # of the "root" connection, *except* for .close(), which is
            # the only feature that branching provides
            self = self.__branch_from

        try:
            conn = self._dbapi_connection
            if conn is None:
                conn = self._revalidate_connection()

            context = constructor(
                dialect, self, conn, execution_options, *args, **kw
            )
        except (exc.PendingRollbackError, exc.ResourceClosedError):
            raise
        except BaseException as e:
            self._handle_dbapi_exception(
                e, util.text_type(statement), parameters, None, None
            )

        if (
            self._transaction
            and not self._transaction.is_active
            or (
                self._nested_transaction
                and not self._nested_transaction.is_active
            )
        ):
            self._invalid_transaction()

        elif self._trans_context_manager:
            TransactionalContext._trans_ctx_check(self)

        if self._is_future and self._transaction is None:
            self._autobegin()

        context.pre_exec()

        if dialect.use_setinputsizes:
            context._set_input_sizes()

        cursor, statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )

        if not context.executemany:
            parameters = parameters[0]

        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                statement, parameters = fn(
                    self,
                    cursor,
                    statement,
                    parameters,
                    context,
                    context.executemany,
                )

        if self._echo:

            self._log_info(statement)

            stats = context._get_cache_stats()

            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        parameters, batches=10, ismulti=context.executemany
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]"
                    % (stats,)
                )

        evt_handled = False
        try:
            if context.executemany:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(cursor, statement, parameters, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor, statement, parameters, context
                    )
            elif not parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, statement, context
                    )
            else:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(cursor, statement, parameters, context):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, statement, parameters, context
                    )

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1802:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7fe2f3b9eaf0>
cursor = <sqlite3.Cursor object at 0x7fe2f849dc00>
statement = 'SELECT pk_index, b, c \nFROM (SELECT original_table_clause.a AS a, original_table_clause.b AS b, original_table_claus...S NULL AND c IS NULL)) AS anon_2 \nWHERE records_with_grouped_column_counts_subquery._num_rows >= ?\n LIMIT ? OFFSET ?'
parameters = (2, 20, 0)
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7fe2f8dbc5e0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlite3.OperationalError: ambiguous column name: pk_index

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/engine/default.py:719: OperationalError

The above exception was the direct cause of the following exception:

self = <great_expectations.execution_engine.sqlalchemy_execution_engine.SqlAlchemyExecutionEngine object at 0x7fe2f3b9e2e0>
metric_fn_direct_configurations = [MetricComputationConfiguration(metric_configuration={
  "metric_name": "compound_columns.unique.unexpected_values",
 ...l_unexpected_count': 20, 'include_unexpected_rows': False}}}, compute_domain_kwargs=None, accessor_domain_kwargs=None)]
metric_fn_bundle_configurations = []

    def _process_direct_and_bundled_metric_computation_configurations(
        self,
        metric_fn_direct_configurations: List[MetricComputationConfiguration],
        metric_fn_bundle_configurations: List[MetricComputationConfiguration],
    ) -> Dict[Tuple[str, str, str], MetricValue]:
        """
        This method processes directly-computable and bundled "MetricComputationConfiguration" objects.

        Args:
            metric_fn_direct_configurations: directly-computable "MetricComputationConfiguration" objects
            metric_fn_bundle_configurations: bundled "MetricComputationConfiguration" objects (column aggregates)

        Returns:
            resolved_metrics (Dict): a dictionary with the values for the metrics that have just been resolved.
        """
        resolved_metrics: Dict[Tuple[str, str, str], MetricValue] = {}

        metric_computation_configuration: MetricComputationConfiguration

        for metric_computation_configuration in metric_fn_direct_configurations:
            try:
                resolved_metrics[
                    metric_computation_configuration.metric_configuration.id
>               ] = metric_computation_configuration.metric_fn(
                    **metric_computation_configuration.metric_provider_kwargs
                )

great_expectations/execution_engine/execution_engine.py:650:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

cls = <class 'great_expectations.expectations.metrics.multicolumn_map_metrics.compound_columns_unique.CompoundColumnsUnique'>
execution_engine = <great_expectations.execution_engine.sqlalchemy_execution_engine.SqlAlchemyExecutionEngine object at 0x7fe2f3b9e2e0>
metric_domain_kwargs = {'batch_id': 'b1ae3225b6aa3d6c44dce474d8b4e741', 'table': None, 'column_list': ['b', 'c'], 'row_condition': None, 'condition_parser': None, 'ignore_row_if': 'all_values_are_missing'}
metric_value_kwargs = {'result_format': {'result_format': 'COMPLETE', 'unexpected_index_column_names': ['pk_index'], 'partial_unexpected_count': 20, 'include_unexpected_rows': False}}
metrics = {'table.column_types': [{'autoincrement': 'auto', 'default': None, 'name': 'a', 'nullable': True, ...}, {'autoincremen...w_condition': None, 'condition_parser': None, 'ignore_row_if': 'all_values_are_missing'}, {'column_list': ['b', 'c']})}
kwargs = {'runtime_configuration': {'catch_exceptions': False, 'include_config': False, 'result_format': {'include_unexpected_rows': False, 'partial_unexpected_count': 20, 'result_format': 'COMPLETE', 'unexpected_index_column_names': ['pk_index']}}}
unexpected_condition = <sqlalchemy.sql.elements.BinaryExpression object at 0x7fe2f8db5d90>
compute_domain_kwargs = {'batch_id': 'b1ae3225b6aa3d6c44dce474d8b4e741', 'table': None, 'row_condition': None, 'condition_parser': None, 'ignore_row_if': 'all_values_are_missing'}
accessor_domain_kwargs = {'column_list': ['b', 'c']}
domain_column_name_list = ['b', 'c'], column_name = 'c'
column_list = ['b', 'c']
domain_kwargs = {'batch_id': 'b1ae3225b6aa3d6c44dce474d8b4e741', 'column_list': ['b', 'c'], 'condition_parser': None, 'ignore_row_if': 'all_values_are_missing', ...}

    def _sqlalchemy_map_condition_index(
        cls,
        execution_engine: SqlAlchemyExecutionEngine,
        metric_domain_kwargs: Dict,
        metric_value_kwargs: Dict,
        metrics: Dict[str, Any],
        **kwargs,
    ) -> List[Dict[str, Any]]:
        """
        Returns indices of the metric values which do not meet an expected Expectation condition for instances
        of ColumnMapExpectation.

        Requires `unexpected_index_column_names` to be part of `result_format` dict to specify primary_key columns
        to return.
        """
        (
            unexpected_condition,
            compute_domain_kwargs,
            accessor_domain_kwargs,
        ) = metrics.get("unexpected_condition")

        domain_column_name_list: List[str] = list()
        # column map expectations
        if "column" in accessor_domain_kwargs:
            column_name: Union[str, quoted_name] = accessor_domain_kwargs["column"]
            domain_column_name_list.append(column_name)
        # multi-column map expectations
        elif "column_list" in accessor_domain_kwargs:
            column_list: List[Union[str, quoted_name]] = accessor_domain_kwargs[
                "column_list"
            ]
            domain_column_name_list = column_list
        # column-map expectations
        elif "column_A" in accessor_domain_kwargs and "column_B" in accessor_domain_kwargs:
            column_list: List[Union[str, quoted_name]] = list()
            column_list.append(accessor_domain_kwargs["column_A"])
            column_list.append(accessor_domain_kwargs["column_B"])
            domain_column_name_list = column_list

        domain_kwargs: dict = dict(**compute_domain_kwargs, **accessor_domain_kwargs)
        result_format: dict = metric_value_kwargs["result_format"]

        all_table_columns: List[str] = metrics.get("table.columns")

        unexpected_index_column_names: Optional[List[str]] = result_format.get(
            "unexpected_index_column_names"
        )

        column_selector: List[sa.Column] = []
        for column_name in unexpected_index_column_names:
            if column_name not in all_table_columns:
                raise gx_exceptions.InvalidMetricAccessorDomainKwargsKeyError(
                    message=f'Error: The unexpected_index_column: "{column_name}" in does not exist in SQL Table. '
                    f"Please check your configuration and try again."
                )
            column_selector.append(sa.column(column_name))

        # expectation_domain_column_name: str = domain_kwargs["column"]

        # the last column we SELECT is the column the Expectation is being run on
        for column_name in domain_column_name_list:
            column_selector.append(sa.column(column_name))

        domain_records_as_selectable: sa.sql.Selectable = (
            execution_engine.get_domain_records(domain_kwargs=domain_kwargs)
        )
        unexpected_condition_query_with_selected_columns: sa.select = sa.select(
            column_selector
        ).where(unexpected_condition)

        if not MapMetricProvider.is_sqlalchemy_metric_selectable(map_metric_provider=cls):
            domain_records_as_selectable: Union[
                sa.Table, sa.Select
            ] = get_sqlalchemy_selectable(domain_records_as_selectable)

        # since SQL tables can be **very** large, truncate query_result values at 20, or at `partial_unexpected_count`
        final_query: sa.select = (
            unexpected_condition_query_with_selected_columns.select_from(
                domain_records_as_selectable
            ).limit(result_format["partial_unexpected_count"])
        )
>       query_result: List[tuple] = execution_engine.engine.execute(final_query).fetchall()

great_expectations/expectations/metrics/map_metric_provider.py:2662:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b9edf0>
statement = <sqlalchemy.sql.selectable.Select object at 0x7fe2f8dbc670>
multiparams = (), params = {}
meth = <bound method ClauseElement._execute_on_connection of <sqlalchemy.sql.selectable.Select object at 0x7fe2f8dbc670>>

    def execute(self, statement, *multiparams, **params):
        r"""Executes a SQL statement construct and returns a
        :class:`_engine.CursorResult`.

        :param statement: The statement to be executed.  May be
         one of:

         * a plain string (deprecated)
         * any :class:`_expression.ClauseElement` construct that is also
           a subclass of :class:`.Executable`, such as a
           :func:`_expression.select` construct
         * a :class:`.FunctionElement`, such as that generated
           by :data:`.func`, will be automatically wrapped in
           a SELECT statement, which is then executed.
         * a :class:`.DDLElement` object
         * a :class:`.DefaultGenerator` object
         * a :class:`.Compiled` object

         .. deprecated:: 2.0 passing a string to
            :meth:`_engine.Connection.execute` is
            deprecated and will be removed in version 2.0.  Use the
            :func:`_expression.text` construct with
            :meth:`_engine.Connection.execute`, or the
            :meth:`_engine.Connection.exec_driver_sql`
            method to invoke a driver-level
            SQL string.

        :param \*multiparams/\**params: represent bound parameter
         values to be used in the execution.   Typically,
         the format is either a collection of one or more
         dictionaries passed to \*multiparams::

             conn.execute(
                 table.insert(),
                 {"id":1, "value":"v1"},
                 {"id":2, "value":"v2"}
             )

         ...or individual key/values interpreted by \**params::

             conn.execute(
                 table.insert(), id=1, value="v1"
             )

         In the case that a plain SQL string is passed, and the underlying
         DBAPI accepts positional bind parameters, a collection of tuples
         or individual values in \*multiparams may be passed::

             conn.execute(
                 "INSERT INTO table (id, value) VALUES (?, ?)",
                 (1, "v1"), (2, "v2")
             )

             conn.execute(
                 "INSERT INTO table (id, value) VALUES (?, ?)",
                 1, "v1"
             )

         Note above, the usage of a question mark "?" or other
         symbol is contingent upon the "paramstyle" accepted by the DBAPI
         in use, which may be any of "qmark", "named", "pyformat", "format",
         "numeric".   See `pep-249
         <https://www.python.org/dev/peps/pep-0249/>`_ for details on
         paramstyle.

         To execute a textual SQL statement which uses bound parameters in a
         DBAPI-agnostic way, use the :func:`_expression.text` construct.

         .. deprecated:: 2.0 use of tuple or scalar positional parameters
            is deprecated. All params should be dicts or sequences of dicts.
            Use :meth:`.exec_driver_sql` to execute a plain string with
            tuple or scalar positional parameters.

        """

        if isinstance(statement, util.string_types):
            util.warn_deprecated_20(
                "Passing a string to Connection.execute() is "
                "deprecated and will be removed in version 2.0.  Use the "
                "text() construct, "
                "or the Connection.exec_driver_sql() method to invoke a "
                "driver-level SQL string."
            )

            return self._exec_driver_sql(
                statement,
                multiparams,
                params,
                _EMPTY_EXECUTION_OPTS,
                future=False,
            )

        try:
            meth = statement._execute_on_connection
        except AttributeError as err:
            util.raise_(
                exc.ObjectNotExecutableError(statement), replace_context=err
            )
        else:
>           return meth(self, multiparams, params, _EMPTY_EXECUTION_OPTS)

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1289:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.sql.selectable.Select object at 0x7fe2f8dbc670>
connection = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b9edf0>
multiparams = (), params = {}, execution_options = immutabledict({})
_force = False

    def _execute_on_connection(
        self, connection, multiparams, params, execution_options, _force=False
    ):
        if _force or self.supports_execution:
>           return connection._execute_clauseelement(
                self, multiparams, params, execution_options
            )

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/sql/elements.py:325:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b9edf0>
elem = <sqlalchemy.sql.selectable.Select object at 0x7fe2f8dbc670>
multiparams = (), params = {}, execution_options = immutabledict({})

    def _execute_clauseelement(
        self, elem, multiparams, params, execution_options
    ):
        """Execute a sql.ClauseElement object."""

        execution_options = elem._execution_options.merge_with(
            self._execution_options, execution_options
        )

        distilled_params = _distill_params(self, multiparams, params)

        has_events = self._has_events or self.engine._has_events
        if has_events:
            (
                elem,
                distilled_params,
                event_multiparams,
                event_params,
            ) = self._invoke_before_exec_event(
                elem, distilled_params, execution_options
            )

        if distilled_params:
            # ensure we don't retain a link to the view object for keys()
            # which links to the values, which we don't want to cache
            keys = sorted(distilled_params[0])
            for_executemany = len(distilled_params) > 1
        else:
            keys = []
            for_executemany = False

        dialect = self.dialect

        schema_translate_map = execution_options.get(
            "schema_translate_map", None
        )

        compiled_cache = execution_options.get(
            "compiled_cache", self.engine._compiled_cache
        )

        compiled_sql, extracted_params, cache_hit = elem._compile_w_cache(
            dialect=dialect,
            compiled_cache=compiled_cache,
            column_keys=keys,
            for_executemany=for_executemany,
            schema_translate_map=schema_translate_map,
            linting=self.dialect.compiler_linting | compiler.WARN_LINTING,
        )
>       ret = self._execute_context(
            dialect,
            dialect.execution_ctx_cls._init_compiled,
            compiled_sql,
            distilled_params,
            execution_options,
            compiled_sql,
            distilled_params,
            elem,
            extracted_params,
            cache_hit=cache_hit,
        )

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1481:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b9edf0>
dialect = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7fe2f3b9eaf0>
constructor = <bound method DefaultExecutionContext._init_compiled of <class 'sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext'>>
statement = 'SELECT pk_index, b, c \nFROM (SELECT original_table_clause.a AS a, original_table_clause.b AS b, original_table_claus...S NULL AND c IS NULL)) AS anon_2 \nWHERE records_with_grouped_column_counts_subquery._num_rows >= ?\n LIMIT ? OFFSET ?'
parameters = (2, 20, 0), execution_options = immutabledict({})
args = (<sqlalchemy.dialects.sqlite.base.SQLiteCompiler object at 0x7fe2f8dbc250>, [], <sqlalchemy.sql.selectable.Select obje...140612814459568 num_rows)s', 2, type_=Integer()), _OffsetLimitParam('%(140612814488864 param)s', 20, type_=Integer())])
kw = {'cache_hit': symbol('CACHE_MISS')}
branched = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b9edf0>
conn = <sqlalchemy.pool.base._ConnectionFairy object at 0x7fe2f3b9ee80>
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7fe2f8dbc5e0>
cursor = <sqlite3.Cursor object at 0x7fe2f849dc00>, evt_handled = False

    def _execute_context(
        self,
        dialect,
        constructor,
        statement,
        parameters,
        execution_options,
        *args,
        **kw
    ):
        """Create an :class:`.ExecutionContext` and execute, returning
        a :class:`_engine.CursorResult`."""

        branched = self
        if self.__branch_from:
            # if this is a "branched" connection, do everything in terms
            # of the "root" connection, *except* for .close(), which is
            # the only feature that branching provides
            self = self.__branch_from

        try:
            conn = self._dbapi_connection
            if conn is None:
                conn = self._revalidate_connection()

            context = constructor(
                dialect, self, conn, execution_options, *args, **kw
            )
        except (exc.PendingRollbackError, exc.ResourceClosedError):
            raise
        except BaseException as e:
            self._handle_dbapi_exception(
                e, util.text_type(statement), parameters, None, None
            )

        if (
            self._transaction
            and not self._transaction.is_active
            or (
                self._nested_transaction
                and not self._nested_transaction.is_active
            )
        ):
            self._invalid_transaction()

        elif self._trans_context_manager:
            TransactionalContext._trans_ctx_check(self)

        if self._is_future and self._transaction is None:
            self._autobegin()

        context.pre_exec()

        if dialect.use_setinputsizes:
            context._set_input_sizes()

        cursor, statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )

        if not context.executemany:
            parameters = parameters[0]

        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                statement, parameters = fn(
                    self,
                    cursor,
                    statement,
                    parameters,
                    context,
                    context.executemany,
                )

        if self._echo:

            self._log_info(statement)

            stats = context._get_cache_stats()

            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        parameters, batches=10, ismulti=context.executemany
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]"
                    % (stats,)
                )

        evt_handled = False
        try:
            if context.executemany:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(cursor, statement, parameters, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor, statement, parameters, context
                    )
            elif not parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, statement, context
                    )
            else:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(cursor, statement, parameters, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute(
                        cursor, statement, parameters, context
                    )

            if self._has_events or self.engine._has_events:
                self.dispatch.after_cursor_execute(
                    self,
                    cursor,
                    statement,
                    parameters,
                    context,
                    context.executemany,
                )

            context.post_exec()

            result = context._setup_result_proxy()

            if not self._is_future:
                should_close_with_result = branched.should_close_with_result

                if not result._soft_closed and should_close_with_result:
                    result._autoclose_connection = True

                if (
                    # usually we're in a transaction so avoid relatively
                    # expensive / legacy should_autocommit call
                    self._transaction is None
                    and context.should_autocommit
                ):
                    self._commit_impl(autocommit=True)

                # for "connectionless" execution, we have to close this
                # Connection after the statement is complete.
                # legacy stuff.
                if should_close_with_result and context._soft_closed:
                    assert not self._is_future

                    # CursorResult already exhausted rows / has no rows.
                    # close us now
                    branched.close()

        except BaseException as e:
>           self._handle_dbapi_exception(
                e, statement, parameters, cursor, context
            )

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1845:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b9edf0>
e = OperationalError('ambiguous column name: pk_index')
statement = 'SELECT pk_index, b, c \nFROM (SELECT original_table_clause.a AS a, original_table_clause.b AS b, original_table_claus...S NULL AND c IS NULL)) AS anon_2 \nWHERE records_with_grouped_column_counts_subquery._num_rows >= ?\n LIMIT ? OFFSET ?'
parameters = (2, 20, 0), cursor = <sqlite3.Cursor object at 0x7fe2f849dc00>
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7fe2f8dbc5e0>

    def _handle_dbapi_exception(
        self, e, statement, parameters, cursor, context
    ):
        exc_info = sys.exc_info()

        is_exit_exception = util.is_exit_exception(e)

        if not self._is_disconnect:
            self._is_disconnect = (
                isinstance(e, self.dialect.dbapi.Error)
                and not self.closed
                and self.dialect.is_disconnect(
                    e,
                    self._dbapi_connection if not self.invalidated else None,
                    cursor,
                )
            ) or (is_exit_exception and not self.closed)

        invalidate_pool_on_disconnect = not is_exit_exception

        if self._reentrant_error:
            util.raise_(
                exc.DBAPIError.instance(
                    statement,
                    parameters,
                    e,
                    self.dialect.dbapi.Error,
                    hide_parameters=self.engine.hide_parameters,
                    dialect=self.dialect,
                    ismulti=context.executemany
                    if context is not None
                    else None,
                ),
                with_traceback=exc_info[2],
                from_=e,
            )
        self._reentrant_error = True
        try:
            # non-DBAPI error - if we already got a context,
            # or there's no string statement, don't wrap it
            should_wrap = isinstance(e, self.dialect.dbapi.Error) or (
                statement is not None
                and context is None
                and not is_exit_exception
            )

            if should_wrap:
                sqlalchemy_exception = exc.DBAPIError.instance(
                    statement,
                    parameters,
                    e,
                    self.dialect.dbapi.Error,
                    hide_parameters=self.engine.hide_parameters,
                    connection_invalidated=self._is_disconnect,
                    dialect=self.dialect,
                    ismulti=context.executemany
                    if context is not None
                    else None,
                )
            else:
                sqlalchemy_exception = None

            newraise = None

            if (
                self._has_events or self.engine._has_events
            ) and not self._execution_options.get(
                "skip_user_error_events", False
            ):
                ctx = ExceptionContextImpl(
                    e,
                    sqlalchemy_exception,
                    self.engine,
                    self,
                    cursor,
                    statement,
                    parameters,
                    context,
                    self._is_disconnect,
                    invalidate_pool_on_disconnect,
                )

                for fn in self.dispatch.handle_error:
                    try:
                        # handler returns an exception;
                        # call next handler in a chain
                        per_fn = fn(ctx)
                        if per_fn is not None:
                            ctx.chained_exception = newraise = per_fn
                    except Exception as _raised:
                        # handler raises an exception - stop processing
                        newraise = _raised
                        break

                if self._is_disconnect != ctx.is_disconnect:
                    self._is_disconnect = ctx.is_disconnect
                    if sqlalchemy_exception:
                        sqlalchemy_exception.connection_invalidated = (
                            ctx.is_disconnect
                        )

                # set up potentially user-defined value for
                # invalidate pool.
                invalidate_pool_on_disconnect = (
                    ctx.invalidate_pool_on_disconnect
                )

            if should_wrap and context:
                context.handle_dbapi_exception(e)

            if not self._is_disconnect:
                if cursor:
                    self._safe_close_cursor(cursor)
                with util.safe_reraise(warn_only=True):
                    self._autorollback()

            if newraise:
                util.raise_(newraise, with_traceback=exc_info[2], from_=e)
            elif should_wrap:
>               util.raise_(
                    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
                )

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/engine/base.py:2026:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

    def raise_(
        exception, with_traceback=None, replace_context=None, from_=False
    ):
        r"""implement "raise" with cause support.

        :param exception: exception to raise
        :param with_traceback: will call exception.with_traceback()
        :param replace_context: an as-yet-unsupported feature.  This is
         an exception object which we are "replacing", e.g., it's our
         "cause" but we don't want it printed.    Basically just what
         ``__suppress_context__`` does but we don't want to suppress
         the enclosing context, if any.  So for now we make it the
         cause.
        :param from\_: the cause.  this actually sets the cause and doesn't
         hope to hide it someday.

        """
        if with_traceback is not None:
            exception = exception.with_traceback(with_traceback)

        if from_ is not False:
            exception.__cause__ = from_
        elif replace_context is not None:
            # no good solution here, we would like to have the exception
            # have only the context of replace_context.__context__ so that the
            # intermediary exception does not change, but we can't figure
            # that out.
            exception.__cause__ = replace_context

        try:
>           raise exception

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/util/compat.py:207:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b9edf0>
dialect = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7fe2f3b9eaf0>
constructor = <bound method DefaultExecutionContext._init_compiled of <class 'sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext'>>
statement = 'SELECT pk_index, b, c \nFROM (SELECT original_table_clause.a AS a, original_table_clause.b AS b, original_table_claus...S NULL AND c IS NULL)) AS anon_2 \nWHERE records_with_grouped_column_counts_subquery._num_rows >= ?\n LIMIT ? OFFSET ?'
parameters = (2, 20, 0), execution_options = immutabledict({})
args = (<sqlalchemy.dialects.sqlite.base.SQLiteCompiler object at 0x7fe2f8dbc250>, [], <sqlalchemy.sql.selectable.Select obje...140612814459568 num_rows)s', 2, type_=Integer()), _OffsetLimitParam('%(140612814488864 param)s', 20, type_=Integer())])
kw = {'cache_hit': symbol('CACHE_MISS')}
branched = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b9edf0>
conn = <sqlalchemy.pool.base._ConnectionFairy object at 0x7fe2f3b9ee80>
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7fe2f8dbc5e0>
cursor = <sqlite3.Cursor object at 0x7fe2f849dc00>, evt_handled = False

    def _execute_context(
        self,
        dialect,
        constructor,
        statement,
        parameters,
        execution_options,
        *args,
        **kw
    ):
        """Create an :class:`.ExecutionContext` and execute, returning
        a :class:`_engine.CursorResult`."""

        branched = self
        if self.__branch_from:
            # if this is a "branched" connection, do everything in terms
            # of the "root" connection, *except* for .close(), which is
            # the only feature that branching provides
            self = self.__branch_from

        try:
            conn = self._dbapi_connection
            if conn is None:
                conn = self._revalidate_connection()

            context = constructor(
                dialect, self, conn, execution_options, *args, **kw
            )
        except (exc.PendingRollbackError, exc.ResourceClosedError):
            raise
        except BaseException as e:
            self._handle_dbapi_exception(
                e, util.text_type(statement), parameters, None, None
            )

        if (
            self._transaction
            and not self._transaction.is_active
            or (
                self._nested_transaction
                and not self._nested_transaction.is_active
            )
        ):
            self._invalid_transaction()

        elif self._trans_context_manager:
            TransactionalContext._trans_ctx_check(self)

        if self._is_future and self._transaction is None:
            self._autobegin()

        context.pre_exec()

        if dialect.use_setinputsizes:
            context._set_input_sizes()

        cursor, statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )

        if not context.executemany:
            parameters = parameters[0]

        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                statement, parameters = fn(
                    self,
                    cursor,
                    statement,
                    parameters,
                    context,
                    context.executemany,
                )

        if self._echo:

            self._log_info(statement)

            stats = context._get_cache_stats()

            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        parameters, batches=10, ismulti=context.executemany
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]"
                    % (stats,)
                )

        evt_handled = False
        try:
            if context.executemany:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(cursor, statement, parameters, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor, statement, parameters, context
                    )
            elif not parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, statement, context
                    )
            else:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(cursor, statement, parameters, context):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, statement, parameters, context
                    )

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1802:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7fe2f3b9eaf0>
cursor = <sqlite3.Cursor object at 0x7fe2f849dc00>
statement = 'SELECT pk_index, b, c \nFROM (SELECT original_table_clause.a AS a, original_table_clause.b AS b, original_table_claus...S NULL AND c IS NULL)) AS anon_2 \nWHERE records_with_grouped_column_counts_subquery._num_rows >= ?\n LIMIT ? OFFSET ?'
parameters = (2, 20, 0)
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7fe2f8dbc5e0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) ambiguous column name: pk_index
E       [SQL: SELECT pk_index, b, c
E       FROM (SELECT original_table_clause.a AS a, original_table_clause.b AS b, original_table_clause.c AS c, original_table_clause.pk_index AS pk_index, group_counts_subquery._num_rows AS _num_rows
E       FROM (SELECT a, b, c, pk_index
E       FROM (SELECT *
E       FROM test_data_c5fncnz3
E       WHERE NOT (b IS NULL AND c IS NULL)) AS anon_1) AS original_table_clause JOIN (SELECT b, c, count(*) AS _num_rows
E       FROM (SELECT a, b, c, pk_index
E       FROM (SELECT *
E       FROM test_data_c5fncnz3
E       WHERE NOT (b IS NULL AND c IS NULL)) AS anon_1) AS original_table_clause GROUP BY b, c) AS group_counts_subquery ON group_counts_subquery.b = original_table_clause.b AND group_counts_subquery.c = original_table_clause.c) AS records_with_grouped_column_counts_subquery, (SELECT *
E       FROM test_data_c5fncnz3
E       WHERE NOT (b IS NULL AND c IS NULL)) AS anon_2
E       WHERE records_with_grouped_column_counts_subquery._num_rows >= ?
E        LIMIT ? OFFSET ?]
E       [parameters: (2, 20, 0)]
E       (Background on this error at: https://sqlalche.me/e/14/e3q8)

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/engine/default.py:719: OperationalError

The above exception was the direct cause of the following exception:

test_case = {'expectation_type': 'expect_compound_columns_to_be_unique', 'pk_column': True, 'skip': False, 'test': {'exact_match_o... False, 'in': {'column_list': ['b', 'c']}, 'include_in_gallery': True, 'input': {'column_list': ['b', 'c']}, ...}, ...}

    @pytest.mark.order(index=0)
    @pytest.mark.integration
    @pytest.mark.slow  # 12.68s
    def test_case_runner_v3_api(test_case):
        if test_case["skip"]:
            pytest.skip()

        # Note: this should never be done in practice, but we are wiping expectations to reuse batches during testing.
        # test_case["batch"]._initialize_expectations()
        if "parse_strings_as_datetimes" in test_case["test"]["in"]:
            with pytest.deprecated_call():
                evaluate_json_test_v3_api(
                    validator=test_case["validator_with_data"],
                    expectation_type=test_case["expectation_type"],
                    test=test_case["test"],
                    pk_column=test_case["pk_column"],
                )
        else:
>           evaluate_json_test_v3_api(
                validator=test_case["validator_with_data"],
                expectation_type=test_case["expectation_type"],
                test=test_case["test"],
                pk_column=test_case["pk_column"],
            )

tests/test_definitions/test_expectations_v3_api.py:428:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
great_expectations/self_check/util.py:2887: in evaluate_json_test_v3_api
    result = getattr(validator, expectation_type)(**runtime_kwargs)
great_expectations/validator/validator.py:595: in inst_expectation
    raise err
great_expectations/validator/validator.py:558: in inst_expectation
    validation_result = expectation.validate(
great_expectations/expectations/expectation.py:1265: in validate
    ] = validator.graph_validate(
great_expectations/validator/validator.py:1046: in graph_validate
    raise err
great_expectations/validator/validator.py:1025: in graph_validate
    ) = self._resolve_suite_level_graph_and_process_metric_evaluation_errors(
great_expectations/validator/validator.py:1184: in _resolve_suite_level_graph_and_process_metric_evaluation_errors
    ) = self._metrics_calculator.resolve_validation_graph(
great_expectations/validator/metrics_calculator.py:282: in resolve_validation_graph
    resolved_metrics, aborted_metrics_info = graph.resolve(
great_expectations/validator/validation_graph.py:196: in resolve
    ] = self._resolve(
great_expectations/validator/validation_graph.py:302: in _resolve
    raise err
great_expectations/validator/validation_graph.py:272: in _resolve
    self._execution_engine.resolve_metrics(
great_expectations/execution_engine/execution_engine.py:375: in resolve_metrics
    return self._process_direct_and_bundled_metric_computation_configurations(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <great_expectations.execution_engine.sqlalchemy_execution_engine.SqlAlchemyExecutionEngine object at 0x7fe2f3b9e2e0>
metric_fn_direct_configurations = [MetricComputationConfiguration(metric_configuration={
  "metric_name": "compound_columns.unique.unexpected_values",
 ...l_unexpected_count': 20, 'include_unexpected_rows': False}}}, compute_domain_kwargs=None, accessor_domain_kwargs=None)]
metric_fn_bundle_configurations = []

    def _process_direct_and_bundled_metric_computation_configurations(
        self,
        metric_fn_direct_configurations: List[MetricComputationConfiguration],
        metric_fn_bundle_configurations: List[MetricComputationConfiguration],
    ) -> Dict[Tuple[str, str, str], MetricValue]:
        """
        This method processes directly-computable and bundled "MetricComputationConfiguration" objects.

        Args:
            metric_fn_direct_configurations: directly-computable "MetricComputationConfiguration" objects
            metric_fn_bundle_configurations: bundled "MetricComputationConfiguration" objects (column aggregates)

        Returns:
            resolved_metrics (Dict): a dictionary with the values for the metrics that have just been resolved.
        """
        resolved_metrics: Dict[Tuple[str, str, str], MetricValue] = {}

        metric_computation_configuration: MetricComputationConfiguration

        for metric_computation_configuration in metric_fn_direct_configurations:
            try:
                resolved_metrics[
                    metric_computation_configuration.metric_configuration.id
                ] = metric_computation_configuration.metric_fn(
                    **metric_computation_configuration.metric_provider_kwargs
                )
            except Exception as e:
>               raise gx_exceptions.MetricResolutionError(
                    message=str(e),
                    failed_metrics=(
                        metric_computation_configuration.metric_configuration,
                    ),
                ) from e
E               great_expectations.exceptions.exceptions.MetricResolutionError: (sqlite3.OperationalError) ambiguous column name: pk_index
E               [SQL: SELECT pk_index, b, c
E               FROM (SELECT original_table_clause.a AS a, original_table_clause.b AS b, original_table_clause.c AS c, original_table_clause.pk_index AS pk_index, group_counts_subquery._num_rows AS _num_rows
E               FROM (SELECT a, b, c, pk_index
E               FROM (SELECT *
E               FROM test_data_c5fncnz3
E               WHERE NOT (b IS NULL AND c IS NULL)) AS anon_1) AS original_table_clause JOIN (SELECT b, c, count(*) AS _num_rows
E               FROM (SELECT a, b, c, pk_index
E               FROM (SELECT *
E               FROM test_data_c5fncnz3
E               WHERE NOT (b IS NULL AND c IS NULL)) AS anon_1) AS original_table_clause GROUP BY b, c) AS group_counts_subquery ON group_counts_subquery.b = original_table_clause.b AND group_counts_subquery.c = original_table_clause.c) AS records_with_grouped_column_counts_subquery, (SELECT *
E               FROM test_data_c5fncnz3
E               WHERE NOT (b IS NULL AND c IS NULL)) AS anon_2
E               WHERE records_with_grouped_column_counts_subquery._num_rows >= ?
E                LIMIT ? OFFSET ?]
E               [parameters: (2, 20, 0)]
E               (Background on this error at: https://sqlalche.me/e/14/e3q8)

great_expectations/execution_engine/execution_engine.py:654: MetricResolutionError
----------------------------- Captured stderr call -----------------------------

Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s][A
Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s][A
Calculating Metrics:  18%|        | 2/11 [00:00<00:00, 2416.07it/s][A
Calculating Metrics:  18%|        | 2/11 [00:00<00:00, 295.38it/s] [A
Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 495.24it/s][A
Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 293.64it/s][A
Calculating Metrics:  45%|     | 5/11 [00:00<00:00, 332.25it/s][A
Calculating Metrics:  45%|     | 5/11 [00:00<00:00, 247.58it/s][A
Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 279.88it/s][A
Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 232.31it/s][A
--------------------------- Captured stderr teardown ---------------------------
Calculating Metrics:  55%|    | 6/11 [00:01<00:01,  3.73it/s]
_ test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_compound_columns_to_be_unique:mostly_set_successful_expectation] _

self = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b9edf0>
dialect = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7fe2f3b9eaf0>
constructor = <bound method DefaultExecutionContext._init_compiled of <class 'sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext'>>
statement = 'SELECT pk_index, b, c \nFROM (SELECT original_table_clause.a AS a, original_table_clause.b AS b, original_table_claus...S NULL AND c IS NULL)) AS anon_2 \nWHERE records_with_grouped_column_counts_subquery._num_rows >= ?\n LIMIT ? OFFSET ?'
parameters = (2, 20, 0), execution_options = immutabledict({})
args = (<sqlalchemy.dialects.sqlite.base.SQLiteCompiler object at 0x7fe2f8dbc250>, [], <sqlalchemy.sql.selectable.Select obje...140612808423600 num_rows)s', 2, type_=Integer()), _OffsetLimitParam('%(140612808424512 param)s', 20, type_=Integer())])
kw = {'cache_hit': symbol('CACHE_HIT')}
branched = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b9edf0>
conn = <sqlalchemy.pool.base._ConnectionFairy object at 0x7fe2f3b9ee80>
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7fe2f8685fd0>
cursor = <sqlite3.Cursor object at 0x7fe2f84dd110>, evt_handled = False

    def _execute_context(
        self,
        dialect,
        constructor,
        statement,
        parameters,
        execution_options,
        *args,
        **kw
    ):
        """Create an :class:`.ExecutionContext` and execute, returning
        a :class:`_engine.CursorResult`."""

        branched = self
        if self.__branch_from:
            # if this is a "branched" connection, do everything in terms
            # of the "root" connection, *except* for .close(), which is
            # the only feature that branching provides
            self = self.__branch_from

        try:
            conn = self._dbapi_connection
            if conn is None:
                conn = self._revalidate_connection()

            context = constructor(
                dialect, self, conn, execution_options, *args, **kw
            )
        except (exc.PendingRollbackError, exc.ResourceClosedError):
            raise
        except BaseException as e:
            self._handle_dbapi_exception(
                e, util.text_type(statement), parameters, None, None
            )

        if (
            self._transaction
            and not self._transaction.is_active
            or (
                self._nested_transaction
                and not self._nested_transaction.is_active
            )
        ):
            self._invalid_transaction()

        elif self._trans_context_manager:
            TransactionalContext._trans_ctx_check(self)

        if self._is_future and self._transaction is None:
            self._autobegin()

        context.pre_exec()

        if dialect.use_setinputsizes:
            context._set_input_sizes()

        cursor, statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )

        if not context.executemany:
            parameters = parameters[0]

        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                statement, parameters = fn(
                    self,
                    cursor,
                    statement,
                    parameters,
                    context,
                    context.executemany,
                )

        if self._echo:

            self._log_info(statement)

            stats = context._get_cache_stats()

            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        parameters, batches=10, ismulti=context.executemany
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]"
                    % (stats,)
                )

        evt_handled = False
        try:
            if context.executemany:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(cursor, statement, parameters, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor, statement, parameters, context
                    )
            elif not parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, statement, context
                    )
            else:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(cursor, statement, parameters, context):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, statement, parameters, context
                    )

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1802:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7fe2f3b9eaf0>
cursor = <sqlite3.Cursor object at 0x7fe2f84dd110>
statement = 'SELECT pk_index, b, c \nFROM (SELECT original_table_clause.a AS a, original_table_clause.b AS b, original_table_claus...S NULL AND c IS NULL)) AS anon_2 \nWHERE records_with_grouped_column_counts_subquery._num_rows >= ?\n LIMIT ? OFFSET ?'
parameters = (2, 20, 0)
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7fe2f8685fd0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlite3.OperationalError: ambiguous column name: pk_index

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/engine/default.py:719: OperationalError

The above exception was the direct cause of the following exception:

self = <great_expectations.execution_engine.sqlalchemy_execution_engine.SqlAlchemyExecutionEngine object at 0x7fe2f3b9e2e0>
metric_fn_direct_configurations = [MetricComputationConfiguration(metric_configuration={
  "metric_name": "compound_columns.unique.unexpected_count",
  ...l_unexpected_count': 20, 'include_unexpected_rows': False}}}, compute_domain_kwargs=None, accessor_domain_kwargs=None)]
metric_fn_bundle_configurations = []

    def _process_direct_and_bundled_metric_computation_configurations(
        self,
        metric_fn_direct_configurations: List[MetricComputationConfiguration],
        metric_fn_bundle_configurations: List[MetricComputationConfiguration],
    ) -> Dict[Tuple[str, str, str], MetricValue]:
        """
        This method processes directly-computable and bundled "MetricComputationConfiguration" objects.

        Args:
            metric_fn_direct_configurations: directly-computable "MetricComputationConfiguration" objects
            metric_fn_bundle_configurations: bundled "MetricComputationConfiguration" objects (column aggregates)

        Returns:
            resolved_metrics (Dict): a dictionary with the values for the metrics that have just been resolved.
        """
        resolved_metrics: Dict[Tuple[str, str, str], MetricValue] = {}

        metric_computation_configuration: MetricComputationConfiguration

        for metric_computation_configuration in metric_fn_direct_configurations:
            try:
                resolved_metrics[
                    metric_computation_configuration.metric_configuration.id
>               ] = metric_computation_configuration.metric_fn(
                    **metric_computation_configuration.metric_provider_kwargs
                )

great_expectations/execution_engine/execution_engine.py:650:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

cls = <class 'great_expectations.expectations.metrics.multicolumn_map_metrics.compound_columns_unique.CompoundColumnsUnique'>
execution_engine = <great_expectations.execution_engine.sqlalchemy_execution_engine.SqlAlchemyExecutionEngine object at 0x7fe2f3b9e2e0>
metric_domain_kwargs = {'batch_id': 'b1ae3225b6aa3d6c44dce474d8b4e741', 'table': None, 'column_list': ['b', 'c'], 'row_condition': None, 'condition_parser': None, 'ignore_row_if': 'all_values_are_missing'}
metric_value_kwargs = {'result_format': {'result_format': 'COMPLETE', 'unexpected_index_column_names': ['pk_index'], 'partial_unexpected_count': 20, 'include_unexpected_rows': False}}
metrics = {'table.column_types': [{'autoincrement': 'auto', 'default': None, 'name': 'a', 'nullable': True, ...}, {'autoincremen...w_condition': None, 'condition_parser': None, 'ignore_row_if': 'all_values_are_missing'}, {'column_list': ['b', 'c']})}
kwargs = {'runtime_configuration': {'catch_exceptions': False, 'include_config': False, 'result_format': {'include_unexpected_rows': False, 'partial_unexpected_count': 20, 'result_format': 'COMPLETE', 'unexpected_index_column_names': ['pk_index']}}}
unexpected_condition = <sqlalchemy.sql.elements.BinaryExpression object at 0x7fe2f87f37f0>
compute_domain_kwargs = {'batch_id': 'b1ae3225b6aa3d6c44dce474d8b4e741', 'table': None, 'row_condition': None, 'condition_parser': None, 'ignore_row_if': 'all_values_are_missing'}
accessor_domain_kwargs = {'column_list': ['b', 'c']}
domain_column_name_list = ['b', 'c'], column_name = 'c'
column_list = ['b', 'c']
domain_kwargs = {'batch_id': 'b1ae3225b6aa3d6c44dce474d8b4e741', 'column_list': ['b', 'c'], 'condition_parser': None, 'ignore_row_if': 'all_values_are_missing', ...}

    def _sqlalchemy_map_condition_index(
        cls,
        execution_engine: SqlAlchemyExecutionEngine,
        metric_domain_kwargs: Dict,
        metric_value_kwargs: Dict,
        metrics: Dict[str, Any],
        **kwargs,
    ) -> List[Dict[str, Any]]:
        """
        Returns indices of the metric values which do not meet an expected Expectation condition for instances
        of ColumnMapExpectation.

        Requires `unexpected_index_column_names` to be part of `result_format` dict to specify primary_key columns
        to return.
        """
        (
            unexpected_condition,
            compute_domain_kwargs,
            accessor_domain_kwargs,
        ) = metrics.get("unexpected_condition")

        domain_column_name_list: List[str] = list()
        # column map expectations
        if "column" in accessor_domain_kwargs:
            column_name: Union[str, quoted_name] = accessor_domain_kwargs["column"]
            domain_column_name_list.append(column_name)
        # multi-column map expectations
        elif "column_list" in accessor_domain_kwargs:
            column_list: List[Union[str, quoted_name]] = accessor_domain_kwargs[
                "column_list"
            ]
            domain_column_name_list = column_list
        # column-map expectations
        elif "column_A" in accessor_domain_kwargs and "column_B" in accessor_domain_kwargs:
            column_list: List[Union[str, quoted_name]] = list()
            column_list.append(accessor_domain_kwargs["column_A"])
            column_list.append(accessor_domain_kwargs["column_B"])
            domain_column_name_list = column_list

        domain_kwargs: dict = dict(**compute_domain_kwargs, **accessor_domain_kwargs)
        result_format: dict = metric_value_kwargs["result_format"]

        all_table_columns: List[str] = metrics.get("table.columns")

        unexpected_index_column_names: Optional[List[str]] = result_format.get(
            "unexpected_index_column_names"
        )

        column_selector: List[sa.Column] = []
        for column_name in unexpected_index_column_names:
            if column_name not in all_table_columns:
                raise gx_exceptions.InvalidMetricAccessorDomainKwargsKeyError(
                    message=f'Error: The unexpected_index_column: "{column_name}" in does not exist in SQL Table. '
                    f"Please check your configuration and try again."
                )
            column_selector.append(sa.column(column_name))

        # expectation_domain_column_name: str = domain_kwargs["column"]

        # the last column we SELECT is the column the Expectation is being run on
        for column_name in domain_column_name_list:
            column_selector.append(sa.column(column_name))

        domain_records_as_selectable: sa.sql.Selectable = (
            execution_engine.get_domain_records(domain_kwargs=domain_kwargs)
        )
        unexpected_condition_query_with_selected_columns: sa.select = sa.select(
            column_selector
        ).where(unexpected_condition)

        if not MapMetricProvider.is_sqlalchemy_metric_selectable(map_metric_provider=cls):
            domain_records_as_selectable: Union[
                sa.Table, sa.Select
            ] = get_sqlalchemy_selectable(domain_records_as_selectable)

        # since SQL tables can be **very** large, truncate query_result values at 20, or at `partial_unexpected_count`
        final_query: sa.select = (
            unexpected_condition_query_with_selected_columns.select_from(
                domain_records_as_selectable
            ).limit(result_format["partial_unexpected_count"])
        )
>       query_result: List[tuple] = execution_engine.engine.execute(final_query).fetchall()

great_expectations/expectations/metrics/map_metric_provider.py:2662:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b9edf0>
statement = <sqlalchemy.sql.selectable.Select object at 0x7fe2f87f3bb0>
multiparams = (), params = {}
meth = <bound method ClauseElement._execute_on_connection of <sqlalchemy.sql.selectable.Select object at 0x7fe2f87f3bb0>>

    def execute(self, statement, *multiparams, **params):
        r"""Executes a SQL statement construct and returns a
        :class:`_engine.CursorResult`.

        :param statement: The statement to be executed.  May be
         one of:

         * a plain string (deprecated)
         * any :class:`_expression.ClauseElement` construct that is also
           a subclass of :class:`.Executable`, such as a
           :func:`_expression.select` construct
         * a :class:`.FunctionElement`, such as that generated
           by :data:`.func`, will be automatically wrapped in
           a SELECT statement, which is then executed.
         * a :class:`.DDLElement` object
         * a :class:`.DefaultGenerator` object
         * a :class:`.Compiled` object

         .. deprecated:: 2.0 passing a string to
            :meth:`_engine.Connection.execute` is
            deprecated and will be removed in version 2.0.  Use the
            :func:`_expression.text` construct with
            :meth:`_engine.Connection.execute`, or the
            :meth:`_engine.Connection.exec_driver_sql`
            method to invoke a driver-level
            SQL string.

        :param \*multiparams/\**params: represent bound parameter
         values to be used in the execution.   Typically,
         the format is either a collection of one or more
         dictionaries passed to \*multiparams::

             conn.execute(
                 table.insert(),
                 {"id":1, "value":"v1"},
                 {"id":2, "value":"v2"}
             )

         ...or individual key/values interpreted by \**params::

             conn.execute(
                 table.insert(), id=1, value="v1"
             )

         In the case that a plain SQL string is passed, and the underlying
         DBAPI accepts positional bind parameters, a collection of tuples
         or individual values in \*multiparams may be passed::

             conn.execute(
                 "INSERT INTO table (id, value) VALUES (?, ?)",
                 (1, "v1"), (2, "v2")
             )

             conn.execute(
                 "INSERT INTO table (id, value) VALUES (?, ?)",
                 1, "v1"
             )

         Note above, the usage of a question mark "?" or other
         symbol is contingent upon the "paramstyle" accepted by the DBAPI
         in use, which may be any of "qmark", "named", "pyformat", "format",
         "numeric".   See `pep-249
         <https://www.python.org/dev/peps/pep-0249/>`_ for details on
         paramstyle.

         To execute a textual SQL statement which uses bound parameters in a
         DBAPI-agnostic way, use the :func:`_expression.text` construct.

         .. deprecated:: 2.0 use of tuple or scalar positional parameters
            is deprecated. All params should be dicts or sequences of dicts.
            Use :meth:`.exec_driver_sql` to execute a plain string with
            tuple or scalar positional parameters.

        """

        if isinstance(statement, util.string_types):
            util.warn_deprecated_20(
                "Passing a string to Connection.execute() is "
                "deprecated and will be removed in version 2.0.  Use the "
                "text() construct, "
                "or the Connection.exec_driver_sql() method to invoke a "
                "driver-level SQL string."
            )

            return self._exec_driver_sql(
                statement,
                multiparams,
                params,
                _EMPTY_EXECUTION_OPTS,
                future=False,
            )

        try:
            meth = statement._execute_on_connection
        except AttributeError as err:
            util.raise_(
                exc.ObjectNotExecutableError(statement), replace_context=err
            )
        else:
>           return meth(self, multiparams, params, _EMPTY_EXECUTION_OPTS)

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1289:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.sql.selectable.Select object at 0x7fe2f87f3bb0>
connection = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b9edf0>
multiparams = (), params = {}, execution_options = immutabledict({})
_force = False

    def _execute_on_connection(
        self, connection, multiparams, params, execution_options, _force=False
    ):
        if _force or self.supports_execution:
>           return connection._execute_clauseelement(
                self, multiparams, params, execution_options
            )

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/sql/elements.py:325:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b9edf0>
elem = <sqlalchemy.sql.selectable.Select object at 0x7fe2f87f3bb0>
multiparams = (), params = {}, execution_options = immutabledict({})

    def _execute_clauseelement(
        self, elem, multiparams, params, execution_options
    ):
        """Execute a sql.ClauseElement object."""

        execution_options = elem._execution_options.merge_with(
            self._execution_options, execution_options
        )

        distilled_params = _distill_params(self, multiparams, params)

        has_events = self._has_events or self.engine._has_events
        if has_events:
            (
                elem,
                distilled_params,
                event_multiparams,
                event_params,
            ) = self._invoke_before_exec_event(
                elem, distilled_params, execution_options
            )

        if distilled_params:
            # ensure we don't retain a link to the view object for keys()
            # which links to the values, which we don't want to cache
            keys = sorted(distilled_params[0])
            for_executemany = len(distilled_params) > 1
        else:
            keys = []
            for_executemany = False

        dialect = self.dialect

        schema_translate_map = execution_options.get(
            "schema_translate_map", None
        )

        compiled_cache = execution_options.get(
            "compiled_cache", self.engine._compiled_cache
        )

        compiled_sql, extracted_params, cache_hit = elem._compile_w_cache(
            dialect=dialect,
            compiled_cache=compiled_cache,
            column_keys=keys,
            for_executemany=for_executemany,
            schema_translate_map=schema_translate_map,
            linting=self.dialect.compiler_linting | compiler.WARN_LINTING,
        )
>       ret = self._execute_context(
            dialect,
            dialect.execution_ctx_cls._init_compiled,
            compiled_sql,
            distilled_params,
            execution_options,
            compiled_sql,
            distilled_params,
            elem,
            extracted_params,
            cache_hit=cache_hit,
        )

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1481:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b9edf0>
dialect = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7fe2f3b9eaf0>
constructor = <bound method DefaultExecutionContext._init_compiled of <class 'sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext'>>
statement = 'SELECT pk_index, b, c \nFROM (SELECT original_table_clause.a AS a, original_table_clause.b AS b, original_table_claus...S NULL AND c IS NULL)) AS anon_2 \nWHERE records_with_grouped_column_counts_subquery._num_rows >= ?\n LIMIT ? OFFSET ?'
parameters = (2, 20, 0), execution_options = immutabledict({})
args = (<sqlalchemy.dialects.sqlite.base.SQLiteCompiler object at 0x7fe2f8dbc250>, [], <sqlalchemy.sql.selectable.Select obje...140612808423600 num_rows)s', 2, type_=Integer()), _OffsetLimitParam('%(140612808424512 param)s', 20, type_=Integer())])
kw = {'cache_hit': symbol('CACHE_HIT')}
branched = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b9edf0>
conn = <sqlalchemy.pool.base._ConnectionFairy object at 0x7fe2f3b9ee80>
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7fe2f8685fd0>
cursor = <sqlite3.Cursor object at 0x7fe2f84dd110>, evt_handled = False

    def _execute_context(
        self,
        dialect,
        constructor,
        statement,
        parameters,
        execution_options,
        *args,
        **kw
    ):
        """Create an :class:`.ExecutionContext` and execute, returning
        a :class:`_engine.CursorResult`."""

        branched = self
        if self.__branch_from:
            # if this is a "branched" connection, do everything in terms
            # of the "root" connection, *except* for .close(), which is
            # the only feature that branching provides
            self = self.__branch_from

        try:
            conn = self._dbapi_connection
            if conn is None:
                conn = self._revalidate_connection()

            context = constructor(
                dialect, self, conn, execution_options, *args, **kw
            )
        except (exc.PendingRollbackError, exc.ResourceClosedError):
            raise
        except BaseException as e:
            self._handle_dbapi_exception(
                e, util.text_type(statement), parameters, None, None
            )

        if (
            self._transaction
            and not self._transaction.is_active
            or (
                self._nested_transaction
                and not self._nested_transaction.is_active
            )
        ):
            self._invalid_transaction()

        elif self._trans_context_manager:
            TransactionalContext._trans_ctx_check(self)

        if self._is_future and self._transaction is None:
            self._autobegin()

        context.pre_exec()

        if dialect.use_setinputsizes:
            context._set_input_sizes()

        cursor, statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )

        if not context.executemany:
            parameters = parameters[0]

        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                statement, parameters = fn(
                    self,
                    cursor,
                    statement,
                    parameters,
                    context,
                    context.executemany,
                )

        if self._echo:

            self._log_info(statement)

            stats = context._get_cache_stats()

            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        parameters, batches=10, ismulti=context.executemany
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]"
                    % (stats,)
                )

        evt_handled = False
        try:
            if context.executemany:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(cursor, statement, parameters, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor, statement, parameters, context
                    )
            elif not parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, statement, context
                    )
            else:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(cursor, statement, parameters, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute(
                        cursor, statement, parameters, context
                    )

            if self._has_events or self.engine._has_events:
                self.dispatch.after_cursor_execute(
                    self,
                    cursor,
                    statement,
                    parameters,
                    context,
                    context.executemany,
                )

            context.post_exec()

            result = context._setup_result_proxy()

            if not self._is_future:
                should_close_with_result = branched.should_close_with_result

                if not result._soft_closed and should_close_with_result:
                    result._autoclose_connection = True

                if (
                    # usually we're in a transaction so avoid relatively
                    # expensive / legacy should_autocommit call
                    self._transaction is None
                    and context.should_autocommit
                ):
                    self._commit_impl(autocommit=True)

                # for "connectionless" execution, we have to close this
                # Connection after the statement is complete.
                # legacy stuff.
                if should_close_with_result and context._soft_closed:
                    assert not self._is_future

                    # CursorResult already exhausted rows / has no rows.
                    # close us now
                    branched.close()

        except BaseException as e:
>           self._handle_dbapi_exception(
                e, statement, parameters, cursor, context
            )

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1845:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b9edf0>
e = OperationalError('ambiguous column name: pk_index')
statement = 'SELECT pk_index, b, c \nFROM (SELECT original_table_clause.a AS a, original_table_clause.b AS b, original_table_claus...S NULL AND c IS NULL)) AS anon_2 \nWHERE records_with_grouped_column_counts_subquery._num_rows >= ?\n LIMIT ? OFFSET ?'
parameters = (2, 20, 0), cursor = <sqlite3.Cursor object at 0x7fe2f84dd110>
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7fe2f8685fd0>

    def _handle_dbapi_exception(
        self, e, statement, parameters, cursor, context
    ):
        exc_info = sys.exc_info()

        is_exit_exception = util.is_exit_exception(e)

        if not self._is_disconnect:
            self._is_disconnect = (
                isinstance(e, self.dialect.dbapi.Error)
                and not self.closed
                and self.dialect.is_disconnect(
                    e,
                    self._dbapi_connection if not self.invalidated else None,
                    cursor,
                )
            ) or (is_exit_exception and not self.closed)

        invalidate_pool_on_disconnect = not is_exit_exception

        if self._reentrant_error:
            util.raise_(
                exc.DBAPIError.instance(
                    statement,
                    parameters,
                    e,
                    self.dialect.dbapi.Error,
                    hide_parameters=self.engine.hide_parameters,
                    dialect=self.dialect,
                    ismulti=context.executemany
                    if context is not None
                    else None,
                ),
                with_traceback=exc_info[2],
                from_=e,
            )
        self._reentrant_error = True
        try:
            # non-DBAPI error - if we already got a context,
            # or there's no string statement, don't wrap it
            should_wrap = isinstance(e, self.dialect.dbapi.Error) or (
                statement is not None
                and context is None
                and not is_exit_exception
            )

            if should_wrap:
                sqlalchemy_exception = exc.DBAPIError.instance(
                    statement,
                    parameters,
                    e,
                    self.dialect.dbapi.Error,
                    hide_parameters=self.engine.hide_parameters,
                    connection_invalidated=self._is_disconnect,
                    dialect=self.dialect,
                    ismulti=context.executemany
                    if context is not None
                    else None,
                )
            else:
                sqlalchemy_exception = None

            newraise = None

            if (
                self._has_events or self.engine._has_events
            ) and not self._execution_options.get(
                "skip_user_error_events", False
            ):
                ctx = ExceptionContextImpl(
                    e,
                    sqlalchemy_exception,
                    self.engine,
                    self,
                    cursor,
                    statement,
                    parameters,
                    context,
                    self._is_disconnect,
                    invalidate_pool_on_disconnect,
                )

                for fn in self.dispatch.handle_error:
                    try:
                        # handler returns an exception;
                        # call next handler in a chain
                        per_fn = fn(ctx)
                        if per_fn is not None:
                            ctx.chained_exception = newraise = per_fn
                    except Exception as _raised:
                        # handler raises an exception - stop processing
                        newraise = _raised
                        break

                if self._is_disconnect != ctx.is_disconnect:
                    self._is_disconnect = ctx.is_disconnect
                    if sqlalchemy_exception:
                        sqlalchemy_exception.connection_invalidated = (
                            ctx.is_disconnect
                        )

                # set up potentially user-defined value for
                # invalidate pool.
                invalidate_pool_on_disconnect = (
                    ctx.invalidate_pool_on_disconnect
                )

            if should_wrap and context:
                context.handle_dbapi_exception(e)

            if not self._is_disconnect:
                if cursor:
                    self._safe_close_cursor(cursor)
                with util.safe_reraise(warn_only=True):
                    self._autorollback()

            if newraise:
                util.raise_(newraise, with_traceback=exc_info[2], from_=e)
            elif should_wrap:
>               util.raise_(
                    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
                )

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/engine/base.py:2026:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

    def raise_(
        exception, with_traceback=None, replace_context=None, from_=False
    ):
        r"""implement "raise" with cause support.

        :param exception: exception to raise
        :param with_traceback: will call exception.with_traceback()
        :param replace_context: an as-yet-unsupported feature.  This is
         an exception object which we are "replacing", e.g., it's our
         "cause" but we don't want it printed.    Basically just what
         ``__suppress_context__`` does but we don't want to suppress
         the enclosing context, if any.  So for now we make it the
         cause.
        :param from\_: the cause.  this actually sets the cause and doesn't
         hope to hide it someday.

        """
        if with_traceback is not None:
            exception = exception.with_traceback(with_traceback)

        if from_ is not False:
            exception.__cause__ = from_
        elif replace_context is not None:
            # no good solution here, we would like to have the exception
            # have only the context of replace_context.__context__ so that the
            # intermediary exception does not change, but we can't figure
            # that out.
            exception.__cause__ = replace_context

        try:
>           raise exception

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/util/compat.py:207:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b9edf0>
dialect = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7fe2f3b9eaf0>
constructor = <bound method DefaultExecutionContext._init_compiled of <class 'sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext'>>
statement = 'SELECT pk_index, b, c \nFROM (SELECT original_table_clause.a AS a, original_table_clause.b AS b, original_table_claus...S NULL AND c IS NULL)) AS anon_2 \nWHERE records_with_grouped_column_counts_subquery._num_rows >= ?\n LIMIT ? OFFSET ?'
parameters = (2, 20, 0), execution_options = immutabledict({})
args = (<sqlalchemy.dialects.sqlite.base.SQLiteCompiler object at 0x7fe2f8dbc250>, [], <sqlalchemy.sql.selectable.Select obje...140612808423600 num_rows)s', 2, type_=Integer()), _OffsetLimitParam('%(140612808424512 param)s', 20, type_=Integer())])
kw = {'cache_hit': symbol('CACHE_HIT')}
branched = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b9edf0>
conn = <sqlalchemy.pool.base._ConnectionFairy object at 0x7fe2f3b9ee80>
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7fe2f8685fd0>
cursor = <sqlite3.Cursor object at 0x7fe2f84dd110>, evt_handled = False

    def _execute_context(
        self,
        dialect,
        constructor,
        statement,
        parameters,
        execution_options,
        *args,
        **kw
    ):
        """Create an :class:`.ExecutionContext` and execute, returning
        a :class:`_engine.CursorResult`."""

        branched = self
        if self.__branch_from:
            # if this is a "branched" connection, do everything in terms
            # of the "root" connection, *except* for .close(), which is
            # the only feature that branching provides
            self = self.__branch_from

        try:
            conn = self._dbapi_connection
            if conn is None:
                conn = self._revalidate_connection()

            context = constructor(
                dialect, self, conn, execution_options, *args, **kw
            )
        except (exc.PendingRollbackError, exc.ResourceClosedError):
            raise
        except BaseException as e:
            self._handle_dbapi_exception(
                e, util.text_type(statement), parameters, None, None
            )

        if (
            self._transaction
            and not self._transaction.is_active
            or (
                self._nested_transaction
                and not self._nested_transaction.is_active
            )
        ):
            self._invalid_transaction()

        elif self._trans_context_manager:
            TransactionalContext._trans_ctx_check(self)

        if self._is_future and self._transaction is None:
            self._autobegin()

        context.pre_exec()

        if dialect.use_setinputsizes:
            context._set_input_sizes()

        cursor, statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )

        if not context.executemany:
            parameters = parameters[0]

        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                statement, parameters = fn(
                    self,
                    cursor,
                    statement,
                    parameters,
                    context,
                    context.executemany,
                )

        if self._echo:

            self._log_info(statement)

            stats = context._get_cache_stats()

            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        parameters, batches=10, ismulti=context.executemany
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]"
                    % (stats,)
                )

        evt_handled = False
        try:
            if context.executemany:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(cursor, statement, parameters, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor, statement, parameters, context
                    )
            elif not parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, statement, context
                    )
            else:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(cursor, statement, parameters, context):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, statement, parameters, context
                    )

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1802:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7fe2f3b9eaf0>
cursor = <sqlite3.Cursor object at 0x7fe2f84dd110>
statement = 'SELECT pk_index, b, c \nFROM (SELECT original_table_clause.a AS a, original_table_clause.b AS b, original_table_claus...S NULL AND c IS NULL)) AS anon_2 \nWHERE records_with_grouped_column_counts_subquery._num_rows >= ?\n LIMIT ? OFFSET ?'
parameters = (2, 20, 0)
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7fe2f8685fd0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) ambiguous column name: pk_index
E       [SQL: SELECT pk_index, b, c
E       FROM (SELECT original_table_clause.a AS a, original_table_clause.b AS b, original_table_clause.c AS c, original_table_clause.pk_index AS pk_index, group_counts_subquery._num_rows AS _num_rows
E       FROM (SELECT a, b, c, pk_index
E       FROM (SELECT *
E       FROM test_data_c5fncnz3
E       WHERE NOT (b IS NULL AND c IS NULL)) AS anon_1) AS original_table_clause JOIN (SELECT b, c, count(*) AS _num_rows
E       FROM (SELECT a, b, c, pk_index
E       FROM (SELECT *
E       FROM test_data_c5fncnz3
E       WHERE NOT (b IS NULL AND c IS NULL)) AS anon_1) AS original_table_clause GROUP BY b, c) AS group_counts_subquery ON group_counts_subquery.b = original_table_clause.b AND group_counts_subquery.c = original_table_clause.c) AS records_with_grouped_column_counts_subquery, (SELECT *
E       FROM test_data_c5fncnz3
E       WHERE NOT (b IS NULL AND c IS NULL)) AS anon_2
E       WHERE records_with_grouped_column_counts_subquery._num_rows >= ?
E        LIMIT ? OFFSET ?]
E       [parameters: (2, 20, 0)]
E       (Background on this error at: https://sqlalche.me/e/14/e3q8)

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/engine/default.py:719: OperationalError

The above exception was the direct cause of the following exception:

test_case = {'expectation_type': 'expect_compound_columns_to_be_unique', 'pk_column': True, 'skip': False, 'test': {'exact_match_o...['b', 'c'], 'mostly': 0.4}, 'include_in_gallery': True, 'input': {'column_list': ['b', 'c'], 'mostly': 0.4}, ...}, ...}

    @pytest.mark.order(index=0)
    @pytest.mark.integration
    @pytest.mark.slow  # 12.68s
    def test_case_runner_v3_api(test_case):
        if test_case["skip"]:
            pytest.skip()

        # Note: this should never be done in practice, but we are wiping expectations to reuse batches during testing.
        # test_case["batch"]._initialize_expectations()
        if "parse_strings_as_datetimes" in test_case["test"]["in"]:
            with pytest.deprecated_call():
                evaluate_json_test_v3_api(
                    validator=test_case["validator_with_data"],
                    expectation_type=test_case["expectation_type"],
                    test=test_case["test"],
                    pk_column=test_case["pk_column"],
                )
        else:
>           evaluate_json_test_v3_api(
                validator=test_case["validator_with_data"],
                expectation_type=test_case["expectation_type"],
                test=test_case["test"],
                pk_column=test_case["pk_column"],
            )

tests/test_definitions/test_expectations_v3_api.py:428:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
great_expectations/self_check/util.py:2887: in evaluate_json_test_v3_api
    result = getattr(validator, expectation_type)(**runtime_kwargs)
great_expectations/validator/validator.py:595: in inst_expectation
    raise err
great_expectations/validator/validator.py:558: in inst_expectation
    validation_result = expectation.validate(
great_expectations/expectations/expectation.py:1265: in validate
    ] = validator.graph_validate(
great_expectations/validator/validator.py:1046: in graph_validate
    raise err
great_expectations/validator/validator.py:1025: in graph_validate
    ) = self._resolve_suite_level_graph_and_process_metric_evaluation_errors(
great_expectations/validator/validator.py:1184: in _resolve_suite_level_graph_and_process_metric_evaluation_errors
    ) = self._metrics_calculator.resolve_validation_graph(
great_expectations/validator/metrics_calculator.py:282: in resolve_validation_graph
    resolved_metrics, aborted_metrics_info = graph.resolve(
great_expectations/validator/validation_graph.py:196: in resolve
    ] = self._resolve(
great_expectations/validator/validation_graph.py:302: in _resolve
    raise err
great_expectations/validator/validation_graph.py:272: in _resolve
    self._execution_engine.resolve_metrics(
great_expectations/execution_engine/execution_engine.py:375: in resolve_metrics
    return self._process_direct_and_bundled_metric_computation_configurations(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <great_expectations.execution_engine.sqlalchemy_execution_engine.SqlAlchemyExecutionEngine object at 0x7fe2f3b9e2e0>
metric_fn_direct_configurations = [MetricComputationConfiguration(metric_configuration={
  "metric_name": "compound_columns.unique.unexpected_count",
  ...l_unexpected_count': 20, 'include_unexpected_rows': False}}}, compute_domain_kwargs=None, accessor_domain_kwargs=None)]
metric_fn_bundle_configurations = []

    def _process_direct_and_bundled_metric_computation_configurations(
        self,
        metric_fn_direct_configurations: List[MetricComputationConfiguration],
        metric_fn_bundle_configurations: List[MetricComputationConfiguration],
    ) -> Dict[Tuple[str, str, str], MetricValue]:
        """
        This method processes directly-computable and bundled "MetricComputationConfiguration" objects.

        Args:
            metric_fn_direct_configurations: directly-computable "MetricComputationConfiguration" objects
            metric_fn_bundle_configurations: bundled "MetricComputationConfiguration" objects (column aggregates)

        Returns:
            resolved_metrics (Dict): a dictionary with the values for the metrics that have just been resolved.
        """
        resolved_metrics: Dict[Tuple[str, str, str], MetricValue] = {}

        metric_computation_configuration: MetricComputationConfiguration

        for metric_computation_configuration in metric_fn_direct_configurations:
            try:
                resolved_metrics[
                    metric_computation_configuration.metric_configuration.id
                ] = metric_computation_configuration.metric_fn(
                    **metric_computation_configuration.metric_provider_kwargs
                )
            except Exception as e:
>               raise gx_exceptions.MetricResolutionError(
                    message=str(e),
                    failed_metrics=(
                        metric_computation_configuration.metric_configuration,
                    ),
                ) from e
E               great_expectations.exceptions.exceptions.MetricResolutionError: (sqlite3.OperationalError) ambiguous column name: pk_index
E               [SQL: SELECT pk_index, b, c
E               FROM (SELECT original_table_clause.a AS a, original_table_clause.b AS b, original_table_clause.c AS c, original_table_clause.pk_index AS pk_index, group_counts_subquery._num_rows AS _num_rows
E               FROM (SELECT a, b, c, pk_index
E               FROM (SELECT *
E               FROM test_data_c5fncnz3
E               WHERE NOT (b IS NULL AND c IS NULL)) AS anon_1) AS original_table_clause JOIN (SELECT b, c, count(*) AS _num_rows
E               FROM (SELECT a, b, c, pk_index
E               FROM (SELECT *
E               FROM test_data_c5fncnz3
E               WHERE NOT (b IS NULL AND c IS NULL)) AS anon_1) AS original_table_clause GROUP BY b, c) AS group_counts_subquery ON group_counts_subquery.b = original_table_clause.b AND group_counts_subquery.c = original_table_clause.c) AS records_with_grouped_column_counts_subquery, (SELECT *
E               FROM test_data_c5fncnz3
E               WHERE NOT (b IS NULL AND c IS NULL)) AS anon_2
E               WHERE records_with_grouped_column_counts_subquery._num_rows >= ?
E                LIMIT ? OFFSET ?]
E               [parameters: (2, 20, 0)]
E               (Background on this error at: https://sqlalche.me/e/14/e3q8)

great_expectations/execution_engine/execution_engine.py:654: MetricResolutionError
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:  18%|        | 2/11 [00:00<00:00, 1539.48it/s]Calculating Metrics:  18%|        | 2/11 [00:00<00:00, 138.86it/s] Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 221.09it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 136.69it/s]Calculating Metrics:  45%|     | 5/11 [00:00<00:00, 157.13it/s]Calculating Metrics:  45%|     | 5/11 [00:00<00:00, 116.82it/s]Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 132.47it/s]Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 111.88it/s]
--------------------------- Captured stderr teardown ---------------------------
Calculating Metrics:  55%|    | 6/11 [00:01<00:01,  3.82it/s]
_ test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_compound_columns_to_be_unique:mostly_set_fails_expectation] _

self = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b9edf0>
dialect = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7fe2f3b9eaf0>
constructor = <bound method DefaultExecutionContext._init_compiled of <class 'sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext'>>
statement = 'SELECT pk_index, b, c \nFROM (SELECT original_table_clause.a AS a, original_table_clause.b AS b, original_table_claus...S NULL AND c IS NULL)) AS anon_2 \nWHERE records_with_grouped_column_counts_subquery._num_rows >= ?\n LIMIT ? OFFSET ?'
parameters = (2, 20, 0), execution_options = immutabledict({})
args = (<sqlalchemy.dialects.sqlite.base.SQLiteCompiler object at 0x7fe2f8dbc250>, [], <sqlalchemy.sql.selectable.Select obje...140612823792752 num_rows)s', 2, type_=Integer()), _OffsetLimitParam('%(140612823716960 param)s', 20, type_=Integer())])
kw = {'cache_hit': symbol('CACHE_HIT')}
branched = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b9edf0>
conn = <sqlalchemy.pool.base._ConnectionFairy object at 0x7fe2f3b9ee80>
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7fe2f96893d0>
cursor = <sqlite3.Cursor object at 0x7fe2f8e86030>, evt_handled = False

    def _execute_context(
        self,
        dialect,
        constructor,
        statement,
        parameters,
        execution_options,
        *args,
        **kw
    ):
        """Create an :class:`.ExecutionContext` and execute, returning
        a :class:`_engine.CursorResult`."""

        branched = self
        if self.__branch_from:
            # if this is a "branched" connection, do everything in terms
            # of the "root" connection, *except* for .close(), which is
            # the only feature that branching provides
            self = self.__branch_from

        try:
            conn = self._dbapi_connection
            if conn is None:
                conn = self._revalidate_connection()

            context = constructor(
                dialect, self, conn, execution_options, *args, **kw
            )
        except (exc.PendingRollbackError, exc.ResourceClosedError):
            raise
        except BaseException as e:
            self._handle_dbapi_exception(
                e, util.text_type(statement), parameters, None, None
            )

        if (
            self._transaction
            and not self._transaction.is_active
            or (
                self._nested_transaction
                and not self._nested_transaction.is_active
            )
        ):
            self._invalid_transaction()

        elif self._trans_context_manager:
            TransactionalContext._trans_ctx_check(self)

        if self._is_future and self._transaction is None:
            self._autobegin()

        context.pre_exec()

        if dialect.use_setinputsizes:
            context._set_input_sizes()

        cursor, statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )

        if not context.executemany:
            parameters = parameters[0]

        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                statement, parameters = fn(
                    self,
                    cursor,
                    statement,
                    parameters,
                    context,
                    context.executemany,
                )

        if self._echo:

            self._log_info(statement)

            stats = context._get_cache_stats()

            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        parameters, batches=10, ismulti=context.executemany
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]"
                    % (stats,)
                )

        evt_handled = False
        try:
            if context.executemany:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(cursor, statement, parameters, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor, statement, parameters, context
                    )
            elif not parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, statement, context
                    )
            else:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(cursor, statement, parameters, context):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, statement, parameters, context
                    )

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1802:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7fe2f3b9eaf0>
cursor = <sqlite3.Cursor object at 0x7fe2f8e86030>
statement = 'SELECT pk_index, b, c \nFROM (SELECT original_table_clause.a AS a, original_table_clause.b AS b, original_table_claus...S NULL AND c IS NULL)) AS anon_2 \nWHERE records_with_grouped_column_counts_subquery._num_rows >= ?\n LIMIT ? OFFSET ?'
parameters = (2, 20, 0)
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7fe2f96893d0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlite3.OperationalError: ambiguous column name: pk_index

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/engine/default.py:719: OperationalError

The above exception was the direct cause of the following exception:

self = <great_expectations.execution_engine.sqlalchemy_execution_engine.SqlAlchemyExecutionEngine object at 0x7fe2f3b9e2e0>
metric_fn_direct_configurations = [MetricComputationConfiguration(metric_configuration={
  "metric_name": "compound_columns.unique.filtered_row_count",
...l_unexpected_count': 20, 'include_unexpected_rows': False}}}, compute_domain_kwargs=None, accessor_domain_kwargs=None)]
metric_fn_bundle_configurations = []

    def _process_direct_and_bundled_metric_computation_configurations(
        self,
        metric_fn_direct_configurations: List[MetricComputationConfiguration],
        metric_fn_bundle_configurations: List[MetricComputationConfiguration],
    ) -> Dict[Tuple[str, str, str], MetricValue]:
        """
        This method processes directly-computable and bundled "MetricComputationConfiguration" objects.

        Args:
            metric_fn_direct_configurations: directly-computable "MetricComputationConfiguration" objects
            metric_fn_bundle_configurations: bundled "MetricComputationConfiguration" objects (column aggregates)

        Returns:
            resolved_metrics (Dict): a dictionary with the values for the metrics that have just been resolved.
        """
        resolved_metrics: Dict[Tuple[str, str, str], MetricValue] = {}

        metric_computation_configuration: MetricComputationConfiguration

        for metric_computation_configuration in metric_fn_direct_configurations:
            try:
                resolved_metrics[
                    metric_computation_configuration.metric_configuration.id
>               ] = metric_computation_configuration.metric_fn(
                    **metric_computation_configuration.metric_provider_kwargs
                )

great_expectations/execution_engine/execution_engine.py:650:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

cls = <class 'great_expectations.expectations.metrics.multicolumn_map_metrics.compound_columns_unique.CompoundColumnsUnique'>
execution_engine = <great_expectations.execution_engine.sqlalchemy_execution_engine.SqlAlchemyExecutionEngine object at 0x7fe2f3b9e2e0>
metric_domain_kwargs = {'batch_id': 'b1ae3225b6aa3d6c44dce474d8b4e741', 'table': None, 'column_list': ['b', 'c'], 'row_condition': None, 'condition_parser': None, 'ignore_row_if': 'all_values_are_missing'}
metric_value_kwargs = {'result_format': {'result_format': 'COMPLETE', 'unexpected_index_column_names': ['pk_index'], 'partial_unexpected_count': 20, 'include_unexpected_rows': False}}
metrics = {'table.column_types': [{'autoincrement': 'auto', 'default': None, 'name': 'a', 'nullable': True, ...}, {'autoincremen...w_condition': None, 'condition_parser': None, 'ignore_row_if': 'all_values_are_missing'}, {'column_list': ['b', 'c']})}
kwargs = {'runtime_configuration': {'catch_exceptions': False, 'include_config': False, 'result_format': {'include_unexpected_rows': False, 'partial_unexpected_count': 20, 'result_format': 'COMPLETE', 'unexpected_index_column_names': ['pk_index']}}}
unexpected_condition = <sqlalchemy.sql.elements.BinaryExpression object at 0x7fe2f969b640>
compute_domain_kwargs = {'batch_id': 'b1ae3225b6aa3d6c44dce474d8b4e741', 'table': None, 'row_condition': None, 'condition_parser': None, 'ignore_row_if': 'all_values_are_missing'}
accessor_domain_kwargs = {'column_list': ['b', 'c']}
domain_column_name_list = ['b', 'c'], column_name = 'c'
column_list = ['b', 'c']
domain_kwargs = {'batch_id': 'b1ae3225b6aa3d6c44dce474d8b4e741', 'column_list': ['b', 'c'], 'condition_parser': None, 'ignore_row_if': 'all_values_are_missing', ...}

    def _sqlalchemy_map_condition_index(
        cls,
        execution_engine: SqlAlchemyExecutionEngine,
        metric_domain_kwargs: Dict,
        metric_value_kwargs: Dict,
        metrics: Dict[str, Any],
        **kwargs,
    ) -> List[Dict[str, Any]]:
        """
        Returns indices of the metric values which do not meet an expected Expectation condition for instances
        of ColumnMapExpectation.

        Requires `unexpected_index_column_names` to be part of `result_format` dict to specify primary_key columns
        to return.
        """
        (
            unexpected_condition,
            compute_domain_kwargs,
            accessor_domain_kwargs,
        ) = metrics.get("unexpected_condition")

        domain_column_name_list: List[str] = list()
        # column map expectations
        if "column" in accessor_domain_kwargs:
            column_name: Union[str, quoted_name] = accessor_domain_kwargs["column"]
            domain_column_name_list.append(column_name)
        # multi-column map expectations
        elif "column_list" in accessor_domain_kwargs:
            column_list: List[Union[str, quoted_name]] = accessor_domain_kwargs[
                "column_list"
            ]
            domain_column_name_list = column_list
        # column-map expectations
        elif "column_A" in accessor_domain_kwargs and "column_B" in accessor_domain_kwargs:
            column_list: List[Union[str, quoted_name]] = list()
            column_list.append(accessor_domain_kwargs["column_A"])
            column_list.append(accessor_domain_kwargs["column_B"])
            domain_column_name_list = column_list

        domain_kwargs: dict = dict(**compute_domain_kwargs, **accessor_domain_kwargs)
        result_format: dict = metric_value_kwargs["result_format"]

        all_table_columns: List[str] = metrics.get("table.columns")

        unexpected_index_column_names: Optional[List[str]] = result_format.get(
            "unexpected_index_column_names"
        )

        column_selector: List[sa.Column] = []
        for column_name in unexpected_index_column_names:
            if column_name not in all_table_columns:
                raise gx_exceptions.InvalidMetricAccessorDomainKwargsKeyError(
                    message=f'Error: The unexpected_index_column: "{column_name}" in does not exist in SQL Table. '
                    f"Please check your configuration and try again."
                )
            column_selector.append(sa.column(column_name))

        # expectation_domain_column_name: str = domain_kwargs["column"]

        # the last column we SELECT is the column the Expectation is being run on
        for column_name in domain_column_name_list:
            column_selector.append(sa.column(column_name))

        domain_records_as_selectable: sa.sql.Selectable = (
            execution_engine.get_domain_records(domain_kwargs=domain_kwargs)
        )
        unexpected_condition_query_with_selected_columns: sa.select = sa.select(
            column_selector
        ).where(unexpected_condition)

        if not MapMetricProvider.is_sqlalchemy_metric_selectable(map_metric_provider=cls):
            domain_records_as_selectable: Union[
                sa.Table, sa.Select
            ] = get_sqlalchemy_selectable(domain_records_as_selectable)

        # since SQL tables can be **very** large, truncate query_result values at 20, or at `partial_unexpected_count`
        final_query: sa.select = (
            unexpected_condition_query_with_selected_columns.select_from(
                domain_records_as_selectable
            ).limit(result_format["partial_unexpected_count"])
        )
>       query_result: List[tuple] = execution_engine.engine.execute(final_query).fetchall()

great_expectations/expectations/metrics/map_metric_provider.py:2662:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b9edf0>
statement = <sqlalchemy.sql.selectable.Select object at 0x7fe2f9689430>
multiparams = (), params = {}
meth = <bound method ClauseElement._execute_on_connection of <sqlalchemy.sql.selectable.Select object at 0x7fe2f9689430>>

    def execute(self, statement, *multiparams, **params):
        r"""Executes a SQL statement construct and returns a
        :class:`_engine.CursorResult`.

        :param statement: The statement to be executed.  May be
         one of:

         * a plain string (deprecated)
         * any :class:`_expression.ClauseElement` construct that is also
           a subclass of :class:`.Executable`, such as a
           :func:`_expression.select` construct
         * a :class:`.FunctionElement`, such as that generated
           by :data:`.func`, will be automatically wrapped in
           a SELECT statement, which is then executed.
         * a :class:`.DDLElement` object
         * a :class:`.DefaultGenerator` object
         * a :class:`.Compiled` object

         .. deprecated:: 2.0 passing a string to
            :meth:`_engine.Connection.execute` is
            deprecated and will be removed in version 2.0.  Use the
            :func:`_expression.text` construct with
            :meth:`_engine.Connection.execute`, or the
            :meth:`_engine.Connection.exec_driver_sql`
            method to invoke a driver-level
            SQL string.

        :param \*multiparams/\**params: represent bound parameter
         values to be used in the execution.   Typically,
         the format is either a collection of one or more
         dictionaries passed to \*multiparams::

             conn.execute(
                 table.insert(),
                 {"id":1, "value":"v1"},
                 {"id":2, "value":"v2"}
             )

         ...or individual key/values interpreted by \**params::

             conn.execute(
                 table.insert(), id=1, value="v1"
             )

         In the case that a plain SQL string is passed, and the underlying
         DBAPI accepts positional bind parameters, a collection of tuples
         or individual values in \*multiparams may be passed::

             conn.execute(
                 "INSERT INTO table (id, value) VALUES (?, ?)",
                 (1, "v1"), (2, "v2")
             )

             conn.execute(
                 "INSERT INTO table (id, value) VALUES (?, ?)",
                 1, "v1"
             )

         Note above, the usage of a question mark "?" or other
         symbol is contingent upon the "paramstyle" accepted by the DBAPI
         in use, which may be any of "qmark", "named", "pyformat", "format",
         "numeric".   See `pep-249
         <https://www.python.org/dev/peps/pep-0249/>`_ for details on
         paramstyle.

         To execute a textual SQL statement which uses bound parameters in a
         DBAPI-agnostic way, use the :func:`_expression.text` construct.

         .. deprecated:: 2.0 use of tuple or scalar positional parameters
            is deprecated. All params should be dicts or sequences of dicts.
            Use :meth:`.exec_driver_sql` to execute a plain string with
            tuple or scalar positional parameters.

        """

        if isinstance(statement, util.string_types):
            util.warn_deprecated_20(
                "Passing a string to Connection.execute() is "
                "deprecated and will be removed in version 2.0.  Use the "
                "text() construct, "
                "or the Connection.exec_driver_sql() method to invoke a "
                "driver-level SQL string."
            )

            return self._exec_driver_sql(
                statement,
                multiparams,
                params,
                _EMPTY_EXECUTION_OPTS,
                future=False,
            )

        try:
            meth = statement._execute_on_connection
        except AttributeError as err:
            util.raise_(
                exc.ObjectNotExecutableError(statement), replace_context=err
            )
        else:
>           return meth(self, multiparams, params, _EMPTY_EXECUTION_OPTS)

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1289:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.sql.selectable.Select object at 0x7fe2f9689430>
connection = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b9edf0>
multiparams = (), params = {}, execution_options = immutabledict({})
_force = False

    def _execute_on_connection(
        self, connection, multiparams, params, execution_options, _force=False
    ):
        if _force or self.supports_execution:
>           return connection._execute_clauseelement(
                self, multiparams, params, execution_options
            )

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/sql/elements.py:325:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b9edf0>
elem = <sqlalchemy.sql.selectable.Select object at 0x7fe2f9689430>
multiparams = (), params = {}, execution_options = immutabledict({})

    def _execute_clauseelement(
        self, elem, multiparams, params, execution_options
    ):
        """Execute a sql.ClauseElement object."""

        execution_options = elem._execution_options.merge_with(
            self._execution_options, execution_options
        )

        distilled_params = _distill_params(self, multiparams, params)

        has_events = self._has_events or self.engine._has_events
        if has_events:
            (
                elem,
                distilled_params,
                event_multiparams,
                event_params,
            ) = self._invoke_before_exec_event(
                elem, distilled_params, execution_options
            )

        if distilled_params:
            # ensure we don't retain a link to the view object for keys()
            # which links to the values, which we don't want to cache
            keys = sorted(distilled_params[0])
            for_executemany = len(distilled_params) > 1
        else:
            keys = []
            for_executemany = False

        dialect = self.dialect

        schema_translate_map = execution_options.get(
            "schema_translate_map", None
        )

        compiled_cache = execution_options.get(
            "compiled_cache", self.engine._compiled_cache
        )

        compiled_sql, extracted_params, cache_hit = elem._compile_w_cache(
            dialect=dialect,
            compiled_cache=compiled_cache,
            column_keys=keys,
            for_executemany=for_executemany,
            schema_translate_map=schema_translate_map,
            linting=self.dialect.compiler_linting | compiler.WARN_LINTING,
        )
>       ret = self._execute_context(
            dialect,
            dialect.execution_ctx_cls._init_compiled,
            compiled_sql,
            distilled_params,
            execution_options,
            compiled_sql,
            distilled_params,
            elem,
            extracted_params,
            cache_hit=cache_hit,
        )

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1481:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b9edf0>
dialect = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7fe2f3b9eaf0>
constructor = <bound method DefaultExecutionContext._init_compiled of <class 'sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext'>>
statement = 'SELECT pk_index, b, c \nFROM (SELECT original_table_clause.a AS a, original_table_clause.b AS b, original_table_claus...S NULL AND c IS NULL)) AS anon_2 \nWHERE records_with_grouped_column_counts_subquery._num_rows >= ?\n LIMIT ? OFFSET ?'
parameters = (2, 20, 0), execution_options = immutabledict({})
args = (<sqlalchemy.dialects.sqlite.base.SQLiteCompiler object at 0x7fe2f8dbc250>, [], <sqlalchemy.sql.selectable.Select obje...140612823792752 num_rows)s', 2, type_=Integer()), _OffsetLimitParam('%(140612823716960 param)s', 20, type_=Integer())])
kw = {'cache_hit': symbol('CACHE_HIT')}
branched = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b9edf0>
conn = <sqlalchemy.pool.base._ConnectionFairy object at 0x7fe2f3b9ee80>
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7fe2f96893d0>
cursor = <sqlite3.Cursor object at 0x7fe2f8e86030>, evt_handled = False

    def _execute_context(
        self,
        dialect,
        constructor,
        statement,
        parameters,
        execution_options,
        *args,
        **kw
    ):
        """Create an :class:`.ExecutionContext` and execute, returning
        a :class:`_engine.CursorResult`."""

        branched = self
        if self.__branch_from:
            # if this is a "branched" connection, do everything in terms
            # of the "root" connection, *except* for .close(), which is
            # the only feature that branching provides
            self = self.__branch_from

        try:
            conn = self._dbapi_connection
            if conn is None:
                conn = self._revalidate_connection()

            context = constructor(
                dialect, self, conn, execution_options, *args, **kw
            )
        except (exc.PendingRollbackError, exc.ResourceClosedError):
            raise
        except BaseException as e:
            self._handle_dbapi_exception(
                e, util.text_type(statement), parameters, None, None
            )

        if (
            self._transaction
            and not self._transaction.is_active
            or (
                self._nested_transaction
                and not self._nested_transaction.is_active
            )
        ):
            self._invalid_transaction()

        elif self._trans_context_manager:
            TransactionalContext._trans_ctx_check(self)

        if self._is_future and self._transaction is None:
            self._autobegin()

        context.pre_exec()

        if dialect.use_setinputsizes:
            context._set_input_sizes()

        cursor, statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )

        if not context.executemany:
            parameters = parameters[0]

        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                statement, parameters = fn(
                    self,
                    cursor,
                    statement,
                    parameters,
                    context,
                    context.executemany,
                )

        if self._echo:

            self._log_info(statement)

            stats = context._get_cache_stats()

            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        parameters, batches=10, ismulti=context.executemany
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]"
                    % (stats,)
                )

        evt_handled = False
        try:
            if context.executemany:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(cursor, statement, parameters, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor, statement, parameters, context
                    )
            elif not parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, statement, context
                    )
            else:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(cursor, statement, parameters, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute(
                        cursor, statement, parameters, context
                    )

            if self._has_events or self.engine._has_events:
                self.dispatch.after_cursor_execute(
                    self,
                    cursor,
                    statement,
                    parameters,
                    context,
                    context.executemany,
                )

            context.post_exec()

            result = context._setup_result_proxy()

            if not self._is_future:
                should_close_with_result = branched.should_close_with_result

                if not result._soft_closed and should_close_with_result:
                    result._autoclose_connection = True

                if (
                    # usually we're in a transaction so avoid relatively
                    # expensive / legacy should_autocommit call
                    self._transaction is None
                    and context.should_autocommit
                ):
                    self._commit_impl(autocommit=True)

                # for "connectionless" execution, we have to close this
                # Connection after the statement is complete.
                # legacy stuff.
                if should_close_with_result and context._soft_closed:
                    assert not self._is_future

                    # CursorResult already exhausted rows / has no rows.
                    # close us now
                    branched.close()

        except BaseException as e:
>           self._handle_dbapi_exception(
                e, statement, parameters, cursor, context
            )

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1845:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b9edf0>
e = OperationalError('ambiguous column name: pk_index')
statement = 'SELECT pk_index, b, c \nFROM (SELECT original_table_clause.a AS a, original_table_clause.b AS b, original_table_claus...S NULL AND c IS NULL)) AS anon_2 \nWHERE records_with_grouped_column_counts_subquery._num_rows >= ?\n LIMIT ? OFFSET ?'
parameters = (2, 20, 0), cursor = <sqlite3.Cursor object at 0x7fe2f8e86030>
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7fe2f96893d0>

    def _handle_dbapi_exception(
        self, e, statement, parameters, cursor, context
    ):
        exc_info = sys.exc_info()

        is_exit_exception = util.is_exit_exception(e)

        if not self._is_disconnect:
            self._is_disconnect = (
                isinstance(e, self.dialect.dbapi.Error)
                and not self.closed
                and self.dialect.is_disconnect(
                    e,
                    self._dbapi_connection if not self.invalidated else None,
                    cursor,
                )
            ) or (is_exit_exception and not self.closed)

        invalidate_pool_on_disconnect = not is_exit_exception

        if self._reentrant_error:
            util.raise_(
                exc.DBAPIError.instance(
                    statement,
                    parameters,
                    e,
                    self.dialect.dbapi.Error,
                    hide_parameters=self.engine.hide_parameters,
                    dialect=self.dialect,
                    ismulti=context.executemany
                    if context is not None
                    else None,
                ),
                with_traceback=exc_info[2],
                from_=e,
            )
        self._reentrant_error = True
        try:
            # non-DBAPI error - if we already got a context,
            # or there's no string statement, don't wrap it
            should_wrap = isinstance(e, self.dialect.dbapi.Error) or (
                statement is not None
                and context is None
                and not is_exit_exception
            )

            if should_wrap:
                sqlalchemy_exception = exc.DBAPIError.instance(
                    statement,
                    parameters,
                    e,
                    self.dialect.dbapi.Error,
                    hide_parameters=self.engine.hide_parameters,
                    connection_invalidated=self._is_disconnect,
                    dialect=self.dialect,
                    ismulti=context.executemany
                    if context is not None
                    else None,
                )
            else:
                sqlalchemy_exception = None

            newraise = None

            if (
                self._has_events or self.engine._has_events
            ) and not self._execution_options.get(
                "skip_user_error_events", False
            ):
                ctx = ExceptionContextImpl(
                    e,
                    sqlalchemy_exception,
                    self.engine,
                    self,
                    cursor,
                    statement,
                    parameters,
                    context,
                    self._is_disconnect,
                    invalidate_pool_on_disconnect,
                )

                for fn in self.dispatch.handle_error:
                    try:
                        # handler returns an exception;
                        # call next handler in a chain
                        per_fn = fn(ctx)
                        if per_fn is not None:
                            ctx.chained_exception = newraise = per_fn
                    except Exception as _raised:
                        # handler raises an exception - stop processing
                        newraise = _raised
                        break

                if self._is_disconnect != ctx.is_disconnect:
                    self._is_disconnect = ctx.is_disconnect
                    if sqlalchemy_exception:
                        sqlalchemy_exception.connection_invalidated = (
                            ctx.is_disconnect
                        )

                # set up potentially user-defined value for
                # invalidate pool.
                invalidate_pool_on_disconnect = (
                    ctx.invalidate_pool_on_disconnect
                )

            if should_wrap and context:
                context.handle_dbapi_exception(e)

            if not self._is_disconnect:
                if cursor:
                    self._safe_close_cursor(cursor)
                with util.safe_reraise(warn_only=True):
                    self._autorollback()

            if newraise:
                util.raise_(newraise, with_traceback=exc_info[2], from_=e)
            elif should_wrap:
>               util.raise_(
                    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
                )

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/engine/base.py:2026:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

    def raise_(
        exception, with_traceback=None, replace_context=None, from_=False
    ):
        r"""implement "raise" with cause support.

        :param exception: exception to raise
        :param with_traceback: will call exception.with_traceback()
        :param replace_context: an as-yet-unsupported feature.  This is
         an exception object which we are "replacing", e.g., it's our
         "cause" but we don't want it printed.    Basically just what
         ``__suppress_context__`` does but we don't want to suppress
         the enclosing context, if any.  So for now we make it the
         cause.
        :param from\_: the cause.  this actually sets the cause and doesn't
         hope to hide it someday.

        """
        if with_traceback is not None:
            exception = exception.with_traceback(with_traceback)

        if from_ is not False:
            exception.__cause__ = from_
        elif replace_context is not None:
            # no good solution here, we would like to have the exception
            # have only the context of replace_context.__context__ so that the
            # intermediary exception does not change, but we can't figure
            # that out.
            exception.__cause__ = replace_context

        try:
>           raise exception

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/util/compat.py:207:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b9edf0>
dialect = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7fe2f3b9eaf0>
constructor = <bound method DefaultExecutionContext._init_compiled of <class 'sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext'>>
statement = 'SELECT pk_index, b, c \nFROM (SELECT original_table_clause.a AS a, original_table_clause.b AS b, original_table_claus...S NULL AND c IS NULL)) AS anon_2 \nWHERE records_with_grouped_column_counts_subquery._num_rows >= ?\n LIMIT ? OFFSET ?'
parameters = (2, 20, 0), execution_options = immutabledict({})
args = (<sqlalchemy.dialects.sqlite.base.SQLiteCompiler object at 0x7fe2f8dbc250>, [], <sqlalchemy.sql.selectable.Select obje...140612823792752 num_rows)s', 2, type_=Integer()), _OffsetLimitParam('%(140612823716960 param)s', 20, type_=Integer())])
kw = {'cache_hit': symbol('CACHE_HIT')}
branched = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b9edf0>
conn = <sqlalchemy.pool.base._ConnectionFairy object at 0x7fe2f3b9ee80>
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7fe2f96893d0>
cursor = <sqlite3.Cursor object at 0x7fe2f8e86030>, evt_handled = False

    def _execute_context(
        self,
        dialect,
        constructor,
        statement,
        parameters,
        execution_options,
        *args,
        **kw
    ):
        """Create an :class:`.ExecutionContext` and execute, returning
        a :class:`_engine.CursorResult`."""

        branched = self
        if self.__branch_from:
            # if this is a "branched" connection, do everything in terms
            # of the "root" connection, *except* for .close(), which is
            # the only feature that branching provides
            self = self.__branch_from

        try:
            conn = self._dbapi_connection
            if conn is None:
                conn = self._revalidate_connection()

            context = constructor(
                dialect, self, conn, execution_options, *args, **kw
            )
        except (exc.PendingRollbackError, exc.ResourceClosedError):
            raise
        except BaseException as e:
            self._handle_dbapi_exception(
                e, util.text_type(statement), parameters, None, None
            )

        if (
            self._transaction
            and not self._transaction.is_active
            or (
                self._nested_transaction
                and not self._nested_transaction.is_active
            )
        ):
            self._invalid_transaction()

        elif self._trans_context_manager:
            TransactionalContext._trans_ctx_check(self)

        if self._is_future and self._transaction is None:
            self._autobegin()

        context.pre_exec()

        if dialect.use_setinputsizes:
            context._set_input_sizes()

        cursor, statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )

        if not context.executemany:
            parameters = parameters[0]

        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                statement, parameters = fn(
                    self,
                    cursor,
                    statement,
                    parameters,
                    context,
                    context.executemany,
                )

        if self._echo:

            self._log_info(statement)

            stats = context._get_cache_stats()

            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        parameters, batches=10, ismulti=context.executemany
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]"
                    % (stats,)
                )

        evt_handled = False
        try:
            if context.executemany:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(cursor, statement, parameters, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor, statement, parameters, context
                    )
            elif not parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, statement, context
                    )
            else:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(cursor, statement, parameters, context):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, statement, parameters, context
                    )

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1802:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7fe2f3b9eaf0>
cursor = <sqlite3.Cursor object at 0x7fe2f8e86030>
statement = 'SELECT pk_index, b, c \nFROM (SELECT original_table_clause.a AS a, original_table_clause.b AS b, original_table_claus...S NULL AND c IS NULL)) AS anon_2 \nWHERE records_with_grouped_column_counts_subquery._num_rows >= ?\n LIMIT ? OFFSET ?'
parameters = (2, 20, 0)
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7fe2f96893d0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) ambiguous column name: pk_index
E       [SQL: SELECT pk_index, b, c
E       FROM (SELECT original_table_clause.a AS a, original_table_clause.b AS b, original_table_clause.c AS c, original_table_clause.pk_index AS pk_index, group_counts_subquery._num_rows AS _num_rows
E       FROM (SELECT a, b, c, pk_index
E       FROM (SELECT *
E       FROM test_data_c5fncnz3
E       WHERE NOT (b IS NULL AND c IS NULL)) AS anon_1) AS original_table_clause JOIN (SELECT b, c, count(*) AS _num_rows
E       FROM (SELECT a, b, c, pk_index
E       FROM (SELECT *
E       FROM test_data_c5fncnz3
E       WHERE NOT (b IS NULL AND c IS NULL)) AS anon_1) AS original_table_clause GROUP BY b, c) AS group_counts_subquery ON group_counts_subquery.b = original_table_clause.b AND group_counts_subquery.c = original_table_clause.c) AS records_with_grouped_column_counts_subquery, (SELECT *
E       FROM test_data_c5fncnz3
E       WHERE NOT (b IS NULL AND c IS NULL)) AS anon_2
E       WHERE records_with_grouped_column_counts_subquery._num_rows >= ?
E        LIMIT ? OFFSET ?]
E       [parameters: (2, 20, 0)]
E       (Background on this error at: https://sqlalche.me/e/14/e3q8)

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/engine/default.py:719: OperationalError

The above exception was the direct cause of the following exception:

test_case = {'expectation_type': 'expect_compound_columns_to_be_unique', 'pk_column': True, 'skip': False, 'test': {'exact_match_o...['b', 'c'], 'mostly': 0.9}, 'include_in_gallery': True, 'input': {'column_list': ['b', 'c'], 'mostly': 0.9}, ...}, ...}

    @pytest.mark.order(index=0)
    @pytest.mark.integration
    @pytest.mark.slow  # 12.68s
    def test_case_runner_v3_api(test_case):
        if test_case["skip"]:
            pytest.skip()

        # Note: this should never be done in practice, but we are wiping expectations to reuse batches during testing.
        # test_case["batch"]._initialize_expectations()
        if "parse_strings_as_datetimes" in test_case["test"]["in"]:
            with pytest.deprecated_call():
                evaluate_json_test_v3_api(
                    validator=test_case["validator_with_data"],
                    expectation_type=test_case["expectation_type"],
                    test=test_case["test"],
                    pk_column=test_case["pk_column"],
                )
        else:
>           evaluate_json_test_v3_api(
                validator=test_case["validator_with_data"],
                expectation_type=test_case["expectation_type"],
                test=test_case["test"],
                pk_column=test_case["pk_column"],
            )

tests/test_definitions/test_expectations_v3_api.py:428:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
great_expectations/self_check/util.py:2887: in evaluate_json_test_v3_api
    result = getattr(validator, expectation_type)(**runtime_kwargs)
great_expectations/validator/validator.py:595: in inst_expectation
    raise err
great_expectations/validator/validator.py:558: in inst_expectation
    validation_result = expectation.validate(
great_expectations/expectations/expectation.py:1265: in validate
    ] = validator.graph_validate(
great_expectations/validator/validator.py:1046: in graph_validate
    raise err
great_expectations/validator/validator.py:1025: in graph_validate
    ) = self._resolve_suite_level_graph_and_process_metric_evaluation_errors(
great_expectations/validator/validator.py:1184: in _resolve_suite_level_graph_and_process_metric_evaluation_errors
    ) = self._metrics_calculator.resolve_validation_graph(
great_expectations/validator/metrics_calculator.py:282: in resolve_validation_graph
    resolved_metrics, aborted_metrics_info = graph.resolve(
great_expectations/validator/validation_graph.py:196: in resolve
    ] = self._resolve(
great_expectations/validator/validation_graph.py:302: in _resolve
    raise err
great_expectations/validator/validation_graph.py:272: in _resolve
    self._execution_engine.resolve_metrics(
great_expectations/execution_engine/execution_engine.py:375: in resolve_metrics
    return self._process_direct_and_bundled_metric_computation_configurations(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <great_expectations.execution_engine.sqlalchemy_execution_engine.SqlAlchemyExecutionEngine object at 0x7fe2f3b9e2e0>
metric_fn_direct_configurations = [MetricComputationConfiguration(metric_configuration={
  "metric_name": "compound_columns.unique.filtered_row_count",
...l_unexpected_count': 20, 'include_unexpected_rows': False}}}, compute_domain_kwargs=None, accessor_domain_kwargs=None)]
metric_fn_bundle_configurations = []

    def _process_direct_and_bundled_metric_computation_configurations(
        self,
        metric_fn_direct_configurations: List[MetricComputationConfiguration],
        metric_fn_bundle_configurations: List[MetricComputationConfiguration],
    ) -> Dict[Tuple[str, str, str], MetricValue]:
        """
        This method processes directly-computable and bundled "MetricComputationConfiguration" objects.

        Args:
            metric_fn_direct_configurations: directly-computable "MetricComputationConfiguration" objects
            metric_fn_bundle_configurations: bundled "MetricComputationConfiguration" objects (column aggregates)

        Returns:
            resolved_metrics (Dict): a dictionary with the values for the metrics that have just been resolved.
        """
        resolved_metrics: Dict[Tuple[str, str, str], MetricValue] = {}

        metric_computation_configuration: MetricComputationConfiguration

        for metric_computation_configuration in metric_fn_direct_configurations:
            try:
                resolved_metrics[
                    metric_computation_configuration.metric_configuration.id
                ] = metric_computation_configuration.metric_fn(
                    **metric_computation_configuration.metric_provider_kwargs
                )
            except Exception as e:
>               raise gx_exceptions.MetricResolutionError(
                    message=str(e),
                    failed_metrics=(
                        metric_computation_configuration.metric_configuration,
                    ),
                ) from e
E               great_expectations.exceptions.exceptions.MetricResolutionError: (sqlite3.OperationalError) ambiguous column name: pk_index
E               [SQL: SELECT pk_index, b, c
E               FROM (SELECT original_table_clause.a AS a, original_table_clause.b AS b, original_table_clause.c AS c, original_table_clause.pk_index AS pk_index, group_counts_subquery._num_rows AS _num_rows
E               FROM (SELECT a, b, c, pk_index
E               FROM (SELECT *
E               FROM test_data_c5fncnz3
E               WHERE NOT (b IS NULL AND c IS NULL)) AS anon_1) AS original_table_clause JOIN (SELECT b, c, count(*) AS _num_rows
E               FROM (SELECT a, b, c, pk_index
E               FROM (SELECT *
E               FROM test_data_c5fncnz3
E               WHERE NOT (b IS NULL AND c IS NULL)) AS anon_1) AS original_table_clause GROUP BY b, c) AS group_counts_subquery ON group_counts_subquery.b = original_table_clause.b AND group_counts_subquery.c = original_table_clause.c) AS records_with_grouped_column_counts_subquery, (SELECT *
E               FROM test_data_c5fncnz3
E               WHERE NOT (b IS NULL AND c IS NULL)) AS anon_2
E               WHERE records_with_grouped_column_counts_subquery._num_rows >= ?
E                LIMIT ? OFFSET ?]
E               [parameters: (2, 20, 0)]
E               (Background on this error at: https://sqlalche.me/e/14/e3q8)

great_expectations/execution_engine/execution_engine.py:654: MetricResolutionError
----------------------------- Captured stderr call -----------------------------

Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s][A
Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s][A
Calculating Metrics:  18%|        | 2/11 [00:00<00:00, 2288.84it/s][A
Calculating Metrics:  18%|        | 2/11 [00:00<00:00, 288.57it/s] [A
Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 482.69it/s][A
Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 281.14it/s][A
Calculating Metrics:  45%|     | 5/11 [00:00<00:00, 317.12it/s][A
Calculating Metrics:  45%|     | 5/11 [00:00<00:00, 237.93it/s][A
Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 266.96it/s][A
Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 221.84it/s][A
--------------------------- Captured stderr teardown ---------------------------
Calculating Metrics:  55%|    | 6/11 [00:01<00:01,  3.35it/s]
_ test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_compound_columns_to_be_unique:basic_test_ignore_if_all_are_missing_the_default_behavior] _

self = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b7d850>
dialect = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7fe2f3b85250>
constructor = <bound method DefaultExecutionContext._init_compiled of <class 'sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext'>>
statement = 'SELECT pk_index, w, x \nFROM (SELECT original_table_clause.w AS w, original_table_clause.x AS x, original_table_claus...S NULL AND x IS NULL)) AS anon_2 \nWHERE records_with_grouped_column_counts_subquery._num_rows >= ?\n LIMIT ? OFFSET ?'
parameters = (2, 20, 0), execution_options = immutabledict({})
args = (<sqlalchemy.dialects.sqlite.base.SQLiteCompiler object at 0x7fe2f9092f40>, [], <sqlalchemy.sql.selectable.Select obje...140612817464000 num_rows)s', 2, type_=Integer()), _OffsetLimitParam('%(140612817464960 param)s', 20, type_=Integer())])
kw = {'cache_hit': symbol('CACHE_MISS')}
branched = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b7d850>
conn = <sqlalchemy.pool.base._ConnectionFairy object at 0x7fe2f3524040>
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7fe2f90b77f0>
cursor = <sqlite3.Cursor object at 0x7fe2f93c4490>, evt_handled = False

    def _execute_context(
        self,
        dialect,
        constructor,
        statement,
        parameters,
        execution_options,
        *args,
        **kw
    ):
        """Create an :class:`.ExecutionContext` and execute, returning
        a :class:`_engine.CursorResult`."""

        branched = self
        if self.__branch_from:
            # if this is a "branched" connection, do everything in terms
            # of the "root" connection, *except* for .close(), which is
            # the only feature that branching provides
            self = self.__branch_from

        try:
            conn = self._dbapi_connection
            if conn is None:
                conn = self._revalidate_connection()

            context = constructor(
                dialect, self, conn, execution_options, *args, **kw
            )
        except (exc.PendingRollbackError, exc.ResourceClosedError):
            raise
        except BaseException as e:
            self._handle_dbapi_exception(
                e, util.text_type(statement), parameters, None, None
            )

        if (
            self._transaction
            and not self._transaction.is_active
            or (
                self._nested_transaction
                and not self._nested_transaction.is_active
            )
        ):
            self._invalid_transaction()

        elif self._trans_context_manager:
            TransactionalContext._trans_ctx_check(self)

        if self._is_future and self._transaction is None:
            self._autobegin()

        context.pre_exec()

        if dialect.use_setinputsizes:
            context._set_input_sizes()

        cursor, statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )

        if not context.executemany:
            parameters = parameters[0]

        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                statement, parameters = fn(
                    self,
                    cursor,
                    statement,
                    parameters,
                    context,
                    context.executemany,
                )

        if self._echo:

            self._log_info(statement)

            stats = context._get_cache_stats()

            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        parameters, batches=10, ismulti=context.executemany
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]"
                    % (stats,)
                )

        evt_handled = False
        try:
            if context.executemany:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(cursor, statement, parameters, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor, statement, parameters, context
                    )
            elif not parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, statement, context
                    )
            else:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(cursor, statement, parameters, context):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, statement, parameters, context
                    )

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1802:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7fe2f3b85250>
cursor = <sqlite3.Cursor object at 0x7fe2f93c4490>
statement = 'SELECT pk_index, w, x \nFROM (SELECT original_table_clause.w AS w, original_table_clause.x AS x, original_table_claus...S NULL AND x IS NULL)) AS anon_2 \nWHERE records_with_grouped_column_counts_subquery._num_rows >= ?\n LIMIT ? OFFSET ?'
parameters = (2, 20, 0)
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7fe2f90b77f0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlite3.OperationalError: ambiguous column name: pk_index

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/engine/default.py:719: OperationalError

The above exception was the direct cause of the following exception:

self = <great_expectations.execution_engine.sqlalchemy_execution_engine.SqlAlchemyExecutionEngine object at 0x7fe2f3b9e2b0>
metric_fn_direct_configurations = [MetricComputationConfiguration(metric_configuration={
  "metric_name": "compound_columns.unique.filtered_row_count",
...l_unexpected_count': 20, 'include_unexpected_rows': False}}}, compute_domain_kwargs=None, accessor_domain_kwargs=None)]
metric_fn_bundle_configurations = []

    def _process_direct_and_bundled_metric_computation_configurations(
        self,
        metric_fn_direct_configurations: List[MetricComputationConfiguration],
        metric_fn_bundle_configurations: List[MetricComputationConfiguration],
    ) -> Dict[Tuple[str, str, str], MetricValue]:
        """
        This method processes directly-computable and bundled "MetricComputationConfiguration" objects.

        Args:
            metric_fn_direct_configurations: directly-computable "MetricComputationConfiguration" objects
            metric_fn_bundle_configurations: bundled "MetricComputationConfiguration" objects (column aggregates)

        Returns:
            resolved_metrics (Dict): a dictionary with the values for the metrics that have just been resolved.
        """
        resolved_metrics: Dict[Tuple[str, str, str], MetricValue] = {}

        metric_computation_configuration: MetricComputationConfiguration

        for metric_computation_configuration in metric_fn_direct_configurations:
            try:
                resolved_metrics[
                    metric_computation_configuration.metric_configuration.id
>               ] = metric_computation_configuration.metric_fn(
                    **metric_computation_configuration.metric_provider_kwargs
                )

great_expectations/execution_engine/execution_engine.py:650:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

cls = <class 'great_expectations.expectations.metrics.multicolumn_map_metrics.compound_columns_unique.CompoundColumnsUnique'>
execution_engine = <great_expectations.execution_engine.sqlalchemy_execution_engine.SqlAlchemyExecutionEngine object at 0x7fe2f3b9e2b0>
metric_domain_kwargs = {'batch_id': 'b1ae3225b6aa3d6c44dce474d8b4e741', 'table': None, 'column_list': ['w', 'x'], 'row_condition': None, 'condition_parser': None, 'ignore_row_if': 'all_values_are_missing'}
metric_value_kwargs = {'result_format': {'result_format': 'COMPLETE', 'unexpected_index_column_names': ['pk_index'], 'partial_unexpected_count': 20, 'include_unexpected_rows': False}}
metrics = {'table.column_types': [{'autoincrement': 'auto', 'default': None, 'name': 'w', 'nullable': True, ...}, {'autoincremen...w_condition': None, 'condition_parser': None, 'ignore_row_if': 'all_values_are_missing'}, {'column_list': ['w', 'x']})}
kwargs = {'runtime_configuration': {'catch_exceptions': False, 'include_config': False, 'result_format': {'include_unexpected_rows': False, 'partial_unexpected_count': 20, 'result_format': 'COMPLETE', 'unexpected_index_column_names': ['pk_index']}}}
unexpected_condition = <sqlalchemy.sql.elements.BinaryExpression object at 0x7fe2f8721c70>
compute_domain_kwargs = {'batch_id': 'b1ae3225b6aa3d6c44dce474d8b4e741', 'table': None, 'row_condition': None, 'condition_parser': None, 'ignore_row_if': 'all_values_are_missing'}
accessor_domain_kwargs = {'column_list': ['w', 'x']}
domain_column_name_list = ['w', 'x'], column_name = 'x'
column_list = ['w', 'x']
domain_kwargs = {'batch_id': 'b1ae3225b6aa3d6c44dce474d8b4e741', 'column_list': ['w', 'x'], 'condition_parser': None, 'ignore_row_if': 'all_values_are_missing', ...}

    def _sqlalchemy_map_condition_index(
        cls,
        execution_engine: SqlAlchemyExecutionEngine,
        metric_domain_kwargs: Dict,
        metric_value_kwargs: Dict,
        metrics: Dict[str, Any],
        **kwargs,
    ) -> List[Dict[str, Any]]:
        """
        Returns indices of the metric values which do not meet an expected Expectation condition for instances
        of ColumnMapExpectation.

        Requires `unexpected_index_column_names` to be part of `result_format` dict to specify primary_key columns
        to return.
        """
        (
            unexpected_condition,
            compute_domain_kwargs,
            accessor_domain_kwargs,
        ) = metrics.get("unexpected_condition")

        domain_column_name_list: List[str] = list()
        # column map expectations
        if "column" in accessor_domain_kwargs:
            column_name: Union[str, quoted_name] = accessor_domain_kwargs["column"]
            domain_column_name_list.append(column_name)
        # multi-column map expectations
        elif "column_list" in accessor_domain_kwargs:
            column_list: List[Union[str, quoted_name]] = accessor_domain_kwargs[
                "column_list"
            ]
            domain_column_name_list = column_list
        # column-map expectations
        elif "column_A" in accessor_domain_kwargs and "column_B" in accessor_domain_kwargs:
            column_list: List[Union[str, quoted_name]] = list()
            column_list.append(accessor_domain_kwargs["column_A"])
            column_list.append(accessor_domain_kwargs["column_B"])
            domain_column_name_list = column_list

        domain_kwargs: dict = dict(**compute_domain_kwargs, **accessor_domain_kwargs)
        result_format: dict = metric_value_kwargs["result_format"]

        all_table_columns: List[str] = metrics.get("table.columns")

        unexpected_index_column_names: Optional[List[str]] = result_format.get(
            "unexpected_index_column_names"
        )

        column_selector: List[sa.Column] = []
        for column_name in unexpected_index_column_names:
            if column_name not in all_table_columns:
                raise gx_exceptions.InvalidMetricAccessorDomainKwargsKeyError(
                    message=f'Error: The unexpected_index_column: "{column_name}" in does not exist in SQL Table. '
                    f"Please check your configuration and try again."
                )
            column_selector.append(sa.column(column_name))

        # expectation_domain_column_name: str = domain_kwargs["column"]

        # the last column we SELECT is the column the Expectation is being run on
        for column_name in domain_column_name_list:
            column_selector.append(sa.column(column_name))

        domain_records_as_selectable: sa.sql.Selectable = (
            execution_engine.get_domain_records(domain_kwargs=domain_kwargs)
        )
        unexpected_condition_query_with_selected_columns: sa.select = sa.select(
            column_selector
        ).where(unexpected_condition)

        if not MapMetricProvider.is_sqlalchemy_metric_selectable(map_metric_provider=cls):
            domain_records_as_selectable: Union[
                sa.Table, sa.Select
            ] = get_sqlalchemy_selectable(domain_records_as_selectable)

        # since SQL tables can be **very** large, truncate query_result values at 20, or at `partial_unexpected_count`
        final_query: sa.select = (
            unexpected_condition_query_with_selected_columns.select_from(
                domain_records_as_selectable
            ).limit(result_format["partial_unexpected_count"])
        )
>       query_result: List[tuple] = execution_engine.engine.execute(final_query).fetchall()

great_expectations/expectations/metrics/map_metric_provider.py:2662:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b7d850>
statement = <sqlalchemy.sql.selectable.Select object at 0x7fe2f9092fd0>
multiparams = (), params = {}
meth = <bound method ClauseElement._execute_on_connection of <sqlalchemy.sql.selectable.Select object at 0x7fe2f9092fd0>>

    def execute(self, statement, *multiparams, **params):
        r"""Executes a SQL statement construct and returns a
        :class:`_engine.CursorResult`.

        :param statement: The statement to be executed.  May be
         one of:

         * a plain string (deprecated)
         * any :class:`_expression.ClauseElement` construct that is also
           a subclass of :class:`.Executable`, such as a
           :func:`_expression.select` construct
         * a :class:`.FunctionElement`, such as that generated
           by :data:`.func`, will be automatically wrapped in
           a SELECT statement, which is then executed.
         * a :class:`.DDLElement` object
         * a :class:`.DefaultGenerator` object
         * a :class:`.Compiled` object

         .. deprecated:: 2.0 passing a string to
            :meth:`_engine.Connection.execute` is
            deprecated and will be removed in version 2.0.  Use the
            :func:`_expression.text` construct with
            :meth:`_engine.Connection.execute`, or the
            :meth:`_engine.Connection.exec_driver_sql`
            method to invoke a driver-level
            SQL string.

        :param \*multiparams/\**params: represent bound parameter
         values to be used in the execution.   Typically,
         the format is either a collection of one or more
         dictionaries passed to \*multiparams::

             conn.execute(
                 table.insert(),
                 {"id":1, "value":"v1"},
                 {"id":2, "value":"v2"}
             )

         ...or individual key/values interpreted by \**params::

             conn.execute(
                 table.insert(), id=1, value="v1"
             )

         In the case that a plain SQL string is passed, and the underlying
         DBAPI accepts positional bind parameters, a collection of tuples
         or individual values in \*multiparams may be passed::

             conn.execute(
                 "INSERT INTO table (id, value) VALUES (?, ?)",
                 (1, "v1"), (2, "v2")
             )

             conn.execute(
                 "INSERT INTO table (id, value) VALUES (?, ?)",
                 1, "v1"
             )

         Note above, the usage of a question mark "?" or other
         symbol is contingent upon the "paramstyle" accepted by the DBAPI
         in use, which may be any of "qmark", "named", "pyformat", "format",
         "numeric".   See `pep-249
         <https://www.python.org/dev/peps/pep-0249/>`_ for details on
         paramstyle.

         To execute a textual SQL statement which uses bound parameters in a
         DBAPI-agnostic way, use the :func:`_expression.text` construct.

         .. deprecated:: 2.0 use of tuple or scalar positional parameters
            is deprecated. All params should be dicts or sequences of dicts.
            Use :meth:`.exec_driver_sql` to execute a plain string with
            tuple or scalar positional parameters.

        """

        if isinstance(statement, util.string_types):
            util.warn_deprecated_20(
                "Passing a string to Connection.execute() is "
                "deprecated and will be removed in version 2.0.  Use the "
                "text() construct, "
                "or the Connection.exec_driver_sql() method to invoke a "
                "driver-level SQL string."
            )

            return self._exec_driver_sql(
                statement,
                multiparams,
                params,
                _EMPTY_EXECUTION_OPTS,
                future=False,
            )

        try:
            meth = statement._execute_on_connection
        except AttributeError as err:
            util.raise_(
                exc.ObjectNotExecutableError(statement), replace_context=err
            )
        else:
>           return meth(self, multiparams, params, _EMPTY_EXECUTION_OPTS)

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1289:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.sql.selectable.Select object at 0x7fe2f9092fd0>
connection = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b7d850>
multiparams = (), params = {}, execution_options = immutabledict({})
_force = False

    def _execute_on_connection(
        self, connection, multiparams, params, execution_options, _force=False
    ):
        if _force or self.supports_execution:
>           return connection._execute_clauseelement(
                self, multiparams, params, execution_options
            )

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/sql/elements.py:325:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b7d850>
elem = <sqlalchemy.sql.selectable.Select object at 0x7fe2f9092fd0>
multiparams = (), params = {}, execution_options = immutabledict({})

    def _execute_clauseelement(
        self, elem, multiparams, params, execution_options
    ):
        """Execute a sql.ClauseElement object."""

        execution_options = elem._execution_options.merge_with(
            self._execution_options, execution_options
        )

        distilled_params = _distill_params(self, multiparams, params)

        has_events = self._has_events or self.engine._has_events
        if has_events:
            (
                elem,
                distilled_params,
                event_multiparams,
                event_params,
            ) = self._invoke_before_exec_event(
                elem, distilled_params, execution_options
            )

        if distilled_params:
            # ensure we don't retain a link to the view object for keys()
            # which links to the values, which we don't want to cache
            keys = sorted(distilled_params[0])
            for_executemany = len(distilled_params) > 1
        else:
            keys = []
            for_executemany = False

        dialect = self.dialect

        schema_translate_map = execution_options.get(
            "schema_translate_map", None
        )

        compiled_cache = execution_options.get(
            "compiled_cache", self.engine._compiled_cache
        )

        compiled_sql, extracted_params, cache_hit = elem._compile_w_cache(
            dialect=dialect,
            compiled_cache=compiled_cache,
            column_keys=keys,
            for_executemany=for_executemany,
            schema_translate_map=schema_translate_map,
            linting=self.dialect.compiler_linting | compiler.WARN_LINTING,
        )
>       ret = self._execute_context(
            dialect,
            dialect.execution_ctx_cls._init_compiled,
            compiled_sql,
            distilled_params,
            execution_options,
            compiled_sql,
            distilled_params,
            elem,
            extracted_params,
            cache_hit=cache_hit,
        )

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1481:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b7d850>
dialect = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7fe2f3b85250>
constructor = <bound method DefaultExecutionContext._init_compiled of <class 'sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext'>>
statement = 'SELECT pk_index, w, x \nFROM (SELECT original_table_clause.w AS w, original_table_clause.x AS x, original_table_claus...S NULL AND x IS NULL)) AS anon_2 \nWHERE records_with_grouped_column_counts_subquery._num_rows >= ?\n LIMIT ? OFFSET ?'
parameters = (2, 20, 0), execution_options = immutabledict({})
args = (<sqlalchemy.dialects.sqlite.base.SQLiteCompiler object at 0x7fe2f9092f40>, [], <sqlalchemy.sql.selectable.Select obje...140612817464000 num_rows)s', 2, type_=Integer()), _OffsetLimitParam('%(140612817464960 param)s', 20, type_=Integer())])
kw = {'cache_hit': symbol('CACHE_MISS')}
branched = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b7d850>
conn = <sqlalchemy.pool.base._ConnectionFairy object at 0x7fe2f3524040>
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7fe2f90b77f0>
cursor = <sqlite3.Cursor object at 0x7fe2f93c4490>, evt_handled = False

    def _execute_context(
        self,
        dialect,
        constructor,
        statement,
        parameters,
        execution_options,
        *args,
        **kw
    ):
        """Create an :class:`.ExecutionContext` and execute, returning
        a :class:`_engine.CursorResult`."""

        branched = self
        if self.__branch_from:
            # if this is a "branched" connection, do everything in terms
            # of the "root" connection, *except* for .close(), which is
            # the only feature that branching provides
            self = self.__branch_from

        try:
            conn = self._dbapi_connection
            if conn is None:
                conn = self._revalidate_connection()

            context = constructor(
                dialect, self, conn, execution_options, *args, **kw
            )
        except (exc.PendingRollbackError, exc.ResourceClosedError):
            raise
        except BaseException as e:
            self._handle_dbapi_exception(
                e, util.text_type(statement), parameters, None, None
            )

        if (
            self._transaction
            and not self._transaction.is_active
            or (
                self._nested_transaction
                and not self._nested_transaction.is_active
            )
        ):
            self._invalid_transaction()

        elif self._trans_context_manager:
            TransactionalContext._trans_ctx_check(self)

        if self._is_future and self._transaction is None:
            self._autobegin()

        context.pre_exec()

        if dialect.use_setinputsizes:
            context._set_input_sizes()

        cursor, statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )

        if not context.executemany:
            parameters = parameters[0]

        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                statement, parameters = fn(
                    self,
                    cursor,
                    statement,
                    parameters,
                    context,
                    context.executemany,
                )

        if self._echo:

            self._log_info(statement)

            stats = context._get_cache_stats()

            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        parameters, batches=10, ismulti=context.executemany
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]"
                    % (stats,)
                )

        evt_handled = False
        try:
            if context.executemany:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(cursor, statement, parameters, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor, statement, parameters, context
                    )
            elif not parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, statement, context
                    )
            else:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(cursor, statement, parameters, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute(
                        cursor, statement, parameters, context
                    )

            if self._has_events or self.engine._has_events:
                self.dispatch.after_cursor_execute(
                    self,
                    cursor,
                    statement,
                    parameters,
                    context,
                    context.executemany,
                )

            context.post_exec()

            result = context._setup_result_proxy()

            if not self._is_future:
                should_close_with_result = branched.should_close_with_result

                if not result._soft_closed and should_close_with_result:
                    result._autoclose_connection = True

                if (
                    # usually we're in a transaction so avoid relatively
                    # expensive / legacy should_autocommit call
                    self._transaction is None
                    and context.should_autocommit
                ):
                    self._commit_impl(autocommit=True)

                # for "connectionless" execution, we have to close this
                # Connection after the statement is complete.
                # legacy stuff.
                if should_close_with_result and context._soft_closed:
                    assert not self._is_future

                    # CursorResult already exhausted rows / has no rows.
                    # close us now
                    branched.close()

        except BaseException as e:
>           self._handle_dbapi_exception(
                e, statement, parameters, cursor, context
            )

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1845:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b7d850>
e = OperationalError('ambiguous column name: pk_index')
statement = 'SELECT pk_index, w, x \nFROM (SELECT original_table_clause.w AS w, original_table_clause.x AS x, original_table_claus...S NULL AND x IS NULL)) AS anon_2 \nWHERE records_with_grouped_column_counts_subquery._num_rows >= ?\n LIMIT ? OFFSET ?'
parameters = (2, 20, 0), cursor = <sqlite3.Cursor object at 0x7fe2f93c4490>
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7fe2f90b77f0>

    def _handle_dbapi_exception(
        self, e, statement, parameters, cursor, context
    ):
        exc_info = sys.exc_info()

        is_exit_exception = util.is_exit_exception(e)

        if not self._is_disconnect:
            self._is_disconnect = (
                isinstance(e, self.dialect.dbapi.Error)
                and not self.closed
                and self.dialect.is_disconnect(
                    e,
                    self._dbapi_connection if not self.invalidated else None,
                    cursor,
                )
            ) or (is_exit_exception and not self.closed)

        invalidate_pool_on_disconnect = not is_exit_exception

        if self._reentrant_error:
            util.raise_(
                exc.DBAPIError.instance(
                    statement,
                    parameters,
                    e,
                    self.dialect.dbapi.Error,
                    hide_parameters=self.engine.hide_parameters,
                    dialect=self.dialect,
                    ismulti=context.executemany
                    if context is not None
                    else None,
                ),
                with_traceback=exc_info[2],
                from_=e,
            )
        self._reentrant_error = True
        try:
            # non-DBAPI error - if we already got a context,
            # or there's no string statement, don't wrap it
            should_wrap = isinstance(e, self.dialect.dbapi.Error) or (
                statement is not None
                and context is None
                and not is_exit_exception
            )

            if should_wrap:
                sqlalchemy_exception = exc.DBAPIError.instance(
                    statement,
                    parameters,
                    e,
                    self.dialect.dbapi.Error,
                    hide_parameters=self.engine.hide_parameters,
                    connection_invalidated=self._is_disconnect,
                    dialect=self.dialect,
                    ismulti=context.executemany
                    if context is not None
                    else None,
                )
            else:
                sqlalchemy_exception = None

            newraise = None

            if (
                self._has_events or self.engine._has_events
            ) and not self._execution_options.get(
                "skip_user_error_events", False
            ):
                ctx = ExceptionContextImpl(
                    e,
                    sqlalchemy_exception,
                    self.engine,
                    self,
                    cursor,
                    statement,
                    parameters,
                    context,
                    self._is_disconnect,
                    invalidate_pool_on_disconnect,
                )

                for fn in self.dispatch.handle_error:
                    try:
                        # handler returns an exception;
                        # call next handler in a chain
                        per_fn = fn(ctx)
                        if per_fn is not None:
                            ctx.chained_exception = newraise = per_fn
                    except Exception as _raised:
                        # handler raises an exception - stop processing
                        newraise = _raised
                        break

                if self._is_disconnect != ctx.is_disconnect:
                    self._is_disconnect = ctx.is_disconnect
                    if sqlalchemy_exception:
                        sqlalchemy_exception.connection_invalidated = (
                            ctx.is_disconnect
                        )

                # set up potentially user-defined value for
                # invalidate pool.
                invalidate_pool_on_disconnect = (
                    ctx.invalidate_pool_on_disconnect
                )

            if should_wrap and context:
                context.handle_dbapi_exception(e)

            if not self._is_disconnect:
                if cursor:
                    self._safe_close_cursor(cursor)
                with util.safe_reraise(warn_only=True):
                    self._autorollback()

            if newraise:
                util.raise_(newraise, with_traceback=exc_info[2], from_=e)
            elif should_wrap:
>               util.raise_(
                    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
                )

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/engine/base.py:2026:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

    def raise_(
        exception, with_traceback=None, replace_context=None, from_=False
    ):
        r"""implement "raise" with cause support.

        :param exception: exception to raise
        :param with_traceback: will call exception.with_traceback()
        :param replace_context: an as-yet-unsupported feature.  This is
         an exception object which we are "replacing", e.g., it's our
         "cause" but we don't want it printed.    Basically just what
         ``__suppress_context__`` does but we don't want to suppress
         the enclosing context, if any.  So for now we make it the
         cause.
        :param from\_: the cause.  this actually sets the cause and doesn't
         hope to hide it someday.

        """
        if with_traceback is not None:
            exception = exception.with_traceback(with_traceback)

        if from_ is not False:
            exception.__cause__ = from_
        elif replace_context is not None:
            # no good solution here, we would like to have the exception
            # have only the context of replace_context.__context__ so that the
            # intermediary exception does not change, but we can't figure
            # that out.
            exception.__cause__ = replace_context

        try:
>           raise exception

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/util/compat.py:207:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b7d850>
dialect = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7fe2f3b85250>
constructor = <bound method DefaultExecutionContext._init_compiled of <class 'sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext'>>
statement = 'SELECT pk_index, w, x \nFROM (SELECT original_table_clause.w AS w, original_table_clause.x AS x, original_table_claus...S NULL AND x IS NULL)) AS anon_2 \nWHERE records_with_grouped_column_counts_subquery._num_rows >= ?\n LIMIT ? OFFSET ?'
parameters = (2, 20, 0), execution_options = immutabledict({})
args = (<sqlalchemy.dialects.sqlite.base.SQLiteCompiler object at 0x7fe2f9092f40>, [], <sqlalchemy.sql.selectable.Select obje...140612817464000 num_rows)s', 2, type_=Integer()), _OffsetLimitParam('%(140612817464960 param)s', 20, type_=Integer())])
kw = {'cache_hit': symbol('CACHE_MISS')}
branched = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b7d850>
conn = <sqlalchemy.pool.base._ConnectionFairy object at 0x7fe2f3524040>
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7fe2f90b77f0>
cursor = <sqlite3.Cursor object at 0x7fe2f93c4490>, evt_handled = False

    def _execute_context(
        self,
        dialect,
        constructor,
        statement,
        parameters,
        execution_options,
        *args,
        **kw
    ):
        """Create an :class:`.ExecutionContext` and execute, returning
        a :class:`_engine.CursorResult`."""

        branched = self
        if self.__branch_from:
            # if this is a "branched" connection, do everything in terms
            # of the "root" connection, *except* for .close(), which is
            # the only feature that branching provides
            self = self.__branch_from

        try:
            conn = self._dbapi_connection
            if conn is None:
                conn = self._revalidate_connection()

            context = constructor(
                dialect, self, conn, execution_options, *args, **kw
            )
        except (exc.PendingRollbackError, exc.ResourceClosedError):
            raise
        except BaseException as e:
            self._handle_dbapi_exception(
                e, util.text_type(statement), parameters, None, None
            )

        if (
            self._transaction
            and not self._transaction.is_active
            or (
                self._nested_transaction
                and not self._nested_transaction.is_active
            )
        ):
            self._invalid_transaction()

        elif self._trans_context_manager:
            TransactionalContext._trans_ctx_check(self)

        if self._is_future and self._transaction is None:
            self._autobegin()

        context.pre_exec()

        if dialect.use_setinputsizes:
            context._set_input_sizes()

        cursor, statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )

        if not context.executemany:
            parameters = parameters[0]

        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                statement, parameters = fn(
                    self,
                    cursor,
                    statement,
                    parameters,
                    context,
                    context.executemany,
                )

        if self._echo:

            self._log_info(statement)

            stats = context._get_cache_stats()

            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        parameters, batches=10, ismulti=context.executemany
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]"
                    % (stats,)
                )

        evt_handled = False
        try:
            if context.executemany:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(cursor, statement, parameters, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor, statement, parameters, context
                    )
            elif not parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, statement, context
                    )
            else:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(cursor, statement, parameters, context):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, statement, parameters, context
                    )

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1802:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7fe2f3b85250>
cursor = <sqlite3.Cursor object at 0x7fe2f93c4490>
statement = 'SELECT pk_index, w, x \nFROM (SELECT original_table_clause.w AS w, original_table_clause.x AS x, original_table_claus...S NULL AND x IS NULL)) AS anon_2 \nWHERE records_with_grouped_column_counts_subquery._num_rows >= ?\n LIMIT ? OFFSET ?'
parameters = (2, 20, 0)
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7fe2f90b77f0>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) ambiguous column name: pk_index
E       [SQL: SELECT pk_index, w, x
E       FROM (SELECT original_table_clause.w AS w, original_table_clause.x AS x, original_table_clause.y AS y, original_table_clause.z AS z, original_table_clause.a AS a, original_table_clause.b AS b, original_table_clause.pk_index AS pk_index, group_counts_subquery._num_rows AS _num_rows
E       FROM (SELECT w, x, y, z, a, b, pk_index
E       FROM (SELECT *
E       FROM test_data_uzirh4kl
E       WHERE NOT (w IS NULL AND x IS NULL)) AS anon_1) AS original_table_clause JOIN (SELECT w, x, count(*) AS _num_rows
E       FROM (SELECT w, x, y, z, a, b, pk_index
E       FROM (SELECT *
E       FROM test_data_uzirh4kl
E       WHERE NOT (w IS NULL AND x IS NULL)) AS anon_1) AS original_table_clause GROUP BY w, x) AS group_counts_subquery ON group_counts_subquery.w = original_table_clause.w AND group_counts_subquery.x = original_table_clause.x) AS records_with_grouped_column_counts_subquery, (SELECT *
E       FROM test_data_uzirh4kl
E       WHERE NOT (w IS NULL AND x IS NULL)) AS anon_2
E       WHERE records_with_grouped_column_counts_subquery._num_rows >= ?
E        LIMIT ? OFFSET ?]
E       [parameters: (2, 20, 0)]
E       (Background on this error at: https://sqlalche.me/e/14/e3q8)

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/engine/default.py:719: OperationalError

The above exception was the direct cause of the following exception:

test_case = {'expectation_type': 'expect_compound_columns_to_be_unique', 'pk_column': True, 'skip': False, 'test': {'exact_match_o... False, 'in': {'column_list': ['w', 'x']}, 'include_in_gallery': True, 'input': {'column_list': ['w', 'x']}, ...}, ...}

    @pytest.mark.order(index=0)
    @pytest.mark.integration
    @pytest.mark.slow  # 12.68s
    def test_case_runner_v3_api(test_case):
        if test_case["skip"]:
            pytest.skip()

        # Note: this should never be done in practice, but we are wiping expectations to reuse batches during testing.
        # test_case["batch"]._initialize_expectations()
        if "parse_strings_as_datetimes" in test_case["test"]["in"]:
            with pytest.deprecated_call():
                evaluate_json_test_v3_api(
                    validator=test_case["validator_with_data"],
                    expectation_type=test_case["expectation_type"],
                    test=test_case["test"],
                    pk_column=test_case["pk_column"],
                )
        else:
>           evaluate_json_test_v3_api(
                validator=test_case["validator_with_data"],
                expectation_type=test_case["expectation_type"],
                test=test_case["test"],
                pk_column=test_case["pk_column"],
            )

tests/test_definitions/test_expectations_v3_api.py:428:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
great_expectations/self_check/util.py:2887: in evaluate_json_test_v3_api
    result = getattr(validator, expectation_type)(**runtime_kwargs)
great_expectations/validator/validator.py:595: in inst_expectation
    raise err
great_expectations/validator/validator.py:558: in inst_expectation
    validation_result = expectation.validate(
great_expectations/expectations/expectation.py:1265: in validate
    ] = validator.graph_validate(
great_expectations/validator/validator.py:1046: in graph_validate
    raise err
great_expectations/validator/validator.py:1025: in graph_validate
    ) = self._resolve_suite_level_graph_and_process_metric_evaluation_errors(
great_expectations/validator/validator.py:1184: in _resolve_suite_level_graph_and_process_metric_evaluation_errors
    ) = self._metrics_calculator.resolve_validation_graph(
great_expectations/validator/metrics_calculator.py:282: in resolve_validation_graph
    resolved_metrics, aborted_metrics_info = graph.resolve(
great_expectations/validator/validation_graph.py:196: in resolve
    ] = self._resolve(
great_expectations/validator/validation_graph.py:302: in _resolve
    raise err
great_expectations/validator/validation_graph.py:272: in _resolve
    self._execution_engine.resolve_metrics(
great_expectations/execution_engine/execution_engine.py:375: in resolve_metrics
    return self._process_direct_and_bundled_metric_computation_configurations(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <great_expectations.execution_engine.sqlalchemy_execution_engine.SqlAlchemyExecutionEngine object at 0x7fe2f3b9e2b0>
metric_fn_direct_configurations = [MetricComputationConfiguration(metric_configuration={
  "metric_name": "compound_columns.unique.filtered_row_count",
...l_unexpected_count': 20, 'include_unexpected_rows': False}}}, compute_domain_kwargs=None, accessor_domain_kwargs=None)]
metric_fn_bundle_configurations = []

    def _process_direct_and_bundled_metric_computation_configurations(
        self,
        metric_fn_direct_configurations: List[MetricComputationConfiguration],
        metric_fn_bundle_configurations: List[MetricComputationConfiguration],
    ) -> Dict[Tuple[str, str, str], MetricValue]:
        """
        This method processes directly-computable and bundled "MetricComputationConfiguration" objects.

        Args:
            metric_fn_direct_configurations: directly-computable "MetricComputationConfiguration" objects
            metric_fn_bundle_configurations: bundled "MetricComputationConfiguration" objects (column aggregates)

        Returns:
            resolved_metrics (Dict): a dictionary with the values for the metrics that have just been resolved.
        """
        resolved_metrics: Dict[Tuple[str, str, str], MetricValue] = {}

        metric_computation_configuration: MetricComputationConfiguration

        for metric_computation_configuration in metric_fn_direct_configurations:
            try:
                resolved_metrics[
                    metric_computation_configuration.metric_configuration.id
                ] = metric_computation_configuration.metric_fn(
                    **metric_computation_configuration.metric_provider_kwargs
                )
            except Exception as e:
>               raise gx_exceptions.MetricResolutionError(
                    message=str(e),
                    failed_metrics=(
                        metric_computation_configuration.metric_configuration,
                    ),
                ) from e
E               great_expectations.exceptions.exceptions.MetricResolutionError: (sqlite3.OperationalError) ambiguous column name: pk_index
E               [SQL: SELECT pk_index, w, x
E               FROM (SELECT original_table_clause.w AS w, original_table_clause.x AS x, original_table_clause.y AS y, original_table_clause.z AS z, original_table_clause.a AS a, original_table_clause.b AS b, original_table_clause.pk_index AS pk_index, group_counts_subquery._num_rows AS _num_rows
E               FROM (SELECT w, x, y, z, a, b, pk_index
E               FROM (SELECT *
E               FROM test_data_uzirh4kl
E               WHERE NOT (w IS NULL AND x IS NULL)) AS anon_1) AS original_table_clause JOIN (SELECT w, x, count(*) AS _num_rows
E               FROM (SELECT w, x, y, z, a, b, pk_index
E               FROM (SELECT *
E               FROM test_data_uzirh4kl
E               WHERE NOT (w IS NULL AND x IS NULL)) AS anon_1) AS original_table_clause GROUP BY w, x) AS group_counts_subquery ON group_counts_subquery.w = original_table_clause.w AND group_counts_subquery.x = original_table_clause.x) AS records_with_grouped_column_counts_subquery, (SELECT *
E               FROM test_data_uzirh4kl
E               WHERE NOT (w IS NULL AND x IS NULL)) AS anon_2
E               WHERE records_with_grouped_column_counts_subquery._num_rows >= ?
E                LIMIT ? OFFSET ?]
E               [parameters: (2, 20, 0)]
E               (Background on this error at: https://sqlalche.me/e/14/e3q8)

great_expectations/execution_engine/execution_engine.py:654: MetricResolutionError
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:  18%|        | 2/11 [00:00<00:00, 2227.46it/s]Calculating Metrics:  18%|        | 2/11 [00:00<00:00, 276.48it/s] Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 448.48it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 274.01it/s]Calculating Metrics:  45%|     | 5/11 [00:00<00:00, 308.49it/s]Calculating Metrics:  45%|     | 5/11 [00:00<00:00, 232.58it/s]Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 259.10it/s]Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 213.75it/s]
--------------------------- Captured stderr teardown ---------------------------
Calculating Metrics:  55%|    | 6/11 [00:01<00:01,  3.24it/s]
_ test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_compound_columns_to_be_unique:basic_test_ignore_if_any_are_missing] _

self = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b7d850>
dialect = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7fe2f3b85250>
constructor = <bound method DefaultExecutionContext._init_compiled of <class 'sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext'>>
statement = 'SELECT pk_index, w, x \nFROM (SELECT original_table_clause.w AS w, original_table_clause.x AS x, original_table_claus...IS NULL OR x IS NULL)) AS anon_2 \nWHERE records_with_grouped_column_counts_subquery._num_rows >= ?\n LIMIT ? OFFSET ?'
parameters = (2, 20, 0), execution_options = immutabledict({})
args = (<sqlalchemy.dialects.sqlite.base.SQLiteCompiler object at 0x7fe2f8844b50>, [], <sqlalchemy.sql.selectable.Select obje...140612810162528 num_rows)s', 2, type_=Integer()), _OffsetLimitParam('%(140612808754320 param)s', 20, type_=Integer())])
kw = {'cache_hit': symbol('CACHE_MISS')}
branched = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b7d850>
conn = <sqlalchemy.pool.base._ConnectionFairy object at 0x7fe2f3524040>
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7fe2f8844970>
cursor = <sqlite3.Cursor object at 0x7fe2f8941f80>, evt_handled = False

    def _execute_context(
        self,
        dialect,
        constructor,
        statement,
        parameters,
        execution_options,
        *args,
        **kw
    ):
        """Create an :class:`.ExecutionContext` and execute, returning
        a :class:`_engine.CursorResult`."""

        branched = self
        if self.__branch_from:
            # if this is a "branched" connection, do everything in terms
            # of the "root" connection, *except* for .close(), which is
            # the only feature that branching provides
            self = self.__branch_from

        try:
            conn = self._dbapi_connection
            if conn is None:
                conn = self._revalidate_connection()

            context = constructor(
                dialect, self, conn, execution_options, *args, **kw
            )
        except (exc.PendingRollbackError, exc.ResourceClosedError):
            raise
        except BaseException as e:
            self._handle_dbapi_exception(
                e, util.text_type(statement), parameters, None, None
            )

        if (
            self._transaction
            and not self._transaction.is_active
            or (
                self._nested_transaction
                and not self._nested_transaction.is_active
            )
        ):
            self._invalid_transaction()

        elif self._trans_context_manager:
            TransactionalContext._trans_ctx_check(self)

        if self._is_future and self._transaction is None:
            self._autobegin()

        context.pre_exec()

        if dialect.use_setinputsizes:
            context._set_input_sizes()

        cursor, statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )

        if not context.executemany:
            parameters = parameters[0]

        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                statement, parameters = fn(
                    self,
                    cursor,
                    statement,
                    parameters,
                    context,
                    context.executemany,
                )

        if self._echo:

            self._log_info(statement)

            stats = context._get_cache_stats()

            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        parameters, batches=10, ismulti=context.executemany
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]"
                    % (stats,)
                )

        evt_handled = False
        try:
            if context.executemany:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(cursor, statement, parameters, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor, statement, parameters, context
                    )
            elif not parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, statement, context
                    )
            else:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(cursor, statement, parameters, context):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, statement, parameters, context
                    )

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1802:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7fe2f3b85250>
cursor = <sqlite3.Cursor object at 0x7fe2f8941f80>
statement = 'SELECT pk_index, w, x \nFROM (SELECT original_table_clause.w AS w, original_table_clause.x AS x, original_table_claus...IS NULL OR x IS NULL)) AS anon_2 \nWHERE records_with_grouped_column_counts_subquery._num_rows >= ?\n LIMIT ? OFFSET ?'
parameters = (2, 20, 0)
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7fe2f8844970>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlite3.OperationalError: ambiguous column name: pk_index

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/engine/default.py:719: OperationalError

The above exception was the direct cause of the following exception:

self = <great_expectations.execution_engine.sqlalchemy_execution_engine.SqlAlchemyExecutionEngine object at 0x7fe2f3b9e2b0>
metric_fn_direct_configurations = [MetricComputationConfiguration(metric_configuration={
  "metric_name": "compound_columns.unique.unexpected_index_quer...l_unexpected_count': 20, 'include_unexpected_rows': False}}}, compute_domain_kwargs=None, accessor_domain_kwargs=None)]
metric_fn_bundle_configurations = []

    def _process_direct_and_bundled_metric_computation_configurations(
        self,
        metric_fn_direct_configurations: List[MetricComputationConfiguration],
        metric_fn_bundle_configurations: List[MetricComputationConfiguration],
    ) -> Dict[Tuple[str, str, str], MetricValue]:
        """
        This method processes directly-computable and bundled "MetricComputationConfiguration" objects.

        Args:
            metric_fn_direct_configurations: directly-computable "MetricComputationConfiguration" objects
            metric_fn_bundle_configurations: bundled "MetricComputationConfiguration" objects (column aggregates)

        Returns:
            resolved_metrics (Dict): a dictionary with the values for the metrics that have just been resolved.
        """
        resolved_metrics: Dict[Tuple[str, str, str], MetricValue] = {}

        metric_computation_configuration: MetricComputationConfiguration

        for metric_computation_configuration in metric_fn_direct_configurations:
            try:
                resolved_metrics[
                    metric_computation_configuration.metric_configuration.id
>               ] = metric_computation_configuration.metric_fn(
                    **metric_computation_configuration.metric_provider_kwargs
                )

great_expectations/execution_engine/execution_engine.py:650:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

cls = <class 'great_expectations.expectations.metrics.multicolumn_map_metrics.compound_columns_unique.CompoundColumnsUnique'>
execution_engine = <great_expectations.execution_engine.sqlalchemy_execution_engine.SqlAlchemyExecutionEngine object at 0x7fe2f3b9e2b0>
metric_domain_kwargs = {'batch_id': 'b1ae3225b6aa3d6c44dce474d8b4e741', 'table': None, 'column_list': ['w', 'x'], 'row_condition': None, 'condition_parser': None, 'ignore_row_if': 'any_value_is_missing'}
metric_value_kwargs = {'result_format': {'result_format': 'COMPLETE', 'unexpected_index_column_names': ['pk_index'], 'partial_unexpected_count': 20, 'include_unexpected_rows': False}}
metrics = {'table.column_types': [{'autoincrement': 'auto', 'default': None, 'name': 'w', 'nullable': True, ...}, {'autoincremen...row_condition': None, 'condition_parser': None, 'ignore_row_if': 'any_value_is_missing'}, {'column_list': ['w', 'x']})}
kwargs = {'runtime_configuration': {'catch_exceptions': False, 'include_config': False, 'result_format': {'include_unexpected_rows': False, 'partial_unexpected_count': 20, 'result_format': 'COMPLETE', 'unexpected_index_column_names': ['pk_index']}}}
unexpected_condition = <sqlalchemy.sql.elements.BinaryExpression object at 0x7fe2f8857790>
compute_domain_kwargs = {'batch_id': 'b1ae3225b6aa3d6c44dce474d8b4e741', 'table': None, 'row_condition': None, 'condition_parser': None, 'ignore_row_if': 'any_value_is_missing'}
accessor_domain_kwargs = {'column_list': ['w', 'x']}
domain_column_name_list = ['w', 'x'], column_name = 'x'
column_list = ['w', 'x']
domain_kwargs = {'batch_id': 'b1ae3225b6aa3d6c44dce474d8b4e741', 'column_list': ['w', 'x'], 'condition_parser': None, 'ignore_row_if': 'any_value_is_missing', ...}

    def _sqlalchemy_map_condition_index(
        cls,
        execution_engine: SqlAlchemyExecutionEngine,
        metric_domain_kwargs: Dict,
        metric_value_kwargs: Dict,
        metrics: Dict[str, Any],
        **kwargs,
    ) -> List[Dict[str, Any]]:
        """
        Returns indices of the metric values which do not meet an expected Expectation condition for instances
        of ColumnMapExpectation.

        Requires `unexpected_index_column_names` to be part of `result_format` dict to specify primary_key columns
        to return.
        """
        (
            unexpected_condition,
            compute_domain_kwargs,
            accessor_domain_kwargs,
        ) = metrics.get("unexpected_condition")

        domain_column_name_list: List[str] = list()
        # column map expectations
        if "column" in accessor_domain_kwargs:
            column_name: Union[str, quoted_name] = accessor_domain_kwargs["column"]
            domain_column_name_list.append(column_name)
        # multi-column map expectations
        elif "column_list" in accessor_domain_kwargs:
            column_list: List[Union[str, quoted_name]] = accessor_domain_kwargs[
                "column_list"
            ]
            domain_column_name_list = column_list
        # column-map expectations
        elif "column_A" in accessor_domain_kwargs and "column_B" in accessor_domain_kwargs:
            column_list: List[Union[str, quoted_name]] = list()
            column_list.append(accessor_domain_kwargs["column_A"])
            column_list.append(accessor_domain_kwargs["column_B"])
            domain_column_name_list = column_list

        domain_kwargs: dict = dict(**compute_domain_kwargs, **accessor_domain_kwargs)
        result_format: dict = metric_value_kwargs["result_format"]

        all_table_columns: List[str] = metrics.get("table.columns")

        unexpected_index_column_names: Optional[List[str]] = result_format.get(
            "unexpected_index_column_names"
        )

        column_selector: List[sa.Column] = []
        for column_name in unexpected_index_column_names:
            if column_name not in all_table_columns:
                raise gx_exceptions.InvalidMetricAccessorDomainKwargsKeyError(
                    message=f'Error: The unexpected_index_column: "{column_name}" in does not exist in SQL Table. '
                    f"Please check your configuration and try again."
                )
            column_selector.append(sa.column(column_name))

        # expectation_domain_column_name: str = domain_kwargs["column"]

        # the last column we SELECT is the column the Expectation is being run on
        for column_name in domain_column_name_list:
            column_selector.append(sa.column(column_name))

        domain_records_as_selectable: sa.sql.Selectable = (
            execution_engine.get_domain_records(domain_kwargs=domain_kwargs)
        )
        unexpected_condition_query_with_selected_columns: sa.select = sa.select(
            column_selector
        ).where(unexpected_condition)

        if not MapMetricProvider.is_sqlalchemy_metric_selectable(map_metric_provider=cls):
            domain_records_as_selectable: Union[
                sa.Table, sa.Select
            ] = get_sqlalchemy_selectable(domain_records_as_selectable)

        # since SQL tables can be **very** large, truncate query_result values at 20, or at `partial_unexpected_count`
        final_query: sa.select = (
            unexpected_condition_query_with_selected_columns.select_from(
                domain_records_as_selectable
            ).limit(result_format["partial_unexpected_count"])
        )
>       query_result: List[tuple] = execution_engine.engine.execute(final_query).fetchall()

great_expectations/expectations/metrics/map_metric_provider.py:2662:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b7d850>
statement = <sqlalchemy.sql.selectable.Select object at 0x7fe2f88449d0>
multiparams = (), params = {}
meth = <bound method ClauseElement._execute_on_connection of <sqlalchemy.sql.selectable.Select object at 0x7fe2f88449d0>>

    def execute(self, statement, *multiparams, **params):
        r"""Executes a SQL statement construct and returns a
        :class:`_engine.CursorResult`.

        :param statement: The statement to be executed.  May be
         one of:

         * a plain string (deprecated)
         * any :class:`_expression.ClauseElement` construct that is also
           a subclass of :class:`.Executable`, such as a
           :func:`_expression.select` construct
         * a :class:`.FunctionElement`, such as that generated
           by :data:`.func`, will be automatically wrapped in
           a SELECT statement, which is then executed.
         * a :class:`.DDLElement` object
         * a :class:`.DefaultGenerator` object
         * a :class:`.Compiled` object

         .. deprecated:: 2.0 passing a string to
            :meth:`_engine.Connection.execute` is
            deprecated and will be removed in version 2.0.  Use the
            :func:`_expression.text` construct with
            :meth:`_engine.Connection.execute`, or the
            :meth:`_engine.Connection.exec_driver_sql`
            method to invoke a driver-level
            SQL string.

        :param \*multiparams/\**params: represent bound parameter
         values to be used in the execution.   Typically,
         the format is either a collection of one or more
         dictionaries passed to \*multiparams::

             conn.execute(
                 table.insert(),
                 {"id":1, "value":"v1"},
                 {"id":2, "value":"v2"}
             )

         ...or individual key/values interpreted by \**params::

             conn.execute(
                 table.insert(), id=1, value="v1"
             )

         In the case that a plain SQL string is passed, and the underlying
         DBAPI accepts positional bind parameters, a collection of tuples
         or individual values in \*multiparams may be passed::

             conn.execute(
                 "INSERT INTO table (id, value) VALUES (?, ?)",
                 (1, "v1"), (2, "v2")
             )

             conn.execute(
                 "INSERT INTO table (id, value) VALUES (?, ?)",
                 1, "v1"
             )

         Note above, the usage of a question mark "?" or other
         symbol is contingent upon the "paramstyle" accepted by the DBAPI
         in use, which may be any of "qmark", "named", "pyformat", "format",
         "numeric".   See `pep-249
         <https://www.python.org/dev/peps/pep-0249/>`_ for details on
         paramstyle.

         To execute a textual SQL statement which uses bound parameters in a
         DBAPI-agnostic way, use the :func:`_expression.text` construct.

         .. deprecated:: 2.0 use of tuple or scalar positional parameters
            is deprecated. All params should be dicts or sequences of dicts.
            Use :meth:`.exec_driver_sql` to execute a plain string with
            tuple or scalar positional parameters.

        """

        if isinstance(statement, util.string_types):
            util.warn_deprecated_20(
                "Passing a string to Connection.execute() is "
                "deprecated and will be removed in version 2.0.  Use the "
                "text() construct, "
                "or the Connection.exec_driver_sql() method to invoke a "
                "driver-level SQL string."
            )

            return self._exec_driver_sql(
                statement,
                multiparams,
                params,
                _EMPTY_EXECUTION_OPTS,
                future=False,
            )

        try:
            meth = statement._execute_on_connection
        except AttributeError as err:
            util.raise_(
                exc.ObjectNotExecutableError(statement), replace_context=err
            )
        else:
>           return meth(self, multiparams, params, _EMPTY_EXECUTION_OPTS)

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1289:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.sql.selectable.Select object at 0x7fe2f88449d0>
connection = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b7d850>
multiparams = (), params = {}, execution_options = immutabledict({})
_force = False

    def _execute_on_connection(
        self, connection, multiparams, params, execution_options, _force=False
    ):
        if _force or self.supports_execution:
>           return connection._execute_clauseelement(
                self, multiparams, params, execution_options
            )

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/sql/elements.py:325:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b7d850>
elem = <sqlalchemy.sql.selectable.Select object at 0x7fe2f88449d0>
multiparams = (), params = {}, execution_options = immutabledict({})

    def _execute_clauseelement(
        self, elem, multiparams, params, execution_options
    ):
        """Execute a sql.ClauseElement object."""

        execution_options = elem._execution_options.merge_with(
            self._execution_options, execution_options
        )

        distilled_params = _distill_params(self, multiparams, params)

        has_events = self._has_events or self.engine._has_events
        if has_events:
            (
                elem,
                distilled_params,
                event_multiparams,
                event_params,
            ) = self._invoke_before_exec_event(
                elem, distilled_params, execution_options
            )

        if distilled_params:
            # ensure we don't retain a link to the view object for keys()
            # which links to the values, which we don't want to cache
            keys = sorted(distilled_params[0])
            for_executemany = len(distilled_params) > 1
        else:
            keys = []
            for_executemany = False

        dialect = self.dialect

        schema_translate_map = execution_options.get(
            "schema_translate_map", None
        )

        compiled_cache = execution_options.get(
            "compiled_cache", self.engine._compiled_cache
        )

        compiled_sql, extracted_params, cache_hit = elem._compile_w_cache(
            dialect=dialect,
            compiled_cache=compiled_cache,
            column_keys=keys,
            for_executemany=for_executemany,
            schema_translate_map=schema_translate_map,
            linting=self.dialect.compiler_linting | compiler.WARN_LINTING,
        )
>       ret = self._execute_context(
            dialect,
            dialect.execution_ctx_cls._init_compiled,
            compiled_sql,
            distilled_params,
            execution_options,
            compiled_sql,
            distilled_params,
            elem,
            extracted_params,
            cache_hit=cache_hit,
        )

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1481:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b7d850>
dialect = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7fe2f3b85250>
constructor = <bound method DefaultExecutionContext._init_compiled of <class 'sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext'>>
statement = 'SELECT pk_index, w, x \nFROM (SELECT original_table_clause.w AS w, original_table_clause.x AS x, original_table_claus...IS NULL OR x IS NULL)) AS anon_2 \nWHERE records_with_grouped_column_counts_subquery._num_rows >= ?\n LIMIT ? OFFSET ?'
parameters = (2, 20, 0), execution_options = immutabledict({})
args = (<sqlalchemy.dialects.sqlite.base.SQLiteCompiler object at 0x7fe2f8844b50>, [], <sqlalchemy.sql.selectable.Select obje...140612810162528 num_rows)s', 2, type_=Integer()), _OffsetLimitParam('%(140612808754320 param)s', 20, type_=Integer())])
kw = {'cache_hit': symbol('CACHE_MISS')}
branched = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b7d850>
conn = <sqlalchemy.pool.base._ConnectionFairy object at 0x7fe2f3524040>
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7fe2f8844970>
cursor = <sqlite3.Cursor object at 0x7fe2f8941f80>, evt_handled = False

    def _execute_context(
        self,
        dialect,
        constructor,
        statement,
        parameters,
        execution_options,
        *args,
        **kw
    ):
        """Create an :class:`.ExecutionContext` and execute, returning
        a :class:`_engine.CursorResult`."""

        branched = self
        if self.__branch_from:
            # if this is a "branched" connection, do everything in terms
            # of the "root" connection, *except* for .close(), which is
            # the only feature that branching provides
            self = self.__branch_from

        try:
            conn = self._dbapi_connection
            if conn is None:
                conn = self._revalidate_connection()

            context = constructor(
                dialect, self, conn, execution_options, *args, **kw
            )
        except (exc.PendingRollbackError, exc.ResourceClosedError):
            raise
        except BaseException as e:
            self._handle_dbapi_exception(
                e, util.text_type(statement), parameters, None, None
            )

        if (
            self._transaction
            and not self._transaction.is_active
            or (
                self._nested_transaction
                and not self._nested_transaction.is_active
            )
        ):
            self._invalid_transaction()

        elif self._trans_context_manager:
            TransactionalContext._trans_ctx_check(self)

        if self._is_future and self._transaction is None:
            self._autobegin()

        context.pre_exec()

        if dialect.use_setinputsizes:
            context._set_input_sizes()

        cursor, statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )

        if not context.executemany:
            parameters = parameters[0]

        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                statement, parameters = fn(
                    self,
                    cursor,
                    statement,
                    parameters,
                    context,
                    context.executemany,
                )

        if self._echo:

            self._log_info(statement)

            stats = context._get_cache_stats()

            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        parameters, batches=10, ismulti=context.executemany
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]"
                    % (stats,)
                )

        evt_handled = False
        try:
            if context.executemany:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(cursor, statement, parameters, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor, statement, parameters, context
                    )
            elif not parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, statement, context
                    )
            else:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(cursor, statement, parameters, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute(
                        cursor, statement, parameters, context
                    )

            if self._has_events or self.engine._has_events:
                self.dispatch.after_cursor_execute(
                    self,
                    cursor,
                    statement,
                    parameters,
                    context,
                    context.executemany,
                )

            context.post_exec()

            result = context._setup_result_proxy()

            if not self._is_future:
                should_close_with_result = branched.should_close_with_result

                if not result._soft_closed and should_close_with_result:
                    result._autoclose_connection = True

                if (
                    # usually we're in a transaction so avoid relatively
                    # expensive / legacy should_autocommit call
                    self._transaction is None
                    and context.should_autocommit
                ):
                    self._commit_impl(autocommit=True)

                # for "connectionless" execution, we have to close this
                # Connection after the statement is complete.
                # legacy stuff.
                if should_close_with_result and context._soft_closed:
                    assert not self._is_future

                    # CursorResult already exhausted rows / has no rows.
                    # close us now
                    branched.close()

        except BaseException as e:
>           self._handle_dbapi_exception(
                e, statement, parameters, cursor, context
            )

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1845:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b7d850>
e = OperationalError('ambiguous column name: pk_index')
statement = 'SELECT pk_index, w, x \nFROM (SELECT original_table_clause.w AS w, original_table_clause.x AS x, original_table_claus...IS NULL OR x IS NULL)) AS anon_2 \nWHERE records_with_grouped_column_counts_subquery._num_rows >= ?\n LIMIT ? OFFSET ?'
parameters = (2, 20, 0), cursor = <sqlite3.Cursor object at 0x7fe2f8941f80>
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7fe2f8844970>

    def _handle_dbapi_exception(
        self, e, statement, parameters, cursor, context
    ):
        exc_info = sys.exc_info()

        is_exit_exception = util.is_exit_exception(e)

        if not self._is_disconnect:
            self._is_disconnect = (
                isinstance(e, self.dialect.dbapi.Error)
                and not self.closed
                and self.dialect.is_disconnect(
                    e,
                    self._dbapi_connection if not self.invalidated else None,
                    cursor,
                )
            ) or (is_exit_exception and not self.closed)

        invalidate_pool_on_disconnect = not is_exit_exception

        if self._reentrant_error:
            util.raise_(
                exc.DBAPIError.instance(
                    statement,
                    parameters,
                    e,
                    self.dialect.dbapi.Error,
                    hide_parameters=self.engine.hide_parameters,
                    dialect=self.dialect,
                    ismulti=context.executemany
                    if context is not None
                    else None,
                ),
                with_traceback=exc_info[2],
                from_=e,
            )
        self._reentrant_error = True
        try:
            # non-DBAPI error - if we already got a context,
            # or there's no string statement, don't wrap it
            should_wrap = isinstance(e, self.dialect.dbapi.Error) or (
                statement is not None
                and context is None
                and not is_exit_exception
            )

            if should_wrap:
                sqlalchemy_exception = exc.DBAPIError.instance(
                    statement,
                    parameters,
                    e,
                    self.dialect.dbapi.Error,
                    hide_parameters=self.engine.hide_parameters,
                    connection_invalidated=self._is_disconnect,
                    dialect=self.dialect,
                    ismulti=context.executemany
                    if context is not None
                    else None,
                )
            else:
                sqlalchemy_exception = None

            newraise = None

            if (
                self._has_events or self.engine._has_events
            ) and not self._execution_options.get(
                "skip_user_error_events", False
            ):
                ctx = ExceptionContextImpl(
                    e,
                    sqlalchemy_exception,
                    self.engine,
                    self,
                    cursor,
                    statement,
                    parameters,
                    context,
                    self._is_disconnect,
                    invalidate_pool_on_disconnect,
                )

                for fn in self.dispatch.handle_error:
                    try:
                        # handler returns an exception;
                        # call next handler in a chain
                        per_fn = fn(ctx)
                        if per_fn is not None:
                            ctx.chained_exception = newraise = per_fn
                    except Exception as _raised:
                        # handler raises an exception - stop processing
                        newraise = _raised
                        break

                if self._is_disconnect != ctx.is_disconnect:
                    self._is_disconnect = ctx.is_disconnect
                    if sqlalchemy_exception:
                        sqlalchemy_exception.connection_invalidated = (
                            ctx.is_disconnect
                        )

                # set up potentially user-defined value for
                # invalidate pool.
                invalidate_pool_on_disconnect = (
                    ctx.invalidate_pool_on_disconnect
                )

            if should_wrap and context:
                context.handle_dbapi_exception(e)

            if not self._is_disconnect:
                if cursor:
                    self._safe_close_cursor(cursor)
                with util.safe_reraise(warn_only=True):
                    self._autorollback()

            if newraise:
                util.raise_(newraise, with_traceback=exc_info[2], from_=e)
            elif should_wrap:
>               util.raise_(
                    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
                )

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/engine/base.py:2026:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

    def raise_(
        exception, with_traceback=None, replace_context=None, from_=False
    ):
        r"""implement "raise" with cause support.

        :param exception: exception to raise
        :param with_traceback: will call exception.with_traceback()
        :param replace_context: an as-yet-unsupported feature.  This is
         an exception object which we are "replacing", e.g., it's our
         "cause" but we don't want it printed.    Basically just what
         ``__suppress_context__`` does but we don't want to suppress
         the enclosing context, if any.  So for now we make it the
         cause.
        :param from\_: the cause.  this actually sets the cause and doesn't
         hope to hide it someday.

        """
        if with_traceback is not None:
            exception = exception.with_traceback(with_traceback)

        if from_ is not False:
            exception.__cause__ = from_
        elif replace_context is not None:
            # no good solution here, we would like to have the exception
            # have only the context of replace_context.__context__ so that the
            # intermediary exception does not change, but we can't figure
            # that out.
            exception.__cause__ = replace_context

        try:
>           raise exception

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/util/compat.py:207:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b7d850>
dialect = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7fe2f3b85250>
constructor = <bound method DefaultExecutionContext._init_compiled of <class 'sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext'>>
statement = 'SELECT pk_index, w, x \nFROM (SELECT original_table_clause.w AS w, original_table_clause.x AS x, original_table_claus...IS NULL OR x IS NULL)) AS anon_2 \nWHERE records_with_grouped_column_counts_subquery._num_rows >= ?\n LIMIT ? OFFSET ?'
parameters = (2, 20, 0), execution_options = immutabledict({})
args = (<sqlalchemy.dialects.sqlite.base.SQLiteCompiler object at 0x7fe2f8844b50>, [], <sqlalchemy.sql.selectable.Select obje...140612810162528 num_rows)s', 2, type_=Integer()), _OffsetLimitParam('%(140612808754320 param)s', 20, type_=Integer())])
kw = {'cache_hit': symbol('CACHE_MISS')}
branched = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b7d850>
conn = <sqlalchemy.pool.base._ConnectionFairy object at 0x7fe2f3524040>
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7fe2f8844970>
cursor = <sqlite3.Cursor object at 0x7fe2f8941f80>, evt_handled = False

    def _execute_context(
        self,
        dialect,
        constructor,
        statement,
        parameters,
        execution_options,
        *args,
        **kw
    ):
        """Create an :class:`.ExecutionContext` and execute, returning
        a :class:`_engine.CursorResult`."""

        branched = self
        if self.__branch_from:
            # if this is a "branched" connection, do everything in terms
            # of the "root" connection, *except* for .close(), which is
            # the only feature that branching provides
            self = self.__branch_from

        try:
            conn = self._dbapi_connection
            if conn is None:
                conn = self._revalidate_connection()

            context = constructor(
                dialect, self, conn, execution_options, *args, **kw
            )
        except (exc.PendingRollbackError, exc.ResourceClosedError):
            raise
        except BaseException as e:
            self._handle_dbapi_exception(
                e, util.text_type(statement), parameters, None, None
            )

        if (
            self._transaction
            and not self._transaction.is_active
            or (
                self._nested_transaction
                and not self._nested_transaction.is_active
            )
        ):
            self._invalid_transaction()

        elif self._trans_context_manager:
            TransactionalContext._trans_ctx_check(self)

        if self._is_future and self._transaction is None:
            self._autobegin()

        context.pre_exec()

        if dialect.use_setinputsizes:
            context._set_input_sizes()

        cursor, statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )

        if not context.executemany:
            parameters = parameters[0]

        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                statement, parameters = fn(
                    self,
                    cursor,
                    statement,
                    parameters,
                    context,
                    context.executemany,
                )

        if self._echo:

            self._log_info(statement)

            stats = context._get_cache_stats()

            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        parameters, batches=10, ismulti=context.executemany
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]"
                    % (stats,)
                )

        evt_handled = False
        try:
            if context.executemany:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(cursor, statement, parameters, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor, statement, parameters, context
                    )
            elif not parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, statement, context
                    )
            else:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(cursor, statement, parameters, context):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, statement, parameters, context
                    )

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1802:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7fe2f3b85250>
cursor = <sqlite3.Cursor object at 0x7fe2f8941f80>
statement = 'SELECT pk_index, w, x \nFROM (SELECT original_table_clause.w AS w, original_table_clause.x AS x, original_table_claus...IS NULL OR x IS NULL)) AS anon_2 \nWHERE records_with_grouped_column_counts_subquery._num_rows >= ?\n LIMIT ? OFFSET ?'
parameters = (2, 20, 0)
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7fe2f8844970>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) ambiguous column name: pk_index
E       [SQL: SELECT pk_index, w, x
E       FROM (SELECT original_table_clause.w AS w, original_table_clause.x AS x, original_table_clause.y AS y, original_table_clause.z AS z, original_table_clause.a AS a, original_table_clause.b AS b, original_table_clause.pk_index AS pk_index, group_counts_subquery._num_rows AS _num_rows
E       FROM (SELECT w, x, y, z, a, b, pk_index
E       FROM (SELECT *
E       FROM test_data_uzirh4kl
E       WHERE NOT (w IS NULL OR x IS NULL)) AS anon_1) AS original_table_clause JOIN (SELECT w, x, count(*) AS _num_rows
E       FROM (SELECT w, x, y, z, a, b, pk_index
E       FROM (SELECT *
E       FROM test_data_uzirh4kl
E       WHERE NOT (w IS NULL OR x IS NULL)) AS anon_1) AS original_table_clause GROUP BY w, x) AS group_counts_subquery ON group_counts_subquery.w = original_table_clause.w AND group_counts_subquery.x = original_table_clause.x) AS records_with_grouped_column_counts_subquery, (SELECT *
E       FROM test_data_uzirh4kl
E       WHERE NOT (w IS NULL OR x IS NULL)) AS anon_2
E       WHERE records_with_grouped_column_counts_subquery._num_rows >= ?
E        LIMIT ? OFFSET ?]
E       [parameters: (2, 20, 0)]
E       (Background on this error at: https://sqlalche.me/e/14/e3q8)

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/engine/default.py:719: OperationalError

The above exception was the direct cause of the following exception:

test_case = {'expectation_type': 'expect_compound_columns_to_be_unique', 'pk_column': True, 'skip': False, 'test': {'exact_match_o..._if': 'any_value_is_missing'}, 'out': {'success': True, 'unexpected_index_list': [], 'unexpected_list': []}, ...}, ...}

    @pytest.mark.order(index=0)
    @pytest.mark.integration
    @pytest.mark.slow  # 12.68s
    def test_case_runner_v3_api(test_case):
        if test_case["skip"]:
            pytest.skip()

        # Note: this should never be done in practice, but we are wiping expectations to reuse batches during testing.
        # test_case["batch"]._initialize_expectations()
        if "parse_strings_as_datetimes" in test_case["test"]["in"]:
            with pytest.deprecated_call():
                evaluate_json_test_v3_api(
                    validator=test_case["validator_with_data"],
                    expectation_type=test_case["expectation_type"],
                    test=test_case["test"],
                    pk_column=test_case["pk_column"],
                )
        else:
>           evaluate_json_test_v3_api(
                validator=test_case["validator_with_data"],
                expectation_type=test_case["expectation_type"],
                test=test_case["test"],
                pk_column=test_case["pk_column"],
            )

tests/test_definitions/test_expectations_v3_api.py:428:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
great_expectations/self_check/util.py:2887: in evaluate_json_test_v3_api
    result = getattr(validator, expectation_type)(**runtime_kwargs)
great_expectations/validator/validator.py:595: in inst_expectation
    raise err
great_expectations/validator/validator.py:558: in inst_expectation
    validation_result = expectation.validate(
great_expectations/expectations/expectation.py:1265: in validate
    ] = validator.graph_validate(
great_expectations/validator/validator.py:1046: in graph_validate
    raise err
great_expectations/validator/validator.py:1025: in graph_validate
    ) = self._resolve_suite_level_graph_and_process_metric_evaluation_errors(
great_expectations/validator/validator.py:1184: in _resolve_suite_level_graph_and_process_metric_evaluation_errors
    ) = self._metrics_calculator.resolve_validation_graph(
great_expectations/validator/metrics_calculator.py:282: in resolve_validation_graph
    resolved_metrics, aborted_metrics_info = graph.resolve(
great_expectations/validator/validation_graph.py:196: in resolve
    ] = self._resolve(
great_expectations/validator/validation_graph.py:302: in _resolve
    raise err
great_expectations/validator/validation_graph.py:272: in _resolve
    self._execution_engine.resolve_metrics(
great_expectations/execution_engine/execution_engine.py:375: in resolve_metrics
    return self._process_direct_and_bundled_metric_computation_configurations(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <great_expectations.execution_engine.sqlalchemy_execution_engine.SqlAlchemyExecutionEngine object at 0x7fe2f3b9e2b0>
metric_fn_direct_configurations = [MetricComputationConfiguration(metric_configuration={
  "metric_name": "compound_columns.unique.unexpected_index_quer...l_unexpected_count': 20, 'include_unexpected_rows': False}}}, compute_domain_kwargs=None, accessor_domain_kwargs=None)]
metric_fn_bundle_configurations = []

    def _process_direct_and_bundled_metric_computation_configurations(
        self,
        metric_fn_direct_configurations: List[MetricComputationConfiguration],
        metric_fn_bundle_configurations: List[MetricComputationConfiguration],
    ) -> Dict[Tuple[str, str, str], MetricValue]:
        """
        This method processes directly-computable and bundled "MetricComputationConfiguration" objects.

        Args:
            metric_fn_direct_configurations: directly-computable "MetricComputationConfiguration" objects
            metric_fn_bundle_configurations: bundled "MetricComputationConfiguration" objects (column aggregates)

        Returns:
            resolved_metrics (Dict): a dictionary with the values for the metrics that have just been resolved.
        """
        resolved_metrics: Dict[Tuple[str, str, str], MetricValue] = {}

        metric_computation_configuration: MetricComputationConfiguration

        for metric_computation_configuration in metric_fn_direct_configurations:
            try:
                resolved_metrics[
                    metric_computation_configuration.metric_configuration.id
                ] = metric_computation_configuration.metric_fn(
                    **metric_computation_configuration.metric_provider_kwargs
                )
            except Exception as e:
>               raise gx_exceptions.MetricResolutionError(
                    message=str(e),
                    failed_metrics=(
                        metric_computation_configuration.metric_configuration,
                    ),
                ) from e
E               great_expectations.exceptions.exceptions.MetricResolutionError: (sqlite3.OperationalError) ambiguous column name: pk_index
E               [SQL: SELECT pk_index, w, x
E               FROM (SELECT original_table_clause.w AS w, original_table_clause.x AS x, original_table_clause.y AS y, original_table_clause.z AS z, original_table_clause.a AS a, original_table_clause.b AS b, original_table_clause.pk_index AS pk_index, group_counts_subquery._num_rows AS _num_rows
E               FROM (SELECT w, x, y, z, a, b, pk_index
E               FROM (SELECT *
E               FROM test_data_uzirh4kl
E               WHERE NOT (w IS NULL OR x IS NULL)) AS anon_1) AS original_table_clause JOIN (SELECT w, x, count(*) AS _num_rows
E               FROM (SELECT w, x, y, z, a, b, pk_index
E               FROM (SELECT *
E               FROM test_data_uzirh4kl
E               WHERE NOT (w IS NULL OR x IS NULL)) AS anon_1) AS original_table_clause GROUP BY w, x) AS group_counts_subquery ON group_counts_subquery.w = original_table_clause.w AND group_counts_subquery.x = original_table_clause.x) AS records_with_grouped_column_counts_subquery, (SELECT *
E               FROM test_data_uzirh4kl
E               WHERE NOT (w IS NULL OR x IS NULL)) AS anon_2
E               WHERE records_with_grouped_column_counts_subquery._num_rows >= ?
E                LIMIT ? OFFSET ?]
E               [parameters: (2, 20, 0)]
E               (Background on this error at: https://sqlalche.me/e/14/e3q8)

great_expectations/execution_engine/execution_engine.py:654: MetricResolutionError
----------------------------- Captured stderr call -----------------------------

Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s][A
Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s][A
Calculating Metrics:  18%|        | 2/11 [00:00<00:00, 1814.93it/s][A
Calculating Metrics:  18%|        | 2/11 [00:00<00:00, 252.75it/s] [A
Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 392.43it/s][A
Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 207.81it/s][A
Calculating Metrics:  45%|     | 5/11 [00:00<00:00, 227.82it/s][A
Calculating Metrics:  45%|     | 5/11 [00:00<00:00, 177.06it/s][A
Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 201.60it/s][A
Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 161.90it/s][A
_ test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_compound_columns_to_be_unique:unexpected_values_without_unexpected_index_list] _

self = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b7d850>
dialect = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7fe2f3b85250>
constructor = <bound method DefaultExecutionContext._init_compiled of <class 'sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext'>>
statement = 'SELECT pk_index, a, b \nFROM (SELECT original_table_clause.w AS w, original_table_clause.x AS x, original_table_claus...S NULL AND b IS NULL)) AS anon_2 \nWHERE records_with_grouped_column_counts_subquery._num_rows >= ?\n LIMIT ? OFFSET ?'
parameters = (2, 20, 0), execution_options = immutabledict({})
args = (<sqlalchemy.dialects.sqlite.base.SQLiteCompiler object at 0x7fe2f85073a0>, [], <sqlalchemy.sql.selectable.Select obje...140612805360176 num_rows)s', 2, type_=Integer()), _OffsetLimitParam('%(140612805358544 param)s', 20, type_=Integer())])
kw = {'cache_hit': symbol('CACHE_MISS')}
branched = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b7d850>
conn = <sqlalchemy.pool.base._ConnectionFairy object at 0x7fe2f3524040>
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7fe2f8507280>
cursor = <sqlite3.Cursor object at 0x7fe2f84c0ce0>, evt_handled = False

    def _execute_context(
        self,
        dialect,
        constructor,
        statement,
        parameters,
        execution_options,
        *args,
        **kw
    ):
        """Create an :class:`.ExecutionContext` and execute, returning
        a :class:`_engine.CursorResult`."""

        branched = self
        if self.__branch_from:
            # if this is a "branched" connection, do everything in terms
            # of the "root" connection, *except* for .close(), which is
            # the only feature that branching provides
            self = self.__branch_from

        try:
            conn = self._dbapi_connection
            if conn is None:
                conn = self._revalidate_connection()

            context = constructor(
                dialect, self, conn, execution_options, *args, **kw
            )
        except (exc.PendingRollbackError, exc.ResourceClosedError):
            raise
        except BaseException as e:
            self._handle_dbapi_exception(
                e, util.text_type(statement), parameters, None, None
            )

        if (
            self._transaction
            and not self._transaction.is_active
            or (
                self._nested_transaction
                and not self._nested_transaction.is_active
            )
        ):
            self._invalid_transaction()

        elif self._trans_context_manager:
            TransactionalContext._trans_ctx_check(self)

        if self._is_future and self._transaction is None:
            self._autobegin()

        context.pre_exec()

        if dialect.use_setinputsizes:
            context._set_input_sizes()

        cursor, statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )

        if not context.executemany:
            parameters = parameters[0]

        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                statement, parameters = fn(
                    self,
                    cursor,
                    statement,
                    parameters,
                    context,
                    context.executemany,
                )

        if self._echo:

            self._log_info(statement)

            stats = context._get_cache_stats()

            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        parameters, batches=10, ismulti=context.executemany
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]"
                    % (stats,)
                )

        evt_handled = False
        try:
            if context.executemany:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(cursor, statement, parameters, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor, statement, parameters, context
                    )
            elif not parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, statement, context
                    )
            else:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(cursor, statement, parameters, context):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, statement, parameters, context
                    )

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1802:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7fe2f3b85250>
cursor = <sqlite3.Cursor object at 0x7fe2f84c0ce0>
statement = 'SELECT pk_index, a, b \nFROM (SELECT original_table_clause.w AS w, original_table_clause.x AS x, original_table_claus...S NULL AND b IS NULL)) AS anon_2 \nWHERE records_with_grouped_column_counts_subquery._num_rows >= ?\n LIMIT ? OFFSET ?'
parameters = (2, 20, 0)
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7fe2f8507280>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlite3.OperationalError: ambiguous column name: pk_index

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/engine/default.py:719: OperationalError

The above exception was the direct cause of the following exception:

self = <great_expectations.execution_engine.sqlalchemy_execution_engine.SqlAlchemyExecutionEngine object at 0x7fe2f3b9e2b0>
metric_fn_direct_configurations = [MetricComputationConfiguration(metric_configuration={
  "metric_name": "compound_columns.unique.unexpected_index_list...l_unexpected_count': 20, 'include_unexpected_rows': False}}}, compute_domain_kwargs=None, accessor_domain_kwargs=None)]
metric_fn_bundle_configurations = []

    def _process_direct_and_bundled_metric_computation_configurations(
        self,
        metric_fn_direct_configurations: List[MetricComputationConfiguration],
        metric_fn_bundle_configurations: List[MetricComputationConfiguration],
    ) -> Dict[Tuple[str, str, str], MetricValue]:
        """
        This method processes directly-computable and bundled "MetricComputationConfiguration" objects.

        Args:
            metric_fn_direct_configurations: directly-computable "MetricComputationConfiguration" objects
            metric_fn_bundle_configurations: bundled "MetricComputationConfiguration" objects (column aggregates)

        Returns:
            resolved_metrics (Dict): a dictionary with the values for the metrics that have just been resolved.
        """
        resolved_metrics: Dict[Tuple[str, str, str], MetricValue] = {}

        metric_computation_configuration: MetricComputationConfiguration

        for metric_computation_configuration in metric_fn_direct_configurations:
            try:
                resolved_metrics[
                    metric_computation_configuration.metric_configuration.id
>               ] = metric_computation_configuration.metric_fn(
                    **metric_computation_configuration.metric_provider_kwargs
                )

great_expectations/execution_engine/execution_engine.py:650:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

cls = <class 'great_expectations.expectations.metrics.multicolumn_map_metrics.compound_columns_unique.CompoundColumnsUnique'>
execution_engine = <great_expectations.execution_engine.sqlalchemy_execution_engine.SqlAlchemyExecutionEngine object at 0x7fe2f3b9e2b0>
metric_domain_kwargs = {'batch_id': 'b1ae3225b6aa3d6c44dce474d8b4e741', 'table': None, 'column_list': ['a', 'b'], 'row_condition': None, 'condition_parser': None, 'ignore_row_if': 'all_values_are_missing'}
metric_value_kwargs = {'result_format': {'result_format': 'COMPLETE', 'unexpected_index_column_names': ['pk_index'], 'partial_unexpected_count': 20, 'include_unexpected_rows': False}}
metrics = {'table.column_types': [{'autoincrement': 'auto', 'default': None, 'name': 'w', 'nullable': True, ...}, {'autoincremen...w_condition': None, 'condition_parser': None, 'ignore_row_if': 'all_values_are_missing'}, {'column_list': ['a', 'b']})}
kwargs = {'runtime_configuration': {'catch_exceptions': False, 'include_config': False, 'result_format': {'include_unexpected_rows': False, 'partial_unexpected_count': 20, 'result_format': 'COMPLETE', 'unexpected_index_column_names': ['pk_index']}}}
unexpected_condition = <sqlalchemy.sql.elements.BinaryExpression object at 0x7fe2f85077f0>
compute_domain_kwargs = {'batch_id': 'b1ae3225b6aa3d6c44dce474d8b4e741', 'table': None, 'row_condition': None, 'condition_parser': None, 'ignore_row_if': 'all_values_are_missing'}
accessor_domain_kwargs = {'column_list': ['a', 'b']}
domain_column_name_list = ['a', 'b'], column_name = 'b'
column_list = ['a', 'b']
domain_kwargs = {'batch_id': 'b1ae3225b6aa3d6c44dce474d8b4e741', 'column_list': ['a', 'b'], 'condition_parser': None, 'ignore_row_if': 'all_values_are_missing', ...}

    def _sqlalchemy_map_condition_index(
        cls,
        execution_engine: SqlAlchemyExecutionEngine,
        metric_domain_kwargs: Dict,
        metric_value_kwargs: Dict,
        metrics: Dict[str, Any],
        **kwargs,
    ) -> List[Dict[str, Any]]:
        """
        Returns indices of the metric values which do not meet an expected Expectation condition for instances
        of ColumnMapExpectation.

        Requires `unexpected_index_column_names` to be part of `result_format` dict to specify primary_key columns
        to return.
        """
        (
            unexpected_condition,
            compute_domain_kwargs,
            accessor_domain_kwargs,
        ) = metrics.get("unexpected_condition")

        domain_column_name_list: List[str] = list()
        # column map expectations
        if "column" in accessor_domain_kwargs:
            column_name: Union[str, quoted_name] = accessor_domain_kwargs["column"]
            domain_column_name_list.append(column_name)
        # multi-column map expectations
        elif "column_list" in accessor_domain_kwargs:
            column_list: List[Union[str, quoted_name]] = accessor_domain_kwargs[
                "column_list"
            ]
            domain_column_name_list = column_list
        # column-map expectations
        elif "column_A" in accessor_domain_kwargs and "column_B" in accessor_domain_kwargs:
            column_list: List[Union[str, quoted_name]] = list()
            column_list.append(accessor_domain_kwargs["column_A"])
            column_list.append(accessor_domain_kwargs["column_B"])
            domain_column_name_list = column_list

        domain_kwargs: dict = dict(**compute_domain_kwargs, **accessor_domain_kwargs)
        result_format: dict = metric_value_kwargs["result_format"]

        all_table_columns: List[str] = metrics.get("table.columns")

        unexpected_index_column_names: Optional[List[str]] = result_format.get(
            "unexpected_index_column_names"
        )

        column_selector: List[sa.Column] = []
        for column_name in unexpected_index_column_names:
            if column_name not in all_table_columns:
                raise gx_exceptions.InvalidMetricAccessorDomainKwargsKeyError(
                    message=f'Error: The unexpected_index_column: "{column_name}" in does not exist in SQL Table. '
                    f"Please check your configuration and try again."
                )
            column_selector.append(sa.column(column_name))

        # expectation_domain_column_name: str = domain_kwargs["column"]

        # the last column we SELECT is the column the Expectation is being run on
        for column_name in domain_column_name_list:
            column_selector.append(sa.column(column_name))

        domain_records_as_selectable: sa.sql.Selectable = (
            execution_engine.get_domain_records(domain_kwargs=domain_kwargs)
        )
        unexpected_condition_query_with_selected_columns: sa.select = sa.select(
            column_selector
        ).where(unexpected_condition)

        if not MapMetricProvider.is_sqlalchemy_metric_selectable(map_metric_provider=cls):
            domain_records_as_selectable: Union[
                sa.Table, sa.Select
            ] = get_sqlalchemy_selectable(domain_records_as_selectable)

        # since SQL tables can be **very** large, truncate query_result values at 20, or at `partial_unexpected_count`
        final_query: sa.select = (
            unexpected_condition_query_with_selected_columns.select_from(
                domain_records_as_selectable
            ).limit(result_format["partial_unexpected_count"])
        )
>       query_result: List[tuple] = execution_engine.engine.execute(final_query).fetchall()

great_expectations/expectations/metrics/map_metric_provider.py:2662:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b7d850>
statement = <sqlalchemy.sql.selectable.Select object at 0x7fe2f8507400>
multiparams = (), params = {}
meth = <bound method ClauseElement._execute_on_connection of <sqlalchemy.sql.selectable.Select object at 0x7fe2f8507400>>

    def execute(self, statement, *multiparams, **params):
        r"""Executes a SQL statement construct and returns a
        :class:`_engine.CursorResult`.

        :param statement: The statement to be executed.  May be
         one of:

         * a plain string (deprecated)
         * any :class:`_expression.ClauseElement` construct that is also
           a subclass of :class:`.Executable`, such as a
           :func:`_expression.select` construct
         * a :class:`.FunctionElement`, such as that generated
           by :data:`.func`, will be automatically wrapped in
           a SELECT statement, which is then executed.
         * a :class:`.DDLElement` object
         * a :class:`.DefaultGenerator` object
         * a :class:`.Compiled` object

         .. deprecated:: 2.0 passing a string to
            :meth:`_engine.Connection.execute` is
            deprecated and will be removed in version 2.0.  Use the
            :func:`_expression.text` construct with
            :meth:`_engine.Connection.execute`, or the
            :meth:`_engine.Connection.exec_driver_sql`
            method to invoke a driver-level
            SQL string.

        :param \*multiparams/\**params: represent bound parameter
         values to be used in the execution.   Typically,
         the format is either a collection of one or more
         dictionaries passed to \*multiparams::

             conn.execute(
                 table.insert(),
                 {"id":1, "value":"v1"},
                 {"id":2, "value":"v2"}
             )

         ...or individual key/values interpreted by \**params::

             conn.execute(
                 table.insert(), id=1, value="v1"
             )

         In the case that a plain SQL string is passed, and the underlying
         DBAPI accepts positional bind parameters, a collection of tuples
         or individual values in \*multiparams may be passed::

             conn.execute(
                 "INSERT INTO table (id, value) VALUES (?, ?)",
                 (1, "v1"), (2, "v2")
             )

             conn.execute(
                 "INSERT INTO table (id, value) VALUES (?, ?)",
                 1, "v1"
             )

         Note above, the usage of a question mark "?" or other
         symbol is contingent upon the "paramstyle" accepted by the DBAPI
         in use, which may be any of "qmark", "named", "pyformat", "format",
         "numeric".   See `pep-249
         <https://www.python.org/dev/peps/pep-0249/>`_ for details on
         paramstyle.

         To execute a textual SQL statement which uses bound parameters in a
         DBAPI-agnostic way, use the :func:`_expression.text` construct.

         .. deprecated:: 2.0 use of tuple or scalar positional parameters
            is deprecated. All params should be dicts or sequences of dicts.
            Use :meth:`.exec_driver_sql` to execute a plain string with
            tuple or scalar positional parameters.

        """

        if isinstance(statement, util.string_types):
            util.warn_deprecated_20(
                "Passing a string to Connection.execute() is "
                "deprecated and will be removed in version 2.0.  Use the "
                "text() construct, "
                "or the Connection.exec_driver_sql() method to invoke a "
                "driver-level SQL string."
            )

            return self._exec_driver_sql(
                statement,
                multiparams,
                params,
                _EMPTY_EXECUTION_OPTS,
                future=False,
            )

        try:
            meth = statement._execute_on_connection
        except AttributeError as err:
            util.raise_(
                exc.ObjectNotExecutableError(statement), replace_context=err
            )
        else:
>           return meth(self, multiparams, params, _EMPTY_EXECUTION_OPTS)

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1289:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.sql.selectable.Select object at 0x7fe2f8507400>
connection = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b7d850>
multiparams = (), params = {}, execution_options = immutabledict({})
_force = False

    def _execute_on_connection(
        self, connection, multiparams, params, execution_options, _force=False
    ):
        if _force or self.supports_execution:
>           return connection._execute_clauseelement(
                self, multiparams, params, execution_options
            )

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/sql/elements.py:325:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b7d850>
elem = <sqlalchemy.sql.selectable.Select object at 0x7fe2f8507400>
multiparams = (), params = {}, execution_options = immutabledict({})

    def _execute_clauseelement(
        self, elem, multiparams, params, execution_options
    ):
        """Execute a sql.ClauseElement object."""

        execution_options = elem._execution_options.merge_with(
            self._execution_options, execution_options
        )

        distilled_params = _distill_params(self, multiparams, params)

        has_events = self._has_events or self.engine._has_events
        if has_events:
            (
                elem,
                distilled_params,
                event_multiparams,
                event_params,
            ) = self._invoke_before_exec_event(
                elem, distilled_params, execution_options
            )

        if distilled_params:
            # ensure we don't retain a link to the view object for keys()
            # which links to the values, which we don't want to cache
            keys = sorted(distilled_params[0])
            for_executemany = len(distilled_params) > 1
        else:
            keys = []
            for_executemany = False

        dialect = self.dialect

        schema_translate_map = execution_options.get(
            "schema_translate_map", None
        )

        compiled_cache = execution_options.get(
            "compiled_cache", self.engine._compiled_cache
        )

        compiled_sql, extracted_params, cache_hit = elem._compile_w_cache(
            dialect=dialect,
            compiled_cache=compiled_cache,
            column_keys=keys,
            for_executemany=for_executemany,
            schema_translate_map=schema_translate_map,
            linting=self.dialect.compiler_linting | compiler.WARN_LINTING,
        )
>       ret = self._execute_context(
            dialect,
            dialect.execution_ctx_cls._init_compiled,
            compiled_sql,
            distilled_params,
            execution_options,
            compiled_sql,
            distilled_params,
            elem,
            extracted_params,
            cache_hit=cache_hit,
        )

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1481:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b7d850>
dialect = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7fe2f3b85250>
constructor = <bound method DefaultExecutionContext._init_compiled of <class 'sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext'>>
statement = 'SELECT pk_index, a, b \nFROM (SELECT original_table_clause.w AS w, original_table_clause.x AS x, original_table_claus...S NULL AND b IS NULL)) AS anon_2 \nWHERE records_with_grouped_column_counts_subquery._num_rows >= ?\n LIMIT ? OFFSET ?'
parameters = (2, 20, 0), execution_options = immutabledict({})
args = (<sqlalchemy.dialects.sqlite.base.SQLiteCompiler object at 0x7fe2f85073a0>, [], <sqlalchemy.sql.selectable.Select obje...140612805360176 num_rows)s', 2, type_=Integer()), _OffsetLimitParam('%(140612805358544 param)s', 20, type_=Integer())])
kw = {'cache_hit': symbol('CACHE_MISS')}
branched = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b7d850>
conn = <sqlalchemy.pool.base._ConnectionFairy object at 0x7fe2f3524040>
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7fe2f8507280>
cursor = <sqlite3.Cursor object at 0x7fe2f84c0ce0>, evt_handled = False

    def _execute_context(
        self,
        dialect,
        constructor,
        statement,
        parameters,
        execution_options,
        *args,
        **kw
    ):
        """Create an :class:`.ExecutionContext` and execute, returning
        a :class:`_engine.CursorResult`."""

        branched = self
        if self.__branch_from:
            # if this is a "branched" connection, do everything in terms
            # of the "root" connection, *except* for .close(), which is
            # the only feature that branching provides
            self = self.__branch_from

        try:
            conn = self._dbapi_connection
            if conn is None:
                conn = self._revalidate_connection()

            context = constructor(
                dialect, self, conn, execution_options, *args, **kw
            )
        except (exc.PendingRollbackError, exc.ResourceClosedError):
            raise
        except BaseException as e:
            self._handle_dbapi_exception(
                e, util.text_type(statement), parameters, None, None
            )

        if (
            self._transaction
            and not self._transaction.is_active
            or (
                self._nested_transaction
                and not self._nested_transaction.is_active
            )
        ):
            self._invalid_transaction()

        elif self._trans_context_manager:
            TransactionalContext._trans_ctx_check(self)

        if self._is_future and self._transaction is None:
            self._autobegin()

        context.pre_exec()

        if dialect.use_setinputsizes:
            context._set_input_sizes()

        cursor, statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )

        if not context.executemany:
            parameters = parameters[0]

        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                statement, parameters = fn(
                    self,
                    cursor,
                    statement,
                    parameters,
                    context,
                    context.executemany,
                )

        if self._echo:

            self._log_info(statement)

            stats = context._get_cache_stats()

            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        parameters, batches=10, ismulti=context.executemany
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]"
                    % (stats,)
                )

        evt_handled = False
        try:
            if context.executemany:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(cursor, statement, parameters, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor, statement, parameters, context
                    )
            elif not parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, statement, context
                    )
            else:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(cursor, statement, parameters, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute(
                        cursor, statement, parameters, context
                    )

            if self._has_events or self.engine._has_events:
                self.dispatch.after_cursor_execute(
                    self,
                    cursor,
                    statement,
                    parameters,
                    context,
                    context.executemany,
                )

            context.post_exec()

            result = context._setup_result_proxy()

            if not self._is_future:
                should_close_with_result = branched.should_close_with_result

                if not result._soft_closed and should_close_with_result:
                    result._autoclose_connection = True

                if (
                    # usually we're in a transaction so avoid relatively
                    # expensive / legacy should_autocommit call
                    self._transaction is None
                    and context.should_autocommit
                ):
                    self._commit_impl(autocommit=True)

                # for "connectionless" execution, we have to close this
                # Connection after the statement is complete.
                # legacy stuff.
                if should_close_with_result and context._soft_closed:
                    assert not self._is_future

                    # CursorResult already exhausted rows / has no rows.
                    # close us now
                    branched.close()

        except BaseException as e:
>           self._handle_dbapi_exception(
                e, statement, parameters, cursor, context
            )

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1845:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b7d850>
e = OperationalError('ambiguous column name: pk_index')
statement = 'SELECT pk_index, a, b \nFROM (SELECT original_table_clause.w AS w, original_table_clause.x AS x, original_table_claus...S NULL AND b IS NULL)) AS anon_2 \nWHERE records_with_grouped_column_counts_subquery._num_rows >= ?\n LIMIT ? OFFSET ?'
parameters = (2, 20, 0), cursor = <sqlite3.Cursor object at 0x7fe2f84c0ce0>
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7fe2f8507280>

    def _handle_dbapi_exception(
        self, e, statement, parameters, cursor, context
    ):
        exc_info = sys.exc_info()

        is_exit_exception = util.is_exit_exception(e)

        if not self._is_disconnect:
            self._is_disconnect = (
                isinstance(e, self.dialect.dbapi.Error)
                and not self.closed
                and self.dialect.is_disconnect(
                    e,
                    self._dbapi_connection if not self.invalidated else None,
                    cursor,
                )
            ) or (is_exit_exception and not self.closed)

        invalidate_pool_on_disconnect = not is_exit_exception

        if self._reentrant_error:
            util.raise_(
                exc.DBAPIError.instance(
                    statement,
                    parameters,
                    e,
                    self.dialect.dbapi.Error,
                    hide_parameters=self.engine.hide_parameters,
                    dialect=self.dialect,
                    ismulti=context.executemany
                    if context is not None
                    else None,
                ),
                with_traceback=exc_info[2],
                from_=e,
            )
        self._reentrant_error = True
        try:
            # non-DBAPI error - if we already got a context,
            # or there's no string statement, don't wrap it
            should_wrap = isinstance(e, self.dialect.dbapi.Error) or (
                statement is not None
                and context is None
                and not is_exit_exception
            )

            if should_wrap:
                sqlalchemy_exception = exc.DBAPIError.instance(
                    statement,
                    parameters,
                    e,
                    self.dialect.dbapi.Error,
                    hide_parameters=self.engine.hide_parameters,
                    connection_invalidated=self._is_disconnect,
                    dialect=self.dialect,
                    ismulti=context.executemany
                    if context is not None
                    else None,
                )
            else:
                sqlalchemy_exception = None

            newraise = None

            if (
                self._has_events or self.engine._has_events
            ) and not self._execution_options.get(
                "skip_user_error_events", False
            ):
                ctx = ExceptionContextImpl(
                    e,
                    sqlalchemy_exception,
                    self.engine,
                    self,
                    cursor,
                    statement,
                    parameters,
                    context,
                    self._is_disconnect,
                    invalidate_pool_on_disconnect,
                )

                for fn in self.dispatch.handle_error:
                    try:
                        # handler returns an exception;
                        # call next handler in a chain
                        per_fn = fn(ctx)
                        if per_fn is not None:
                            ctx.chained_exception = newraise = per_fn
                    except Exception as _raised:
                        # handler raises an exception - stop processing
                        newraise = _raised
                        break

                if self._is_disconnect != ctx.is_disconnect:
                    self._is_disconnect = ctx.is_disconnect
                    if sqlalchemy_exception:
                        sqlalchemy_exception.connection_invalidated = (
                            ctx.is_disconnect
                        )

                # set up potentially user-defined value for
                # invalidate pool.
                invalidate_pool_on_disconnect = (
                    ctx.invalidate_pool_on_disconnect
                )

            if should_wrap and context:
                context.handle_dbapi_exception(e)

            if not self._is_disconnect:
                if cursor:
                    self._safe_close_cursor(cursor)
                with util.safe_reraise(warn_only=True):
                    self._autorollback()

            if newraise:
                util.raise_(newraise, with_traceback=exc_info[2], from_=e)
            elif should_wrap:
>               util.raise_(
                    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
                )

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/engine/base.py:2026:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

    def raise_(
        exception, with_traceback=None, replace_context=None, from_=False
    ):
        r"""implement "raise" with cause support.

        :param exception: exception to raise
        :param with_traceback: will call exception.with_traceback()
        :param replace_context: an as-yet-unsupported feature.  This is
         an exception object which we are "replacing", e.g., it's our
         "cause" but we don't want it printed.    Basically just what
         ``__suppress_context__`` does but we don't want to suppress
         the enclosing context, if any.  So for now we make it the
         cause.
        :param from\_: the cause.  this actually sets the cause and doesn't
         hope to hide it someday.

        """
        if with_traceback is not None:
            exception = exception.with_traceback(with_traceback)

        if from_ is not False:
            exception.__cause__ = from_
        elif replace_context is not None:
            # no good solution here, we would like to have the exception
            # have only the context of replace_context.__context__ so that the
            # intermediary exception does not change, but we can't figure
            # that out.
            exception.__cause__ = replace_context

        try:
>           raise exception

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/util/compat.py:207:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b7d850>
dialect = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7fe2f3b85250>
constructor = <bound method DefaultExecutionContext._init_compiled of <class 'sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext'>>
statement = 'SELECT pk_index, a, b \nFROM (SELECT original_table_clause.w AS w, original_table_clause.x AS x, original_table_claus...S NULL AND b IS NULL)) AS anon_2 \nWHERE records_with_grouped_column_counts_subquery._num_rows >= ?\n LIMIT ? OFFSET ?'
parameters = (2, 20, 0), execution_options = immutabledict({})
args = (<sqlalchemy.dialects.sqlite.base.SQLiteCompiler object at 0x7fe2f85073a0>, [], <sqlalchemy.sql.selectable.Select obje...140612805360176 num_rows)s', 2, type_=Integer()), _OffsetLimitParam('%(140612805358544 param)s', 20, type_=Integer())])
kw = {'cache_hit': symbol('CACHE_MISS')}
branched = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b7d850>
conn = <sqlalchemy.pool.base._ConnectionFairy object at 0x7fe2f3524040>
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7fe2f8507280>
cursor = <sqlite3.Cursor object at 0x7fe2f84c0ce0>, evt_handled = False

    def _execute_context(
        self,
        dialect,
        constructor,
        statement,
        parameters,
        execution_options,
        *args,
        **kw
    ):
        """Create an :class:`.ExecutionContext` and execute, returning
        a :class:`_engine.CursorResult`."""

        branched = self
        if self.__branch_from:
            # if this is a "branched" connection, do everything in terms
            # of the "root" connection, *except* for .close(), which is
            # the only feature that branching provides
            self = self.__branch_from

        try:
            conn = self._dbapi_connection
            if conn is None:
                conn = self._revalidate_connection()

            context = constructor(
                dialect, self, conn, execution_options, *args, **kw
            )
        except (exc.PendingRollbackError, exc.ResourceClosedError):
            raise
        except BaseException as e:
            self._handle_dbapi_exception(
                e, util.text_type(statement), parameters, None, None
            )

        if (
            self._transaction
            and not self._transaction.is_active
            or (
                self._nested_transaction
                and not self._nested_transaction.is_active
            )
        ):
            self._invalid_transaction()

        elif self._trans_context_manager:
            TransactionalContext._trans_ctx_check(self)

        if self._is_future and self._transaction is None:
            self._autobegin()

        context.pre_exec()

        if dialect.use_setinputsizes:
            context._set_input_sizes()

        cursor, statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )

        if not context.executemany:
            parameters = parameters[0]

        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                statement, parameters = fn(
                    self,
                    cursor,
                    statement,
                    parameters,
                    context,
                    context.executemany,
                )

        if self._echo:

            self._log_info(statement)

            stats = context._get_cache_stats()

            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        parameters, batches=10, ismulti=context.executemany
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]"
                    % (stats,)
                )

        evt_handled = False
        try:
            if context.executemany:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(cursor, statement, parameters, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor, statement, parameters, context
                    )
            elif not parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, statement, context
                    )
            else:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(cursor, statement, parameters, context):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, statement, parameters, context
                    )

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1802:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7fe2f3b85250>
cursor = <sqlite3.Cursor object at 0x7fe2f84c0ce0>
statement = 'SELECT pk_index, a, b \nFROM (SELECT original_table_clause.w AS w, original_table_clause.x AS x, original_table_claus...S NULL AND b IS NULL)) AS anon_2 \nWHERE records_with_grouped_column_counts_subquery._num_rows >= ?\n LIMIT ? OFFSET ?'
parameters = (2, 20, 0)
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7fe2f8507280>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) ambiguous column name: pk_index
E       [SQL: SELECT pk_index, a, b
E       FROM (SELECT original_table_clause.w AS w, original_table_clause.x AS x, original_table_clause.y AS y, original_table_clause.z AS z, original_table_clause.a AS a, original_table_clause.b AS b, original_table_clause.pk_index AS pk_index, group_counts_subquery._num_rows AS _num_rows
E       FROM (SELECT w, x, y, z, a, b, pk_index
E       FROM (SELECT *
E       FROM test_data_uzirh4kl
E       WHERE NOT (a IS NULL AND b IS NULL)) AS anon_1) AS original_table_clause JOIN (SELECT a, b, count(*) AS _num_rows
E       FROM (SELECT w, x, y, z, a, b, pk_index
E       FROM (SELECT *
E       FROM test_data_uzirh4kl
E       WHERE NOT (a IS NULL AND b IS NULL)) AS anon_1) AS original_table_clause GROUP BY a, b) AS group_counts_subquery ON group_counts_subquery.a = original_table_clause.a AND group_counts_subquery.b = original_table_clause.b) AS records_with_grouped_column_counts_subquery, (SELECT *
E       FROM test_data_uzirh4kl
E       WHERE NOT (a IS NULL AND b IS NULL)) AS anon_2
E       WHERE records_with_grouped_column_counts_subquery._num_rows >= ?
E        LIMIT ? OFFSET ?]
E       [parameters: (2, 20, 0)]
E       (Background on this error at: https://sqlalche.me/e/14/e3q8)

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/engine/default.py:719: OperationalError

The above exception was the direct cause of the following exception:

test_case = {'expectation_type': 'expect_compound_columns_to_be_unique', 'pk_column': True, 'skip': False, 'test': {'exact_match_o...0, 'b': 2.0}, {'a': 1.0, 'b': 1.0}, {'a': 1.0, 'b': 2.0}, {'a': 1.0, 'b': 1.0}, {'a': 2.0, 'b': 2.0}, ...]}, ...}, ...}

    @pytest.mark.order(index=0)
    @pytest.mark.integration
    @pytest.mark.slow  # 12.68s
    def test_case_runner_v3_api(test_case):
        if test_case["skip"]:
            pytest.skip()

        # Note: this should never be done in practice, but we are wiping expectations to reuse batches during testing.
        # test_case["batch"]._initialize_expectations()
        if "parse_strings_as_datetimes" in test_case["test"]["in"]:
            with pytest.deprecated_call():
                evaluate_json_test_v3_api(
                    validator=test_case["validator_with_data"],
                    expectation_type=test_case["expectation_type"],
                    test=test_case["test"],
                    pk_column=test_case["pk_column"],
                )
        else:
>           evaluate_json_test_v3_api(
                validator=test_case["validator_with_data"],
                expectation_type=test_case["expectation_type"],
                test=test_case["test"],
                pk_column=test_case["pk_column"],
            )

tests/test_definitions/test_expectations_v3_api.py:428:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
great_expectations/self_check/util.py:2887: in evaluate_json_test_v3_api
    result = getattr(validator, expectation_type)(**runtime_kwargs)
great_expectations/validator/validator.py:595: in inst_expectation
    raise err
great_expectations/validator/validator.py:558: in inst_expectation
    validation_result = expectation.validate(
great_expectations/expectations/expectation.py:1265: in validate
    ] = validator.graph_validate(
great_expectations/validator/validator.py:1046: in graph_validate
    raise err
great_expectations/validator/validator.py:1025: in graph_validate
    ) = self._resolve_suite_level_graph_and_process_metric_evaluation_errors(
great_expectations/validator/validator.py:1184: in _resolve_suite_level_graph_and_process_metric_evaluation_errors
    ) = self._metrics_calculator.resolve_validation_graph(
great_expectations/validator/metrics_calculator.py:282: in resolve_validation_graph
    resolved_metrics, aborted_metrics_info = graph.resolve(
great_expectations/validator/validation_graph.py:196: in resolve
    ] = self._resolve(
great_expectations/validator/validation_graph.py:302: in _resolve
    raise err
great_expectations/validator/validation_graph.py:272: in _resolve
    self._execution_engine.resolve_metrics(
great_expectations/execution_engine/execution_engine.py:375: in resolve_metrics
    return self._process_direct_and_bundled_metric_computation_configurations(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <great_expectations.execution_engine.sqlalchemy_execution_engine.SqlAlchemyExecutionEngine object at 0x7fe2f3b9e2b0>
metric_fn_direct_configurations = [MetricComputationConfiguration(metric_configuration={
  "metric_name": "compound_columns.unique.unexpected_index_list...l_unexpected_count': 20, 'include_unexpected_rows': False}}}, compute_domain_kwargs=None, accessor_domain_kwargs=None)]
metric_fn_bundle_configurations = []

    def _process_direct_and_bundled_metric_computation_configurations(
        self,
        metric_fn_direct_configurations: List[MetricComputationConfiguration],
        metric_fn_bundle_configurations: List[MetricComputationConfiguration],
    ) -> Dict[Tuple[str, str, str], MetricValue]:
        """
        This method processes directly-computable and bundled "MetricComputationConfiguration" objects.

        Args:
            metric_fn_direct_configurations: directly-computable "MetricComputationConfiguration" objects
            metric_fn_bundle_configurations: bundled "MetricComputationConfiguration" objects (column aggregates)

        Returns:
            resolved_metrics (Dict): a dictionary with the values for the metrics that have just been resolved.
        """
        resolved_metrics: Dict[Tuple[str, str, str], MetricValue] = {}

        metric_computation_configuration: MetricComputationConfiguration

        for metric_computation_configuration in metric_fn_direct_configurations:
            try:
                resolved_metrics[
                    metric_computation_configuration.metric_configuration.id
                ] = metric_computation_configuration.metric_fn(
                    **metric_computation_configuration.metric_provider_kwargs
                )
            except Exception as e:
>               raise gx_exceptions.MetricResolutionError(
                    message=str(e),
                    failed_metrics=(
                        metric_computation_configuration.metric_configuration,
                    ),
                ) from e
E               great_expectations.exceptions.exceptions.MetricResolutionError: (sqlite3.OperationalError) ambiguous column name: pk_index
E               [SQL: SELECT pk_index, a, b
E               FROM (SELECT original_table_clause.w AS w, original_table_clause.x AS x, original_table_clause.y AS y, original_table_clause.z AS z, original_table_clause.a AS a, original_table_clause.b AS b, original_table_clause.pk_index AS pk_index, group_counts_subquery._num_rows AS _num_rows
E               FROM (SELECT w, x, y, z, a, b, pk_index
E               FROM (SELECT *
E               FROM test_data_uzirh4kl
E               WHERE NOT (a IS NULL AND b IS NULL)) AS anon_1) AS original_table_clause JOIN (SELECT a, b, count(*) AS _num_rows
E               FROM (SELECT w, x, y, z, a, b, pk_index
E               FROM (SELECT *
E               FROM test_data_uzirh4kl
E               WHERE NOT (a IS NULL AND b IS NULL)) AS anon_1) AS original_table_clause GROUP BY a, b) AS group_counts_subquery ON group_counts_subquery.a = original_table_clause.a AND group_counts_subquery.b = original_table_clause.b) AS records_with_grouped_column_counts_subquery, (SELECT *
E               FROM test_data_uzirh4kl
E               WHERE NOT (a IS NULL AND b IS NULL)) AS anon_2
E               WHERE records_with_grouped_column_counts_subquery._num_rows >= ?
E                LIMIT ? OFFSET ?]
E               [parameters: (2, 20, 0)]
E               (Background on this error at: https://sqlalche.me/e/14/e3q8)

great_expectations/execution_engine/execution_engine.py:654: MetricResolutionError
----------------------------- Captured stderr call -----------------------------


Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s][A[A

Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s][A[A

Calculating Metrics:  18%|        | 2/11 [00:00<00:00, 2074.33it/s][A[A

Calculating Metrics:  18%|        | 2/11 [00:00<00:00, 271.06it/s] [A[A

Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 451.36it/s][A[A

Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 263.95it/s][A[A

Calculating Metrics:  45%|     | 5/11 [00:00<00:00, 297.81it/s][A[A

Calculating Metrics:  45%|     | 5/11 [00:00<00:00, 227.59it/s][A[A

Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 257.12it/s][A[A

Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 215.97it/s][A[A
--------------------------- Captured stderr teardown ---------------------------
Calculating Metrics:  55%|    | 6/11 [00:02<00:01,  2.80it/s]
Calculating Metrics:  55%|    | 6/11 [00:00<00:00,  6.47it/s]
_ test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_compound_columns_to_be_unique:unexpected_values_exact_match_out_with_unexpected_index_list_pandas_v3] _

self = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b7d850>
dialect = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7fe2f3b85250>
constructor = <bound method DefaultExecutionContext._init_compiled of <class 'sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext'>>
statement = 'SELECT pk_index, a, b \nFROM (SELECT original_table_clause.w AS w, original_table_clause.x AS x, original_table_claus...S NULL AND b IS NULL)) AS anon_2 \nWHERE records_with_grouped_column_counts_subquery._num_rows >= ?\n LIMIT ? OFFSET ?'
parameters = (2, 20, 0), execution_options = immutabledict({})
args = (<sqlalchemy.dialects.sqlite.base.SQLiteCompiler object at 0x7fe2f85073a0>, [], <sqlalchemy.sql.selectable.Select obje...140612822139184 num_rows)s', 2, type_=Integer()), _OffsetLimitParam('%(140612822281520 param)s', 20, type_=Integer())])
kw = {'cache_hit': symbol('CACHE_HIT')}
branched = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b7d850>
conn = <sqlalchemy.pool.base._ConnectionFairy object at 0x7fe2f3524040>
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7fe2f952a940>
cursor = <sqlite3.Cursor object at 0x7fe2f84fe030>, evt_handled = False

    def _execute_context(
        self,
        dialect,
        constructor,
        statement,
        parameters,
        execution_options,
        *args,
        **kw
    ):
        """Create an :class:`.ExecutionContext` and execute, returning
        a :class:`_engine.CursorResult`."""

        branched = self
        if self.__branch_from:
            # if this is a "branched" connection, do everything in terms
            # of the "root" connection, *except* for .close(), which is
            # the only feature that branching provides
            self = self.__branch_from

        try:
            conn = self._dbapi_connection
            if conn is None:
                conn = self._revalidate_connection()

            context = constructor(
                dialect, self, conn, execution_options, *args, **kw
            )
        except (exc.PendingRollbackError, exc.ResourceClosedError):
            raise
        except BaseException as e:
            self._handle_dbapi_exception(
                e, util.text_type(statement), parameters, None, None
            )

        if (
            self._transaction
            and not self._transaction.is_active
            or (
                self._nested_transaction
                and not self._nested_transaction.is_active
            )
        ):
            self._invalid_transaction()

        elif self._trans_context_manager:
            TransactionalContext._trans_ctx_check(self)

        if self._is_future and self._transaction is None:
            self._autobegin()

        context.pre_exec()

        if dialect.use_setinputsizes:
            context._set_input_sizes()

        cursor, statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )

        if not context.executemany:
            parameters = parameters[0]

        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                statement, parameters = fn(
                    self,
                    cursor,
                    statement,
                    parameters,
                    context,
                    context.executemany,
                )

        if self._echo:

            self._log_info(statement)

            stats = context._get_cache_stats()

            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        parameters, batches=10, ismulti=context.executemany
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]"
                    % (stats,)
                )

        evt_handled = False
        try:
            if context.executemany:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(cursor, statement, parameters, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor, statement, parameters, context
                    )
            elif not parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, statement, context
                    )
            else:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(cursor, statement, parameters, context):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, statement, parameters, context
                    )

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1802:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7fe2f3b85250>
cursor = <sqlite3.Cursor object at 0x7fe2f84fe030>
statement = 'SELECT pk_index, a, b \nFROM (SELECT original_table_clause.w AS w, original_table_clause.x AS x, original_table_claus...S NULL AND b IS NULL)) AS anon_2 \nWHERE records_with_grouped_column_counts_subquery._num_rows >= ?\n LIMIT ? OFFSET ?'
parameters = (2, 20, 0)
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7fe2f952a940>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlite3.OperationalError: ambiguous column name: pk_index

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/engine/default.py:719: OperationalError

The above exception was the direct cause of the following exception:

self = <great_expectations.execution_engine.sqlalchemy_execution_engine.SqlAlchemyExecutionEngine object at 0x7fe2f3b9e2b0>
metric_fn_direct_configurations = [MetricComputationConfiguration(metric_configuration={
  "metric_name": "compound_columns.unique.filtered_row_count",
...l_unexpected_count': 20, 'include_unexpected_rows': False}}}, compute_domain_kwargs=None, accessor_domain_kwargs=None)]
metric_fn_bundle_configurations = []

    def _process_direct_and_bundled_metric_computation_configurations(
        self,
        metric_fn_direct_configurations: List[MetricComputationConfiguration],
        metric_fn_bundle_configurations: List[MetricComputationConfiguration],
    ) -> Dict[Tuple[str, str, str], MetricValue]:
        """
        This method processes directly-computable and bundled "MetricComputationConfiguration" objects.

        Args:
            metric_fn_direct_configurations: directly-computable "MetricComputationConfiguration" objects
            metric_fn_bundle_configurations: bundled "MetricComputationConfiguration" objects (column aggregates)

        Returns:
            resolved_metrics (Dict): a dictionary with the values for the metrics that have just been resolved.
        """
        resolved_metrics: Dict[Tuple[str, str, str], MetricValue] = {}

        metric_computation_configuration: MetricComputationConfiguration

        for metric_computation_configuration in metric_fn_direct_configurations:
            try:
                resolved_metrics[
                    metric_computation_configuration.metric_configuration.id
>               ] = metric_computation_configuration.metric_fn(
                    **metric_computation_configuration.metric_provider_kwargs
                )

great_expectations/execution_engine/execution_engine.py:650:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

cls = <class 'great_expectations.expectations.metrics.multicolumn_map_metrics.compound_columns_unique.CompoundColumnsUnique'>
execution_engine = <great_expectations.execution_engine.sqlalchemy_execution_engine.SqlAlchemyExecutionEngine object at 0x7fe2f3b9e2b0>
metric_domain_kwargs = {'batch_id': 'b1ae3225b6aa3d6c44dce474d8b4e741', 'table': None, 'column_list': ['a', 'b'], 'row_condition': None, 'condition_parser': None, 'ignore_row_if': 'all_values_are_missing'}
metric_value_kwargs = {'result_format': {'result_format': 'COMPLETE', 'unexpected_index_column_names': ['pk_index'], 'partial_unexpected_count': 20, 'include_unexpected_rows': False}}
metrics = {'table.column_types': [{'autoincrement': 'auto', 'default': None, 'name': 'w', 'nullable': True, ...}, {'autoincremen...w_condition': None, 'condition_parser': None, 'ignore_row_if': 'all_values_are_missing'}, {'column_list': ['a', 'b']})}
kwargs = {'runtime_configuration': {'catch_exceptions': False, 'include_config': False, 'result_format': {'include_unexpected_rows': False, 'partial_unexpected_count': 20, 'result_format': 'COMPLETE', 'unexpected_index_column_names': ['pk_index']}}}
unexpected_condition = <sqlalchemy.sql.elements.BinaryExpression object at 0x7fe2f9508460>
compute_domain_kwargs = {'batch_id': 'b1ae3225b6aa3d6c44dce474d8b4e741', 'table': None, 'row_condition': None, 'condition_parser': None, 'ignore_row_if': 'all_values_are_missing'}
accessor_domain_kwargs = {'column_list': ['a', 'b']}
domain_column_name_list = ['a', 'b'], column_name = 'b'
column_list = ['a', 'b']
domain_kwargs = {'batch_id': 'b1ae3225b6aa3d6c44dce474d8b4e741', 'column_list': ['a', 'b'], 'condition_parser': None, 'ignore_row_if': 'all_values_are_missing', ...}

    def _sqlalchemy_map_condition_index(
        cls,
        execution_engine: SqlAlchemyExecutionEngine,
        metric_domain_kwargs: Dict,
        metric_value_kwargs: Dict,
        metrics: Dict[str, Any],
        **kwargs,
    ) -> List[Dict[str, Any]]:
        """
        Returns indices of the metric values which do not meet an expected Expectation condition for instances
        of ColumnMapExpectation.

        Requires `unexpected_index_column_names` to be part of `result_format` dict to specify primary_key columns
        to return.
        """
        (
            unexpected_condition,
            compute_domain_kwargs,
            accessor_domain_kwargs,
        ) = metrics.get("unexpected_condition")

        domain_column_name_list: List[str] = list()
        # column map expectations
        if "column" in accessor_domain_kwargs:
            column_name: Union[str, quoted_name] = accessor_domain_kwargs["column"]
            domain_column_name_list.append(column_name)
        # multi-column map expectations
        elif "column_list" in accessor_domain_kwargs:
            column_list: List[Union[str, quoted_name]] = accessor_domain_kwargs[
                "column_list"
            ]
            domain_column_name_list = column_list
        # column-map expectations
        elif "column_A" in accessor_domain_kwargs and "column_B" in accessor_domain_kwargs:
            column_list: List[Union[str, quoted_name]] = list()
            column_list.append(accessor_domain_kwargs["column_A"])
            column_list.append(accessor_domain_kwargs["column_B"])
            domain_column_name_list = column_list

        domain_kwargs: dict = dict(**compute_domain_kwargs, **accessor_domain_kwargs)
        result_format: dict = metric_value_kwargs["result_format"]

        all_table_columns: List[str] = metrics.get("table.columns")

        unexpected_index_column_names: Optional[List[str]] = result_format.get(
            "unexpected_index_column_names"
        )

        column_selector: List[sa.Column] = []
        for column_name in unexpected_index_column_names:
            if column_name not in all_table_columns:
                raise gx_exceptions.InvalidMetricAccessorDomainKwargsKeyError(
                    message=f'Error: The unexpected_index_column: "{column_name}" in does not exist in SQL Table. '
                    f"Please check your configuration and try again."
                )
            column_selector.append(sa.column(column_name))

        # expectation_domain_column_name: str = domain_kwargs["column"]

        # the last column we SELECT is the column the Expectation is being run on
        for column_name in domain_column_name_list:
            column_selector.append(sa.column(column_name))

        domain_records_as_selectable: sa.sql.Selectable = (
            execution_engine.get_domain_records(domain_kwargs=domain_kwargs)
        )
        unexpected_condition_query_with_selected_columns: sa.select = sa.select(
            column_selector
        ).where(unexpected_condition)

        if not MapMetricProvider.is_sqlalchemy_metric_selectable(map_metric_provider=cls):
            domain_records_as_selectable: Union[
                sa.Table, sa.Select
            ] = get_sqlalchemy_selectable(domain_records_as_selectable)

        # since SQL tables can be **very** large, truncate query_result values at 20, or at `partial_unexpected_count`
        final_query: sa.select = (
            unexpected_condition_query_with_selected_columns.select_from(
                domain_records_as_selectable
            ).limit(result_format["partial_unexpected_count"])
        )
>       query_result: List[tuple] = execution_engine.engine.execute(final_query).fetchall()

great_expectations/expectations/metrics/map_metric_provider.py:2662:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b7d850>
statement = <sqlalchemy.sql.selectable.Select object at 0x7fe2f952abb0>
multiparams = (), params = {}
meth = <bound method ClauseElement._execute_on_connection of <sqlalchemy.sql.selectable.Select object at 0x7fe2f952abb0>>

    def execute(self, statement, *multiparams, **params):
        r"""Executes a SQL statement construct and returns a
        :class:`_engine.CursorResult`.

        :param statement: The statement to be executed.  May be
         one of:

         * a plain string (deprecated)
         * any :class:`_expression.ClauseElement` construct that is also
           a subclass of :class:`.Executable`, such as a
           :func:`_expression.select` construct
         * a :class:`.FunctionElement`, such as that generated
           by :data:`.func`, will be automatically wrapped in
           a SELECT statement, which is then executed.
         * a :class:`.DDLElement` object
         * a :class:`.DefaultGenerator` object
         * a :class:`.Compiled` object

         .. deprecated:: 2.0 passing a string to
            :meth:`_engine.Connection.execute` is
            deprecated and will be removed in version 2.0.  Use the
            :func:`_expression.text` construct with
            :meth:`_engine.Connection.execute`, or the
            :meth:`_engine.Connection.exec_driver_sql`
            method to invoke a driver-level
            SQL string.

        :param \*multiparams/\**params: represent bound parameter
         values to be used in the execution.   Typically,
         the format is either a collection of one or more
         dictionaries passed to \*multiparams::

             conn.execute(
                 table.insert(),
                 {"id":1, "value":"v1"},
                 {"id":2, "value":"v2"}
             )

         ...or individual key/values interpreted by \**params::

             conn.execute(
                 table.insert(), id=1, value="v1"
             )

         In the case that a plain SQL string is passed, and the underlying
         DBAPI accepts positional bind parameters, a collection of tuples
         or individual values in \*multiparams may be passed::

             conn.execute(
                 "INSERT INTO table (id, value) VALUES (?, ?)",
                 (1, "v1"), (2, "v2")
             )

             conn.execute(
                 "INSERT INTO table (id, value) VALUES (?, ?)",
                 1, "v1"
             )

         Note above, the usage of a question mark "?" or other
         symbol is contingent upon the "paramstyle" accepted by the DBAPI
         in use, which may be any of "qmark", "named", "pyformat", "format",
         "numeric".   See `pep-249
         <https://www.python.org/dev/peps/pep-0249/>`_ for details on
         paramstyle.

         To execute a textual SQL statement which uses bound parameters in a
         DBAPI-agnostic way, use the :func:`_expression.text` construct.

         .. deprecated:: 2.0 use of tuple or scalar positional parameters
            is deprecated. All params should be dicts or sequences of dicts.
            Use :meth:`.exec_driver_sql` to execute a plain string with
            tuple or scalar positional parameters.

        """

        if isinstance(statement, util.string_types):
            util.warn_deprecated_20(
                "Passing a string to Connection.execute() is "
                "deprecated and will be removed in version 2.0.  Use the "
                "text() construct, "
                "or the Connection.exec_driver_sql() method to invoke a "
                "driver-level SQL string."
            )

            return self._exec_driver_sql(
                statement,
                multiparams,
                params,
                _EMPTY_EXECUTION_OPTS,
                future=False,
            )

        try:
            meth = statement._execute_on_connection
        except AttributeError as err:
            util.raise_(
                exc.ObjectNotExecutableError(statement), replace_context=err
            )
        else:
>           return meth(self, multiparams, params, _EMPTY_EXECUTION_OPTS)

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1289:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.sql.selectable.Select object at 0x7fe2f952abb0>
connection = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b7d850>
multiparams = (), params = {}, execution_options = immutabledict({})
_force = False

    def _execute_on_connection(
        self, connection, multiparams, params, execution_options, _force=False
    ):
        if _force or self.supports_execution:
>           return connection._execute_clauseelement(
                self, multiparams, params, execution_options
            )

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/sql/elements.py:325:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b7d850>
elem = <sqlalchemy.sql.selectable.Select object at 0x7fe2f952abb0>
multiparams = (), params = {}, execution_options = immutabledict({})

    def _execute_clauseelement(
        self, elem, multiparams, params, execution_options
    ):
        """Execute a sql.ClauseElement object."""

        execution_options = elem._execution_options.merge_with(
            self._execution_options, execution_options
        )

        distilled_params = _distill_params(self, multiparams, params)

        has_events = self._has_events or self.engine._has_events
        if has_events:
            (
                elem,
                distilled_params,
                event_multiparams,
                event_params,
            ) = self._invoke_before_exec_event(
                elem, distilled_params, execution_options
            )

        if distilled_params:
            # ensure we don't retain a link to the view object for keys()
            # which links to the values, which we don't want to cache
            keys = sorted(distilled_params[0])
            for_executemany = len(distilled_params) > 1
        else:
            keys = []
            for_executemany = False

        dialect = self.dialect

        schema_translate_map = execution_options.get(
            "schema_translate_map", None
        )

        compiled_cache = execution_options.get(
            "compiled_cache", self.engine._compiled_cache
        )

        compiled_sql, extracted_params, cache_hit = elem._compile_w_cache(
            dialect=dialect,
            compiled_cache=compiled_cache,
            column_keys=keys,
            for_executemany=for_executemany,
            schema_translate_map=schema_translate_map,
            linting=self.dialect.compiler_linting | compiler.WARN_LINTING,
        )
>       ret = self._execute_context(
            dialect,
            dialect.execution_ctx_cls._init_compiled,
            compiled_sql,
            distilled_params,
            execution_options,
            compiled_sql,
            distilled_params,
            elem,
            extracted_params,
            cache_hit=cache_hit,
        )

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1481:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b7d850>
dialect = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7fe2f3b85250>
constructor = <bound method DefaultExecutionContext._init_compiled of <class 'sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext'>>
statement = 'SELECT pk_index, a, b \nFROM (SELECT original_table_clause.w AS w, original_table_clause.x AS x, original_table_claus...S NULL AND b IS NULL)) AS anon_2 \nWHERE records_with_grouped_column_counts_subquery._num_rows >= ?\n LIMIT ? OFFSET ?'
parameters = (2, 20, 0), execution_options = immutabledict({})
args = (<sqlalchemy.dialects.sqlite.base.SQLiteCompiler object at 0x7fe2f85073a0>, [], <sqlalchemy.sql.selectable.Select obje...140612822139184 num_rows)s', 2, type_=Integer()), _OffsetLimitParam('%(140612822281520 param)s', 20, type_=Integer())])
kw = {'cache_hit': symbol('CACHE_HIT')}
branched = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b7d850>
conn = <sqlalchemy.pool.base._ConnectionFairy object at 0x7fe2f3524040>
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7fe2f952a940>
cursor = <sqlite3.Cursor object at 0x7fe2f84fe030>, evt_handled = False

    def _execute_context(
        self,
        dialect,
        constructor,
        statement,
        parameters,
        execution_options,
        *args,
        **kw
    ):
        """Create an :class:`.ExecutionContext` and execute, returning
        a :class:`_engine.CursorResult`."""

        branched = self
        if self.__branch_from:
            # if this is a "branched" connection, do everything in terms
            # of the "root" connection, *except* for .close(), which is
            # the only feature that branching provides
            self = self.__branch_from

        try:
            conn = self._dbapi_connection
            if conn is None:
                conn = self._revalidate_connection()

            context = constructor(
                dialect, self, conn, execution_options, *args, **kw
            )
        except (exc.PendingRollbackError, exc.ResourceClosedError):
            raise
        except BaseException as e:
            self._handle_dbapi_exception(
                e, util.text_type(statement), parameters, None, None
            )

        if (
            self._transaction
            and not self._transaction.is_active
            or (
                self._nested_transaction
                and not self._nested_transaction.is_active
            )
        ):
            self._invalid_transaction()

        elif self._trans_context_manager:
            TransactionalContext._trans_ctx_check(self)

        if self._is_future and self._transaction is None:
            self._autobegin()

        context.pre_exec()

        if dialect.use_setinputsizes:
            context._set_input_sizes()

        cursor, statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )

        if not context.executemany:
            parameters = parameters[0]

        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                statement, parameters = fn(
                    self,
                    cursor,
                    statement,
                    parameters,
                    context,
                    context.executemany,
                )

        if self._echo:

            self._log_info(statement)

            stats = context._get_cache_stats()

            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        parameters, batches=10, ismulti=context.executemany
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]"
                    % (stats,)
                )

        evt_handled = False
        try:
            if context.executemany:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(cursor, statement, parameters, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor, statement, parameters, context
                    )
            elif not parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, statement, context
                    )
            else:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(cursor, statement, parameters, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute(
                        cursor, statement, parameters, context
                    )

            if self._has_events or self.engine._has_events:
                self.dispatch.after_cursor_execute(
                    self,
                    cursor,
                    statement,
                    parameters,
                    context,
                    context.executemany,
                )

            context.post_exec()

            result = context._setup_result_proxy()

            if not self._is_future:
                should_close_with_result = branched.should_close_with_result

                if not result._soft_closed and should_close_with_result:
                    result._autoclose_connection = True

                if (
                    # usually we're in a transaction so avoid relatively
                    # expensive / legacy should_autocommit call
                    self._transaction is None
                    and context.should_autocommit
                ):
                    self._commit_impl(autocommit=True)

                # for "connectionless" execution, we have to close this
                # Connection after the statement is complete.
                # legacy stuff.
                if should_close_with_result and context._soft_closed:
                    assert not self._is_future

                    # CursorResult already exhausted rows / has no rows.
                    # close us now
                    branched.close()

        except BaseException as e:
>           self._handle_dbapi_exception(
                e, statement, parameters, cursor, context
            )

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1845:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b7d850>
e = OperationalError('ambiguous column name: pk_index')
statement = 'SELECT pk_index, a, b \nFROM (SELECT original_table_clause.w AS w, original_table_clause.x AS x, original_table_claus...S NULL AND b IS NULL)) AS anon_2 \nWHERE records_with_grouped_column_counts_subquery._num_rows >= ?\n LIMIT ? OFFSET ?'
parameters = (2, 20, 0), cursor = <sqlite3.Cursor object at 0x7fe2f84fe030>
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7fe2f952a940>

    def _handle_dbapi_exception(
        self, e, statement, parameters, cursor, context
    ):
        exc_info = sys.exc_info()

        is_exit_exception = util.is_exit_exception(e)

        if not self._is_disconnect:
            self._is_disconnect = (
                isinstance(e, self.dialect.dbapi.Error)
                and not self.closed
                and self.dialect.is_disconnect(
                    e,
                    self._dbapi_connection if not self.invalidated else None,
                    cursor,
                )
            ) or (is_exit_exception and not self.closed)

        invalidate_pool_on_disconnect = not is_exit_exception

        if self._reentrant_error:
            util.raise_(
                exc.DBAPIError.instance(
                    statement,
                    parameters,
                    e,
                    self.dialect.dbapi.Error,
                    hide_parameters=self.engine.hide_parameters,
                    dialect=self.dialect,
                    ismulti=context.executemany
                    if context is not None
                    else None,
                ),
                with_traceback=exc_info[2],
                from_=e,
            )
        self._reentrant_error = True
        try:
            # non-DBAPI error - if we already got a context,
            # or there's no string statement, don't wrap it
            should_wrap = isinstance(e, self.dialect.dbapi.Error) or (
                statement is not None
                and context is None
                and not is_exit_exception
            )

            if should_wrap:
                sqlalchemy_exception = exc.DBAPIError.instance(
                    statement,
                    parameters,
                    e,
                    self.dialect.dbapi.Error,
                    hide_parameters=self.engine.hide_parameters,
                    connection_invalidated=self._is_disconnect,
                    dialect=self.dialect,
                    ismulti=context.executemany
                    if context is not None
                    else None,
                )
            else:
                sqlalchemy_exception = None

            newraise = None

            if (
                self._has_events or self.engine._has_events
            ) and not self._execution_options.get(
                "skip_user_error_events", False
            ):
                ctx = ExceptionContextImpl(
                    e,
                    sqlalchemy_exception,
                    self.engine,
                    self,
                    cursor,
                    statement,
                    parameters,
                    context,
                    self._is_disconnect,
                    invalidate_pool_on_disconnect,
                )

                for fn in self.dispatch.handle_error:
                    try:
                        # handler returns an exception;
                        # call next handler in a chain
                        per_fn = fn(ctx)
                        if per_fn is not None:
                            ctx.chained_exception = newraise = per_fn
                    except Exception as _raised:
                        # handler raises an exception - stop processing
                        newraise = _raised
                        break

                if self._is_disconnect != ctx.is_disconnect:
                    self._is_disconnect = ctx.is_disconnect
                    if sqlalchemy_exception:
                        sqlalchemy_exception.connection_invalidated = (
                            ctx.is_disconnect
                        )

                # set up potentially user-defined value for
                # invalidate pool.
                invalidate_pool_on_disconnect = (
                    ctx.invalidate_pool_on_disconnect
                )

            if should_wrap and context:
                context.handle_dbapi_exception(e)

            if not self._is_disconnect:
                if cursor:
                    self._safe_close_cursor(cursor)
                with util.safe_reraise(warn_only=True):
                    self._autorollback()

            if newraise:
                util.raise_(newraise, with_traceback=exc_info[2], from_=e)
            elif should_wrap:
>               util.raise_(
                    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
                )

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/engine/base.py:2026:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

    def raise_(
        exception, with_traceback=None, replace_context=None, from_=False
    ):
        r"""implement "raise" with cause support.

        :param exception: exception to raise
        :param with_traceback: will call exception.with_traceback()
        :param replace_context: an as-yet-unsupported feature.  This is
         an exception object which we are "replacing", e.g., it's our
         "cause" but we don't want it printed.    Basically just what
         ``__suppress_context__`` does but we don't want to suppress
         the enclosing context, if any.  So for now we make it the
         cause.
        :param from\_: the cause.  this actually sets the cause and doesn't
         hope to hide it someday.

        """
        if with_traceback is not None:
            exception = exception.with_traceback(with_traceback)

        if from_ is not False:
            exception.__cause__ = from_
        elif replace_context is not None:
            # no good solution here, we would like to have the exception
            # have only the context of replace_context.__context__ so that the
            # intermediary exception does not change, but we can't figure
            # that out.
            exception.__cause__ = replace_context

        try:
>           raise exception

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/util/compat.py:207:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b7d850>
dialect = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7fe2f3b85250>
constructor = <bound method DefaultExecutionContext._init_compiled of <class 'sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext'>>
statement = 'SELECT pk_index, a, b \nFROM (SELECT original_table_clause.w AS w, original_table_clause.x AS x, original_table_claus...S NULL AND b IS NULL)) AS anon_2 \nWHERE records_with_grouped_column_counts_subquery._num_rows >= ?\n LIMIT ? OFFSET ?'
parameters = (2, 20, 0), execution_options = immutabledict({})
args = (<sqlalchemy.dialects.sqlite.base.SQLiteCompiler object at 0x7fe2f85073a0>, [], <sqlalchemy.sql.selectable.Select obje...140612822139184 num_rows)s', 2, type_=Integer()), _OffsetLimitParam('%(140612822281520 param)s', 20, type_=Integer())])
kw = {'cache_hit': symbol('CACHE_HIT')}
branched = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b7d850>
conn = <sqlalchemy.pool.base._ConnectionFairy object at 0x7fe2f3524040>
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7fe2f952a940>
cursor = <sqlite3.Cursor object at 0x7fe2f84fe030>, evt_handled = False

    def _execute_context(
        self,
        dialect,
        constructor,
        statement,
        parameters,
        execution_options,
        *args,
        **kw
    ):
        """Create an :class:`.ExecutionContext` and execute, returning
        a :class:`_engine.CursorResult`."""

        branched = self
        if self.__branch_from:
            # if this is a "branched" connection, do everything in terms
            # of the "root" connection, *except* for .close(), which is
            # the only feature that branching provides
            self = self.__branch_from

        try:
            conn = self._dbapi_connection
            if conn is None:
                conn = self._revalidate_connection()

            context = constructor(
                dialect, self, conn, execution_options, *args, **kw
            )
        except (exc.PendingRollbackError, exc.ResourceClosedError):
            raise
        except BaseException as e:
            self._handle_dbapi_exception(
                e, util.text_type(statement), parameters, None, None
            )

        if (
            self._transaction
            and not self._transaction.is_active
            or (
                self._nested_transaction
                and not self._nested_transaction.is_active
            )
        ):
            self._invalid_transaction()

        elif self._trans_context_manager:
            TransactionalContext._trans_ctx_check(self)

        if self._is_future and self._transaction is None:
            self._autobegin()

        context.pre_exec()

        if dialect.use_setinputsizes:
            context._set_input_sizes()

        cursor, statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )

        if not context.executemany:
            parameters = parameters[0]

        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                statement, parameters = fn(
                    self,
                    cursor,
                    statement,
                    parameters,
                    context,
                    context.executemany,
                )

        if self._echo:

            self._log_info(statement)

            stats = context._get_cache_stats()

            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        parameters, batches=10, ismulti=context.executemany
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]"
                    % (stats,)
                )

        evt_handled = False
        try:
            if context.executemany:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(cursor, statement, parameters, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor, statement, parameters, context
                    )
            elif not parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, statement, context
                    )
            else:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(cursor, statement, parameters, context):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, statement, parameters, context
                    )

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1802:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7fe2f3b85250>
cursor = <sqlite3.Cursor object at 0x7fe2f84fe030>
statement = 'SELECT pk_index, a, b \nFROM (SELECT original_table_clause.w AS w, original_table_clause.x AS x, original_table_claus...S NULL AND b IS NULL)) AS anon_2 \nWHERE records_with_grouped_column_counts_subquery._num_rows >= ?\n LIMIT ? OFFSET ?'
parameters = (2, 20, 0)
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7fe2f952a940>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) ambiguous column name: pk_index
E       [SQL: SELECT pk_index, a, b
E       FROM (SELECT original_table_clause.w AS w, original_table_clause.x AS x, original_table_clause.y AS y, original_table_clause.z AS z, original_table_clause.a AS a, original_table_clause.b AS b, original_table_clause.pk_index AS pk_index, group_counts_subquery._num_rows AS _num_rows
E       FROM (SELECT w, x, y, z, a, b, pk_index
E       FROM (SELECT *
E       FROM test_data_uzirh4kl
E       WHERE NOT (a IS NULL AND b IS NULL)) AS anon_1) AS original_table_clause JOIN (SELECT a, b, count(*) AS _num_rows
E       FROM (SELECT w, x, y, z, a, b, pk_index
E       FROM (SELECT *
E       FROM test_data_uzirh4kl
E       WHERE NOT (a IS NULL AND b IS NULL)) AS anon_1) AS original_table_clause GROUP BY a, b) AS group_counts_subquery ON group_counts_subquery.a = original_table_clause.a AND group_counts_subquery.b = original_table_clause.b) AS records_with_grouped_column_counts_subquery, (SELECT *
E       FROM test_data_uzirh4kl
E       WHERE NOT (a IS NULL AND b IS NULL)) AS anon_2
E       WHERE records_with_grouped_column_counts_subquery._num_rows >= ?
E        LIMIT ? OFFSET ?]
E       [parameters: (2, 20, 0)]
E       (Background on this error at: https://sqlalche.me/e/14/e3q8)

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/engine/default.py:719: OperationalError

The above exception was the direct cause of the following exception:

test_case = {'expectation_type': 'expect_compound_columns_to_be_unique', 'pk_column': True, 'skip': False, 'test': {'exact_match_o...rue, 'in': {'column_list': ['a', 'b']}, 'input': {'column_list': ['a', 'b']}, 'only_for': ['pandas_v3_api'], ...}, ...}

    @pytest.mark.order(index=0)
    @pytest.mark.integration
    @pytest.mark.slow  # 12.68s
    def test_case_runner_v3_api(test_case):
        if test_case["skip"]:
            pytest.skip()

        # Note: this should never be done in practice, but we are wiping expectations to reuse batches during testing.
        # test_case["batch"]._initialize_expectations()
        if "parse_strings_as_datetimes" in test_case["test"]["in"]:
            with pytest.deprecated_call():
                evaluate_json_test_v3_api(
                    validator=test_case["validator_with_data"],
                    expectation_type=test_case["expectation_type"],
                    test=test_case["test"],
                    pk_column=test_case["pk_column"],
                )
        else:
>           evaluate_json_test_v3_api(
                validator=test_case["validator_with_data"],
                expectation_type=test_case["expectation_type"],
                test=test_case["test"],
                pk_column=test_case["pk_column"],
            )

tests/test_definitions/test_expectations_v3_api.py:428:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
great_expectations/self_check/util.py:2887: in evaluate_json_test_v3_api
    result = getattr(validator, expectation_type)(**runtime_kwargs)
great_expectations/validator/validator.py:595: in inst_expectation
    raise err
great_expectations/validator/validator.py:558: in inst_expectation
    validation_result = expectation.validate(
great_expectations/expectations/expectation.py:1265: in validate
    ] = validator.graph_validate(
great_expectations/validator/validator.py:1046: in graph_validate
    raise err
great_expectations/validator/validator.py:1025: in graph_validate
    ) = self._resolve_suite_level_graph_and_process_metric_evaluation_errors(
great_expectations/validator/validator.py:1184: in _resolve_suite_level_graph_and_process_metric_evaluation_errors
    ) = self._metrics_calculator.resolve_validation_graph(
great_expectations/validator/metrics_calculator.py:282: in resolve_validation_graph
    resolved_metrics, aborted_metrics_info = graph.resolve(
great_expectations/validator/validation_graph.py:196: in resolve
    ] = self._resolve(
great_expectations/validator/validation_graph.py:302: in _resolve
    raise err
great_expectations/validator/validation_graph.py:272: in _resolve
    self._execution_engine.resolve_metrics(
great_expectations/execution_engine/execution_engine.py:375: in resolve_metrics
    return self._process_direct_and_bundled_metric_computation_configurations(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <great_expectations.execution_engine.sqlalchemy_execution_engine.SqlAlchemyExecutionEngine object at 0x7fe2f3b9e2b0>
metric_fn_direct_configurations = [MetricComputationConfiguration(metric_configuration={
  "metric_name": "compound_columns.unique.filtered_row_count",
...l_unexpected_count': 20, 'include_unexpected_rows': False}}}, compute_domain_kwargs=None, accessor_domain_kwargs=None)]
metric_fn_bundle_configurations = []

    def _process_direct_and_bundled_metric_computation_configurations(
        self,
        metric_fn_direct_configurations: List[MetricComputationConfiguration],
        metric_fn_bundle_configurations: List[MetricComputationConfiguration],
    ) -> Dict[Tuple[str, str, str], MetricValue]:
        """
        This method processes directly-computable and bundled "MetricComputationConfiguration" objects.

        Args:
            metric_fn_direct_configurations: directly-computable "MetricComputationConfiguration" objects
            metric_fn_bundle_configurations: bundled "MetricComputationConfiguration" objects (column aggregates)

        Returns:
            resolved_metrics (Dict): a dictionary with the values for the metrics that have just been resolved.
        """
        resolved_metrics: Dict[Tuple[str, str, str], MetricValue] = {}

        metric_computation_configuration: MetricComputationConfiguration

        for metric_computation_configuration in metric_fn_direct_configurations:
            try:
                resolved_metrics[
                    metric_computation_configuration.metric_configuration.id
                ] = metric_computation_configuration.metric_fn(
                    **metric_computation_configuration.metric_provider_kwargs
                )
            except Exception as e:
>               raise gx_exceptions.MetricResolutionError(
                    message=str(e),
                    failed_metrics=(
                        metric_computation_configuration.metric_configuration,
                    ),
                ) from e
E               great_expectations.exceptions.exceptions.MetricResolutionError: (sqlite3.OperationalError) ambiguous column name: pk_index
E               [SQL: SELECT pk_index, a, b
E               FROM (SELECT original_table_clause.w AS w, original_table_clause.x AS x, original_table_clause.y AS y, original_table_clause.z AS z, original_table_clause.a AS a, original_table_clause.b AS b, original_table_clause.pk_index AS pk_index, group_counts_subquery._num_rows AS _num_rows
E               FROM (SELECT w, x, y, z, a, b, pk_index
E               FROM (SELECT *
E               FROM test_data_uzirh4kl
E               WHERE NOT (a IS NULL AND b IS NULL)) AS anon_1) AS original_table_clause JOIN (SELECT a, b, count(*) AS _num_rows
E               FROM (SELECT w, x, y, z, a, b, pk_index
E               FROM (SELECT *
E               FROM test_data_uzirh4kl
E               WHERE NOT (a IS NULL AND b IS NULL)) AS anon_1) AS original_table_clause GROUP BY a, b) AS group_counts_subquery ON group_counts_subquery.a = original_table_clause.a AND group_counts_subquery.b = original_table_clause.b) AS records_with_grouped_column_counts_subquery, (SELECT *
E               FROM test_data_uzirh4kl
E               WHERE NOT (a IS NULL AND b IS NULL)) AS anon_2
E               WHERE records_with_grouped_column_counts_subquery._num_rows >= ?
E                LIMIT ? OFFSET ?]
E               [parameters: (2, 20, 0)]
E               (Background on this error at: https://sqlalche.me/e/14/e3q8)

great_expectations/execution_engine/execution_engine.py:654: MetricResolutionError
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:  18%|        | 2/11 [00:00<00:00, 2114.06it/s]Calculating Metrics:  18%|        | 2/11 [00:00<00:00, 282.92it/s] Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 475.34it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 283.34it/s]Calculating Metrics:  45%|     | 5/11 [00:00<00:00, 312.61it/s]Calculating Metrics:  45%|     | 5/11 [00:00<00:00, 228.85it/s]Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 255.41it/s]Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 209.93it/s]
--------------------------- Captured stderr teardown ---------------------------
Calculating Metrics:  55%|    | 6/11 [00:01<00:00,  5.28it/s]
_ test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_compound_columns_to_be_unique:unexpected_values_exact_match_out_without_unexpected_index_list] _

self = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b7d850>
dialect = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7fe2f3b85250>
constructor = <bound method DefaultExecutionContext._init_compiled of <class 'sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext'>>
statement = 'SELECT pk_index, a, b \nFROM (SELECT original_table_clause.w AS w, original_table_clause.x AS x, original_table_claus...S NULL AND b IS NULL)) AS anon_2 \nWHERE records_with_grouped_column_counts_subquery._num_rows >= ?\n LIMIT ? OFFSET ?'
parameters = (2, 20, 0), execution_options = immutabledict({})
args = (<sqlalchemy.dialects.sqlite.base.SQLiteCompiler object at 0x7fe2f85073a0>, [], <sqlalchemy.sql.selectable.Select obje...140612817122304 num_rows)s', 2, type_=Integer()), _OffsetLimitParam('%(140612817340016 param)s', 20, type_=Integer())])
kw = {'cache_hit': symbol('CACHE_HIT')}
branched = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b7d850>
conn = <sqlalchemy.pool.base._ConnectionFairy object at 0x7fe2f3524040>
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7fe2f9074580>
cursor = <sqlite3.Cursor object at 0x7fe2f8b2eab0>, evt_handled = False

    def _execute_context(
        self,
        dialect,
        constructor,
        statement,
        parameters,
        execution_options,
        *args,
        **kw
    ):
        """Create an :class:`.ExecutionContext` and execute, returning
        a :class:`_engine.CursorResult`."""

        branched = self
        if self.__branch_from:
            # if this is a "branched" connection, do everything in terms
            # of the "root" connection, *except* for .close(), which is
            # the only feature that branching provides
            self = self.__branch_from

        try:
            conn = self._dbapi_connection
            if conn is None:
                conn = self._revalidate_connection()

            context = constructor(
                dialect, self, conn, execution_options, *args, **kw
            )
        except (exc.PendingRollbackError, exc.ResourceClosedError):
            raise
        except BaseException as e:
            self._handle_dbapi_exception(
                e, util.text_type(statement), parameters, None, None
            )

        if (
            self._transaction
            and not self._transaction.is_active
            or (
                self._nested_transaction
                and not self._nested_transaction.is_active
            )
        ):
            self._invalid_transaction()

        elif self._trans_context_manager:
            TransactionalContext._trans_ctx_check(self)

        if self._is_future and self._transaction is None:
            self._autobegin()

        context.pre_exec()

        if dialect.use_setinputsizes:
            context._set_input_sizes()

        cursor, statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )

        if not context.executemany:
            parameters = parameters[0]

        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                statement, parameters = fn(
                    self,
                    cursor,
                    statement,
                    parameters,
                    context,
                    context.executemany,
                )

        if self._echo:

            self._log_info(statement)

            stats = context._get_cache_stats()

            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        parameters, batches=10, ismulti=context.executemany
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]"
                    % (stats,)
                )

        evt_handled = False
        try:
            if context.executemany:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(cursor, statement, parameters, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor, statement, parameters, context
                    )
            elif not parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, statement, context
                    )
            else:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(cursor, statement, parameters, context):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, statement, parameters, context
                    )

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1802:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7fe2f3b85250>
cursor = <sqlite3.Cursor object at 0x7fe2f8b2eab0>
statement = 'SELECT pk_index, a, b \nFROM (SELECT original_table_clause.w AS w, original_table_clause.x AS x, original_table_claus...S NULL AND b IS NULL)) AS anon_2 \nWHERE records_with_grouped_column_counts_subquery._num_rows >= ?\n LIMIT ? OFFSET ?'
parameters = (2, 20, 0)
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7fe2f9074580>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlite3.OperationalError: ambiguous column name: pk_index

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/engine/default.py:719: OperationalError

The above exception was the direct cause of the following exception:

self = <great_expectations.execution_engine.sqlalchemy_execution_engine.SqlAlchemyExecutionEngine object at 0x7fe2f3b9e2b0>
metric_fn_direct_configurations = [MetricComputationConfiguration(metric_configuration={
  "metric_name": "compound_columns.unique.unexpected_index_quer...l_unexpected_count': 20, 'include_unexpected_rows': False}}}, compute_domain_kwargs=None, accessor_domain_kwargs=None)]
metric_fn_bundle_configurations = []

    def _process_direct_and_bundled_metric_computation_configurations(
        self,
        metric_fn_direct_configurations: List[MetricComputationConfiguration],
        metric_fn_bundle_configurations: List[MetricComputationConfiguration],
    ) -> Dict[Tuple[str, str, str], MetricValue]:
        """
        This method processes directly-computable and bundled "MetricComputationConfiguration" objects.

        Args:
            metric_fn_direct_configurations: directly-computable "MetricComputationConfiguration" objects
            metric_fn_bundle_configurations: bundled "MetricComputationConfiguration" objects (column aggregates)

        Returns:
            resolved_metrics (Dict): a dictionary with the values for the metrics that have just been resolved.
        """
        resolved_metrics: Dict[Tuple[str, str, str], MetricValue] = {}

        metric_computation_configuration: MetricComputationConfiguration

        for metric_computation_configuration in metric_fn_direct_configurations:
            try:
                resolved_metrics[
                    metric_computation_configuration.metric_configuration.id
>               ] = metric_computation_configuration.metric_fn(
                    **metric_computation_configuration.metric_provider_kwargs
                )

great_expectations/execution_engine/execution_engine.py:650:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

cls = <class 'great_expectations.expectations.metrics.multicolumn_map_metrics.compound_columns_unique.CompoundColumnsUnique'>
execution_engine = <great_expectations.execution_engine.sqlalchemy_execution_engine.SqlAlchemyExecutionEngine object at 0x7fe2f3b9e2b0>
metric_domain_kwargs = {'batch_id': 'b1ae3225b6aa3d6c44dce474d8b4e741', 'table': None, 'column_list': ['a', 'b'], 'row_condition': None, 'condition_parser': None, 'ignore_row_if': 'all_values_are_missing'}
metric_value_kwargs = {'result_format': {'result_format': 'COMPLETE', 'unexpected_index_column_names': ['pk_index'], 'partial_unexpected_count': 20, 'include_unexpected_rows': False}}
metrics = {'table.column_types': [{'autoincrement': 'auto', 'default': None, 'name': 'w', 'nullable': True, ...}, {'autoincremen...w_condition': None, 'condition_parser': None, 'ignore_row_if': 'all_values_are_missing'}, {'column_list': ['a', 'b']})}
kwargs = {'runtime_configuration': {'catch_exceptions': False, 'include_config': False, 'result_format': {'include_unexpected_rows': False, 'partial_unexpected_count': 20, 'result_format': 'COMPLETE', 'unexpected_index_column_names': ['pk_index']}}}
unexpected_condition = <sqlalchemy.sql.elements.BinaryExpression object at 0x7fe2f903f670>
compute_domain_kwargs = {'batch_id': 'b1ae3225b6aa3d6c44dce474d8b4e741', 'table': None, 'row_condition': None, 'condition_parser': None, 'ignore_row_if': 'all_values_are_missing'}
accessor_domain_kwargs = {'column_list': ['a', 'b']}
domain_column_name_list = ['a', 'b'], column_name = 'b'
column_list = ['a', 'b']
domain_kwargs = {'batch_id': 'b1ae3225b6aa3d6c44dce474d8b4e741', 'column_list': ['a', 'b'], 'condition_parser': None, 'ignore_row_if': 'all_values_are_missing', ...}

    def _sqlalchemy_map_condition_index(
        cls,
        execution_engine: SqlAlchemyExecutionEngine,
        metric_domain_kwargs: Dict,
        metric_value_kwargs: Dict,
        metrics: Dict[str, Any],
        **kwargs,
    ) -> List[Dict[str, Any]]:
        """
        Returns indices of the metric values which do not meet an expected Expectation condition for instances
        of ColumnMapExpectation.

        Requires `unexpected_index_column_names` to be part of `result_format` dict to specify primary_key columns
        to return.
        """
        (
            unexpected_condition,
            compute_domain_kwargs,
            accessor_domain_kwargs,
        ) = metrics.get("unexpected_condition")

        domain_column_name_list: List[str] = list()
        # column map expectations
        if "column" in accessor_domain_kwargs:
            column_name: Union[str, quoted_name] = accessor_domain_kwargs["column"]
            domain_column_name_list.append(column_name)
        # multi-column map expectations
        elif "column_list" in accessor_domain_kwargs:
            column_list: List[Union[str, quoted_name]] = accessor_domain_kwargs[
                "column_list"
            ]
            domain_column_name_list = column_list
        # column-map expectations
        elif "column_A" in accessor_domain_kwargs and "column_B" in accessor_domain_kwargs:
            column_list: List[Union[str, quoted_name]] = list()
            column_list.append(accessor_domain_kwargs["column_A"])
            column_list.append(accessor_domain_kwargs["column_B"])
            domain_column_name_list = column_list

        domain_kwargs: dict = dict(**compute_domain_kwargs, **accessor_domain_kwargs)
        result_format: dict = metric_value_kwargs["result_format"]

        all_table_columns: List[str] = metrics.get("table.columns")

        unexpected_index_column_names: Optional[List[str]] = result_format.get(
            "unexpected_index_column_names"
        )

        column_selector: List[sa.Column] = []
        for column_name in unexpected_index_column_names:
            if column_name not in all_table_columns:
                raise gx_exceptions.InvalidMetricAccessorDomainKwargsKeyError(
                    message=f'Error: The unexpected_index_column: "{column_name}" in does not exist in SQL Table. '
                    f"Please check your configuration and try again."
                )
            column_selector.append(sa.column(column_name))

        # expectation_domain_column_name: str = domain_kwargs["column"]

        # the last column we SELECT is the column the Expectation is being run on
        for column_name in domain_column_name_list:
            column_selector.append(sa.column(column_name))

        domain_records_as_selectable: sa.sql.Selectable = (
            execution_engine.get_domain_records(domain_kwargs=domain_kwargs)
        )
        unexpected_condition_query_with_selected_columns: sa.select = sa.select(
            column_selector
        ).where(unexpected_condition)

        if not MapMetricProvider.is_sqlalchemy_metric_selectable(map_metric_provider=cls):
            domain_records_as_selectable: Union[
                sa.Table, sa.Select
            ] = get_sqlalchemy_selectable(domain_records_as_selectable)

        # since SQL tables can be **very** large, truncate query_result values at 20, or at `partial_unexpected_count`
        final_query: sa.select = (
            unexpected_condition_query_with_selected_columns.select_from(
                domain_records_as_selectable
            ).limit(result_format["partial_unexpected_count"])
        )
>       query_result: List[tuple] = execution_engine.engine.execute(final_query).fetchall()

great_expectations/expectations/metrics/map_metric_provider.py:2662:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b7d850>
statement = <sqlalchemy.sql.selectable.Select object at 0x7fe2f90744c0>
multiparams = (), params = {}
meth = <bound method ClauseElement._execute_on_connection of <sqlalchemy.sql.selectable.Select object at 0x7fe2f90744c0>>

    def execute(self, statement, *multiparams, **params):
        r"""Executes a SQL statement construct and returns a
        :class:`_engine.CursorResult`.

        :param statement: The statement to be executed.  May be
         one of:

         * a plain string (deprecated)
         * any :class:`_expression.ClauseElement` construct that is also
           a subclass of :class:`.Executable`, such as a
           :func:`_expression.select` construct
         * a :class:`.FunctionElement`, such as that generated
           by :data:`.func`, will be automatically wrapped in
           a SELECT statement, which is then executed.
         * a :class:`.DDLElement` object
         * a :class:`.DefaultGenerator` object
         * a :class:`.Compiled` object

         .. deprecated:: 2.0 passing a string to
            :meth:`_engine.Connection.execute` is
            deprecated and will be removed in version 2.0.  Use the
            :func:`_expression.text` construct with
            :meth:`_engine.Connection.execute`, or the
            :meth:`_engine.Connection.exec_driver_sql`
            method to invoke a driver-level
            SQL string.

        :param \*multiparams/\**params: represent bound parameter
         values to be used in the execution.   Typically,
         the format is either a collection of one or more
         dictionaries passed to \*multiparams::

             conn.execute(
                 table.insert(),
                 {"id":1, "value":"v1"},
                 {"id":2, "value":"v2"}
             )

         ...or individual key/values interpreted by \**params::

             conn.execute(
                 table.insert(), id=1, value="v1"
             )

         In the case that a plain SQL string is passed, and the underlying
         DBAPI accepts positional bind parameters, a collection of tuples
         or individual values in \*multiparams may be passed::

             conn.execute(
                 "INSERT INTO table (id, value) VALUES (?, ?)",
                 (1, "v1"), (2, "v2")
             )

             conn.execute(
                 "INSERT INTO table (id, value) VALUES (?, ?)",
                 1, "v1"
             )

         Note above, the usage of a question mark "?" or other
         symbol is contingent upon the "paramstyle" accepted by the DBAPI
         in use, which may be any of "qmark", "named", "pyformat", "format",
         "numeric".   See `pep-249
         <https://www.python.org/dev/peps/pep-0249/>`_ for details on
         paramstyle.

         To execute a textual SQL statement which uses bound parameters in a
         DBAPI-agnostic way, use the :func:`_expression.text` construct.

         .. deprecated:: 2.0 use of tuple or scalar positional parameters
            is deprecated. All params should be dicts or sequences of dicts.
            Use :meth:`.exec_driver_sql` to execute a plain string with
            tuple or scalar positional parameters.

        """

        if isinstance(statement, util.string_types):
            util.warn_deprecated_20(
                "Passing a string to Connection.execute() is "
                "deprecated and will be removed in version 2.0.  Use the "
                "text() construct, "
                "or the Connection.exec_driver_sql() method to invoke a "
                "driver-level SQL string."
            )

            return self._exec_driver_sql(
                statement,
                multiparams,
                params,
                _EMPTY_EXECUTION_OPTS,
                future=False,
            )

        try:
            meth = statement._execute_on_connection
        except AttributeError as err:
            util.raise_(
                exc.ObjectNotExecutableError(statement), replace_context=err
            )
        else:
>           return meth(self, multiparams, params, _EMPTY_EXECUTION_OPTS)

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1289:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.sql.selectable.Select object at 0x7fe2f90744c0>
connection = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b7d850>
multiparams = (), params = {}, execution_options = immutabledict({})
_force = False

    def _execute_on_connection(
        self, connection, multiparams, params, execution_options, _force=False
    ):
        if _force or self.supports_execution:
>           return connection._execute_clauseelement(
                self, multiparams, params, execution_options
            )

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/sql/elements.py:325:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b7d850>
elem = <sqlalchemy.sql.selectable.Select object at 0x7fe2f90744c0>
multiparams = (), params = {}, execution_options = immutabledict({})

    def _execute_clauseelement(
        self, elem, multiparams, params, execution_options
    ):
        """Execute a sql.ClauseElement object."""

        execution_options = elem._execution_options.merge_with(
            self._execution_options, execution_options
        )

        distilled_params = _distill_params(self, multiparams, params)

        has_events = self._has_events or self.engine._has_events
        if has_events:
            (
                elem,
                distilled_params,
                event_multiparams,
                event_params,
            ) = self._invoke_before_exec_event(
                elem, distilled_params, execution_options
            )

        if distilled_params:
            # ensure we don't retain a link to the view object for keys()
            # which links to the values, which we don't want to cache
            keys = sorted(distilled_params[0])
            for_executemany = len(distilled_params) > 1
        else:
            keys = []
            for_executemany = False

        dialect = self.dialect

        schema_translate_map = execution_options.get(
            "schema_translate_map", None
        )

        compiled_cache = execution_options.get(
            "compiled_cache", self.engine._compiled_cache
        )

        compiled_sql, extracted_params, cache_hit = elem._compile_w_cache(
            dialect=dialect,
            compiled_cache=compiled_cache,
            column_keys=keys,
            for_executemany=for_executemany,
            schema_translate_map=schema_translate_map,
            linting=self.dialect.compiler_linting | compiler.WARN_LINTING,
        )
>       ret = self._execute_context(
            dialect,
            dialect.execution_ctx_cls._init_compiled,
            compiled_sql,
            distilled_params,
            execution_options,
            compiled_sql,
            distilled_params,
            elem,
            extracted_params,
            cache_hit=cache_hit,
        )

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1481:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b7d850>
dialect = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7fe2f3b85250>
constructor = <bound method DefaultExecutionContext._init_compiled of <class 'sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext'>>
statement = 'SELECT pk_index, a, b \nFROM (SELECT original_table_clause.w AS w, original_table_clause.x AS x, original_table_claus...S NULL AND b IS NULL)) AS anon_2 \nWHERE records_with_grouped_column_counts_subquery._num_rows >= ?\n LIMIT ? OFFSET ?'
parameters = (2, 20, 0), execution_options = immutabledict({})
args = (<sqlalchemy.dialects.sqlite.base.SQLiteCompiler object at 0x7fe2f85073a0>, [], <sqlalchemy.sql.selectable.Select obje...140612817122304 num_rows)s', 2, type_=Integer()), _OffsetLimitParam('%(140612817340016 param)s', 20, type_=Integer())])
kw = {'cache_hit': symbol('CACHE_HIT')}
branched = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b7d850>
conn = <sqlalchemy.pool.base._ConnectionFairy object at 0x7fe2f3524040>
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7fe2f9074580>
cursor = <sqlite3.Cursor object at 0x7fe2f8b2eab0>, evt_handled = False

    def _execute_context(
        self,
        dialect,
        constructor,
        statement,
        parameters,
        execution_options,
        *args,
        **kw
    ):
        """Create an :class:`.ExecutionContext` and execute, returning
        a :class:`_engine.CursorResult`."""

        branched = self
        if self.__branch_from:
            # if this is a "branched" connection, do everything in terms
            # of the "root" connection, *except* for .close(), which is
            # the only feature that branching provides
            self = self.__branch_from

        try:
            conn = self._dbapi_connection
            if conn is None:
                conn = self._revalidate_connection()

            context = constructor(
                dialect, self, conn, execution_options, *args, **kw
            )
        except (exc.PendingRollbackError, exc.ResourceClosedError):
            raise
        except BaseException as e:
            self._handle_dbapi_exception(
                e, util.text_type(statement), parameters, None, None
            )

        if (
            self._transaction
            and not self._transaction.is_active
            or (
                self._nested_transaction
                and not self._nested_transaction.is_active
            )
        ):
            self._invalid_transaction()

        elif self._trans_context_manager:
            TransactionalContext._trans_ctx_check(self)

        if self._is_future and self._transaction is None:
            self._autobegin()

        context.pre_exec()

        if dialect.use_setinputsizes:
            context._set_input_sizes()

        cursor, statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )

        if not context.executemany:
            parameters = parameters[0]

        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                statement, parameters = fn(
                    self,
                    cursor,
                    statement,
                    parameters,
                    context,
                    context.executemany,
                )

        if self._echo:

            self._log_info(statement)

            stats = context._get_cache_stats()

            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        parameters, batches=10, ismulti=context.executemany
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]"
                    % (stats,)
                )

        evt_handled = False
        try:
            if context.executemany:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(cursor, statement, parameters, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor, statement, parameters, context
                    )
            elif not parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, statement, context
                    )
            else:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(cursor, statement, parameters, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute(
                        cursor, statement, parameters, context
                    )

            if self._has_events or self.engine._has_events:
                self.dispatch.after_cursor_execute(
                    self,
                    cursor,
                    statement,
                    parameters,
                    context,
                    context.executemany,
                )

            context.post_exec()

            result = context._setup_result_proxy()

            if not self._is_future:
                should_close_with_result = branched.should_close_with_result

                if not result._soft_closed and should_close_with_result:
                    result._autoclose_connection = True

                if (
                    # usually we're in a transaction so avoid relatively
                    # expensive / legacy should_autocommit call
                    self._transaction is None
                    and context.should_autocommit
                ):
                    self._commit_impl(autocommit=True)

                # for "connectionless" execution, we have to close this
                # Connection after the statement is complete.
                # legacy stuff.
                if should_close_with_result and context._soft_closed:
                    assert not self._is_future

                    # CursorResult already exhausted rows / has no rows.
                    # close us now
                    branched.close()

        except BaseException as e:
>           self._handle_dbapi_exception(
                e, statement, parameters, cursor, context
            )

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1845:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b7d850>
e = OperationalError('ambiguous column name: pk_index')
statement = 'SELECT pk_index, a, b \nFROM (SELECT original_table_clause.w AS w, original_table_clause.x AS x, original_table_claus...S NULL AND b IS NULL)) AS anon_2 \nWHERE records_with_grouped_column_counts_subquery._num_rows >= ?\n LIMIT ? OFFSET ?'
parameters = (2, 20, 0), cursor = <sqlite3.Cursor object at 0x7fe2f8b2eab0>
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7fe2f9074580>

    def _handle_dbapi_exception(
        self, e, statement, parameters, cursor, context
    ):
        exc_info = sys.exc_info()

        is_exit_exception = util.is_exit_exception(e)

        if not self._is_disconnect:
            self._is_disconnect = (
                isinstance(e, self.dialect.dbapi.Error)
                and not self.closed
                and self.dialect.is_disconnect(
                    e,
                    self._dbapi_connection if not self.invalidated else None,
                    cursor,
                )
            ) or (is_exit_exception and not self.closed)

        invalidate_pool_on_disconnect = not is_exit_exception

        if self._reentrant_error:
            util.raise_(
                exc.DBAPIError.instance(
                    statement,
                    parameters,
                    e,
                    self.dialect.dbapi.Error,
                    hide_parameters=self.engine.hide_parameters,
                    dialect=self.dialect,
                    ismulti=context.executemany
                    if context is not None
                    else None,
                ),
                with_traceback=exc_info[2],
                from_=e,
            )
        self._reentrant_error = True
        try:
            # non-DBAPI error - if we already got a context,
            # or there's no string statement, don't wrap it
            should_wrap = isinstance(e, self.dialect.dbapi.Error) or (
                statement is not None
                and context is None
                and not is_exit_exception
            )

            if should_wrap:
                sqlalchemy_exception = exc.DBAPIError.instance(
                    statement,
                    parameters,
                    e,
                    self.dialect.dbapi.Error,
                    hide_parameters=self.engine.hide_parameters,
                    connection_invalidated=self._is_disconnect,
                    dialect=self.dialect,
                    ismulti=context.executemany
                    if context is not None
                    else None,
                )
            else:
                sqlalchemy_exception = None

            newraise = None

            if (
                self._has_events or self.engine._has_events
            ) and not self._execution_options.get(
                "skip_user_error_events", False
            ):
                ctx = ExceptionContextImpl(
                    e,
                    sqlalchemy_exception,
                    self.engine,
                    self,
                    cursor,
                    statement,
                    parameters,
                    context,
                    self._is_disconnect,
                    invalidate_pool_on_disconnect,
                )

                for fn in self.dispatch.handle_error:
                    try:
                        # handler returns an exception;
                        # call next handler in a chain
                        per_fn = fn(ctx)
                        if per_fn is not None:
                            ctx.chained_exception = newraise = per_fn
                    except Exception as _raised:
                        # handler raises an exception - stop processing
                        newraise = _raised
                        break

                if self._is_disconnect != ctx.is_disconnect:
                    self._is_disconnect = ctx.is_disconnect
                    if sqlalchemy_exception:
                        sqlalchemy_exception.connection_invalidated = (
                            ctx.is_disconnect
                        )

                # set up potentially user-defined value for
                # invalidate pool.
                invalidate_pool_on_disconnect = (
                    ctx.invalidate_pool_on_disconnect
                )

            if should_wrap and context:
                context.handle_dbapi_exception(e)

            if not self._is_disconnect:
                if cursor:
                    self._safe_close_cursor(cursor)
                with util.safe_reraise(warn_only=True):
                    self._autorollback()

            if newraise:
                util.raise_(newraise, with_traceback=exc_info[2], from_=e)
            elif should_wrap:
>               util.raise_(
                    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
                )

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/engine/base.py:2026:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

    def raise_(
        exception, with_traceback=None, replace_context=None, from_=False
    ):
        r"""implement "raise" with cause support.

        :param exception: exception to raise
        :param with_traceback: will call exception.with_traceback()
        :param replace_context: an as-yet-unsupported feature.  This is
         an exception object which we are "replacing", e.g., it's our
         "cause" but we don't want it printed.    Basically just what
         ``__suppress_context__`` does but we don't want to suppress
         the enclosing context, if any.  So for now we make it the
         cause.
        :param from\_: the cause.  this actually sets the cause and doesn't
         hope to hide it someday.

        """
        if with_traceback is not None:
            exception = exception.with_traceback(with_traceback)

        if from_ is not False:
            exception.__cause__ = from_
        elif replace_context is not None:
            # no good solution here, we would like to have the exception
            # have only the context of replace_context.__context__ so that the
            # intermediary exception does not change, but we can't figure
            # that out.
            exception.__cause__ = replace_context

        try:
>           raise exception

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/util/compat.py:207:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b7d850>
dialect = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7fe2f3b85250>
constructor = <bound method DefaultExecutionContext._init_compiled of <class 'sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext'>>
statement = 'SELECT pk_index, a, b \nFROM (SELECT original_table_clause.w AS w, original_table_clause.x AS x, original_table_claus...S NULL AND b IS NULL)) AS anon_2 \nWHERE records_with_grouped_column_counts_subquery._num_rows >= ?\n LIMIT ? OFFSET ?'
parameters = (2, 20, 0), execution_options = immutabledict({})
args = (<sqlalchemy.dialects.sqlite.base.SQLiteCompiler object at 0x7fe2f85073a0>, [], <sqlalchemy.sql.selectable.Select obje...140612817122304 num_rows)s', 2, type_=Integer()), _OffsetLimitParam('%(140612817340016 param)s', 20, type_=Integer())])
kw = {'cache_hit': symbol('CACHE_HIT')}
branched = <sqlalchemy.engine.base.Connection object at 0x7fe2f3b7d850>
conn = <sqlalchemy.pool.base._ConnectionFairy object at 0x7fe2f3524040>
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7fe2f9074580>
cursor = <sqlite3.Cursor object at 0x7fe2f8b2eab0>, evt_handled = False

    def _execute_context(
        self,
        dialect,
        constructor,
        statement,
        parameters,
        execution_options,
        *args,
        **kw
    ):
        """Create an :class:`.ExecutionContext` and execute, returning
        a :class:`_engine.CursorResult`."""

        branched = self
        if self.__branch_from:
            # if this is a "branched" connection, do everything in terms
            # of the "root" connection, *except* for .close(), which is
            # the only feature that branching provides
            self = self.__branch_from

        try:
            conn = self._dbapi_connection
            if conn is None:
                conn = self._revalidate_connection()

            context = constructor(
                dialect, self, conn, execution_options, *args, **kw
            )
        except (exc.PendingRollbackError, exc.ResourceClosedError):
            raise
        except BaseException as e:
            self._handle_dbapi_exception(
                e, util.text_type(statement), parameters, None, None
            )

        if (
            self._transaction
            and not self._transaction.is_active
            or (
                self._nested_transaction
                and not self._nested_transaction.is_active
            )
        ):
            self._invalid_transaction()

        elif self._trans_context_manager:
            TransactionalContext._trans_ctx_check(self)

        if self._is_future and self._transaction is None:
            self._autobegin()

        context.pre_exec()

        if dialect.use_setinputsizes:
            context._set_input_sizes()

        cursor, statement, parameters = (
            context.cursor,
            context.statement,
            context.parameters,
        )

        if not context.executemany:
            parameters = parameters[0]

        if self._has_events or self.engine._has_events:
            for fn in self.dispatch.before_cursor_execute:
                statement, parameters = fn(
                    self,
                    cursor,
                    statement,
                    parameters,
                    context,
                    context.executemany,
                )

        if self._echo:

            self._log_info(statement)

            stats = context._get_cache_stats()

            if not self.engine.hide_parameters:
                self._log_info(
                    "[%s] %r",
                    stats,
                    sql_util._repr_params(
                        parameters, batches=10, ismulti=context.executemany
                    ),
                )
            else:
                self._log_info(
                    "[%s] [SQL parameters hidden due to hide_parameters=True]"
                    % (stats,)
                )

        evt_handled = False
        try:
            if context.executemany:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_executemany:
                        if fn(cursor, statement, parameters, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_executemany(
                        cursor, statement, parameters, context
                    )
            elif not parameters and context.no_parameters:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute_no_params:
                        if fn(cursor, statement, context):
                            evt_handled = True
                            break
                if not evt_handled:
                    self.dialect.do_execute_no_params(
                        cursor, statement, context
                    )
            else:
                if self.dialect._has_events:
                    for fn in self.dialect.dispatch.do_execute:
                        if fn(cursor, statement, parameters, context):
                            evt_handled = True
                            break
                if not evt_handled:
>                   self.dialect.do_execute(
                        cursor, statement, parameters, context
                    )

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1802:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <sqlalchemy.dialects.sqlite.pysqlite.SQLiteDialect_pysqlite object at 0x7fe2f3b85250>
cursor = <sqlite3.Cursor object at 0x7fe2f8b2eab0>
statement = 'SELECT pk_index, a, b \nFROM (SELECT original_table_clause.w AS w, original_table_clause.x AS x, original_table_claus...S NULL AND b IS NULL)) AS anon_2 \nWHERE records_with_grouped_column_counts_subquery._num_rows >= ?\n LIMIT ? OFFSET ?'
parameters = (2, 20, 0)
context = <sqlalchemy.dialects.sqlite.base.SQLiteExecutionContext object at 0x7fe2f9074580>

    def do_execute(self, cursor, statement, parameters, context=None):
>       cursor.execute(statement, parameters)
E       sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) ambiguous column name: pk_index
E       [SQL: SELECT pk_index, a, b
E       FROM (SELECT original_table_clause.w AS w, original_table_clause.x AS x, original_table_clause.y AS y, original_table_clause.z AS z, original_table_clause.a AS a, original_table_clause.b AS b, original_table_clause.pk_index AS pk_index, group_counts_subquery._num_rows AS _num_rows
E       FROM (SELECT w, x, y, z, a, b, pk_index
E       FROM (SELECT *
E       FROM test_data_uzirh4kl
E       WHERE NOT (a IS NULL AND b IS NULL)) AS anon_1) AS original_table_clause JOIN (SELECT a, b, count(*) AS _num_rows
E       FROM (SELECT w, x, y, z, a, b, pk_index
E       FROM (SELECT *
E       FROM test_data_uzirh4kl
E       WHERE NOT (a IS NULL AND b IS NULL)) AS anon_1) AS original_table_clause GROUP BY a, b) AS group_counts_subquery ON group_counts_subquery.a = original_table_clause.a AND group_counts_subquery.b = original_table_clause.b) AS records_with_grouped_column_counts_subquery, (SELECT *
E       FROM test_data_uzirh4kl
E       WHERE NOT (a IS NULL AND b IS NULL)) AS anon_2
E       WHERE records_with_grouped_column_counts_subquery._num_rows >= ?
E        LIMIT ? OFFSET ?]
E       [parameters: (2, 20, 0)]
E       (Background on this error at: https://sqlalche.me/e/14/e3q8)

../ENVs/supercon_ge/lib/python3.9/site-packages/sqlalchemy/engine/default.py:719: OperationalError

The above exception was the direct cause of the following exception:

test_case = {'expectation_type': 'expect_compound_columns_to_be_unique', 'pk_column': True, 'skip': False, 'test': {'exact_match_o... 'b': 1.0}, {'a': 1.0, 'b': 2.0}, {'a': 1.0, 'b': 1.0}, {'a': 2.0, 'b': 2.0}, ...], ...}, 'success': False}, ...}, ...}

    @pytest.mark.order(index=0)
    @pytest.mark.integration
    @pytest.mark.slow  # 12.68s
    def test_case_runner_v3_api(test_case):
        if test_case["skip"]:
            pytest.skip()

        # Note: this should never be done in practice, but we are wiping expectations to reuse batches during testing.
        # test_case["batch"]._initialize_expectations()
        if "parse_strings_as_datetimes" in test_case["test"]["in"]:
            with pytest.deprecated_call():
                evaluate_json_test_v3_api(
                    validator=test_case["validator_with_data"],
                    expectation_type=test_case["expectation_type"],
                    test=test_case["test"],
                    pk_column=test_case["pk_column"],
                )
        else:
>           evaluate_json_test_v3_api(
                validator=test_case["validator_with_data"],
                expectation_type=test_case["expectation_type"],
                test=test_case["test"],
                pk_column=test_case["pk_column"],
            )

tests/test_definitions/test_expectations_v3_api.py:428:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
great_expectations/self_check/util.py:2887: in evaluate_json_test_v3_api
    result = getattr(validator, expectation_type)(**runtime_kwargs)
great_expectations/validator/validator.py:595: in inst_expectation
    raise err
great_expectations/validator/validator.py:558: in inst_expectation
    validation_result = expectation.validate(
great_expectations/expectations/expectation.py:1265: in validate
    ] = validator.graph_validate(
great_expectations/validator/validator.py:1046: in graph_validate
    raise err
great_expectations/validator/validator.py:1025: in graph_validate
    ) = self._resolve_suite_level_graph_and_process_metric_evaluation_errors(
great_expectations/validator/validator.py:1184: in _resolve_suite_level_graph_and_process_metric_evaluation_errors
    ) = self._metrics_calculator.resolve_validation_graph(
great_expectations/validator/metrics_calculator.py:282: in resolve_validation_graph
    resolved_metrics, aborted_metrics_info = graph.resolve(
great_expectations/validator/validation_graph.py:196: in resolve
    ] = self._resolve(
great_expectations/validator/validation_graph.py:302: in _resolve
    raise err
great_expectations/validator/validation_graph.py:272: in _resolve
    self._execution_engine.resolve_metrics(
great_expectations/execution_engine/execution_engine.py:375: in resolve_metrics
    return self._process_direct_and_bundled_metric_computation_configurations(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <great_expectations.execution_engine.sqlalchemy_execution_engine.SqlAlchemyExecutionEngine object at 0x7fe2f3b9e2b0>
metric_fn_direct_configurations = [MetricComputationConfiguration(metric_configuration={
  "metric_name": "compound_columns.unique.unexpected_index_quer...l_unexpected_count': 20, 'include_unexpected_rows': False}}}, compute_domain_kwargs=None, accessor_domain_kwargs=None)]
metric_fn_bundle_configurations = []

    def _process_direct_and_bundled_metric_computation_configurations(
        self,
        metric_fn_direct_configurations: List[MetricComputationConfiguration],
        metric_fn_bundle_configurations: List[MetricComputationConfiguration],
    ) -> Dict[Tuple[str, str, str], MetricValue]:
        """
        This method processes directly-computable and bundled "MetricComputationConfiguration" objects.

        Args:
            metric_fn_direct_configurations: directly-computable "MetricComputationConfiguration" objects
            metric_fn_bundle_configurations: bundled "MetricComputationConfiguration" objects (column aggregates)

        Returns:
            resolved_metrics (Dict): a dictionary with the values for the metrics that have just been resolved.
        """
        resolved_metrics: Dict[Tuple[str, str, str], MetricValue] = {}

        metric_computation_configuration: MetricComputationConfiguration

        for metric_computation_configuration in metric_fn_direct_configurations:
            try:
                resolved_metrics[
                    metric_computation_configuration.metric_configuration.id
                ] = metric_computation_configuration.metric_fn(
                    **metric_computation_configuration.metric_provider_kwargs
                )
            except Exception as e:
>               raise gx_exceptions.MetricResolutionError(
                    message=str(e),
                    failed_metrics=(
                        metric_computation_configuration.metric_configuration,
                    ),
                ) from e
E               great_expectations.exceptions.exceptions.MetricResolutionError: (sqlite3.OperationalError) ambiguous column name: pk_index
E               [SQL: SELECT pk_index, a, b
E               FROM (SELECT original_table_clause.w AS w, original_table_clause.x AS x, original_table_clause.y AS y, original_table_clause.z AS z, original_table_clause.a AS a, original_table_clause.b AS b, original_table_clause.pk_index AS pk_index, group_counts_subquery._num_rows AS _num_rows
E               FROM (SELECT w, x, y, z, a, b, pk_index
E               FROM (SELECT *
E               FROM test_data_uzirh4kl
E               WHERE NOT (a IS NULL AND b IS NULL)) AS anon_1) AS original_table_clause JOIN (SELECT a, b, count(*) AS _num_rows
E               FROM (SELECT w, x, y, z, a, b, pk_index
E               FROM (SELECT *
E               FROM test_data_uzirh4kl
E               WHERE NOT (a IS NULL AND b IS NULL)) AS anon_1) AS original_table_clause GROUP BY a, b) AS group_counts_subquery ON group_counts_subquery.a = original_table_clause.a AND group_counts_subquery.b = original_table_clause.b) AS records_with_grouped_column_counts_subquery, (SELECT *
E               FROM test_data_uzirh4kl
E               WHERE NOT (a IS NULL AND b IS NULL)) AS anon_2
E               WHERE records_with_grouped_column_counts_subquery._num_rows >= ?
E                LIMIT ? OFFSET ?]
E               [parameters: (2, 20, 0)]
E               (Background on this error at: https://sqlalche.me/e/14/e3q8)

great_expectations/execution_engine/execution_engine.py:654: MetricResolutionError
----------------------------- Captured stderr call -----------------------------

Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s][A
Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s][A
Calculating Metrics:  18%|        | 2/11 [00:00<00:00, 1453.33it/s][A
Calculating Metrics:  18%|        | 2/11 [00:00<00:00, 264.37it/s] [A
Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 440.49it/s][A
Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 262.47it/s][A
Calculating Metrics:  45%|     | 5/11 [00:00<00:00, 296.16it/s][A
Calculating Metrics:  45%|     | 5/11 [00:00<00:00, 223.10it/s][A
Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 251.07it/s][A
Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 209.94it/s][A
--------------------------- Captured stderr teardown ---------------------------
Calculating Metrics:  55%|    | 6/11 [00:01<00:00,  5.15it/s]
=============================== warnings summary ===============================
../../../../Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/inspect.py:351
  /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/inspect.py:351: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
    value = getattr(object, key)

../../../../Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/inspect.py:351
  /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/inspect.py:351: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
    value = getattr(object, key)

../../../../Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/inspect.py:351
  /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/inspect.py:351: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.
    value = getattr(object, key)

../ENVs/supercon_ge/lib/python3.9/site-packages/botocore/httpsession.py:18
  /Users/work/Development/ENVs/supercon_ge/lib/python3.9/site-packages/botocore/httpsession.py:18: DeprecationWarning: 'urllib3.contrib.pyopenssl' module is deprecated and will be removed in a future release of urllib3 2.x. Read more in this issue: https://github.com/urllib3/urllib3/issues/2680
    from urllib3.contrib.pyopenssl import orig_util_SSLContext as SSLContext

tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_be_null:basic_positive_case_complete_result_format]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_null:basic_positive_case_basic_result_format]
  /Users/work/Development/great_expectations/great_expectations/expectations/metrics/map_metric_provider.py:1527: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.
    return list(domain_values[: result_format["partial_unexpected_count"]])

tests/test_definitions/test_expectations_v3_api.py: 37 warnings
  /Users/work/Development/great_expectations/great_expectations/core/expectation_validation_result.py:139: DeprecationWarning: NotImplemented should not be used in a boolean context
    return all(

tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_compound_columns_to_be_unique:mostly_default_successful_expectation]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_compound_columns_to_be_unique:basic_test_ignore_if_all_are_missing_the_default_behavior]
  /Users/work/Development/great_expectations/great_expectations/expectations/metrics/map_metric_provider.py:2662: SAWarning: SELECT statement has a cartesian product between FROM element(s) "anon_2" and FROM element "records_with_grouped_column_counts_subquery".  Apply join condition(s) between each element to resolve.
    query_result: List[tuple] = execution_engine.engine.execute(final_query).fetchall()

tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_compound_columns_to_be_unique:mostly_default_fails_expectation]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_compound_columns_to_be_unique:basic_test_ignore_if_any_are_missing]
tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_compound_columns_to_be_unique:unexpected_values_without_unexpected_index_list]
  /Users/work/Development/great_expectations/great_expectations/expectations/metrics/map_metric_provider.py:2662: SAWarning: SELECT statement has a cartesian product between FROM element(s) "records_with_grouped_column_counts_subquery" and FROM element "anon_2".  Apply join condition(s) between each element to resolve.
    query_result: List[tuple] = execution_engine.engine.execute(final_query).fetchall()

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
==================================== PASSES ====================================
_ test_case_runner_v3_api[sqlite/multi_table_expectations/expect_table_row_count_to_equal_other_table:basic_positive] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 651.44it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 519.71it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 286.06it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 277.66it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 275.27it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 271.76it/s]
_ test_case_runner_v3_api[sqlite/multi_table_expectations/expect_table_row_count_to_equal_other_table:basic_negative] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 2876.75it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1486.81it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1054.57it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 955.53it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 927.84it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 898.09it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_lengths_to_equal:positive_test_string_one_character_length] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:  18%|        | 2/11 [00:00<00:00, 1227.12it/s]Calculating Metrics:  18%|        | 2/11 [00:00<00:00, 238.98it/s] Calculating Metrics:  27%|       | 3/11 [00:00<00:00, 342.47it/s]Calculating Metrics:  27%|       | 3/11 [00:00<00:00, 187.51it/s]Calculating Metrics:  45%|     | 5/11 [00:00<00:00, 251.31it/s]Calculating Metrics:  45%|     | 5/11 [00:00<00:00, 196.07it/s]Calculating Metrics:  64%|   | 7/11 [00:00<00:00, 250.02it/s]Calculating Metrics:  64%|   | 7/11 [00:00<00:00, 215.54it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 293.43it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 276.95it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 276.02it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 275.00it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_lengths_to_equal:negative_test_string_value_is_1_too_high] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:  18%|        | 2/11 [00:00<00:00, 2774.93it/s]Calculating Metrics:  18%|        | 2/11 [00:00<00:00, 267.60it/s] Calculating Metrics:  27%|       | 3/11 [00:00<00:00, 378.84it/s]Calculating Metrics:  27%|       | 3/11 [00:00<00:00, 200.54it/s]Calculating Metrics:  45%|     | 5/11 [00:00<00:00, 285.05it/s]Calculating Metrics:  45%|     | 5/11 [00:00<00:00, 214.47it/s]Calculating Metrics:  64%|   | 7/11 [00:00<00:00, 272.68it/s]Calculating Metrics:  64%|   | 7/11 [00:00<00:00, 228.37it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 297.39it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 280.35it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 279.28it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 278.24it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_lengths_to_equal:positive_test_with_missing_value_in_column_mostly] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:  18%|        | 2/11 [00:00<00:00, 2843.60it/s]Calculating Metrics:  18%|        | 2/11 [00:00<00:00, 273.89it/s] Calculating Metrics:  27%|       | 3/11 [00:00<00:00, 390.66it/s]Calculating Metrics:  27%|       | 3/11 [00:00<00:00, 214.71it/s]Calculating Metrics:  45%|     | 5/11 [00:00<00:00, 302.11it/s]Calculating Metrics:  45%|     | 5/11 [00:00<00:00, 225.64it/s]Calculating Metrics:  64%|   | 7/11 [00:00<00:00, 286.28it/s]Calculating Metrics:  64%|   | 7/11 [00:00<00:00, 242.73it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 326.05it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 305.72it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 303.54it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 301.90it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_lengths_to_equal:negative_one_length_too_small] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:  18%|        | 2/11 [00:00<00:00, 2898.62it/s]Calculating Metrics:  18%|        | 2/11 [00:00<00:00, 271.41it/s] Calculating Metrics:  27%|       | 3/11 [00:00<00:00, 386.80it/s]Calculating Metrics:  27%|       | 3/11 [00:00<00:00, 212.62it/s]Calculating Metrics:  45%|     | 5/11 [00:00<00:00, 302.74it/s]Calculating Metrics:  45%|     | 5/11 [00:00<00:00, 226.54it/s]Calculating Metrics:  64%|   | 7/11 [00:00<00:00, 286.75it/s]Calculating Metrics:  64%|   | 7/11 [00:00<00:00, 243.21it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 326.85it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 306.83it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 305.77it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 304.56it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_lengths_to_equal:positive_one_length_too_small_mostly] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:  18%|        | 2/11 [00:00<00:00, 2878.73it/s]Calculating Metrics:  18%|        | 2/11 [00:00<00:00, 275.71it/s] Calculating Metrics:  27%|       | 3/11 [00:00<00:00, 393.35it/s]Calculating Metrics:  27%|       | 3/11 [00:00<00:00, 213.72it/s]Calculating Metrics:  45%|     | 5/11 [00:00<00:00, 296.00it/s]Calculating Metrics:  45%|     | 5/11 [00:00<00:00, 220.21it/s]Calculating Metrics:  64%|   | 7/11 [00:00<00:00, 280.71it/s]Calculating Metrics:  64%|   | 7/11 [00:00<00:00, 233.57it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 305.39it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 287.59it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 286.59it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 285.53it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_lengths_to_equal:test_conditional_expectation_passes] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:  18%|        | 2/11 [00:00<00:00, 151.16it/s]Calculating Metrics:  18%|        | 2/11 [00:00<00:00, 111.75it/s]Calculating Metrics:  27%|       | 3/11 [00:00<00:00, 164.58it/s]Calculating Metrics:  27%|       | 3/11 [00:00<00:00, 130.57it/s]Calculating Metrics:  45%|     | 5/11 [00:00<00:00, 172.05it/s]Calculating Metrics:  45%|     | 5/11 [00:00<00:00, 151.55it/s]Calculating Metrics:  64%|   | 7/11 [00:00<00:00, 190.06it/s]Calculating Metrics:  64%|   | 7/11 [00:00<00:00, 174.96it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 209.82it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 203.45it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 202.93it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 202.38it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_lengths_to_equal:test_conditional_expectation_fails] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:  18%|        | 2/11 [00:00<00:00, 367.37it/s]Calculating Metrics:  18%|        | 2/11 [00:00<00:00, 199.24it/s]Calculating Metrics:  27%|       | 3/11 [00:00<00:00, 288.90it/s]Calculating Metrics:  27%|       | 3/11 [00:00<00:00, 203.59it/s]Calculating Metrics:  45%|     | 5/11 [00:00<00:00, 237.19it/s]Calculating Metrics:  45%|     | 5/11 [00:00<00:00, 199.60it/s]Calculating Metrics:  64%|   | 7/11 [00:00<00:00, 243.99it/s]Calculating Metrics:  64%|   | 7/11 [00:00<00:00, 219.06it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 261.65it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 252.17it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 251.46it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 250.65it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_lengths_to_equal:test_conditional_expectation_parser_errors] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:basic_positive_now_test] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2545.09it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 225.58it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 310.65it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 174.11it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 236.96it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 181.61it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 287.26it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 265.62it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 264.59it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 263.58it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:basic_negative_now_test] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2808.37it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 235.84it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 338.44it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 183.94it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 261.79it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 198.66it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 301.00it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 278.86it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 277.85it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 276.75it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:basic_positive_now_timedelta_test] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2735.12it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 228.54it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 326.73it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 170.89it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 233.52it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 167.06it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 268.40it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 246.86it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 245.57it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 243.75it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:basic_negative_now_timedelta_test] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2472.33it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 228.46it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 326.44it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 179.35it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 254.99it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 192.48it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 295.32it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 274.00it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 273.02it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 271.91it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:basic_positive_datetime_test] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2673.23it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 245.73it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 348.72it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 180.11it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 249.59it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 191.09it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 296.68it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 275.29it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 273.79it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 272.07it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:basic_negative_datetime_test] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2652.94it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 228.52it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 325.80it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 177.01it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 242.48it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 178.81it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 273.11it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 253.59it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 251.45it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 249.81it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_json_parseable:basic_positive_test] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2732.45it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 328.62it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 462.47it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 237.89it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 323.73it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 254.14it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 391.19it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 365.51it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 363.73it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 361.84it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_json_parseable:positive_test_with_nulls] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2732.45it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 317.81it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 445.49it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 253.72it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 347.52it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 269.54it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 417.61it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 388.61it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 386.65it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 384.48it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_json_parseable:negative_test_integers] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2858.13it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 318.93it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 445.26it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 251.47it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 348.02it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 268.72it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 410.06it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 381.68it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 379.75it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 377.60it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_json_parseable:negative_test_string_only] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2825.40it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 333.45it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 469.56it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 255.99it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 349.71it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 268.51it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 408.18it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 380.12it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 378.15it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 376.00it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_json_parseable:negative_test_null_only] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2832.08it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 328.78it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 462.52it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 259.04it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 359.22it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 276.93it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 420.34it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 387.14it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 385.10it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 382.98it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:basic_positive_test_with_timestamps_tz_informed] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2620.62it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 243.81it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 346.46it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 192.89it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 271.08it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 207.30it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 331.97it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 307.30it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 306.09it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 304.78it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:basic_negative_test_with_timestamps_tz_informed] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2873.80it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 254.84it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 363.15it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 198.91it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 280.87it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 213.74it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 340.13it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 314.19it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 312.86it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 311.49it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_be_null:basic_positive_case_complete_result_format] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 2624.72it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 608.84it/s] Calculating Metrics:  50%|     | 3/6 [00:00<00:00, 818.56it/s]Calculating Metrics:  50%|     | 3/6 [00:00<00:00, 503.96it/s]Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 575.21it/s]Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 439.94it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 530.04it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 480.58it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 474.99it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 469.26it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_be_null:negative_all_missing_values_pandas] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/8 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/8 [00:00<?, ?it/s]Calculating Metrics:  25%|       | 2/8 [00:00<00:00, 2573.98it/s]Calculating Metrics:  25%|       | 2/8 [00:00<00:00, 409.40it/s] Calculating Metrics:  38%|      | 3/8 [00:00<00:00, 563.17it/s]Calculating Metrics:  38%|      | 3/8 [00:00<00:00, 326.44it/s]Calculating Metrics:  50%|     | 4/8 [00:00<00:00, 376.50it/s]Calculating Metrics:  50%|     | 4/8 [00:00<00:00, 283.18it/s]Calculating Metrics: 100%|| 8/8 [00:00<00:00, 447.40it/s]Calculating Metrics: 100%|| 8/8 [00:00<00:00, 414.83it/s]Calculating Metrics: 100%|| 8/8 [00:00<00:00, 411.76it/s]Calculating Metrics: 100%|| 8/8 [00:00<00:00, 408.70it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_be_null:positive_mostly_pandas] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/8 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/8 [00:00<?, ?it/s]Calculating Metrics:  25%|       | 2/8 [00:00<00:00, 2844.56it/s]Calculating Metrics:  25%|       | 2/8 [00:00<00:00, 417.12it/s] Calculating Metrics:  38%|      | 3/8 [00:00<00:00, 578.37it/s]Calculating Metrics:  38%|      | 3/8 [00:00<00:00, 335.49it/s]Calculating Metrics:  50%|     | 4/8 [00:00<00:00, 403.22it/s]Calculating Metrics:  50%|     | 4/8 [00:00<00:00, 300.60it/s]Calculating Metrics: 100%|| 8/8 [00:00<00:00, 456.75it/s]Calculating Metrics: 100%|| 8/8 [00:00<00:00, 416.06it/s]Calculating Metrics: 100%|| 8/8 [00:00<00:00, 412.37it/s]Calculating Metrics: 100%|| 8/8 [00:00<00:00, 407.52it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_be_null:negative_no_mostly_one_missing_pandas] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/8 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/8 [00:00<?, ?it/s]Calculating Metrics:  25%|       | 2/8 [00:00<00:00, 2937.19it/s]Calculating Metrics:  25%|       | 2/8 [00:00<00:00, 430.30it/s] Calculating Metrics:  38%|      | 3/8 [00:00<00:00, 596.80it/s]Calculating Metrics:  38%|      | 3/8 [00:00<00:00, 341.15it/s]Calculating Metrics:  50%|     | 4/8 [00:00<00:00, 412.38it/s]Calculating Metrics:  50%|     | 4/8 [00:00<00:00, 310.32it/s]Calculating Metrics: 100%|| 8/8 [00:00<00:00, 494.39it/s]Calculating Metrics: 100%|| 8/8 [00:00<00:00, 456.47it/s]Calculating Metrics: 100%|| 8/8 [00:00<00:00, 453.39it/s]Calculating Metrics: 100%|| 8/8 [00:00<00:00, 449.85it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_be_null:negative_mostly] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/8 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/8 [00:00<?, ?it/s]Calculating Metrics:  25%|       | 2/8 [00:00<00:00, 3003.44it/s]Calculating Metrics:  25%|       | 2/8 [00:00<00:00, 427.36it/s] Calculating Metrics:  38%|      | 3/8 [00:00<00:00, 591.94it/s]Calculating Metrics:  38%|      | 3/8 [00:00<00:00, 338.68it/s]Calculating Metrics:  50%|     | 4/8 [00:00<00:00, 407.46it/s]Calculating Metrics:  50%|     | 4/8 [00:00<00:00, 306.11it/s]Calculating Metrics: 100%|| 8/8 [00:00<00:00, 485.40it/s]Calculating Metrics: 100%|| 8/8 [00:00<00:00, 448.50it/s]Calculating Metrics: 100%|| 8/8 [00:00<00:00, 445.58it/s]Calculating Metrics: 100%|| 8/8 [00:00<00:00, 442.18it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_be_null:positive_case_with_mostly_and_no_unexpected_values] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/8 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/8 [00:00<?, ?it/s]Calculating Metrics:  25%|       | 2/8 [00:00<00:00, 2481.84it/s]Calculating Metrics:  25%|       | 2/8 [00:00<00:00, 409.24it/s] Calculating Metrics:  38%|      | 3/8 [00:00<00:00, 570.68it/s]Calculating Metrics:  38%|      | 3/8 [00:00<00:00, 329.96it/s]Calculating Metrics:  50%|     | 4/8 [00:00<00:00, 397.97it/s]Calculating Metrics:  50%|     | 4/8 [00:00<00:00, 291.44it/s]Calculating Metrics: 100%|| 8/8 [00:00<00:00, 458.34it/s]Calculating Metrics: 100%|| 8/8 [00:00<00:00, 424.72it/s]Calculating Metrics: 100%|| 8/8 [00:00<00:00, 422.03it/s]Calculating Metrics: 100%|| 8/8 [00:00<00:00, 418.95it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_be_null:negative_case_with_75percent_null_values_no_mostly] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/8 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/8 [00:00<?, ?it/s]Calculating Metrics:  25%|       | 2/8 [00:00<00:00, 2928.98it/s]Calculating Metrics:  25%|       | 2/8 [00:00<00:00, 430.38it/s] Calculating Metrics:  38%|      | 3/8 [00:00<00:00, 597.03it/s]Calculating Metrics:  38%|      | 3/8 [00:00<00:00, 339.87it/s]Calculating Metrics:  50%|     | 4/8 [00:00<00:00, 410.34it/s]Calculating Metrics:  50%|     | 4/8 [00:00<00:00, 308.64it/s]Calculating Metrics: 100%|| 8/8 [00:00<00:00, 488.22it/s]Calculating Metrics: 100%|| 8/8 [00:00<00:00, 450.68it/s]Calculating Metrics: 100%|| 8/8 [00:00<00:00, 447.73it/s]Calculating Metrics: 100%|| 8/8 [00:00<00:00, 444.32it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_regex_list:basic_positive_test] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2736.90it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 281.30it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 396.47it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 206.59it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 272.45it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 209.79it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 340.37it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 317.57it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 316.29it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 314.86it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_regex_list:positive_test_with_multiple_regexes] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2232.20it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 275.71it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 392.63it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 219.24it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 289.64it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 224.70it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 362.82it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 337.18it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 335.77it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 334.19it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_regex_list:basic_negative_test] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2937.19it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 280.71it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 398.72it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 223.40it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 298.13it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 230.86it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 366.41it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 339.08it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 337.44it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 335.79it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_regex_list:negative_test_with_more_string-ish_strings] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2862.03it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 181.39it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 253.29it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 128.90it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 174.53it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 135.50it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 219.02it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 203.62it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 202.86it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 202.02it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_regex_list:positive_test_with_match_on__any] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 1962.25it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 94.12it/s]  Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 135.03it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 75.53it/s] Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 106.90it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 84.66it/s] Calculating Metrics: 100%|| 10/10 [00:00<00:00, 120.41it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 105.14it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 104.83it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 104.56it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_regex_list:positive_test_column_name_has_space_and_match_on__any] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 1846.90it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 96.33it/s]  Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 139.48it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 92.23it/s] Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 112.40it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 45.17it/s] Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 45.17it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 45.17it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 45.17it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 45.17it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 58.50it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_z_scores_to_be_less_than:basic_successful_test] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 1727.12it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 46.75it/s]  Calculating Metrics:  23%|       | 3/13 [00:00<00:00, 68.92it/s]Calculating Metrics:  23%|       | 3/13 [00:00<00:00, 34.65it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 64.86it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 46.11it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 46.11it/s]Calculating Metrics:  62%|   | 8/13 [00:00<00:00, 46.11it/s]Calculating Metrics:  62%|   | 8/13 [00:00<00:00, 46.11it/s]Calculating Metrics:  69%|   | 9/13 [00:00<00:00, 46.11it/s]Calculating Metrics:  69%|   | 9/13 [00:00<00:00, 46.11it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 46.11it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 46.11it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 46.11it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 59.27it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_z_scores_to_be_less_than:basic_unsuccessful_test] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 1763.42it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 38.69it/s]  Calculating Metrics:  23%|       | 3/13 [00:00<00:00, 57.19it/s]Calculating Metrics:  23%|       | 3/13 [00:00<00:00, 34.84it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 66.08it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 46.95it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 46.95it/s]Calculating Metrics:  62%|   | 8/13 [00:00<00:00, 46.95it/s]Calculating Metrics:  62%|   | 8/13 [00:00<00:00, 46.95it/s]Calculating Metrics:  69%|   | 9/13 [00:00<00:00, 46.95it/s]Calculating Metrics:  69%|   | 9/13 [00:00<00:00, 46.95it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 46.95it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 46.95it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 46.95it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 63.99it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_z_scores_to_be_less_than:basic_test_with_outlier] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 1800.52it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 131.30it/s] Calculating Metrics:  23%|       | 3/13 [00:00<00:00, 190.81it/s]Calculating Metrics:  23%|       | 3/13 [00:00<00:00, 36.76it/s] Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 69.86it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 50.49it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 50.49it/s]Calculating Metrics:  62%|   | 8/13 [00:00<00:00, 50.49it/s]Calculating Metrics:  62%|   | 8/13 [00:00<00:00, 50.49it/s]Calculating Metrics:  69%|   | 9/13 [00:00<00:00, 50.49it/s]Calculating Metrics:  69%|   | 9/13 [00:00<00:00, 50.49it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 50.49it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 50.49it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 50.49it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 71.67it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_z_scores_to_be_less_than:basic_test_mostly_zero] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2387.20it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 111.98it/s] Calculating Metrics:  23%|       | 3/13 [00:00<00:00, 160.97it/s]Calculating Metrics:  23%|       | 3/13 [00:00<00:00, 90.06it/s] Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 159.19it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 114.32it/s]Calculating Metrics:  62%|   | 8/13 [00:00<00:00, 141.73it/s]Calculating Metrics:  62%|   | 8/13 [00:00<00:00, 120.18it/s]Calculating Metrics:  69%|   | 9/13 [00:00<00:00, 130.26it/s]Calculating Metrics:  69%|   | 9/13 [00:00<00:00, 117.24it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 152.36it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 144.07it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 143.65it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 143.29it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_z_scores_to_be_less_than:basic_test_with_missing] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 1883.39it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 148.69it/s] Calculating Metrics:  23%|       | 3/13 [00:00<00:00, 212.77it/s]Calculating Metrics:  23%|       | 3/13 [00:00<00:00, 117.91it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 214.33it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 153.83it/s]Calculating Metrics:  62%|   | 8/13 [00:00<00:00, 187.38it/s]Calculating Metrics:  62%|   | 8/13 [00:00<00:00, 151.08it/s]Calculating Metrics:  69%|   | 9/13 [00:00<00:00, 161.24it/s]Calculating Metrics:  69%|   | 9/13 [00:00<00:00, 140.69it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 182.91it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 170.00it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 169.41it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 168.86it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:basic_positive_test0] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2518.35it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 178.82it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 257.44it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 129.71it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 180.67it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 147.19it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 242.54it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 228.70it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 227.88it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 227.13it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:another_basic_positive_test0] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2319.86it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 185.92it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 267.07it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 161.18it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 215.28it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 149.50it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 227.37it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 207.62it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 206.85it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 205.97it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:basic_positive_test_with_timestamps0] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2770.35it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 170.22it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 242.83it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 118.70it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 173.04it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 143.70it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 228.20it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 215.87it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 215.16it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 214.47it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:missing_min_value0] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2674.09it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 234.50it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 334.82it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 183.68it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 263.88it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 198.10it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 308.10it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 284.97it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 283.77it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 282.61it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:null_min_value0] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2797.14it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 231.37it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 328.95it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 181.02it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 257.40it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 193.38it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 301.15it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 278.99it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 277.92it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 276.78it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:missing_max_value0] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2754.88it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 235.77it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 336.13it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 181.72it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 261.35it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 197.89it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 309.00it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 285.62it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 284.45it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 283.27it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:null_max_value0] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2764.87it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 236.13it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 336.77it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 184.89it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 262.52it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 198.59it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 304.03it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 281.59it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 280.46it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 279.31it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:basic_negative_test0] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2765.78it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 251.16it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 357.23it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 195.99it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 275.26it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 208.74it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 308.66it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 281.02it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 279.57it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 278.27it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:another_negative_test0] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2655.46it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 202.53it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 290.13it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 169.03it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 240.82it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 188.70it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 270.01it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 246.79it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 245.65it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 244.55it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:basic_negative_test_with_timestamps0] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2706.00it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 249.50it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 354.48it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 183.74it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 242.68it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 188.00it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 294.87it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 275.05it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 274.00it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 272.92it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:positive_test_with_result_format__boolean_only0] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/7 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/7 [00:00<?, ?it/s]Calculating Metrics:  29%|       | 2/7 [00:00<00:00, 2789.69it/s]Calculating Metrics:  29%|       | 2/7 [00:00<00:00, 446.94it/s] Calculating Metrics:  43%|     | 3/7 [00:00<00:00, 596.18it/s]Calculating Metrics:  43%|     | 3/7 [00:00<00:00, 354.07it/s]Calculating Metrics:  71%|  | 5/7 [00:00<00:00, 443.04it/s]Calculating Metrics:  71%|  | 5/7 [00:00<00:00, 364.65it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 462.72it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 426.98it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 423.89it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 420.32it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:another_positive_test_with_result_format__boolean_only0] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/7 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/7 [00:00<?, ?it/s]Calculating Metrics:  29%|       | 2/7 [00:00<00:00, 2781.37it/s]Calculating Metrics:  29%|       | 2/7 [00:00<00:00, 430.65it/s] Calculating Metrics:  43%|     | 3/7 [00:00<00:00, 586.04it/s]Calculating Metrics:  43%|     | 3/7 [00:00<00:00, 349.24it/s]Calculating Metrics:  71%|  | 5/7 [00:00<00:00, 412.99it/s]Calculating Metrics:  71%|  | 5/7 [00:00<00:00, 341.18it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 434.70it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 402.41it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 399.43it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 395.50it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:negative_test_with_result_format__boolean_only0] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/7 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/7 [00:00<?, ?it/s]Calculating Metrics:  29%|       | 2/7 [00:00<00:00, 2840.71it/s]Calculating Metrics:  29%|       | 2/7 [00:00<00:00, 457.84it/s] Calculating Metrics:  43%|     | 3/7 [00:00<00:00, 631.01it/s]Calculating Metrics:  43%|     | 3/7 [00:00<00:00, 370.50it/s]Calculating Metrics:  71%|  | 5/7 [00:00<00:00, 459.25it/s]Calculating Metrics:  71%|  | 5/7 [00:00<00:00, 361.40it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 433.38it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 387.27it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 383.81it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 380.51it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:another_negative_test_with_result_format__boolean_only0] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/7 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/7 [00:00<?, ?it/s]Calculating Metrics:  29%|       | 2/7 [00:00<00:00, 2789.69it/s]Calculating Metrics:  29%|       | 2/7 [00:00<00:00, 455.58it/s] Calculating Metrics:  43%|     | 3/7 [00:00<00:00, 627.61it/s]Calculating Metrics:  43%|     | 3/7 [00:00<00:00, 368.97it/s]Calculating Metrics:  71%|  | 5/7 [00:00<00:00, 458.81it/s]Calculating Metrics:  71%|  | 5/7 [00:00<00:00, 374.34it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 474.19it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 435.78it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 432.31it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 428.50it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:positive_test_with_mostly0] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2813.08it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 242.25it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 339.71it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 171.46it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 233.66it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 178.63it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 269.53it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 251.57it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 250.56it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 249.63it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:2nd_positive_test_with_mostly0] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2797.14it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 230.34it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 328.95it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 182.45it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 257.56it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 194.02it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 285.54it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 261.32it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 259.69it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 258.13it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:3rd_positive_test_with_mostly0] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2663.05it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 244.68it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 348.03it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 166.50it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 230.58it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 180.42it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 282.12it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 263.57it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 262.50it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 261.44it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:negative_test_with_mostly0] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2763.05it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 250.57it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 356.26it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 157.38it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 227.02it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 175.02it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 270.60it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 253.21it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 252.25it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 251.30it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:error:_improperly_mixed_types0] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2002.05it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 240.07it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 341.93it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 187.99it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 92.54it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 70.01it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 53.99it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 69.16it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 61.69it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 75.48it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 68.68it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 68.16it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 68.01it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:error:_improperly_mixed_types_again0] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2490.68it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 225.30it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 321.48it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 161.14it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 102.15it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 72.37it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 57.40it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 74.51it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 64.34it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 78.93it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 69.45it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 68.91it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 68.75it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:error:_improperly_mixed_types_once_more0] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2454.24it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 167.91it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 242.54it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 139.79it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 81.09it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 54.35it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 43.08it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 55.63it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 49.98it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 60.91it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 54.12it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 53.60it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 53.45it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:negative_test_to_verify_that_the_denominator_for_mostly_works_with_missing_values0] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 1755.67it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 164.39it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 237.59it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 132.50it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 183.52it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 143.22it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 211.69it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 192.63it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 191.66it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 190.79it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:positive_test_to_verify_that_the_denominator_for_mostly_works_with_missing_values0] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2824.45it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 156.18it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 221.45it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 117.08it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 173.36it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 137.81it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 221.51it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 201.61it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 200.64it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 199.70it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:error_on_string-to-int_comparisons0] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 1962.71it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 149.78it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 213.20it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 121.39it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 74.83it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 56.47it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 44.00it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 56.72it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 50.78it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 62.33it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 55.21it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 54.87it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 54.77it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:test_min_value_is_greater_than_max_value0] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 1843.65it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 158.10it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 227.24it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 122.29it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 81.48it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 61.23it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 47.12it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 61.19it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 52.58it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 64.36it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 57.29it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 56.92it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 56.82it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:test_allow_cross_type_comparisons0] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2761.23it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 200.76it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 281.10it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 153.73it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 208.53it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 147.59it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 225.38it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 210.90it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 209.73it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 208.67it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:test_allow_cross_type_comparisons_again0] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2769.43it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 178.24it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 252.44it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 137.63it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 192.37it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 137.56it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 223.39it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 211.83it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 211.04it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 210.35it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:test_strict_min_failure0] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 1585.75it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 142.18it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 203.51it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 112.13it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 168.76it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 135.59it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 208.62it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 195.50it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 194.57it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 193.60it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:test_strict_min_success0] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 1416.52it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 136.10it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 197.90it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 109.22it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 155.98it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 120.10it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 192.35it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 179.17it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 178.58it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 177.78it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:test_strict_max_failure0] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2274.57it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 154.97it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 220.25it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 116.74it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 172.16it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 140.17it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 223.24it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 211.15it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 210.43it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 209.76it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:test_strict_max_success0] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2364.99it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 200.74it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 287.75it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 159.87it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 225.90it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 174.13it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 267.75it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 248.81it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 247.41it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 246.00it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:test_conditional_expectation_passes0] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 308.97it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 143.35it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 209.15it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 153.53it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 184.61it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 150.48it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 212.37it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 203.80it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 202.68it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 201.70it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:test_conditional_expectation_fails0] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 285.07it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 131.59it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 189.59it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 134.20it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 166.08it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 140.78it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 189.41it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 178.12it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 177.35it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 176.63it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:test_conditional_expectation_parser_errors0] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_regex:negative_test_insufficient_mostly_and_one_non_matching_value] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 1669.71it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 158.00it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 228.37it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 135.34it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 195.73it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 153.11it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 237.46it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 219.20it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 218.07it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 216.95it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_regex:negative_test_insufficient_mostly_and_one_non_matching_value_summary_output] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 1913.90it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 165.33it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 233.92it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 140.53it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 207.43it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 166.77it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 273.55it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 255.01it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 253.64it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 252.25it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_regex:positive_test_exact_mostly_w_one_non_matching_value] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2516.08it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 164.91it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 233.77it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 140.02it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 196.97it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 150.00it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 245.18it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 232.20it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 231.26it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 230.35it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_regex:positive_test_column_name_has_space] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2762.14it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 234.82it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 333.85it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 200.09it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 275.12it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 217.58it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 341.11it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 319.23it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 317.87it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 316.40it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_regex:positive_test_sufficient_mostly_w_one_non_matching_value] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2516.08it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 283.12it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 399.62it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 228.26it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 318.55it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 246.40it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 387.79it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 357.65it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 355.80it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 353.94it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_regex:negative_test_one_missing_value_and_insufficent_mostly] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2941.31it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 302.72it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 429.42it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 234.96it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 329.25it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 252.64it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 394.26it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 366.29it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 364.71it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 362.87it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_regex:positive_test_one_missing_value_and_exact_mostly] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2394.69it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 289.14it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 410.05it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 228.14it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 322.73it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 248.82it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 381.81it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 354.81it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 352.87it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 350.84it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_regex:positive_test_one_missing_value_and_sufficent_mostly] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2865.94it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 269.83it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 380.86it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 200.64it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 286.06it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 225.82it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 348.27it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 324.69it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 322.35it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 320.70it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_regex:positive_test_all_missing_values] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2845.53it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 272.37it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 381.88it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 215.06it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 301.46it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 236.02it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 375.70it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 349.26it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 347.67it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 345.95it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_regex:positive_test_all_missing_values_mostly] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2680.92it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 295.86it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 417.84it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 231.71it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 327.47it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 250.58it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 393.61it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 364.60it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 362.57it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 360.66it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_regex:positive_test_empty_regex] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2954.78it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 299.23it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 419.12it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 234.73it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 311.94it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 239.76it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 379.25it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 352.80it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 351.22it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 349.49it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_regex:positive_test_more_complicated_regex] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2648.76it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 290.83it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 411.00it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 222.52it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 296.53it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 232.36it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 370.47it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 345.33it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 343.87it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 342.21it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_regex:positive_test_match_characters_not_at_the_beginning_of_string] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2864.96it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 281.88it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 398.41it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 228.68it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 317.56it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 241.57it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 379.88it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 353.22it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 351.61it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 349.86it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:basic_positive_test1] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2325.65it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 238.41it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 340.17it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 184.86it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 254.30it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 196.65it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 307.72it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 283.23it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 281.94it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 280.73it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:another_basic_positive_test1] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2858.13it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 249.82it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 356.77it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 196.30it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 278.18it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 211.67it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 327.34it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 300.58it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 299.17it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 297.81it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:basic_positive_test_with_timestamps1] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2844.56it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 246.69it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 352.06it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 194.44it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 262.75it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 198.80it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 304.65it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 283.03it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 281.82it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 280.66it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:missing_min_value1] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2821.60it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 224.29it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 319.66it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 176.42it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 253.22it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 192.41it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 304.33it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 281.50it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 280.51it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 279.38it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:null_min_value1] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2889.63it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 231.51it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 331.23it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 182.89it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 264.48it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 198.51it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 310.70it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 287.51it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 286.51it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 285.36it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:missing_max_value1] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2857.16it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 237.05it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 339.64it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 181.82it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 262.70it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 193.90it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 300.55it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 275.21it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 273.92it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 272.69it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:null_max_value1] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2400.86it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 203.19it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 291.41it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 167.46it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 244.68it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 185.25it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 293.31it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 270.34it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 269.28it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 268.17it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:basic_negative_test1] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2877.74it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 250.26it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 356.76it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 193.02it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 273.63it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 206.36it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 306.88it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 284.54it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 283.25it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 282.07it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:another_negative_test1] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2347.78it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 222.69it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 318.38it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 181.92it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 254.65it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 193.32it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 300.39it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 280.05it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 279.09it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 277.99it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:basic_negative_test_with_timestamps1] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2865.94it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 249.69it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 356.38it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 196.43it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 267.85it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 205.17it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 317.86it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 294.73it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 293.62it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 292.41it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:positive_test_with_result_format__boolean_only1] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/7 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/7 [00:00<?, ?it/s]Calculating Metrics:  29%|       | 2/7 [00:00<00:00, 2890.63it/s]Calculating Metrics:  29%|       | 2/7 [00:00<00:00, 452.31it/s] Calculating Metrics:  43%|     | 3/7 [00:00<00:00, 620.73it/s]Calculating Metrics:  43%|     | 3/7 [00:00<00:00, 363.47it/s]Calculating Metrics:  71%|  | 5/7 [00:00<00:00, 456.09it/s]Calculating Metrics:  71%|  | 5/7 [00:00<00:00, 373.58it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 474.04it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 436.82it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 433.71it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 429.93it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:another_positive_test_with_result_format__boolean_only1] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/7 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/7 [00:00<?, ?it/s]Calculating Metrics:  29%|       | 2/7 [00:00<00:00, 2848.42it/s]Calculating Metrics:  29%|       | 2/7 [00:00<00:00, 456.40it/s] Calculating Metrics:  43%|     | 3/7 [00:00<00:00, 628.39it/s]Calculating Metrics:  43%|     | 3/7 [00:00<00:00, 363.41it/s]Calculating Metrics:  71%|  | 5/7 [00:00<00:00, 451.25it/s]Calculating Metrics:  71%|  | 5/7 [00:00<00:00, 366.99it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 461.34it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 424.65it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 421.48it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 417.91it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:negative_test_with_result_format__boolean_only1] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/7 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/7 [00:00<?, ?it/s]Calculating Metrics:  29%|       | 2/7 [00:00<00:00, 2829.21it/s]Calculating Metrics:  29%|       | 2/7 [00:00<00:00, 443.84it/s] Calculating Metrics:  43%|     | 3/7 [00:00<00:00, 612.25it/s]Calculating Metrics:  43%|     | 3/7 [00:00<00:00, 361.74it/s]Calculating Metrics:  71%|  | 5/7 [00:00<00:00, 445.19it/s]Calculating Metrics:  71%|  | 5/7 [00:00<00:00, 364.94it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 463.36it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 427.90it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 424.94it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 421.40it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:another_negative_test_with_result_format__boolean_only1] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/7 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/7 [00:00<?, ?it/s]Calculating Metrics:  29%|       | 2/7 [00:00<00:00, 2985.27it/s]Calculating Metrics:  29%|       | 2/7 [00:00<00:00, 464.69it/s] Calculating Metrics:  43%|     | 3/7 [00:00<00:00, 640.09it/s]Calculating Metrics:  43%|     | 3/7 [00:00<00:00, 373.37it/s]Calculating Metrics:  71%|  | 5/7 [00:00<00:00, 461.55it/s]Calculating Metrics:  71%|  | 5/7 [00:00<00:00, 376.96it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 477.75it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 440.34it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 437.25it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 432.50it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:positive_test_with_mostly1] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2395.38it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 240.85it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 343.30it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 192.32it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 273.03it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 208.74it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 328.71it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 304.65it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 303.55it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 302.24it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:2nd_positive_test_with_mostly1] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2941.31it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 253.23it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 362.19it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 197.35it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 280.49it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 211.10it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 329.62it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 304.26it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 302.94it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 301.62it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:3rd_positive_test_with_mostly1] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2993.79it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 258.52it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 368.77it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 199.81it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 282.72it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 213.21it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 324.56it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 293.09it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 291.60it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 290.31it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:negative_test_with_mostly1] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2797.14it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 251.99it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 360.23it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 197.97it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 281.20it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 213.33it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 329.63it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 305.45it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 304.31it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 303.00it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:error:_improperly_mixed_types1] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2954.78it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 255.45it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 365.76it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 199.10it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 120.79it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 86.66it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 67.43it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 87.30it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 76.51it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 93.77it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 84.15it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 83.40it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 83.17it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:error:_improperly_mixed_types_again1] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2836.86it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 252.36it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 360.15it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 187.78it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 115.48it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 84.40it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 66.67it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 86.54it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 75.98it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 93.15it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 83.61it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 82.91it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 82.69it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:error:_improperly_mixed_types_once_more1] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2906.66it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 252.27it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 360.87it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 194.29it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 119.47it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 86.92it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 68.38it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 88.65it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 77.54it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 94.98it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 85.27it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 84.57it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 84.36it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:negative_test_to_verify_that_the_denominator_for_mostly_works_with_missing_values1] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2919.81it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 254.19it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 363.73it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 199.18it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 281.34it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 212.74it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 330.22it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 305.64it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 304.44it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 303.12it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:positive_test_to_verify_that_the_denominator_for_mostly_works_with_missing_values1] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2510.06it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 253.03it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 362.28it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 197.08it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 282.39it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 213.83it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 332.35it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 307.95it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 306.83it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 305.52it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:error_on_string-to-int_comparisons1] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2915.75it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 253.65it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 362.93it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 195.68it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 119.61it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 86.85it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 68.15it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 88.47it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 77.42it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 94.87it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 85.29it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 84.61it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 84.40it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:test_min_value_is_greater_than_max_value1] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2692.11it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 248.60it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 354.54it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 194.36it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 116.79it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 79.50it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 62.35it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 80.89it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 71.58it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 87.69it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 79.13it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 78.50it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 78.27it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:test_allow_cross_type_comparisons1] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2306.46it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 262.23it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 372.75it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 205.52it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 291.13it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 223.21it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 330.11it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 306.52it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 304.91it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 303.47it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:test_allow_cross_type_comparisons_again1] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2848.42it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 262.05it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 371.37it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 207.70it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 294.76it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 222.04it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 339.04it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 313.39it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 311.83it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 310.37it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:test_strict_min_failure1] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2898.62it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 256.04it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 366.66it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 199.36it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 279.98it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 213.14it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 332.10it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 307.64it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 306.53it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 305.26it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:test_strict_min_success1] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 3006.67it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 255.36it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 365.81it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 196.17it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 277.58it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 208.51it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 326.70it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 301.62it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 300.46it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 299.16it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:test_strict_max_failure1] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2864.96it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 255.46it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 365.05it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 198.92it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 281.80it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 213.81it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 329.65it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 305.32it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 304.18it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 302.86it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:test_strict_max_success1] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2845.53it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 256.45it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 366.85it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 199.15it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 278.57it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 211.06it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 328.03it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 301.49it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 300.15it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 298.81it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:test_conditional_expectation_passes1] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 432.07it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 198.57it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 287.03it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 190.03it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 228.98it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 187.94it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 265.61it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 252.11it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 251.19it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 250.27it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:test_conditional_expectation_fails1] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 526.72it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 215.89it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 312.79it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 203.48it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 246.93it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 204.14it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 281.33it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 266.99it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 266.11it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 265.10it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:test_conditional_expectation_parser_errors1] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_be_in_set:basic_positive_test_case_single_value_not_in_column] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2778.60it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 274.08it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 388.87it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 217.75it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 309.05it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 236.31it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 375.74it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 348.23it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 346.78it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 345.08it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_be_in_set:negative_test_case_include_one_existing_column_value] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 3164.32it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 288.52it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 410.62it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 225.17it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 317.56it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 241.06it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 376.45it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 349.00it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 347.52it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 345.85it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_be_in_set:positive_empty_values_set] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2998.07it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 288.53it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 409.45it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 225.73it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 321.09it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 244.76it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 384.03it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 355.19it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 353.59it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 351.82it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_be_in_set:basic_negative_strings_set_all_character_values] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2915.75it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 278.52it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 395.27it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 216.00it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 307.24it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 235.36it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 366.25it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 339.43it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 338.02it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 336.43it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_be_in_set:positive_test_strings_set_extra_value_in_column] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2968.37it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 275.44it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 390.83it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 219.52it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 312.74it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 238.21it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 375.74it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 347.83it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 346.22it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 344.50it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_be_in_set:negative_test_float_set_two_out_of_three_column_values_included_mostly] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2902.63it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 257.37it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 364.83it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 200.88it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 287.60it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 218.64it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 342.82it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 317.83it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 316.56it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 315.08it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_be_in_set:negative_test_float_set_two_out_of_three_column_values_included_mostly_summary_output] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2957.90it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 267.77it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 382.41it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 209.16it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 301.22it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 227.87it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 360.59it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 333.42it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 332.07it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 330.52it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_be_in_set:positive_test_float_set_two_out_of_three_column_values_included_mostly] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 3100.00it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 268.32it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 383.09it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 210.16it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 303.14it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 228.75it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 359.67it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 332.19it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 330.83it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 329.27it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_be_in_set:positive_test_values_set_is_null] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2515.32it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 259.36it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 370.46it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 191.63it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 275.31it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 212.02it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 337.49it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 313.11it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 311.93it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 310.59it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_of_type:basic_python_int_positive_test] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 2211.02it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1533.57it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1308.68it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1118.18it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_of_type:negative_test_python_ints_are_not_string] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 2341.88it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1597.83it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1360.46it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1157.37it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_of_type:positive_test_pandas_floats] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 2235.77it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1540.32it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1314.01it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1118.48it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_of_type:positive_test_pandas_strings] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2989.53it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 304.97it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 433.03it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 238.57it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 321.92it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 247.84it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 386.68it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 359.15it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 357.62it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 355.80it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_of_type:negative_test_python_floats_are_not_python_bools] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 2364.32it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1610.10it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1366.22it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1161.54it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_of_type:dtype_object_and_type_object_still_has_aggregate_semantics] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 2357.68it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1612.57it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1373.38it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1169.63it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_of_type:dtype_object_and_type_object_still_has_aggregate_semantics_object_underscore] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 2376.38it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1623.81it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1377.44it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1172.25it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_of_type:dtype_object_and_type_object_still_has_aggregate_semantics_big_o] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 2359.00it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1610.72it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1368.01it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1164.11it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_of_type:positive_pandas_datetime_no_timezone] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 2385.84it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1625.70it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1380.61it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1174.88it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_of_type:positive_pandas_datetime_with_timezone] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 2391.28it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1628.22it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1382.89it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1176.19it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_of_type:negative_pandas_datetime_with_timezone] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 2371.00it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1623.81it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1377.44it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1172.58it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_of_type:negative_pandas_datetime_expected_int] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 2398.12it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1630.76it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1383.35it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1176.19it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_in_set:basic_positive_test_case_number_set] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 3220.20it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 283.52it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 403.87it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 216.12it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 305.66it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 233.15it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 368.74it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 341.53it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 340.11it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 338.47it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_in_set:vacuously_true_empty_value_set] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2966.27it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 253.46it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 360.40it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 201.00it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 288.50it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 218.75it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 342.33it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 314.81it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 313.23it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 311.68it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_in_set:negative_test_case_exclude_existing_column_value] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2948.54it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 289.22it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 411.92it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 217.15it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 309.88it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 236.72it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 372.15it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 344.78it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 343.32it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 341.62it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_in_set:negative_empty_values_set] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2845.53it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 279.02it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 395.73it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 210.97it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 297.70it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 230.83it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 354.94it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 330.27it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 328.96it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 327.44it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_in_set:basic_positive_strings_set] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2535.09it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 280.00it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 398.79it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 216.58it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 307.00it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 232.24it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 366.96it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 339.96it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 338.55it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 336.93it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_in_set:negative_test_strings_set_extra_value_in_column] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2901.63it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 278.98it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 394.72it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 218.72it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 300.37it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 229.95it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 355.07it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 330.16it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 328.85it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 327.33it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_in_set:negative_test_numbers_set_no_matching_values] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2813.08it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 282.41it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 400.81it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 222.63it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 318.74it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 242.60it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 381.26it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 353.13it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 351.67it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 349.97it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_in_set:positive_test_float_set] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2666.44it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 263.40it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 376.54it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 204.15it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 293.43it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 222.90it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 348.72it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 322.21it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 320.90it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 319.44it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_in_set:negative_test_float_set] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2923.88it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 263.20it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 374.87it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 205.80it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 296.88it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 224.35it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 355.90it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 329.07it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 327.81it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 326.32it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_in_set:test_conditional_expectation_passes] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 528.68it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 235.60it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 340.33it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 229.94it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 286.76it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 238.63it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 340.40it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 321.42it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 319.97it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 318.49it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_in_set:test_conditional_expectation_fails] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 636.75it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 264.35it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 381.24it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 247.97it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 305.12it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 251.48it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 351.95it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 333.86it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 332.55it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 331.00it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_in_set:test_conditional_expectation_parser_errors] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_in_set:test_empty_column_should_be_vacuously_true] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2785.06it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 275.86it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 391.13it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 218.65it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 314.94it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 239.70it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 383.49it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 354.27it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 352.61it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 350.83it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_in_set:basic_positive_test_case_datetime_set] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 1687.85it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 255.56it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 364.26it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 209.48it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 295.39it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 227.07it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 358.16it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 332.88it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 331.59it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 330.08it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_in_set:basic_negative_test_case_datetime_set] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 1823.21it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 176.76it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 254.74it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 146.98it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 214.19it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 175.90it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 287.41it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 270.51it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 269.62it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 268.59it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_decreasing:positive_test_with_mostly] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 3025.10it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 286.65it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 407.99it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 224.11it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 288.90it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 225.15it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 354.51it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 331.53it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 330.26it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 328.81it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_decreasing:basic_negative_test] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 3053.73it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 305.67it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 433.22it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 239.12it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 314.96it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 240.84it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 382.59it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 355.59it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 353.34it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 351.53it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_decreasing:basic_negative_test_with_strictly] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 3072.75it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 294.81it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 418.70it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 232.27it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 304.42it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 236.34it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 375.19it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 349.37it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 347.98it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 346.37it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_decreasing:basic_positive_test] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 3367.57it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 300.33it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 427.18it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 235.02it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 312.84it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 242.70it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 388.82it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 361.26it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 359.76it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 358.03it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_decreasing:test_empty_column_should_be_vacuously_true] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 3010.99it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 300.88it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 428.37it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 236.44it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 318.91it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 245.77it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 393.70it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 365.41it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 363.78it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 361.95it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_match_regex:negative_test_insufficient_mostly_and_one_non_matching_value] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 3049.29it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 318.58it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 451.81it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 250.48it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 347.08it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 265.92it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 416.90it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 386.92it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 385.24it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 383.22it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_match_regex:positive_test_exact_mostly_w_one_non_matching_value] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 3006.67it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 306.09it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 433.07it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 235.96it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 327.43it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 252.88it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 399.92it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 370.14it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 368.24it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 366.34it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_match_regex:positive_test_sufficient_mostly_w_one_non_matching_value] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2923.88it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 298.60it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 423.42it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 238.28it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 335.62it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 259.47it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 409.68it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 380.84it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 379.22it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 377.30it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_match_regex:negative_test_one_missing_value_and_insufficent_mostly] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 3303.90it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 313.03it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 444.42it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 246.24it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 347.26it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 265.32it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 412.52it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 382.48it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 380.79it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 378.89it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_match_regex:positive_test_one_missing_value_no_exceptions] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 3320.91it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 320.05it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 454.19it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 250.02it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 349.85it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 267.09it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 422.22it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 391.14it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 389.39it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 387.37it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_match_regex:positive_test_all_missing_values] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2567.68it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 307.50it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 436.48it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 244.38it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 346.19it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 264.12it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 413.70it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 383.63it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 381.95it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 379.98it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_match_regex:positive_test_all_missing_values_mostly] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 3316.97it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 319.59it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 453.24it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 249.55it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 356.92it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 271.06it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 427.94it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 396.22it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 394.45it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 392.41it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_match_regex:negative_test_empty_regex] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 3039.35it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 291.76it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 414.47it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 237.21it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 333.18it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 257.33it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 407.32it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 378.62it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 377.03it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 375.15it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_match_regex:negative_test_match_characters_not_at_the_beginning_of_string_exact_mostly] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 3472.11it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 323.63it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 459.28it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 252.02it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 350.65it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 268.46it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 416.18it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 385.27it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 383.47it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 381.45it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_dateutil_parseable:positive_test] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2637.93it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 339.50it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 479.55it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 264.62it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 361.92it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 281.78it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 439.21it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 409.16it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 407.17it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 404.94it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_dateutil_parseable:positive_test_with_nulls] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2950.62it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 339.28it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 478.78it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 268.81it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 368.81it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 285.36it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 436.34it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 405.93it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 403.94it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 401.69it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_dateutil_parseable:negative_test] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 3062.65it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 345.72it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 488.28it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 273.25it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 378.77it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 291.97it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 451.88it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 420.96it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 418.99it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 416.72it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_dateutil_parseable:test_raising_exception_for_wrong_input_data_type] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 3464.94it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 349.77it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 493.76it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 275.25it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 150.21it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 110.73it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 88.37it/s] Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 114.35it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 101.24it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 123.79it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 112.63it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 111.80it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 111.44it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_match_regex_list:basic_positive_test] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2861.05it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 312.51it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 444.05it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 243.82it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 327.78it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 252.77it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 379.19it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 213.69it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 212.73it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 211.84it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_match_regex_list:positive_test_with_multiple_regexes] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 3067.13it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 308.50it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 438.02it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 242.21it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 314.17it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 244.34it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 392.93it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 365.03it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 363.51it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 361.74it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_match_regex_list:basic_negative_test] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 3101.15it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 313.38it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 445.03it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 242.89it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 315.80it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 245.69it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 391.87it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 364.30it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 362.81it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 361.06it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_match_regex_list:negative_test_with_more_string-ish_strings] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 3383.87it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 312.26it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 443.73it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 244.62it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 308.23it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 240.56it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 386.38it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 359.75it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 358.26it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 356.57it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_increasing:basic_positive_test] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 3242.60it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 298.56it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 422.49it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 221.80it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 294.36it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 228.65it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 370.19it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 345.09it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 343.72it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 342.13it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_increasing:2nd_basic_positive_test] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 3303.90it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 305.66it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 433.27it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 233.48it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 301.09it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 236.85it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 384.08it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 358.25it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 356.86it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 355.21it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_increasing:positive_test_with_strictly] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 3350.08it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 314.76it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 447.36it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 244.59it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 326.39it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 252.14it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 398.66it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 370.65it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 369.09it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 367.25it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_increasing:basic_negative_test] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 3344.74it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 311.62it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 443.28it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 244.84it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 309.68it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 241.78it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 386.74it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 359.91it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 358.47it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 356.80it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_increasing:positive_test_with_parse_strings_as_datetimes] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 3272.96it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 314.02it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 446.30it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 245.34it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 299.60it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 231.73it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 376.70it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 351.54it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 350.20it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 348.62it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_increasing:positive_test_with_interspersed_nulls] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 3350.08it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 317.15it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 450.79it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 248.20it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 326.97it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 252.76it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 404.77it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 376.11it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 374.56it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 372.77it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_increasing:negative_test_with_interspersed_nulls] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 3199.32it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 298.23it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 423.11it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 240.73it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 320.82it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 248.60it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 397.83it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 370.04it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 368.56it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 366.81it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_lengths_to_be_between:positive_test_exact_min_and_max] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:  18%|        | 2/11 [00:00<00:00, 3175.10it/s]Calculating Metrics:  18%|        | 2/11 [00:00<00:00, 236.64it/s] Calculating Metrics:  27%|       | 3/11 [00:00<00:00, 340.64it/s]Calculating Metrics:  27%|       | 3/11 [00:00<00:00, 182.11it/s]Calculating Metrics:  45%|     | 5/11 [00:00<00:00, 263.94it/s]Calculating Metrics:  45%|     | 5/11 [00:00<00:00, 195.69it/s]Calculating Metrics:  64%|   | 7/11 [00:00<00:00, 252.25it/s]Calculating Metrics:  64%|   | 7/11 [00:00<00:00, 212.44it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 292.14it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 273.44it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 272.70it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 271.84it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_lengths_to_be_between:negative_test_matching_min_max_too_small] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:  18%|        | 2/11 [00:00<00:00, 3372.98it/s]Calculating Metrics:  18%|        | 2/11 [00:00<00:00, 244.08it/s] Calculating Metrics:  27%|       | 3/11 [00:00<00:00, 351.38it/s]Calculating Metrics:  27%|       | 3/11 [00:00<00:00, 188.12it/s]Calculating Metrics:  45%|     | 5/11 [00:00<00:00, 277.39it/s]Calculating Metrics:  45%|     | 5/11 [00:00<00:00, 202.71it/s]Calculating Metrics:  64%|   | 7/11 [00:00<00:00, 259.31it/s]Calculating Metrics:  64%|   | 7/11 [00:00<00:00, 216.95it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 296.32it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 277.30it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 276.54it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 275.65it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_lengths_to_be_between:negative_test_matching_max_min_too_large] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:  18%|        | 2/11 [00:00<00:00, 3442.19it/s]Calculating Metrics:  18%|        | 2/11 [00:00<00:00, 245.34it/s] Calculating Metrics:  27%|       | 3/11 [00:00<00:00, 352.99it/s]Calculating Metrics:  27%|       | 3/11 [00:00<00:00, 189.75it/s]Calculating Metrics:  45%|     | 5/11 [00:00<00:00, 279.66it/s]Calculating Metrics:  45%|     | 5/11 [00:00<00:00, 204.17it/s]Calculating Metrics:  64%|   | 7/11 [00:00<00:00, 263.04it/s]Calculating Metrics:  64%|   | 7/11 [00:00<00:00, 219.71it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 298.08it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 278.85it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 278.09it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 277.21it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_lengths_to_be_between:positive_test_with_null_min_value] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:  18%|        | 2/11 [00:00<00:00, 3552.99it/s]Calculating Metrics:  18%|        | 2/11 [00:00<00:00, 229.46it/s] Calculating Metrics:  27%|       | 3/11 [00:00<00:00, 331.16it/s]Calculating Metrics:  27%|       | 3/11 [00:00<00:00, 177.50it/s]Calculating Metrics:  45%|     | 5/11 [00:00<00:00, 264.97it/s]Calculating Metrics:  45%|     | 5/11 [00:00<00:00, 192.35it/s]Calculating Metrics:  64%|   | 7/11 [00:00<00:00, 249.34it/s]Calculating Metrics:  64%|   | 7/11 [00:00<00:00, 207.77it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 283.12it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 264.84it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 264.15it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 263.32it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_lengths_to_be_between:positive_test_with_null_max_value] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:  18%|        | 2/11 [00:00<00:00, 3164.32it/s]Calculating Metrics:  18%|        | 2/11 [00:00<00:00, 223.41it/s] Calculating Metrics:  27%|       | 3/11 [00:00<00:00, 321.96it/s]Calculating Metrics:  27%|       | 3/11 [00:00<00:00, 173.80it/s]Calculating Metrics:  45%|     | 5/11 [00:00<00:00, 258.13it/s]Calculating Metrics:  45%|     | 5/11 [00:00<00:00, 188.88it/s]Calculating Metrics:  64%|   | 7/11 [00:00<00:00, 246.62it/s]Calculating Metrics:  64%|   | 7/11 [00:00<00:00, 206.19it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 281.84it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 263.42it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 262.74it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 261.94it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_lengths_to_be_between:negative_test_with_max_lt_min] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:  18%|        | 2/11 [00:00<00:00, 2692.11it/s]Calculating Metrics:  18%|        | 2/11 [00:00<00:00, 236.80it/s] Calculating Metrics:  27%|       | 3/11 [00:00<00:00, 340.69it/s]Calculating Metrics:  27%|       | 3/11 [00:00<00:00, 183.34it/s]Calculating Metrics:  45%|     | 5/11 [00:00<00:00, 269.54it/s]Calculating Metrics:  45%|     | 5/11 [00:00<00:00, 198.96it/s]Calculating Metrics:  64%|   | 7/11 [00:00<00:00, 255.85it/s]Calculating Metrics:  64%|   | 7/11 [00:00<00:00, 214.78it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 291.14it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 272.76it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 272.02it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 271.16it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_lengths_to_be_between:positive_test_with_missing_value_in_column] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:  18%|        | 2/11 [00:00<00:00, 3496.71it/s]Calculating Metrics:  18%|        | 2/11 [00:00<00:00, 245.70it/s] Calculating Metrics:  27%|       | 3/11 [00:00<00:00, 353.69it/s]Calculating Metrics:  27%|       | 3/11 [00:00<00:00, 189.79it/s]Calculating Metrics:  45%|     | 5/11 [00:00<00:00, 280.87it/s]Calculating Metrics:  45%|     | 5/11 [00:00<00:00, 205.00it/s]Calculating Metrics:  64%|   | 7/11 [00:00<00:00, 262.46it/s]Calculating Metrics:  64%|   | 7/11 [00:00<00:00, 219.22it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 300.77it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 281.37it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 280.60it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 279.71it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_lengths_to_be_between:test_error_handling_values_are_integers] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:  18%|        | 2/11 [00:00<00:00, 2202.89it/s]Calculating Metrics:  18%|        | 2/11 [00:00<00:00, 196.17it/s] Calculating Metrics:  27%|       | 3/11 [00:00<00:00, 283.42it/s]Calculating Metrics:  27%|       | 3/11 [00:00<00:00, 161.19it/s]Calculating Metrics:  45%|     | 5/11 [00:00<00:00, 240.44it/s]Calculating Metrics:  45%|     | 5/11 [00:00<00:00, 182.30it/s]Calculating Metrics:  64%|   | 7/11 [00:00<00:00, 236.55it/s]Calculating Metrics:  64%|   | 7/11 [00:00<00:00, 200.90it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 278.12it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 261.13it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 260.42it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 259.61it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_lengths_to_be_between:test_conditional_expectation_passes] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:  18%|        | 2/11 [00:00<00:00, 614.06it/s]Calculating Metrics:  18%|        | 2/11 [00:00<00:00, 224.32it/s]Calculating Metrics:  27%|       | 3/11 [00:00<00:00, 326.30it/s]Calculating Metrics:  27%|       | 3/11 [00:00<00:00, 204.35it/s]Calculating Metrics:  45%|     | 5/11 [00:00<00:00, 267.97it/s]Calculating Metrics:  45%|     | 5/11 [00:00<00:00, 211.18it/s]Calculating Metrics:  64%|   | 7/11 [00:00<00:00, 263.45it/s]Calculating Metrics:  64%|   | 7/11 [00:00<00:00, 228.68it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 288.96it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 274.76it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 273.95it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 272.66it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_lengths_to_be_between:test_conditional_expectation_fails] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:  18%|        | 2/11 [00:00<00:00, 593.46it/s]Calculating Metrics:  18%|        | 2/11 [00:00<00:00, 220.51it/s]Calculating Metrics:  27%|       | 3/11 [00:00<00:00, 320.97it/s]Calculating Metrics:  27%|       | 3/11 [00:00<00:00, 202.14it/s]Calculating Metrics:  45%|     | 5/11 [00:00<00:00, 264.92it/s]Calculating Metrics:  45%|     | 5/11 [00:00<00:00, 209.12it/s]Calculating Metrics:  64%|   | 7/11 [00:00<00:00, 259.67it/s]Calculating Metrics:  64%|   | 7/11 [00:00<00:00, 225.60it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 283.84it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 270.07it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 269.34it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 268.49it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_lengths_to_be_between:test_conditional_expectation_parser_errors] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_strftime_format:simple_positive_test] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 3043.76it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 324.94it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 461.32it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 254.32it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 356.43it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 268.04it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 420.52it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 387.72it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 385.55it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 383.45it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_strftime_format:negative_test_wrong_format] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 3092.00it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 325.68it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 461.52it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 256.48it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 356.61it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 273.10it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 425.46it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 394.26it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 392.35it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 390.31it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_strftime_format:positive_test_w_nulls] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 3082.91it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 320.37it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 452.90it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 250.25it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 353.29it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 270.36it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 428.67it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 397.33it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 395.59it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 393.55it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_strftime_format:positive_test_w_mostly] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 3145.33it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 323.42it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 458.24it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 256.33it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 362.64it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 277.20it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 432.53it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 401.03it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 399.27it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 397.21it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_strftime_format:simple_negative_test] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 3236.35it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 333.61it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 473.02it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 261.07it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 370.07it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 282.12it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 442.91it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 410.12it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 408.32it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 406.17it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_strftime_format:negative_test_out_of_bounds_value_for_month] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2159.79it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 315.31it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 448.49it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 255.10it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 362.79it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 278.61it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 438.50it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 407.18it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 405.35it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 403.28it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_strftime_format:negative_test_iso8601] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 3236.35it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 332.22it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 469.56it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 263.53it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 366.67it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 280.00it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 433.43it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 395.52it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 393.02it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 390.83it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_strftime_format:test_raising_exception_for_wrong_input_data_type] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 3089.73it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 321.78it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 453.29it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 249.41it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 143.66it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 103.73it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 82.35it/s] Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 106.57it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 94.76it/s] Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 116.17it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 105.41it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 104.62it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 104.31it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_unique:basic_positive_test_case] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2848.42it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 348.49it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 489.80it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 282.69it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 394.04it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 303.36it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 473.48it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 441.09it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 439.02it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 436.60it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_unique:basic_negative_case_all_non_unique_character_values] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 3241.35it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 354.55it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 499.68it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 283.78it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 399.05it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 304.42it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 464.41it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 432.19it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 430.05it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 427.65it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_unique:multi_type_column_contains_2_and_quoted_2_suppressed_for_sqalchemy] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 3169.10it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 362.92it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 510.38it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 289.44it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 402.61it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 309.85it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 471.72it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 439.00it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 436.85it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 434.46it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_unique:positive_case_using_mostly] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 3216.49it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 370.11it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 522.03it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 292.60it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 410.92it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 306.56it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 463.01it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 429.19it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 426.59it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 424.15it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_unique:negative_case_using_mostly] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 3169.10it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 368.75it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 520.92it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 280.32it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 392.62it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 304.60it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 460.77it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 429.28it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 427.11it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 424.74it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_unique:positive_case_multiple_null_values] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 3062.65it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 345.84it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 487.09it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 278.06it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 389.41it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 301.62it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 454.56it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 421.61it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 418.96it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 416.51it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_unique:negative_case_non_unique_numeric_values] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 3085.18it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 328.46it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 461.74it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 271.93it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 378.78it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 292.84it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 448.93it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 416.96it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 414.28it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 409.85it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_unique:positive_case_all_null_values] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 3231.36it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 365.96it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 514.32it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 283.85it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 399.55it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 308.87it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 481.65it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 448.53it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 446.41it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 443.91it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_unique:negative_multiple_duplicate_values] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 3090.87it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 349.41it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 491.96it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 268.63it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 372.08it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 292.31it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 445.73it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 415.71it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 413.61it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 411.37it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_json_schema:basic_positive_test] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2954.78it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 333.73it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 473.13it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 255.45it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 257.04it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 210.73it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 349.72it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 329.39it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 328.24it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 326.91it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_json_schema:positive_test_with_a_more_complex_schema] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 3160.74it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 313.43it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 441.97it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 243.85it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 211.01it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 177.56it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 302.85it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 286.61it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 285.75it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 284.72it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_json_schema:basic_negative_test] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 3134.76it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 316.52it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 448.17it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 246.87it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 207.89it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 171.49it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 290.21it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 274.22it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 273.24it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 272.26it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_null:basic_positive_case_basic_result_format] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 3267.86it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 698.58it/s] Calculating Metrics:  50%|     | 3/6 [00:00<00:00, 937.20it/s]Calculating Metrics:  50%|     | 3/6 [00:00<00:00, 570.91it/s]Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 658.01it/s]Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 516.19it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 641.99it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 590.15it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 583.95it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 577.16it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_null:negative_no_missing_values] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/8 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/8 [00:00<?, ?it/s]Calculating Metrics:  25%|       | 2/8 [00:00<00:00, 3059.30it/s]Calculating Metrics:  25%|       | 2/8 [00:00<00:00, 435.46it/s] Calculating Metrics:  38%|      | 3/8 [00:00<00:00, 600.87it/s]Calculating Metrics:  38%|      | 3/8 [00:00<00:00, 354.58it/s]Calculating Metrics:  50%|     | 4/8 [00:00<00:00, 428.96it/s]Calculating Metrics:  50%|     | 4/8 [00:00<00:00, 325.10it/s]Calculating Metrics: 100%|| 8/8 [00:00<00:00, 503.94it/s]Calculating Metrics: 100%|| 8/8 [00:00<00:00, 466.56it/s]Calculating Metrics: 100%|| 8/8 [00:00<00:00, 463.54it/s]Calculating Metrics: 100%|| 8/8 [00:00<00:00, 460.07it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_null:positive_mostly] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/8 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/8 [00:00<?, ?it/s]Calculating Metrics:  25%|       | 2/8 [00:00<00:00, 3002.37it/s]Calculating Metrics:  25%|       | 2/8 [00:00<00:00, 447.03it/s] Calculating Metrics:  38%|      | 3/8 [00:00<00:00, 615.66it/s]Calculating Metrics:  38%|      | 3/8 [00:00<00:00, 350.14it/s]Calculating Metrics:  50%|     | 4/8 [00:00<00:00, 420.61it/s]Calculating Metrics:  50%|     | 4/8 [00:00<00:00, 319.75it/s]Calculating Metrics: 100%|| 8/8 [00:00<00:00, 511.70it/s]Calculating Metrics: 100%|| 8/8 [00:00<00:00, 473.87it/s]Calculating Metrics: 100%|| 8/8 [00:00<00:00, 470.87it/s]Calculating Metrics: 100%|| 8/8 [00:00<00:00, 467.34it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_null:negative_mostly] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/8 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/8 [00:00<?, ?it/s]Calculating Metrics:  25%|       | 2/8 [00:00<00:00, 3081.78it/s]Calculating Metrics:  25%|       | 2/8 [00:00<00:00, 461.24it/s] Calculating Metrics:  38%|      | 3/8 [00:00<00:00, 640.48it/s]Calculating Metrics:  38%|      | 3/8 [00:00<00:00, 369.28it/s]Calculating Metrics:  50%|     | 4/8 [00:00<00:00, 447.68it/s]Calculating Metrics:  50%|     | 4/8 [00:00<00:00, 334.28it/s]Calculating Metrics: 100%|| 8/8 [00:00<00:00, 525.70it/s]Calculating Metrics: 100%|| 8/8 [00:00<00:00, 485.58it/s]Calculating Metrics: 100%|| 8/8 [00:00<00:00, 482.37it/s]Calculating Metrics: 100%|| 8/8 [00:00<00:00, 478.73it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_null:positive_case_with_mostly_and_no_unexpected_values] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/8 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/8 [00:00<?, ?it/s]Calculating Metrics:  25%|       | 2/8 [00:00<00:00, 3164.32it/s]Calculating Metrics:  25%|       | 2/8 [00:00<00:00, 433.74it/s] Calculating Metrics:  38%|      | 3/8 [00:00<00:00, 599.76it/s]Calculating Metrics:  38%|      | 3/8 [00:00<00:00, 355.45it/s]Calculating Metrics:  50%|     | 4/8 [00:00<00:00, 431.83it/s]Calculating Metrics:  50%|     | 4/8 [00:00<00:00, 327.44it/s]Calculating Metrics: 100%|| 8/8 [00:00<00:00, 527.15it/s]Calculating Metrics: 100%|| 8/8 [00:00<00:00, 487.81it/s]Calculating Metrics: 100%|| 8/8 [00:00<00:00, 484.69it/s]Calculating Metrics: 100%|| 8/8 [00:00<00:00, 481.03it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_null:negative_case_with_75percent_non_null_values_no_mostly] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/8 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/8 [00:00<?, ?it/s]Calculating Metrics:  25%|       | 2/8 [00:00<00:00, 3306.51it/s]Calculating Metrics:  25%|       | 2/8 [00:00<00:00, 472.49it/s] Calculating Metrics:  38%|      | 3/8 [00:00<00:00, 657.35it/s]Calculating Metrics:  38%|      | 3/8 [00:00<00:00, 375.42it/s]Calculating Metrics:  50%|     | 4/8 [00:00<00:00, 455.43it/s]Calculating Metrics:  50%|     | 4/8 [00:00<00:00, 341.79it/s]Calculating Metrics: 100%|| 8/8 [00:00<00:00, 540.29it/s]Calculating Metrics: 100%|| 8/8 [00:00<00:00, 499.04it/s]Calculating Metrics: 100%|| 8/8 [00:00<00:00, 495.79it/s]Calculating Metrics: 100%|| 8/8 [00:00<00:00, 492.01it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_in_type_list:positive_test_pandas_integer_column] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 2409.13it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1680.41it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1440.85it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1231.81it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_in_type_list:negative_test_pandas_float_values_are_not_strings] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 2252.58it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1589.96it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1372.03it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1182.16it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_in_type_list:positive_test_float_values] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 2416.07it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1678.39it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1437.39it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1228.92it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_in_type_list:positive_test_string_values] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 3170.30it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 329.97it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 467.73it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 242.25it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 338.28it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 260.84it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 410.72it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 382.54it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 380.88it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 379.03it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_in_type_list:positive_test_boolean_values] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 2624.72it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1788.62it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1521.88it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1293.74it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_in_type_list:positive_test_string_and_int_values] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 3179.91it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 316.99it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 446.95it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 251.00it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 356.35it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 273.24it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 429.79it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 398.65it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 396.89it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 394.87it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_in_type_list:negative_test_string_and_int_values_summary_output] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 3184.74it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 333.23it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 473.10it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 261.46it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 365.63it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 278.97it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 432.32it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 401.33it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 399.60it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 397.57it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_in_type_list:negative_test_string_and_int_values_complete_output] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 3215.26it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 338.24it/s] Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 479.60it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 263.96it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 373.25it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 284.51it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 441.03it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 409.11it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 407.31it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 405.18it/s]
_ test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_in_type_list:positive_test_placeholder_expectation] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 2421.65it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1678.39it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1432.97it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1221.05it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_value_lengths_to_equal:positive_test_string_one_character_length] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/14 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/14 [00:00<?, ?it/s]Calculating Metrics:  14%|        | 2/14 [00:00<00:00, 1705.00it/s]Calculating Metrics:  14%|        | 2/14 [00:00<00:00, 223.32it/s] Calculating Metrics:  29%|       | 4/14 [00:00<00:00, 370.03it/s]Calculating Metrics:  29%|       | 4/14 [00:00<00:00, 223.47it/s]Calculating Metrics:  43%|     | 6/14 [00:00<00:00, 291.48it/s]Calculating Metrics:  43%|     | 6/14 [00:00<00:00, 222.71it/s]Calculating Metrics:  57%|    | 8/14 [00:00<00:00, 279.14it/s]Calculating Metrics:  57%|    | 8/14 [00:00<00:00, 235.91it/s]Calculating Metrics:  93%|| 13/14 [00:00<00:00, 316.62it/s]Calculating Metrics:  93%|| 13/14 [00:00<00:00, 296.07it/s]Calculating Metrics: 100%|| 14/14 [00:00<00:00, 305.85it/s]Calculating Metrics: 100%|| 14/14 [00:00<00:00, 290.72it/s]Calculating Metrics: 100%|| 14/14 [00:00<00:00, 289.98it/s]Calculating Metrics: 100%|| 14/14 [00:00<00:00, 289.19it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_value_lengths_to_equal:negative_test_string_value_is_1_too_high] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/14 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/14 [00:00<?, ?it/s]Calculating Metrics:  14%|        | 2/14 [00:00<00:00, 2499.59it/s]Calculating Metrics:  14%|        | 2/14 [00:00<00:00, 237.92it/s] Calculating Metrics:  29%|       | 4/14 [00:00<00:00, 411.73it/s]Calculating Metrics:  29%|       | 4/14 [00:00<00:00, 236.76it/s]Calculating Metrics:  43%|     | 6/14 [00:00<00:00, 321.51it/s]Calculating Metrics:  43%|     | 6/14 [00:00<00:00, 238.29it/s]Calculating Metrics:  57%|    | 8/14 [00:00<00:00, 299.40it/s]Calculating Metrics:  57%|    | 8/14 [00:00<00:00, 249.66it/s]Calculating Metrics:  93%|| 13/14 [00:00<00:00, 353.44it/s]Calculating Metrics:  93%|| 13/14 [00:00<00:00, 327.94it/s]Calculating Metrics: 100%|| 14/14 [00:00<00:00, 340.12it/s]Calculating Metrics: 100%|| 14/14 [00:00<00:00, 321.23it/s]Calculating Metrics: 100%|| 14/14 [00:00<00:00, 320.41it/s]Calculating Metrics: 100%|| 14/14 [00:00<00:00, 319.46it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_value_lengths_to_equal:positive_test_with_missing_value_in_column_mostly] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/14 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/14 [00:00<?, ?it/s]Calculating Metrics:  14%|        | 2/14 [00:00<00:00, 1976.58it/s]Calculating Metrics:  14%|        | 2/14 [00:00<00:00, 237.44it/s] Calculating Metrics:  29%|       | 4/14 [00:00<00:00, 414.47it/s]Calculating Metrics:  29%|       | 4/14 [00:00<00:00, 239.61it/s]Calculating Metrics:  43%|     | 6/14 [00:00<00:00, 326.71it/s]Calculating Metrics:  43%|     | 6/14 [00:00<00:00, 243.23it/s]Calculating Metrics:  57%|    | 8/14 [00:00<00:00, 305.75it/s]Calculating Metrics:  57%|    | 8/14 [00:00<00:00, 255.12it/s]Calculating Metrics:  93%|| 13/14 [00:00<00:00, 353.97it/s]Calculating Metrics:  93%|| 13/14 [00:00<00:00, 328.97it/s]Calculating Metrics: 100%|| 14/14 [00:00<00:00, 339.95it/s]Calculating Metrics: 100%|| 14/14 [00:00<00:00, 321.63it/s]Calculating Metrics: 100%|| 14/14 [00:00<00:00, 320.85it/s]Calculating Metrics: 100%|| 14/14 [00:00<00:00, 319.93it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_value_lengths_to_equal:negative_one_length_too_small] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/14 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/14 [00:00<?, ?it/s]Calculating Metrics:  14%|        | 2/14 [00:00<00:00, 2314.74it/s]Calculating Metrics:  14%|        | 2/14 [00:00<00:00, 219.40it/s] Calculating Metrics:  29%|       | 4/14 [00:00<00:00, 380.26it/s]Calculating Metrics:  29%|       | 4/14 [00:00<00:00, 226.90it/s]Calculating Metrics:  43%|     | 6/14 [00:00<00:00, 309.89it/s]Calculating Metrics:  43%|     | 6/14 [00:00<00:00, 232.91it/s]Calculating Metrics:  57%|    | 8/14 [00:00<00:00, 292.79it/s]Calculating Metrics:  57%|    | 8/14 [00:00<00:00, 245.96it/s]Calculating Metrics:  93%|| 13/14 [00:00<00:00, 342.08it/s]Calculating Metrics:  93%|| 13/14 [00:00<00:00, 318.56it/s]Calculating Metrics: 100%|| 14/14 [00:00<00:00, 329.60it/s]Calculating Metrics: 100%|| 14/14 [00:00<00:00, 312.38it/s]Calculating Metrics: 100%|| 14/14 [00:00<00:00, 311.64it/s]Calculating Metrics: 100%|| 14/14 [00:00<00:00, 310.75it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_value_lengths_to_equal:positive_one_length_too_small_mostly] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/14 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/14 [00:00<?, ?it/s]Calculating Metrics:  14%|        | 2/14 [00:00<00:00, 2538.16it/s]Calculating Metrics:  14%|        | 2/14 [00:00<00:00, 245.58it/s] Calculating Metrics:  29%|       | 4/14 [00:00<00:00, 429.18it/s]Calculating Metrics:  29%|       | 4/14 [00:00<00:00, 244.70it/s]Calculating Metrics:  43%|     | 6/14 [00:00<00:00, 331.40it/s]Calculating Metrics:  43%|     | 6/14 [00:00<00:00, 245.85it/s]Calculating Metrics:  57%|    | 8/14 [00:00<00:00, 308.93it/s]Calculating Metrics:  57%|    | 8/14 [00:00<00:00, 254.10it/s]Calculating Metrics:  93%|| 13/14 [00:00<00:00, 355.73it/s]Calculating Metrics:  93%|| 13/14 [00:00<00:00, 329.85it/s]Calculating Metrics: 100%|| 14/14 [00:00<00:00, 342.46it/s]Calculating Metrics: 100%|| 14/14 [00:00<00:00, 323.62it/s]Calculating Metrics: 100%|| 14/14 [00:00<00:00, 322.81it/s]Calculating Metrics: 100%|| 14/14 [00:00<00:00, 321.87it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:basic_positive_now_test] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2334.71it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 208.49it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 362.68it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 204.03it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 284.85it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 210.87it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 326.47it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 291.28it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 321.20it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 299.61it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 298.80it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 297.91it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:basic_positive_now_timedelta_test] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2400.86it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 205.80it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 362.81it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 202.95it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 280.98it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 209.07it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 329.22it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 291.35it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 319.71it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 297.99it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 297.18it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 296.28it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:basic_positive_datetime_test] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2487.72it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 221.22it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 386.25it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 220.16it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 305.11it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 227.54it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 347.75it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 311.44it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 340.02it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 317.58it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 316.74it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 315.75it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:basic_positive_test_with_timestamps_tz_informed] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 1382.89it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 39.66it/s]  Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 73.47it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 40.65it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 58.97it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 58.97it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 58.97it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 58.97it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 58.97it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 58.97it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 58.97it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 58.97it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 104.34it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_be_null:basic_positive_case_complete_result_format] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/8 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/8 [00:00<?, ?it/s]Calculating Metrics:  25%|       | 2/8 [00:00<00:00, 2350.41it/s]Calculating Metrics:  25%|       | 2/8 [00:00<00:00, 505.43it/s] Calculating Metrics:  50%|     | 4/8 [00:00<00:00, 720.61it/s]Calculating Metrics:  50%|     | 4/8 [00:00<00:00, 475.45it/s]Calculating Metrics:  62%|   | 5/8 [00:00<00:00, 547.47it/s]Calculating Metrics:  62%|   | 5/8 [00:00<00:00, 435.77it/s]Calculating Metrics:  88%| | 7/8 [00:00<00:00, 522.03it/s]Calculating Metrics:  88%| | 7/8 [00:00<00:00, 469.80it/s]Calculating Metrics: 100%|| 8/8 [00:00<00:00, 476.31it/s]Calculating Metrics: 100%|| 8/8 [00:00<00:00, 447.60it/s]Calculating Metrics: 100%|| 8/8 [00:00<00:00, 444.62it/s]Calculating Metrics: 100%|| 8/8 [00:00<00:00, 440.58it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_be_null:negative_mostly] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2597.09it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 381.87it/s] Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 617.08it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 375.75it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 441.26it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 334.18it/s]Calculating Metrics:  90%| | 9/10 [00:00<00:00, 479.67it/s]Calculating Metrics:  90%| | 9/10 [00:00<00:00, 435.66it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 450.02it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 422.38it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 420.50it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 418.31it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_be_null:positive_case_with_mostly_and_no_unexpected_values] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2255.00it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 369.54it/s] Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 603.97it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 370.92it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 435.46it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 328.28it/s]Calculating Metrics:  90%| | 9/10 [00:00<00:00, 465.19it/s]Calculating Metrics:  90%| | 9/10 [00:00<00:00, 422.83it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 441.15it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 414.10it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 412.03it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 409.77it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_be_null:negative_case_with_75percent_null_values_no_mostly] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2497.35it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 367.65it/s] Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 592.58it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 366.04it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 430.00it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 326.82it/s]Calculating Metrics:  90%| | 9/10 [00:00<00:00, 461.68it/s]Calculating Metrics:  90%| | 9/10 [00:00<00:00, 420.19it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 434.91it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 408.46it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 406.65it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 404.52it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_value_z_scores_to_be_less_than:basic_successful_test] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/21 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/21 [00:00<?, ?it/s]Calculating Metrics:  10%|         | 2/21 [00:00<00:00, 2624.72it/s]Calculating Metrics:  10%|         | 2/21 [00:00<00:00, 148.16it/s] Calculating Metrics:  19%|        | 4/21 [00:00<00:00, 268.82it/s]Calculating Metrics:  19%|        | 4/21 [00:00<00:00, 146.78it/s]Calculating Metrics:  33%|      | 7/21 [00:00<00:00, 241.50it/s]Calculating Metrics:  33%|      | 7/21 [00:00<00:00, 170.72it/s]Calculating Metrics:  48%|     | 10/21 [00:00<00:00, 227.35it/s]Calculating Metrics:  48%|     | 10/21 [00:00<00:00, 184.68it/s]Calculating Metrics:  57%|    | 12/21 [00:00<00:00, 211.21it/s]Calculating Metrics:  57%|    | 12/21 [00:00<00:00, 181.18it/s]Calculating Metrics:  62%|   | 13/21 [00:00<00:00, 192.96it/s]Calculating Metrics:  62%|   | 13/21 [00:00<00:00, 170.55it/s]Calculating Metrics:  67%|   | 14/21 [00:00<00:00, 178.51it/s]Calculating Metrics:  67%|   | 14/21 [00:00<00:00, 161.36it/s]Calculating Metrics:  71%|  | 15/21 [00:00<00:00, 170.07it/s]Calculating Metrics:  71%|  | 15/21 [00:00<00:00, 156.62it/s]Calculating Metrics:  76%|  | 16/21 [00:00<00:00, 165.43it/s]Calculating Metrics:  76%|  | 16/21 [00:00<00:00, 154.89it/s]Calculating Metrics:  76%|  | 16/21 [00:00<00:00, 154.89it/s]Calculating Metrics:  95%|| 20/21 [00:00<00:00, 154.89it/s]Calculating Metrics:  95%|| 20/21 [00:00<00:00, 154.89it/s]Calculating Metrics: 100%|| 21/21 [00:00<00:00, 154.89it/s]Calculating Metrics: 100%|| 21/21 [00:00<00:00, 154.89it/s]Calculating Metrics: 100%|| 21/21 [00:00<00:00, 154.89it/s]Calculating Metrics: 100%|| 21/21 [00:00<00:00, 177.46it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_value_z_scores_to_be_less_than:basic_unsuccessful_test] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/21 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/21 [00:00<?, ?it/s]Calculating Metrics:  10%|         | 2/21 [00:00<00:00, 2478.90it/s]Calculating Metrics:  10%|         | 2/21 [00:00<00:00, 145.64it/s] Calculating Metrics:  19%|        | 4/21 [00:00<00:00, 267.78it/s]Calculating Metrics:  19%|        | 4/21 [00:00<00:00, 146.28it/s]Calculating Metrics:  33%|      | 7/21 [00:00<00:00, 241.12it/s]Calculating Metrics:  33%|      | 7/21 [00:00<00:00, 173.87it/s]Calculating Metrics:  48%|     | 10/21 [00:00<00:00, 234.68it/s]Calculating Metrics:  48%|     | 10/21 [00:00<00:00, 190.02it/s]Calculating Metrics:  57%|    | 12/21 [00:00<00:00, 218.31it/s]Calculating Metrics:  57%|    | 12/21 [00:00<00:00, 186.57it/s]Calculating Metrics:  62%|   | 13/21 [00:00<00:00, 198.39it/s]Calculating Metrics:  62%|   | 13/21 [00:00<00:00, 174.08it/s]Calculating Metrics:  67%|   | 14/21 [00:00<00:00, 182.54it/s]Calculating Metrics:  67%|   | 14/21 [00:00<00:00, 164.45it/s]Calculating Metrics:  71%|  | 15/21 [00:00<00:00, 173.29it/s]Calculating Metrics:  71%|  | 15/21 [00:00<00:00, 159.45it/s]Calculating Metrics:  76%|  | 16/21 [00:00<00:00, 168.43it/s]Calculating Metrics:  76%|  | 16/21 [00:00<00:00, 157.59it/s]Calculating Metrics:  76%|  | 16/21 [00:00<00:00, 157.59it/s]Calculating Metrics:  95%|| 20/21 [00:00<00:00, 157.59it/s]Calculating Metrics:  95%|| 20/21 [00:00<00:00, 157.59it/s]Calculating Metrics: 100%|| 21/21 [00:00<00:00, 157.59it/s]Calculating Metrics: 100%|| 21/21 [00:00<00:00, 157.59it/s]Calculating Metrics: 100%|| 21/21 [00:00<00:00, 157.59it/s]Calculating Metrics: 100%|| 21/21 [00:00<00:00, 182.15it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_value_z_scores_to_be_less_than:basic_test_with_outlier] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/21 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/21 [00:00<?, ?it/s]Calculating Metrics:  10%|         | 2/21 [00:00<00:00, 2560.63it/s]Calculating Metrics:  10%|         | 2/21 [00:00<00:00, 149.80it/s] Calculating Metrics:  19%|        | 4/21 [00:00<00:00, 274.35it/s]Calculating Metrics:  19%|        | 4/21 [00:00<00:00, 150.79it/s]Calculating Metrics:  33%|      | 7/21 [00:00<00:00, 146.57it/s]Calculating Metrics:  33%|      | 7/21 [00:00<00:00, 105.45it/s]Calculating Metrics:  48%|     | 10/21 [00:00<00:00, 130.44it/s]Calculating Metrics:  48%|     | 10/21 [00:00<00:00, 95.01it/s] Calculating Metrics:  48%|     | 10/21 [00:00<00:00, 95.01it/s]Calculating Metrics:  57%|    | 12/21 [00:00<00:00, 95.01it/s]Calculating Metrics:  57%|    | 12/21 [00:00<00:00, 95.01it/s]Calculating Metrics:  62%|   | 13/21 [00:00<00:00, 95.01it/s]Calculating Metrics:  62%|   | 13/21 [00:00<00:00, 95.01it/s]Calculating Metrics:  67%|   | 14/21 [00:00<00:00, 95.01it/s]Calculating Metrics:  67%|   | 14/21 [00:00<00:00, 95.01it/s]Calculating Metrics:  71%|  | 15/21 [00:00<00:00, 95.01it/s]Calculating Metrics:  71%|  | 15/21 [00:00<00:00, 95.01it/s]Calculating Metrics:  76%|  | 16/21 [00:00<00:00, 95.01it/s]Calculating Metrics:  76%|  | 16/21 [00:00<00:00, 95.01it/s]Calculating Metrics:  95%|| 20/21 [00:00<00:00, 95.01it/s]Calculating Metrics:  95%|| 20/21 [00:00<00:00, 95.01it/s]Calculating Metrics: 100%|| 21/21 [00:00<00:00, 95.01it/s]Calculating Metrics: 100%|| 21/21 [00:00<00:00, 95.01it/s]Calculating Metrics: 100%|| 21/21 [00:00<00:00, 95.01it/s]Calculating Metrics: 100%|| 21/21 [00:00<00:00, 113.75it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_value_z_scores_to_be_less_than:basic_test_mostly_zero] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/21 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/21 [00:00<?, ?it/s]Calculating Metrics:  10%|         | 2/21 [00:00<00:00, 2677.50it/s]Calculating Metrics:  10%|         | 2/21 [00:00<00:00, 153.92it/s] Calculating Metrics:  19%|        | 4/21 [00:00<00:00, 282.23it/s]Calculating Metrics:  19%|        | 4/21 [00:00<00:00, 153.59it/s]Calculating Metrics:  33%|      | 7/21 [00:00<00:00, 252.58it/s]Calculating Metrics:  33%|      | 7/21 [00:00<00:00, 182.01it/s]Calculating Metrics:  48%|     | 10/21 [00:00<00:00, 243.74it/s]Calculating Metrics:  48%|     | 10/21 [00:00<00:00, 196.35it/s]Calculating Metrics:  57%|    | 12/21 [00:00<00:00, 225.64it/s]Calculating Metrics:  57%|    | 12/21 [00:00<00:00, 194.82it/s]Calculating Metrics:  62%|   | 13/21 [00:00<00:00, 207.32it/s]Calculating Metrics:  62%|   | 13/21 [00:00<00:00, 183.47it/s]Calculating Metrics:  67%|   | 14/21 [00:00<00:00, 191.34it/s]Calculating Metrics:  67%|   | 14/21 [00:00<00:00, 173.30it/s]Calculating Metrics:  71%|  | 15/21 [00:00<00:00, 182.41it/s]Calculating Metrics:  71%|  | 15/21 [00:00<00:00, 168.37it/s]Calculating Metrics:  76%|  | 16/21 [00:00<00:00, 177.73it/s]Calculating Metrics:  76%|  | 16/21 [00:00<00:00, 166.27it/s]Calculating Metrics:  95%|| 20/21 [00:00<00:00, 199.22it/s]Calculating Metrics:  95%|| 20/21 [00:00<00:00, 199.22it/s]Calculating Metrics:  95%|| 20/21 [00:00<00:00, 199.22it/s]Calculating Metrics: 100%|| 21/21 [00:00<00:00, 199.22it/s]Calculating Metrics: 100%|| 21/21 [00:00<00:00, 199.22it/s]Calculating Metrics: 100%|| 21/21 [00:00<00:00, 199.22it/s]Calculating Metrics: 100%|| 21/21 [00:00<00:00, 187.94it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_value_z_scores_to_be_less_than:basic_test_with_missing] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/21 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/21 [00:00<?, ?it/s]Calculating Metrics:  10%|         | 2/21 [00:00<00:00, 2747.66it/s]Calculating Metrics:  10%|         | 2/21 [00:00<00:00, 153.66it/s] Calculating Metrics:  19%|        | 4/21 [00:00<00:00, 278.69it/s]Calculating Metrics:  19%|        | 4/21 [00:00<00:00, 152.87it/s]Calculating Metrics:  33%|      | 7/21 [00:00<00:00, 251.18it/s]Calculating Metrics:  33%|      | 7/21 [00:00<00:00, 181.26it/s]Calculating Metrics:  48%|     | 10/21 [00:00<00:00, 242.75it/s]Calculating Metrics:  48%|     | 10/21 [00:00<00:00, 198.49it/s]Calculating Metrics:  57%|    | 12/21 [00:00<00:00, 228.48it/s]Calculating Metrics:  57%|    | 12/21 [00:00<00:00, 196.72it/s]Calculating Metrics:  62%|   | 13/21 [00:00<00:00, 209.47it/s]Calculating Metrics:  62%|   | 13/21 [00:00<00:00, 185.91it/s]Calculating Metrics:  67%|   | 14/21 [00:00<00:00, 194.22it/s]Calculating Metrics:  67%|   | 14/21 [00:00<00:00, 176.22it/s]Calculating Metrics:  71%|  | 15/21 [00:00<00:00, 185.73it/s]Calculating Metrics:  71%|  | 15/21 [00:00<00:00, 171.24it/s]Calculating Metrics:  76%|  | 16/21 [00:00<00:00, 180.88it/s]Calculating Metrics:  76%|  | 16/21 [00:00<00:00, 169.09it/s]Calculating Metrics:  95%|| 20/21 [00:00<00:00, 202.49it/s]Calculating Metrics:  95%|| 20/21 [00:00<00:00, 194.42it/s]Calculating Metrics:  95%|| 20/21 [00:00<00:00, 194.42it/s]Calculating Metrics: 100%|| 21/21 [00:00<00:00, 194.42it/s]Calculating Metrics: 100%|| 21/21 [00:00<00:00, 194.42it/s]Calculating Metrics: 100%|| 21/21 [00:00<00:00, 194.42it/s]Calculating Metrics: 100%|| 21/21 [00:00<00:00, 193.24it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:basic_positive_test0] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2570.83it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 224.26it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 373.42it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 220.27it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 307.16it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 232.16it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 356.91it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 320.90it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 353.67it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 330.95it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 330.11it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 329.11it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:another_basic_positive_test0] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2620.62it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 234.49it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 395.45it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 221.99it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 303.17it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 225.62it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 352.79it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 313.66it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 344.17it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 321.12it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 320.29it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 319.31it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:basic_positive_test_with_timestamps0] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2666.44it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 226.94it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 390.43it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 227.51it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 312.22it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 234.94it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 362.14it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 321.85it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 346.24it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 323.67it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 322.58it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 321.55it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:missing_min_value0] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2560.63it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 219.11it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 358.56it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 210.23it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 295.47it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 221.94it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 346.36it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 310.39it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 343.04it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 320.17it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 319.36it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 318.43it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:null_min_value0] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2372.34it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 188.61it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 322.74it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 191.62it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 269.26it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 205.87it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 329.59it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 296.45it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 331.51it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 310.07it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 309.32it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 308.44it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:missing_max_value0] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2577.94it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 219.45it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 379.90it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 213.38it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 298.51it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 222.10it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 346.69it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 309.58it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 342.34it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 319.61it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 318.79it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 317.79it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:null_max_value0] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2226.87it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 211.24it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 362.45it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 210.68it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 295.00it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 221.42it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 351.61it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 314.47it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 347.33it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 323.92it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 323.09it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 322.12it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:basic_negative_test0] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2659.67it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 228.78it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 394.40it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 221.77it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 308.61it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 233.38it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 366.94it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 329.14it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 365.93it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 341.49it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 340.58it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 339.51it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:another_negative_test0] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2836.86it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 236.94it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 410.68it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 233.51it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 325.26it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 242.14it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 382.04it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 340.74it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 378.27it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 351.98it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 351.02it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 349.92it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:positive_test_with_result_format__boolean_only0] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2637.93it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 359.32it/s] Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 593.19it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 359.68it/s]Calculating Metrics:  60%|    | 6/10 [00:00<00:00, 482.16it/s]Calculating Metrics:  60%|    | 6/10 [00:00<00:00, 375.16it/s]Calculating Metrics:  80%|  | 8/10 [00:00<00:00, 458.43it/s]Calculating Metrics:  80%|  | 8/10 [00:00<00:00, 401.20it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 453.43it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 423.30it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 421.51it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 419.38it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:another_positive_test_with_result_format__boolean_only0] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2732.45it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 366.44it/s] Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 591.00it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 359.13it/s]Calculating Metrics:  60%|    | 6/10 [00:00<00:00, 481.81it/s]Calculating Metrics:  60%|    | 6/10 [00:00<00:00, 374.62it/s]Calculating Metrics:  80%|  | 8/10 [00:00<00:00, 460.06it/s]Calculating Metrics:  80%|  | 8/10 [00:00<00:00, 402.29it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 454.77it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 424.34it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 422.56it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 420.50it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:negative_test_with_result_format__boolean_only0] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2864.96it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 373.54it/s] Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 623.16it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 372.74it/s]Calculating Metrics:  60%|    | 6/10 [00:00<00:00, 498.67it/s]Calculating Metrics:  60%|    | 6/10 [00:00<00:00, 385.75it/s]Calculating Metrics:  80%|  | 8/10 [00:00<00:00, 473.57it/s]Calculating Metrics:  80%|  | 8/10 [00:00<00:00, 413.26it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 457.77it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 427.11it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 425.30it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 423.21it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:another_negative_test_with_result_format__boolean_only0] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2739.58it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 369.88it/s] Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 579.28it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 350.50it/s]Calculating Metrics:  60%|    | 6/10 [00:00<00:00, 470.36it/s]Calculating Metrics:  60%|    | 6/10 [00:00<00:00, 368.45it/s]Calculating Metrics:  80%|  | 8/10 [00:00<00:00, 453.23it/s]Calculating Metrics:  80%|  | 8/10 [00:00<00:00, 392.37it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 437.60it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 408.91it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 407.18it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 405.20it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:positive_test_with_mostly0] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2676.65it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 237.08it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 405.56it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 232.94it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 324.52it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 242.52it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 362.21it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 281.75it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 303.52it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 247.28it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 246.22it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 245.20it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:2nd_positive_test_with_mostly0] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2581.11it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 234.38it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 395.92it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 228.54it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 317.67it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 238.61it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 375.45it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 333.23it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 368.40it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 343.70it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 342.78it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 341.63it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:3rd_positive_test_with_mostly0] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2597.90it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 234.38it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 404.33it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 228.94it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 314.90it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 236.32it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 370.98it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 332.16it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 369.17it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 344.56it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 343.67it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 342.60it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:negative_test_with_mostly0] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2657.15it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 237.95it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 410.64it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 234.56it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 326.48it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 241.34it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 378.50it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 338.57it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 375.92it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 350.57it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 349.61it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 348.50it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:error:_improperly_mixed_types0] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2663.05it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 233.21it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 398.80it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 230.24it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 319.37it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 236.71it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 359.97it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 321.06it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 351.59it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 327.81it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 326.87it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 325.78it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:error:_improperly_mixed_types_again0] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2481.84it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 204.71it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 356.29it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 213.40it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 298.36it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 227.05it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 360.19it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 323.26it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 359.99it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 336.45it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 335.56it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 334.52it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:error:_improperly_mixed_types_once_more0] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2674.09it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 234.66it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 405.43it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 231.13it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 322.02it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 240.74it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 377.99it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 337.26it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 374.51it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 348.89it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 347.96it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 346.85it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:negative_test_to_verify_that_the_denominator_for_mostly_works_with_missing_values0] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2534.32it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 226.73it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 379.83it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 224.14it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 312.68it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 235.23it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 360.79it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 324.06it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 357.06it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 333.75it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 332.88it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 331.87it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:positive_test_to_verify_that_the_denominator_for_mostly_works_with_missing_values0] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2702.52it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 236.80it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 406.34it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 212.67it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 280.58it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 190.89it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 304.79it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 277.64it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 311.41it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 293.55it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 292.86it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 292.06it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:error_on_string-to-int_comparisons0] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2691.24it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 241.92it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 417.19it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 238.52it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 332.06it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 247.80it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 380.79it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 340.81it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 373.10it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 347.47it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 346.27it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 345.14it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:test_min_value_is_greater_than_max_value0] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2396.06it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 238.79it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 407.58it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 232.59it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 153.58it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 115.29it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 92.25it/s] Calculating Metrics:  38%|      | 5/13 [00:00<00:00, 112.38it/s]Calculating Metrics:  38%|      | 5/13 [00:00<00:00, 96.80it/s] Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 113.81it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 100.91it/s]Calculating Metrics:  54%|    | 7/13 [00:00<00:00, 114.04it/s]Calculating Metrics:  54%|    | 7/13 [00:00<00:00, 103.83it/s]Calculating Metrics:  54%|    | 7/13 [00:00<00:00, 103.22it/s]Calculating Metrics:  54%|    | 7/13 [00:00<00:00, 103.02it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:test_strict_min_failure0] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2688.66it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 238.67it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 420.69it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 239.48it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 333.48it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 247.38it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 379.98it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 340.85it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 374.87it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 350.32it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 349.40it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 348.30it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:test_strict_min_success0] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2724.46it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 234.35it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 400.39it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 231.10it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 321.68it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 241.65it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 381.29it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 341.50it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 378.99it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 353.44it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 352.49it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 351.38it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:test_strict_max_failure0] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2706.00it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 240.64it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 398.44it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 231.23it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 322.68it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 241.43it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 365.90it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 328.38it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 361.28it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 336.66it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 335.69it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 334.63it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:test_strict_max_success0] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2721.81it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 246.30it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 422.34it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 241.57it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 336.27it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 250.70it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 395.49it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 353.40it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 392.21it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 365.39it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 364.38it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 363.22it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:basic_positive_test1] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 1420.35it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 82.24it/s]  Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 115.68it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 75.31it/s] Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 108.05it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 80.29it/s] Calculating Metrics:  85%| | 11/13 [00:00<00:00, 131.80it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 115.94it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 126.13it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 126.13it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 126.13it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 126.13it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 119.57it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:another_basic_positive_test1] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 1620.99it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 67.15it/s]  Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 122.26it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 60.84it/s] Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 85.13it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 70.70it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 116.93it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 109.50it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 109.50it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 109.50it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 109.50it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 109.50it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 107.33it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:basic_positive_test_with_timestamps1] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 1681.08it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 118.72it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 205.94it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 110.74it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 127.73it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 97.97it/s] Calculating Metrics:  85%| | 11/13 [00:00<00:00, 134.20it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 120.75it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 134.61it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 126.05it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 126.05it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 126.05it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 125.24it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:missing_min_value1] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 1633.93it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 77.39it/s]  Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 141.15it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 85.12it/s] Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 121.40it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 82.63it/s] Calculating Metrics:  85%| | 11/13 [00:00<00:00, 134.96it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 123.91it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 139.68it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 126.17it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 126.17it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 126.17it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 125.15it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:null_min_value1] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2478.17it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 165.71it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 290.34it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 162.54it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 228.01it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 156.97it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 204.93it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 177.18it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 193.45it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 161.13it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 160.68it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 160.25it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:missing_max_value1] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 1636.80it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 68.65it/s]  Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 120.89it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 69.78it/s] Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 100.39it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 64.38it/s] Calculating Metrics:  85%| | 11/13 [00:00<00:00, 103.64it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 103.64it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 103.64it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 103.64it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 103.64it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 103.64it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 94.61it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:null_max_value1] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2608.40it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 155.53it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 266.84it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 131.60it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 174.91it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 143.38it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 239.25it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 221.91it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 250.93it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 238.53it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 238.08it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 237.56it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:basic_negative_test1] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2677.50it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 240.53it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 414.16it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 239.32it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 333.26it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 248.93it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 390.68it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 348.83it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 386.64it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 359.97it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 358.53it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 356.92it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:another_negative_test1] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2628.01it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 238.27it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 381.50it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 224.37it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 312.08it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 235.39it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 371.72it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 333.65it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 370.75it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 346.47it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 345.56it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 344.50it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:positive_test_with_result_format__boolean_only1] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 1556.62it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 66.32it/s]  Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 123.81it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 75.93it/s] Calculating Metrics:  60%|    | 6/10 [00:00<00:00, 108.32it/s]Calculating Metrics:  60%|    | 6/10 [00:00<00:00, 85.21it/s] Calculating Metrics:  80%|  | 8/10 [00:00<00:00, 109.51it/s]Calculating Metrics:  80%|  | 8/10 [00:00<00:00, 102.83it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 109.64it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 106.33it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 106.12it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 105.90it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:another_positive_test_with_result_format__boolean_only1] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 1722.86it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 84.90it/s]  Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 154.59it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 116.58it/s]Calculating Metrics:  60%|    | 6/10 [00:00<00:00, 163.35it/s]Calculating Metrics:  60%|    | 6/10 [00:00<00:00, 97.78it/s] Calculating Metrics:  80%|  | 8/10 [00:00<00:00, 124.45it/s]Calculating Metrics:  80%|  | 8/10 [00:00<00:00, 114.46it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 118.87it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 114.76it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 114.50it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 114.25it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:negative_test_with_result_format__boolean_only1] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2515.32it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 362.11it/s] Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 585.82it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 347.76it/s]Calculating Metrics:  60%|    | 6/10 [00:00<00:00, 462.74it/s]Calculating Metrics:  60%|    | 6/10 [00:00<00:00, 362.87it/s]Calculating Metrics:  80%|  | 8/10 [00:00<00:00, 446.05it/s]Calculating Metrics:  80%|  | 8/10 [00:00<00:00, 391.18it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 435.06it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 406.14it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 404.13it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 402.07it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:another_negative_test_with_result_format__boolean_only1] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2762.14it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 376.15it/s] Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 624.90it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 369.96it/s]Calculating Metrics:  60%|    | 6/10 [00:00<00:00, 483.67it/s]Calculating Metrics:  60%|    | 6/10 [00:00<00:00, 375.80it/s]Calculating Metrics:  80%|  | 8/10 [00:00<00:00, 456.75it/s]Calculating Metrics:  80%|  | 8/10 [00:00<00:00, 395.63it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 438.56it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 410.78it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 409.08it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 407.06it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:positive_test_with_mostly1] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2642.08it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 243.64it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 415.98it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 238.11it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 330.58it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 247.72it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 386.21it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 344.31it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 381.08it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 355.58it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 354.57it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 353.42it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:2nd_positive_test_with_mostly1] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2412.60it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 228.47it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 392.27it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 225.73it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 313.53it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 235.43it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 368.67it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 330.99it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 367.40it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 343.60it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 342.70it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 341.67it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:3rd_positive_test_with_mostly1] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2480.37it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 239.66it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 411.60it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 232.70it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 323.38it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 239.96it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 373.92it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 335.19it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 371.38it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 346.75it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 345.82it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 344.74it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:negative_test_with_mostly1] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 1712.31it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 204.77it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 348.83it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 200.39it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 280.23it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 216.06it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 343.49it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 310.72it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 344.35it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 318.66it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 317.41it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 316.28it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:error:_improperly_mixed_types1] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2564.54it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 208.33it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 353.92it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 161.76it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 228.01it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 165.29it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 251.71it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 223.46it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 246.07it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 232.00it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 231.37it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 230.82it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:error:_improperly_mixed_types_again1] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2695.57it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 242.57it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 413.19it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 235.91it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 327.37it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 245.56it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 384.74it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 343.84it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 380.13it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 354.58it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 353.57it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 352.43it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:error:_improperly_mixed_types_once_more1] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2590.68it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 241.52it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 404.12it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 234.29it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 326.55it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 243.31it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 382.14it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 342.19it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 375.16it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 350.37it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 349.45it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 348.35it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:negative_test_to_verify_that_the_denominator_for_mostly_works_with_missing_values1] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2380.42it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 237.24it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 403.02it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 230.11it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 319.57it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 241.37it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 371.12it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 333.16it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 366.91it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 342.74it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 341.83it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 340.77it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:positive_test_to_verify_that_the_denominator_for_mostly_works_with_missing_values1] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2692.11it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 241.02it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 410.72it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 237.16it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 330.34it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 125.48it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 197.66it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 163.75it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 181.56it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 156.96it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 156.51it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 156.14it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:error_on_string-to-int_comparisons1] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 1619.42it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 119.98it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 95.46it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 52.26it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 75.40it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 51.10it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 51.10it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 51.10it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 51.10it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 51.10it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 51.10it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 51.10it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 72.83it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:test_min_value_is_greater_than_max_value1] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 1646.12it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 39.69it/s]  Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 75.61it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 41.30it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 29.75it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 29.75it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 29.75it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 29.75it/s]Calculating Metrics:  38%|      | 5/13 [00:00<00:00, 29.75it/s]Calculating Metrics:  38%|      | 5/13 [00:00<00:00, 29.75it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 29.75it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 29.75it/s]Calculating Metrics:  54%|    | 7/13 [00:00<00:00, 29.75it/s]Calculating Metrics:  54%|    | 7/13 [00:00<00:00, 29.75it/s]Calculating Metrics:  54%|    | 7/13 [00:00<00:00, 29.75it/s]Calculating Metrics:  54%|    | 7/13 [00:00<00:00, 35.62it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:test_strict_min_failure1] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2556.72it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 233.85it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 409.70it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 224.91it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 308.26it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 218.17it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 327.63it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 283.65it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 309.77it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 291.75it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 291.01it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 290.16it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:test_strict_min_success1] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2398.12it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 194.73it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 337.69it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 202.80it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 283.46it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 211.95it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 328.35it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 295.60it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 329.42it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 309.21it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 308.44it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 307.52it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:test_strict_max_failure1] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2537.39it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 211.16it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 363.73it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 213.93it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 298.42it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 226.89it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 351.94it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 316.57it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 347.10it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 324.61it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 323.72it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 322.73it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:test_strict_max_success1] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2548.18it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 207.53it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 328.73it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 148.65it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 205.00it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 156.48it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 255.38it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 234.00it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 262.03it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 245.91it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 245.25it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 244.60it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_be_in_set:basic_positive_test_case_single_value_not_in_column] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2557.50it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 244.94it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 400.64it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 222.09it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 304.63it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 228.00it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 329.85it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 295.44it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 323.58it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 299.33it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 298.16it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 297.18it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_be_in_set:negative_test_case_include_one_existing_column_value] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 1647.41it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 129.06it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 219.53it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 118.94it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 163.92it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 124.38it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 194.99it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 178.02it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 196.69it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 186.10it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 185.65it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 185.27it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_be_in_set:positive_empty_values_set] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 1833.17it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 157.58it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 264.90it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 144.77it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 200.29it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 147.17it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 237.46it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 218.73it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 238.55it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 228.29it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 227.75it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 227.24it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_be_in_set:basic_negative_strings_set_all_character_values] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 1792.44it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 188.25it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 289.10it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 161.04it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 224.44it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 163.79it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 260.91it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 238.78it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 264.59it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 251.48it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 250.72it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 250.08it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_be_in_set:positive_test_strings_set_extra_value_in_column] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2577.94it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 198.59it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 316.26it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 203.77it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 284.64it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 202.38it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 323.44it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 295.84it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 326.23it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 308.93it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 308.09it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 307.21it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_be_in_set:negative_test_float_set_two_out_of_three_column_values_included_mostly] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2000.14it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 230.15it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 387.63it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 213.92it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 297.74it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 218.68it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 339.66it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 297.29it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 321.73it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 299.54it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 298.58it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 297.66it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_be_in_set:positive_test_float_set_two_out_of_three_column_values_included_mostly] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2522.13it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 217.56it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 371.71it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 226.08it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 314.40it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 225.60it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 355.08it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 318.44it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 353.90it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 330.86it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 329.81it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 328.76it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_be_in_set:positive_test_values_set_is_null] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2645.41it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 234.47it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 399.65it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 233.71it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 324.61it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 244.33it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 377.39it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 338.51it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 372.58it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 348.23it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 347.25it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 346.07it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_of_type:basic_sqlalchemy_int_positive_test] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 979.29it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 771.01it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 693.50it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 618.81it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_of_type:negative_sqlite_integer_is_not_varchar] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1179.50it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 905.12it/s] Calculating Metrics: 100%|| 1/1 [00:00<00:00, 802.58it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 706.83it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_of_type:positive_test_sql_non_postgres_floats] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1074.09it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 816.33it/s] Calculating Metrics: 100%|| 1/1 [00:00<00:00, 728.81it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 648.87it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_of_type:positive_test_sql_varchar] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 664.39it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 542.81it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 498.73it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 450.42it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_of_type:negative_test_sqlalchemy_floats_are_not_boolean] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1016.06it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 776.87it/s] Calculating Metrics: 100%|| 1/1 [00:00<00:00, 688.72it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 607.08it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_in_set:basic_positive_test_case_number_set] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 1549.14it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 50.32it/s]  Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 92.93it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 56.75it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 82.11it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 51.87it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 51.87it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 51.87it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 51.87it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 51.87it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 51.87it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 51.87it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 77.89it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_in_set:vacuously_true_empty_value_set] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2236.96it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 226.88it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 388.19it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 229.13it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 320.32it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 241.53it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 369.46it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 317.97it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 342.60it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 314.18it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 312.95it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 311.93it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_in_set:negative_test_case_exclude_existing_column_value] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2427.26it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 195.69it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 334.90it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 185.99it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 260.34it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 201.40it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 317.44it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 285.36it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 307.69it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 290.46it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 289.49it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 288.61it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_in_set:negative_empty_values_set] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2024.77it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 217.80it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 367.52it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 217.85it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 301.46it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 224.50it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 353.27it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 314.95it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 347.18it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 325.43it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 324.30it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 323.25it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_in_set:basic_positive_strings_set] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 1288.77it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 130.86it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 234.65it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 155.99it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 218.72it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 175.17it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 269.26it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 244.63it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 268.40it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 254.65it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 253.88it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 252.78it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_in_set:negative_test_strings_set_extra_value_in_column] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2577.15it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 230.92it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 384.98it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 228.27it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 315.66it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 241.05it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 370.57it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 333.58it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 363.62it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 340.73it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 339.05it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 337.76it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_in_set:negative_test_numbers_set_no_matching_values] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 1886.78it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 237.47it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 376.36it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 222.64it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 309.01it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 228.08it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 352.57it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 316.69it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 343.25it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 318.17it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 316.92it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 315.75it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_in_set:positive_test_float_set] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2134.51it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 224.54it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 24.55it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 24.55it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 24.55it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 24.55it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 24.55it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 24.55it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 24.55it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 24.55it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 24.55it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 24.55it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 66.20it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_in_set:negative_test_float_set] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2519.86it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 217.98it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 367.08it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 210.83it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 293.13it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 219.25it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 333.99it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 290.81it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 321.71it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 302.15it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 301.26it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 300.34it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_in_set:test_empty_column_should_be_vacuously_true] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2389.24it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 238.86it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 385.46it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 229.33it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 317.66it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 243.40it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 369.77it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 333.60it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 365.35it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 343.15it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 342.20it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 341.09it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_match_like_pattern_list:basic_positive_test] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2358.34it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 229.02it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 388.31it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 224.54it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 310.60it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 232.12it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 357.99it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 316.07it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 346.43it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 324.62it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 323.75it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 322.76it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_match_like_pattern_list:positive_test_with_multiple_like_patternes] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2453.53it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 221.26it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 373.37it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 219.68it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 303.15it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 227.45it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 349.51it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 313.93it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 341.65it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 319.34it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 318.26it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 317.23it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_match_like_pattern:positive_test_one_missing_value_no_exceptions] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 1586.05it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 164.76it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 292.74it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 174.81it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 241.83it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 176.35it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 275.32it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 254.44it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 284.38it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 268.23it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 267.24it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 266.05it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_match_like_pattern:positive_test_all_missing_values] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 1659.80it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 231.40it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 357.75it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 172.30it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 235.15it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 180.23it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 268.81it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 236.90it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 257.03it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 237.40it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 236.72it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 236.02it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_match_like_pattern:positive_test_all_missing_values_mostly] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 1561.25it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 166.53it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 286.00it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 172.72it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 238.77it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 183.30it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 285.66it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 261.25it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 284.95it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 261.85it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 260.91it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 260.11it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_like_pattern:positive_test_all_missing_values] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2435.72it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 257.00it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 434.35it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 252.67it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 349.29it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 263.38it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 403.65it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 362.22it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 395.33it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 370.21it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 369.08it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 367.73it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_like_pattern:positive_test_all_missing_values_mostly] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2423.75it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 250.12it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 415.49it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 246.67it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 341.41it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 258.60it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 405.29it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 363.77it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 396.51it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 371.17it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 370.01it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 368.65it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_value_lengths_to_be_between:positive_test_exact_min_and_max] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/14 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/14 [00:00<?, ?it/s]Calculating Metrics:  14%|        | 2/14 [00:00<00:00, 2339.27it/s]Calculating Metrics:  14%|        | 2/14 [00:00<00:00, 176.80it/s] Calculating Metrics:  29%|       | 4/14 [00:00<00:00, 307.06it/s]Calculating Metrics:  29%|       | 4/14 [00:00<00:00, 177.67it/s]Calculating Metrics:  43%|     | 6/14 [00:00<00:00, 245.71it/s]Calculating Metrics:  43%|     | 6/14 [00:00<00:00, 180.23it/s]Calculating Metrics:  57%|    | 8/14 [00:00<00:00, 228.11it/s]Calculating Metrics:  57%|    | 8/14 [00:00<00:00, 187.68it/s]Calculating Metrics:  93%|| 13/14 [00:00<00:00, 263.67it/s]Calculating Metrics:  93%|| 13/14 [00:00<00:00, 241.72it/s]Calculating Metrics: 100%|| 14/14 [00:00<00:00, 247.67it/s]Calculating Metrics: 100%|| 14/14 [00:00<00:00, 234.24it/s]Calculating Metrics: 100%|| 14/14 [00:00<00:00, 233.71it/s]Calculating Metrics: 100%|| 14/14 [00:00<00:00, 233.18it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_value_lengths_to_be_between:negative_test_matching_min_max_too_small] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/14 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/14 [00:00<?, ?it/s]Calculating Metrics:  14%|        | 2/14 [00:00<00:00, 2218.03it/s]Calculating Metrics:  14%|        | 2/14 [00:00<00:00, 181.82it/s] Calculating Metrics:  29%|       | 4/14 [00:00<00:00, 318.84it/s]Calculating Metrics:  29%|       | 4/14 [00:00<00:00, 178.38it/s]Calculating Metrics:  43%|     | 6/14 [00:00<00:00, 246.09it/s]Calculating Metrics:  43%|     | 6/14 [00:00<00:00, 181.91it/s]Calculating Metrics:  57%|    | 8/14 [00:00<00:00, 229.10it/s]Calculating Metrics:  57%|    | 8/14 [00:00<00:00, 188.47it/s]Calculating Metrics:  93%|| 13/14 [00:00<00:00, 265.47it/s]Calculating Metrics:  93%|| 13/14 [00:00<00:00, 246.20it/s]Calculating Metrics: 100%|| 14/14 [00:00<00:00, 255.12it/s]Calculating Metrics: 100%|| 14/14 [00:00<00:00, 238.86it/s]Calculating Metrics: 100%|| 14/14 [00:00<00:00, 238.19it/s]Calculating Metrics: 100%|| 14/14 [00:00<00:00, 237.60it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_value_lengths_to_be_between:negative_test_matching_max_min_too_large] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/14 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/14 [00:00<?, ?it/s]Calculating Metrics:  14%|        | 2/14 [00:00<00:00, 2385.84it/s]Calculating Metrics:  14%|        | 2/14 [00:00<00:00, 182.38it/s] Calculating Metrics:  29%|       | 4/14 [00:00<00:00, 324.28it/s]Calculating Metrics:  29%|       | 4/14 [00:00<00:00, 180.55it/s]Calculating Metrics:  43%|     | 6/14 [00:00<00:00, 249.49it/s]Calculating Metrics:  43%|     | 6/14 [00:00<00:00, 181.90it/s]Calculating Metrics:  57%|    | 8/14 [00:00<00:00, 228.98it/s]Calculating Metrics:  57%|    | 8/14 [00:00<00:00, 189.53it/s]Calculating Metrics:  93%|| 13/14 [00:00<00:00, 269.17it/s]Calculating Metrics:  93%|| 13/14 [00:00<00:00, 247.79it/s]Calculating Metrics: 100%|| 14/14 [00:00<00:00, 257.38it/s]Calculating Metrics: 100%|| 14/14 [00:00<00:00, 243.10it/s]Calculating Metrics: 100%|| 14/14 [00:00<00:00, 242.58it/s]Calculating Metrics: 100%|| 14/14 [00:00<00:00, 242.01it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_value_lengths_to_be_between:positive_test_with_null_min_value] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/14 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/14 [00:00<?, ?it/s]Calculating Metrics:  14%|        | 2/14 [00:00<00:00, 1561.25it/s]Calculating Metrics:  14%|        | 2/14 [00:00<00:00, 73.70it/s]  Calculating Metrics:  29%|       | 4/14 [00:00<00:00, 126.67it/s]Calculating Metrics:  29%|       | 4/14 [00:00<00:00, 76.33it/s] Calculating Metrics:  43%|     | 6/14 [00:00<00:00, 108.09it/s]Calculating Metrics:  43%|     | 6/14 [00:00<00:00, 74.18it/s] Calculating Metrics:  57%|    | 8/14 [00:00<00:00, 93.16it/s]Calculating Metrics:  57%|    | 8/14 [00:00<00:00, 79.52it/s]Calculating Metrics:  57%|    | 8/14 [00:00<00:00, 79.52it/s]Calculating Metrics:  93%|| 13/14 [00:00<00:00, 79.52it/s]Calculating Metrics:  93%|| 13/14 [00:00<00:00, 79.52it/s]Calculating Metrics: 100%|| 14/14 [00:00<00:00, 79.52it/s]Calculating Metrics: 100%|| 14/14 [00:00<00:00, 79.52it/s]Calculating Metrics: 100%|| 14/14 [00:00<00:00, 79.52it/s]Calculating Metrics: 100%|| 14/14 [00:00<00:00, 113.82it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_value_lengths_to_be_between:positive_test_with_null_max_value] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/14 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/14 [00:00<?, ?it/s]Calculating Metrics:  14%|        | 2/14 [00:00<00:00, 2430.07it/s]Calculating Metrics:  14%|        | 2/14 [00:00<00:00, 178.68it/s] Calculating Metrics:  29%|       | 4/14 [00:00<00:00, 317.89it/s]Calculating Metrics:  29%|       | 4/14 [00:00<00:00, 179.29it/s]Calculating Metrics:  43%|     | 6/14 [00:00<00:00, 248.43it/s]Calculating Metrics:  43%|     | 6/14 [00:00<00:00, 180.25it/s]Calculating Metrics:  57%|    | 8/14 [00:00<00:00, 228.12it/s]Calculating Metrics:  57%|    | 8/14 [00:00<00:00, 186.83it/s]Calculating Metrics:  93%|| 13/14 [00:00<00:00, 263.70it/s]Calculating Metrics:  93%|| 13/14 [00:00<00:00, 242.59it/s]Calculating Metrics: 100%|| 14/14 [00:00<00:00, 251.29it/s]Calculating Metrics: 100%|| 14/14 [00:00<00:00, 237.14it/s]Calculating Metrics: 100%|| 14/14 [00:00<00:00, 236.68it/s]Calculating Metrics: 100%|| 14/14 [00:00<00:00, 236.16it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_value_lengths_to_be_between:negative_test_with_max_lt_min] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/14 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/14 [00:00<?, ?it/s]Calculating Metrics:  14%|        | 2/14 [00:00<00:00, 2460.00it/s]Calculating Metrics:  14%|        | 2/14 [00:00<00:00, 193.65it/s] Calculating Metrics:  29%|       | 4/14 [00:00<00:00, 346.86it/s]Calculating Metrics:  29%|       | 4/14 [00:00<00:00, 191.02it/s]Calculating Metrics:  43%|     | 6/14 [00:00<00:00, 262.86it/s]Calculating Metrics:  43%|     | 6/14 [00:00<00:00, 188.85it/s]Calculating Metrics:  57%|    | 8/14 [00:00<00:00, 238.09it/s]Calculating Metrics:  57%|    | 8/14 [00:00<00:00, 195.39it/s]Calculating Metrics:  93%|| 13/14 [00:00<00:00, 277.55it/s]Calculating Metrics:  93%|| 13/14 [00:00<00:00, 256.32it/s]Calculating Metrics: 100%|| 14/14 [00:00<00:00, 267.19it/s]Calculating Metrics: 100%|| 14/14 [00:00<00:00, 252.16it/s]Calculating Metrics: 100%|| 14/14 [00:00<00:00, 251.66it/s]Calculating Metrics: 100%|| 14/14 [00:00<00:00, 251.06it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_value_lengths_to_be_between:positive_test_with_missing_value_in_column] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/14 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/14 [00:00<?, ?it/s]Calculating Metrics:  14%|        | 2/14 [00:00<00:00, 2481.84it/s]Calculating Metrics:  14%|        | 2/14 [00:00<00:00, 191.26it/s] Calculating Metrics:  29%|       | 4/14 [00:00<00:00, 339.96it/s]Calculating Metrics:  29%|       | 4/14 [00:00<00:00, 156.99it/s]Calculating Metrics:  43%|     | 6/14 [00:00<00:00, 209.78it/s]Calculating Metrics:  43%|     | 6/14 [00:00<00:00, 137.64it/s]Calculating Metrics:  57%|    | 8/14 [00:00<00:00, 171.28it/s]Calculating Metrics:  57%|    | 8/14 [00:00<00:00, 146.43it/s]Calculating Metrics:  93%|| 13/14 [00:00<00:00, 205.62it/s]Calculating Metrics:  93%|| 13/14 [00:00<00:00, 190.48it/s]Calculating Metrics: 100%|| 14/14 [00:00<00:00, 195.77it/s]Calculating Metrics: 100%|| 14/14 [00:00<00:00, 186.18it/s]Calculating Metrics: 100%|| 14/14 [00:00<00:00, 185.74it/s]Calculating Metrics: 100%|| 14/14 [00:00<00:00, 185.37it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_value_lengths_to_be_between:test_error_handling_values_are_integers] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/14 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/14 [00:00<?, ?it/s]Calculating Metrics:  14%|        | 2/14 [00:00<00:00, 2098.20it/s]Calculating Metrics:  14%|        | 2/14 [00:00<00:00, 147.40it/s] Calculating Metrics:  29%|       | 4/14 [00:00<00:00, 263.64it/s]Calculating Metrics:  29%|       | 4/14 [00:00<00:00, 146.27it/s]Calculating Metrics:  43%|     | 6/14 [00:00<00:00, 202.51it/s]Calculating Metrics:  43%|     | 6/14 [00:00<00:00, 156.01it/s]Calculating Metrics:  57%|    | 8/14 [00:00<00:00, 198.30it/s]Calculating Metrics:  57%|    | 8/14 [00:00<00:00, 165.23it/s]Calculating Metrics:  93%|| 13/14 [00:00<00:00, 229.50it/s]Calculating Metrics:  93%|| 13/14 [00:00<00:00, 206.90it/s]Calculating Metrics: 100%|| 14/14 [00:00<00:00, 209.35it/s]Calculating Metrics: 100%|| 14/14 [00:00<00:00, 196.51it/s]Calculating Metrics: 100%|| 14/14 [00:00<00:00, 196.06it/s]Calculating Metrics: 100%|| 14/14 [00:00<00:00, 195.66it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_like_pattern_list:basic_positive_test] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2360.99it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 95.47it/s]  Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 155.55it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 103.08it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 143.37it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 89.07it/s] Calculating Metrics:  85%| | 11/13 [00:00<00:00, 109.17it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 109.17it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 109.17it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 109.17it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 109.17it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 109.17it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 101.89it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_like_pattern_list:positive_test_with_multiple_like_patternes] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2403.61it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 223.49it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 365.43it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 214.49it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 292.75it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 222.19it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 345.52it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 302.73it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 318.31it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 298.81it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 297.82it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 296.86it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_like_pattern_list:positive_test_with_match_on__any] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2478.90it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 234.96it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 390.01it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 226.36it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 311.60it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 233.00it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 352.51it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 317.30it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 345.76it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 320.56it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 319.35it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 318.26it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_like_pattern_list:positive_test_column_name_has_space_and_match_on__any] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/13 [00:00<?, ?it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 2436.42it/s]Calculating Metrics:  15%|        | 2/13 [00:00<00:00, 226.96it/s] Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 378.04it/s]Calculating Metrics:  31%|       | 4/13 [00:00<00:00, 223.50it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 307.03it/s]Calculating Metrics:  46%|     | 6/13 [00:00<00:00, 233.00it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 355.47it/s]Calculating Metrics:  85%| | 11/13 [00:00<00:00, 316.64it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 345.25it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 323.03it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 321.89it/s]Calculating Metrics: 100%|| 13/13 [00:00<00:00, 320.74it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_unique:basic_positive_test_case] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/12 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/12 [00:00<?, ?it/s]Calculating Metrics:  17%|        | 2/12 [00:00<00:00, 2285.72it/s]Calculating Metrics:  17%|        | 2/12 [00:00<00:00, 295.86it/s] Calculating Metrics:  33%|      | 4/12 [00:00<00:00, 454.45it/s]Calculating Metrics:  33%|      | 4/12 [00:00<00:00, 275.85it/s]Calculating Metrics:  50%|     | 6/12 [00:00<00:00, 369.39it/s]Calculating Metrics:  50%|     | 6/12 [00:00<00:00, 287.40it/s]Calculating Metrics:  92%|| 11/12 [00:00<00:00, 380.83it/s]Calculating Metrics:  92%|| 11/12 [00:00<00:00, 352.38it/s]Calculating Metrics: 100%|| 12/12 [00:00<00:00, 365.11it/s]Calculating Metrics: 100%|| 12/12 [00:00<00:00, 344.83it/s]Calculating Metrics: 100%|| 12/12 [00:00<00:00, 343.27it/s]Calculating Metrics: 100%|| 12/12 [00:00<00:00, 341.58it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_unique:basic_negative_case_all_non_unique_character_values] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/12 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/12 [00:00<?, ?it/s]Calculating Metrics:  17%|        | 2/12 [00:00<00:00, 2098.73it/s]Calculating Metrics:  17%|        | 2/12 [00:00<00:00, 271.66it/s] Calculating Metrics:  33%|      | 4/12 [00:00<00:00, 456.67it/s]Calculating Metrics:  33%|      | 4/12 [00:00<00:00, 272.98it/s]Calculating Metrics:  50%|     | 6/12 [00:00<00:00, 357.44it/s]Calculating Metrics:  50%|     | 6/12 [00:00<00:00, 269.69it/s]Calculating Metrics:  92%|| 11/12 [00:00<00:00, 374.15it/s]Calculating Metrics:  92%|| 11/12 [00:00<00:00, 343.88it/s]Calculating Metrics: 100%|| 12/12 [00:00<00:00, 354.02it/s]Calculating Metrics: 100%|| 12/12 [00:00<00:00, 335.19it/s]Calculating Metrics: 100%|| 12/12 [00:00<00:00, 333.98it/s]Calculating Metrics: 100%|| 12/12 [00:00<00:00, 332.66it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_unique:positive_case_using_mostly] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/12 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/12 [00:00<?, ?it/s]Calculating Metrics:  17%|        | 2/12 [00:00<00:00, 942.54it/s]Calculating Metrics:  17%|        | 2/12 [00:00<00:00, 235.73it/s]Calculating Metrics:  33%|      | 4/12 [00:00<00:00, 403.27it/s]Calculating Metrics:  33%|      | 4/12 [00:00<00:00, 257.17it/s]Calculating Metrics:  50%|     | 6/12 [00:00<00:00, 342.56it/s]Calculating Metrics:  50%|     | 6/12 [00:00<00:00, 271.89it/s]Calculating Metrics:  92%|| 11/12 [00:00<00:00, 377.32it/s]Calculating Metrics:  92%|| 11/12 [00:00<00:00, 349.57it/s]Calculating Metrics: 100%|| 12/12 [00:00<00:00, 362.90it/s]Calculating Metrics: 100%|| 12/12 [00:00<00:00, 343.19it/s]Calculating Metrics: 100%|| 12/12 [00:00<00:00, 341.96it/s]Calculating Metrics: 100%|| 12/12 [00:00<00:00, 340.59it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_unique:negative_case_using_mostly] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/12 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/12 [00:00<?, ?it/s]Calculating Metrics:  17%|        | 2/12 [00:00<00:00, 2214.52it/s]Calculating Metrics:  17%|        | 2/12 [00:00<00:00, 293.73it/s] Calculating Metrics:  33%|      | 4/12 [00:00<00:00, 470.31it/s]Calculating Metrics:  33%|      | 4/12 [00:00<00:00, 282.06it/s]Calculating Metrics:  50%|     | 6/12 [00:00<00:00, 379.60it/s]Calculating Metrics:  50%|     | 6/12 [00:00<00:00, 289.94it/s]Calculating Metrics:  92%|| 11/12 [00:00<00:00, 425.81it/s]Calculating Metrics:  92%|| 11/12 [00:00<00:00, 390.68it/s]Calculating Metrics: 100%|| 12/12 [00:00<00:00, 405.75it/s]Calculating Metrics: 100%|| 12/12 [00:00<00:00, 381.42it/s]Calculating Metrics: 100%|| 12/12 [00:00<00:00, 379.88it/s]Calculating Metrics: 100%|| 12/12 [00:00<00:00, 378.21it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_unique:positive_case_multiple_null_values] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/12 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/12 [00:00<?, ?it/s]Calculating Metrics:  17%|        | 2/12 [00:00<00:00, 2306.46it/s]Calculating Metrics:  17%|        | 2/12 [00:00<00:00, 295.20it/s] Calculating Metrics:  33%|      | 4/12 [00:00<00:00, 493.22it/s]Calculating Metrics:  33%|      | 4/12 [00:00<00:00, 294.09it/s]Calculating Metrics:  50%|     | 6/12 [00:00<00:00, 395.91it/s]Calculating Metrics:  50%|     | 6/12 [00:00<00:00, 298.00it/s]Calculating Metrics:  92%|| 11/12 [00:00<00:00, 401.69it/s]Calculating Metrics:  92%|| 11/12 [00:00<00:00, 366.87it/s]Calculating Metrics: 100%|| 12/12 [00:00<00:00, 369.98it/s]Calculating Metrics: 100%|| 12/12 [00:00<00:00, 349.71it/s]Calculating Metrics: 100%|| 12/12 [00:00<00:00, 348.53it/s]Calculating Metrics: 100%|| 12/12 [00:00<00:00, 347.19it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_unique:negative_case_non_unique_numeric_values] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/12 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/12 [00:00<?, ?it/s]Calculating Metrics:  17%|        | 2/12 [00:00<00:00, 1488.13it/s]Calculating Metrics:  17%|        | 2/12 [00:00<00:00, 167.68it/s] Calculating Metrics:  33%|      | 4/12 [00:00<00:00, 260.79it/s]Calculating Metrics:  33%|      | 4/12 [00:00<00:00, 114.97it/s]Calculating Metrics:  50%|     | 6/12 [00:00<00:00, 159.83it/s]Calculating Metrics:  50%|     | 6/12 [00:00<00:00, 125.94it/s]Calculating Metrics:  92%|| 11/12 [00:00<00:00, 186.02it/s]Calculating Metrics:  92%|| 11/12 [00:00<00:00, 170.48it/s]Calculating Metrics: 100%|| 12/12 [00:00<00:00, 177.28it/s]Calculating Metrics: 100%|| 12/12 [00:00<00:00, 167.03it/s]Calculating Metrics: 100%|| 12/12 [00:00<00:00, 166.46it/s]Calculating Metrics: 100%|| 12/12 [00:00<00:00, 165.92it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_unique:positive_case_all_null_values] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/12 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/12 [00:00<?, ?it/s]Calculating Metrics:  17%|        | 2/12 [00:00<00:00, 1241.47it/s]Calculating Metrics:  17%|        | 2/12 [00:00<00:00, 71.49it/s]  Calculating Metrics:  33%|      | 4/12 [00:00<00:00, 131.64it/s]Calculating Metrics:  33%|      | 4/12 [00:00<00:00, 97.33it/s] Calculating Metrics:  50%|     | 6/12 [00:00<00:00, 137.12it/s]Calculating Metrics:  50%|     | 6/12 [00:00<00:00, 115.20it/s]Calculating Metrics:  92%|| 11/12 [00:00<00:00, 166.62it/s]Calculating Metrics:  92%|| 11/12 [00:00<00:00, 156.63it/s]Calculating Metrics: 100%|| 12/12 [00:00<00:00, 151.79it/s]Calculating Metrics: 100%|| 12/12 [00:00<00:00, 145.23it/s]Calculating Metrics: 100%|| 12/12 [00:00<00:00, 144.82it/s]Calculating Metrics: 100%|| 12/12 [00:00<00:00, 144.44it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_unique:negative_multiple_duplicate_values] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/12 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/12 [00:00<?, ?it/s]Calculating Metrics:  17%|        | 2/12 [00:00<00:00, 2081.02it/s]Calculating Metrics:  17%|        | 2/12 [00:00<00:00, 276.63it/s] Calculating Metrics:  33%|      | 4/12 [00:00<00:00, 465.00it/s]Calculating Metrics:  33%|      | 4/12 [00:00<00:00, 273.69it/s]Calculating Metrics:  50%|     | 6/12 [00:00<00:00, 365.32it/s]Calculating Metrics:  50%|     | 6/12 [00:00<00:00, 278.04it/s]Calculating Metrics:  92%|| 11/12 [00:00<00:00, 354.73it/s]Calculating Metrics:  92%|| 11/12 [00:00<00:00, 325.87it/s]Calculating Metrics: 100%|| 12/12 [00:00<00:00, 334.44it/s]Calculating Metrics: 100%|| 12/12 [00:00<00:00, 313.87it/s]Calculating Metrics: 100%|| 12/12 [00:00<00:00, 312.49it/s]Calculating Metrics: 100%|| 12/12 [00:00<00:00, 310.82it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_null:basic_positive_case_basic_result_format] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/8 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/8 [00:00<?, ?it/s]Calculating Metrics:  25%|       | 2/8 [00:00<00:00, 1213.45it/s]Calculating Metrics:  25%|       | 2/8 [00:00<00:00, 399.34it/s] Calculating Metrics:  50%|     | 4/8 [00:00<00:00, 609.37it/s]Calculating Metrics:  50%|     | 4/8 [00:00<00:00, 407.96it/s]Calculating Metrics:  62%|   | 5/8 [00:00<00:00, 472.54it/s]Calculating Metrics:  62%|   | 5/8 [00:00<00:00, 370.39it/s]Calculating Metrics:  88%| | 7/8 [00:00<00:00, 421.76it/s]Calculating Metrics:  88%| | 7/8 [00:00<00:00, 383.64it/s]Calculating Metrics: 100%|| 8/8 [00:00<00:00, 395.73it/s]Calculating Metrics: 100%|| 8/8 [00:00<00:00, 374.46it/s]Calculating Metrics: 100%|| 8/8 [00:00<00:00, 372.06it/s]Calculating Metrics: 100%|| 8/8 [00:00<00:00, 369.58it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_null:negative_no_missing_values] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 1922.67it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 333.54it/s] Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 540.75it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 337.58it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 395.29it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 299.85it/s]Calculating Metrics:  90%| | 9/10 [00:00<00:00, 429.18it/s]Calculating Metrics:  90%| | 9/10 [00:00<00:00, 391.95it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 405.78it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 382.00it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 380.37it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 378.46it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_null:positive_mostly] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2400.86it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 365.69it/s] Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 582.83it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 354.58it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 413.39it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 313.71it/s]Calculating Metrics:  90%| | 9/10 [00:00<00:00, 449.64it/s]Calculating Metrics:  90%| | 9/10 [00:00<00:00, 409.37it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 423.98it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 397.77it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 396.01it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 393.95it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_null:negative_mostly] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 1931.97it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 349.83it/s] Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 570.77it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 353.08it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 413.91it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 315.67it/s]Calculating Metrics:  90%| | 9/10 [00:00<00:00, 473.83it/s]Calculating Metrics:  90%| | 9/10 [00:00<00:00, 429.41it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 443.54it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 413.80it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 411.66it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 409.38it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_null:positive_case_with_mostly_and_no_unexpected_values] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2346.46it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 357.01it/s] Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 572.41it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 350.63it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 410.47it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 310.39it/s]Calculating Metrics:  90%| | 9/10 [00:00<00:00, 451.58it/s]Calculating Metrics:  90%| | 9/10 [00:00<00:00, 401.08it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 412.46it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 387.97it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 386.26it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 384.32it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_null:negative_case_with_75percent_non_null_values_no_mostly] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2432.89it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 369.14it/s] Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 600.06it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 359.36it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 421.73it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 313.44it/s]Calculating Metrics:  90%| | 9/10 [00:00<00:00, 444.69it/s]Calculating Metrics:  90%| | 9/10 [00:00<00:00, 404.64it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 417.57it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 392.50it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 390.75it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 388.74it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_in_type_list:positive_test_sqlalchemy_integer_column] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1315.65it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 996.98it/s] Calculating Metrics: 100%|| 1/1 [00:00<00:00, 879.68it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 785.01it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_in_type_list:negative_test_sqlalchemy_float_values_are_not_text] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1524.09it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1180.50it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1051.47it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 930.00it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_in_type_list:positive_test_float_values] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1483.13it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1137.28it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1012.87it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 894.12it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_in_type_list:positive_test_text_values] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1449.31it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1125.99it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1004.86it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 893.55it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_in_type_list:positive_test_boolean_values] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1692.62it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1285.41it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1135.13it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 999.12it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_in_type_list:positive_test_text_and_integer_values] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1798.59it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1349.08it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1187.52it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1036.14it/s]
_ test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_in_type_list:positive_test_placeholder_expectation] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1128.41it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 803.81it/s] Calculating Metrics: 100%|| 1/1 [00:00<00:00, 695.34it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 629.30it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_stdev_to_be_between:basic_positive_test] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 2770.35it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1144.89it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1364.15it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 996.98it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 990.57it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 860.02it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 834.52it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 807.57it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_stdev_to_be_between:vacuously_true] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 2259.86it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 988.06it/s] Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1191.00it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 905.25it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 740.75it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 679.13it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 666.11it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 641.04it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_stdev_to_be_between:positive_test__exact_min_and_max] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3184.74it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1243.13it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1532.07it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1087.45it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1113.95it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 980.89it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 955.15it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 916.39it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_stdev_to_be_between:basic_negative_test] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3087.45it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1217.33it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1508.20it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1087.73it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1086.40it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 965.71it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 940.69it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 913.19it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_stdev_to_be_between:positive_zero_stdev_exact_min_and_max] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3236.35it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1252.40it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1543.92it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1111.07it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1118.56it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 996.04it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 970.17it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 941.59it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_stdev_to_be_between:positive_test_null_max_exact_min] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3216.49it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1249.98it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1539.38it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1102.51it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1100.72it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 979.92it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 954.88it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 926.36it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_stdev_to_be_between:positive_test_null_min_exact_max] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 2656.30it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1159.45it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1450.65it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1063.46it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1102.60it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 984.46it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 959.69it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 932.22it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_stdev_to_be_between:negative_test_null_max] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3300.00it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1269.08it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1564.07it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1122.37it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1138.67it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1012.20it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 979.18it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 949.21it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_stdev_to_be_between:negative_test_null_min] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3267.86it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1274.67it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1573.26it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1127.80it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1151.73it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1023.25it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 996.51it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 966.88it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_stdev_to_be_between:positive_test_missing_value_in_column_complete_result_format] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3205.43it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1248.49it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1545.62it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1115.31it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1112.62it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 994.09it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 968.83it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 940.27it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_be_in_set:basic_positive_test] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3086.32it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1059.30it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1328.01it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 944.95it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 866.01it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 780.52it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 764.55it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 746.58it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_be_in_set:vacuously_true_universal_set] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3221.43it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1091.84it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1365.63it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 962.51it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 925.95it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 824.92it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 806.64it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 785.71it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_be_in_set:positive_test_with_null_values_in_column] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3289.65it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1095.26it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1374.43it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 966.88it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 908.69it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 812.06it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 794.45it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 774.46it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_be_in_set:positive_test_with_duplicate_values_in_column] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3240.10it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1044.27it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1304.74it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 930.48it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 898.04it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 805.78it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 789.11it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 769.81it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_be_in_set:positive_test_duplicate_and_null_values] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3257.71it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1131.30it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1421.16it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 992.11it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 959.96it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 855.28it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 836.14it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 814.63it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_be_in_set:basic_negative_test_no_set_intersection] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3101.15it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1109.31it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1383.19it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 974.29it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 951.74it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 849.61it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 830.72it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 809.40it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_be_in_set:negative_test_some_set_intersection_and_extra] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3169.10it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1111.66it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1392.07it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 942.12it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 886.09it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 793.77it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 777.26it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 758.40it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_be_in_set:negative_test_with_null_values_in_column] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3246.37it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1067.80it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1335.20it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 893.42it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 860.41it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 772.36it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 756.00it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 732.31it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_be_in_set:negative_test_with_duplicate_values_in_column] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3169.10it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1129.78it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1413.02it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 983.27it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 924.82it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 823.50it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 805.59it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 785.19it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_be_in_set:negative_test_duplicate_and_null_values] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 2229.83it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 974.17it/s] Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1252.53it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 886.00it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 880.83it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 791.90it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 775.18it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 755.29it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_most_common_value_to_be_in_set:negative_test_tie_for_most_common_with_missing_values_and_complete_result_format] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 2945.44it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1189.70it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1474.27it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1050.06it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1040.58it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 931.76it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 908.64it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 882.22it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_most_common_value_to_be_in_set:negative_test__tie_for_most_common__full_value_set__ties_okay__false] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3016.40it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1148.02it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1420.51it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1041.98it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1063.19it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 951.25it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 928.30it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 901.52it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_most_common_value_to_be_in_set:positive_test__tie_for_most_common__ties_okay__true] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3215.26it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1175.86it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1438.87it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1050.06it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1060.77it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 948.99it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 925.03it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 897.90it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_most_common_value_to_be_in_set:positive_test__tie_for_most_common_but_test_for_last_value__ties_okay__true] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3013.15it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1186.17it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1454.34it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1048.66it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1059.30it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 944.50it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 921.07it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 893.45it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_most_common_value_to_be_in_set:negative_test__tie_for_most_common__value_set_does_not_match__ties_okay__false] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3204.20it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1260.88it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1555.94it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1123.17it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1136.05it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1011.35it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 985.45it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 955.80it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_most_common_value_to_be_in_set:negative_test__tie_for_most_common__value_set_does_not_match__ties_okay__true] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3215.26it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1257.85it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1552.10it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1120.67it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1139.99it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1014.53it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 988.17it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 958.53it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_most_common_value_to_be_in_set:positive_test_string_values_value_set_contains_more_than_actual_mode_list] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3215.26it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1259.55it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1556.14it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1114.52it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1107.11it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 965.32it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 936.12it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 907.22it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_most_common_value_to_be_in_set:negative_test_string_values_value_set_contains_more_than_actual_mode_list] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 2998.07it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 974.63it/s] Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1191.34it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 897.37it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 886.51it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 803.31it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 785.67it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 765.56it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_quantile_values_to_be_between:basic_positive_test_extremes] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3076.13it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1105.36it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1394.07it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 907.40it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 728.18it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 659.82it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 646.89it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 633.10it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_quantile_values_to_be_between:basic_positive_test_normal_quantiles] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 2489.94it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 976.56it/s] Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1249.79it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 889.38it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 794.26it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 716.18it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 702.24it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 686.55it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_quantile_values_to_be_between:basic_positive_test_uneven_spacing] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3200.54it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1007.04it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1274.99it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 890.20it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 786.96it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 708.11it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 693.24it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 677.65it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_quantile_values_to_be_between:basic_negative_test_normal_quantiles_wrong_distribution] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3119.60it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1040.51it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1319.24it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 926.24it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 811.16it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 729.67it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 715.29it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 699.28it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_max_to_be_between:basic_positive_test_case] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3044.87it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1226.40it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1480.17it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 897.18it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 938.32it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 847.68it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 828.18it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 806.64it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_max_to_be_between:basic_negative_test_case] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3225.15it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1195.47it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1452.82it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1052.96it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1104.35it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 984.46it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 957.88it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 928.05it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_max_to_be_between:test_case_with_result_format_summary_also_verifies_that_max_value_is_inclusive] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 2915.75it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1126.29it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1386.39it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1019.02it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1072.99it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 899.73it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 855.63it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 815.34it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_max_to_be_between:test_case_with_only_a_lower_bound_and_a_missing_value] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3220.20it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1245.89it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1537.50it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1102.02it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1094.62it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 968.72it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 942.91it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 914.24it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_max_to_be_between:negative_test_case_with_only_a_lower_bound] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3261.51it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1197.52it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1472.03it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1064.54it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1062.12it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 950.34it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 926.76it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 900.45it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_max_to_be_between:datetime_except_sqlite] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3160.74it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1249.98it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1545.62it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1106.68it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1114.54it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 992.85it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 967.60it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 939.69it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_max_to_be_between:datetime_with_evaluation_parameter_except_sqlite] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3134.76it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1227.84it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1520.41it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1084.92it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1105.87it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 983.25it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 958.04it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 929.54it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_max_to_be_between:test_empty_column_should_be_false_no_observed_value_with_which_to_compare] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3071.63it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1219.45it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1513.64it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1088.86it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1141.46it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1013.91it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 985.16it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 955.75it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_mean_to_be_between:simple_mean_positive_range] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3425.32it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1276.22it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1567.18it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1121.07it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1147.08it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1018.28it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 992.03it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 962.49it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_mean_to_be_between:simple_mean_negative_range] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3401.71it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1275.45it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1567.38it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1119.38it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1084.29it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 969.73it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 945.41it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 918.70it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_mean_to_be_between:simple_mean_positive_exact_match0] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3164.32it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1246.26it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1533.75it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1106.19it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1135.67it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1010.07it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 982.56it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 953.09it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_mean_to_be_between:simple_mean_negative_exact_match] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3407.23it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1299.55it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1599.86it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1142.86it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1196.83it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1062.72it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1034.35it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1003.48it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_mean_to_be_between:simple_mean_positive_exact_match1] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3545.48it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1320.00it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1621.51it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1155.14it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1194.96it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1059.30it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1030.86it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 999.95it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_mean_to_be_between:simple_mean_negative_range_match] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3189.58it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1227.84it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1518.21it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1089.71it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1129.63it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1003.96it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 977.52it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 947.92it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_mean_to_be_between:simple_mean_includes_null] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3220.20it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1262.39it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1555.94it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1116.00it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1139.21it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 995.98it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 965.43it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 935.45it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_mean_to_be_between:vacuously_true_missing_min_and_max] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3306.51it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1265.82it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1560.96it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1123.98it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1169.96it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1038.97it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1011.65it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 980.89it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_mean_to_be_between:type_mismatch_null_observed_value] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3294.82it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1284.04it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1584.95it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1139.03it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 217.11it/s] Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 187.19it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 165.59it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 162.58it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 161.37it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_mean_to_be_between:coerced_types_true_false_values] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3356.79it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1289.76it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1587.35it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1133.80it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1038.45it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 928.77it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 905.80it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 879.77it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_mean_to_be_between:coerced_types_true_false_and_null] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3338.09it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1286.99it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1584.55it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1110.68it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1123.95it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 999.95it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 973.95it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 945.20it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_mean_to_be_between:test_empty_column_should_be_false_no_observed_value_with_which_to_compare] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 2813.08it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1184.66it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1474.10it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1074.91it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1089.01it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 947.65it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 918.65it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 889.90it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_equal_set:basic_positive_test] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 2932.05it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1098.27it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1375.48it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 968.29it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 917.89it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 821.69it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 804.51it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 784.79it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_equal_set:positive_test_with_null_values_in_column] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3294.82it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1133.29it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1424.70it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 992.42it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 928.30it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 826.83it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 808.07it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 786.00it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_equal_set:positive_test_with_duplicate_values_in_column] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3472.11it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1138.83it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1422.28it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 987.13it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 962.16it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 855.94it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 836.81it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 815.46it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_equal_set:positive_test_duplicate_and_null_values] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 2550.50it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1027.64it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1309.49it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 937.48it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 923.55it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 827.12it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 809.20it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 789.26it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_equal_set:basic_negative_test_set_contained] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3251.40it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1128.56it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1416.52it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 986.12it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 952.82it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 847.81it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 828.79it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 807.41it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_equal_set:negative_test_some_set_intersection] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3169.10it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1119.08it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1406.23it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 985.20it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 957.55it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 853.76it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 834.69it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 813.16it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_equal_set:negative_test_with_null_values_in_column] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 2923.88it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1083.38it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1369.35it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 968.74it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 951.90it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 850.90it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 832.12it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 811.16it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_equal_set:negative_test_with_duplicate_values_in_column] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3437.95it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1158.17it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1451.48it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1006.39it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 957.44it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 850.51it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 831.13it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 809.44it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_equal_set:negative_test_duplicate_and_null_values] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3311.73it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1107.99it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1384.26it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 966.13it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 910.52it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 811.83it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 794.11it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 774.29it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_sum_to_be_between:basic_positive_test_case] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3285.78it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1265.25it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1563.29it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1124.58it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1161.45it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1032.57it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1005.83it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 975.87it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_sum_to_be_between:basic_negative_test_case] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3622.02it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1320.00it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1621.51it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1155.14it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1222.03it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1080.45it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1051.20it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1019.33it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_sum_to_be_between:test_case_with_result_format_summary] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3294.82it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1281.09it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1572.27it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1126.90it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1186.26it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1052.92it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1024.88it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 992.03it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_sum_to_be_between:test_case_with_only_a_lower_bound_and_a_missing_value] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3378.42it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1287.78it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1584.55it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1133.29it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1160.01it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1028.52it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1001.45it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 971.07it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_sum_to_be_between:negative_test_case_with_only_a_lower_bound] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3343.41it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1281.88it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1579.78it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1133.70it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1195.72it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1057.30it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1029.02it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 997.75it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_sum_to_be_between:negative_test_case_with_only_a_max] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3412.78it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1289.56it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1587.55it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1132.17it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1175.53it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1041.93it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1013.97it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 983.08it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_sum_to_be_between:raise_valueerror_with_both_max_and_min_are_missing] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3407.23it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1287.98it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1584.95it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1132.47it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1156.41it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1024.63it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 997.28it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 967.15it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_unique_value_count_to_be_between:basic_positive_test] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3148.88it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1249.23it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1539.19it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1109.02it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1139.60it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1013.73it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 987.65it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 958.53it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_unique_value_count_to_be_between:positive_test_with_null_values_in_column] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3283.21it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1267.35it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1561.54it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1122.77it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1150.07it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1024.31it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 997.52it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 967.38it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_unique_value_count_to_be_between:null_min_duplicate_values_in_column] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3453.52it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1302.17it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1604.14it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1148.91it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1192.92it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1057.63it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1030.10it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 998.47it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_unique_value_count_to_be_between:null_max_duplicate_and_null_values] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3636.15it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1331.53it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1632.02it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1159.18it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1204.05it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1066.37it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1037.87it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1006.07it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_unique_value_count_to_be_between:vacuously_true_null_min_and_max] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3443.60it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1299.75it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1600.88it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1144.63it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1205.95it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1069.57it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1041.48it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1009.88it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_median_to_be_between:positive_test_min_equal_max] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 2378.40it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1106.82it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1397.95it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1029.53it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 913.24it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 826.30it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 808.27it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 787.74it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_median_to_be_between:positive_test_null_min] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 2933.08it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1204.22it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1494.05it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1051.82it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 980.44it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 883.01it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 862.45it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 838.73it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_median_to_be_between:positive_test_null_max] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3245.11it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1268.89it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1567.18it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1078.23it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 971.07it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 873.54it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 852.46it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 829.16it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_median_to_be_between:negative_test_min_equal_max] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3179.91it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1246.08it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1534.69it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1103.76it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 993.09it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 893.45it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 872.00it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 847.85it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_median_to_be_between:negative_test_null_min] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3184.74it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1245.34it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1509.83it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1072.62it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1004.02it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 902.92it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 881.43it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 857.07it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_median_to_be_between:negative_test_null_max] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3278.08it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1273.70it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1569.72it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1123.98it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1061.51it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 951.47it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 928.05it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 901.90it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_median_to_be_between:positive_test_missing_value_in_column_exact_min_and_max] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3401.71it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1294.54it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1593.38it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1140.27it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1053.18it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 943.65it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 920.61it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 894.83it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_median_to_be_between:negative_test_missing_value_in_column_complete_result_format] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3247.62it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1230.18it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1516.01it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1099.33it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1028.58it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 923.35it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 901.13it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 876.23it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_median_to_be_between:vacuously_true_both_min_and_max_null] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3134.76it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1208.38it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1469.79it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1069.16it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 998.70it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 899.29it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 878.34it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 854.54it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_median_to_be_between:test_empty_column_should_be_false_no_observed_value_with_which_to_compare] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3081.78it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1232.53it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1525.39it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1101.35it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1019.40it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 914.14it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 892.07it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 867.71it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_min_to_be_between:basic_positive_test_case] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3096.57it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1228.74it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1522.99it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1090.94it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1114.91it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 992.09it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 966.65it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 938.32it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_min_to_be_between:negative_test_case_with_max_value_none] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 2999.14it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1221.23it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1430.04it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1037.00it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1092.62it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 974.46it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 949.90it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 921.88it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_min_to_be_between:test_case_with_result_format_summary_also_verifies_that_max_value_is_inclusive] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3236.35it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1257.10it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1549.43it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1108.53it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1166.46it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1034.35it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1007.04it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 976.33it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_min_to_be_between:test_case_with_only_a_lower_bound_and_a_missing_value] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 2966.27it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1203.88it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1493.88it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1083.33it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1114.10it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 992.26it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 966.15it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 936.28it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_min_to_be_between:negative_test_case_with_only_a_lower_bound] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3169.10it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1236.16it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1528.17it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1098.46it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1155.30it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 992.56it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 961.50it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 931.50it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_min_to_be_between:test_on_a_series_with_mostly_nulls] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3252.66it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1246.82it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1539.19it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1103.38it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1131.84it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 984.46it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 954.39it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 925.03it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_min_to_be_between:negative_test_case_with_only_a_max] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3300.00it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1263.34it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1551.15it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1114.32it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1127.96it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 965.71it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 935.92it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 907.22it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_min_to_be_between:raise_valueerror_with_both_max_and_min_are_missing] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3279.36it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1258.61it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1552.87it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1057.12it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 1094.98it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 961.11it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 935.24it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 907.47it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_proportion_of_unique_values_to_be_between:basic_positive_test] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/7 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/7 [00:00<?, ?it/s]Calculating Metrics:  29%|       | 2/7 [00:00<00:00, 2946.47it/s]Calculating Metrics:  29%|       | 2/7 [00:00<00:00, 493.01it/s] Calculating Metrics:  43%|     | 3/7 [00:00<00:00, 675.56it/s]Calculating Metrics:  43%|     | 3/7 [00:00<00:00, 417.03it/s]Calculating Metrics:  71%|  | 5/7 [00:00<00:00, 572.15it/s]Calculating Metrics:  71%|  | 5/7 [00:00<00:00, 445.47it/s]Calculating Metrics:  86%| | 6/7 [00:00<00:00, 503.74it/s]Calculating Metrics:  86%| | 6/7 [00:00<00:00, 446.33it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 489.25it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 454.34it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 450.71it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 446.75it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_proportion_of_unique_values_to_be_between:positive_test_with_null_values_in_column] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/7 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/7 [00:00<?, ?it/s]Calculating Metrics:  29%|       | 2/7 [00:00<00:00, 3116.12it/s]Calculating Metrics:  29%|       | 2/7 [00:00<00:00, 535.50it/s] Calculating Metrics:  43%|     | 3/7 [00:00<00:00, 669.95it/s]Calculating Metrics:  43%|     | 3/7 [00:00<00:00, 400.76it/s]Calculating Metrics:  71%|  | 5/7 [00:00<00:00, 508.81it/s]Calculating Metrics:  71%|  | 5/7 [00:00<00:00, 399.11it/s]Calculating Metrics:  86%| | 6/7 [00:00<00:00, 452.59it/s]Calculating Metrics:  86%| | 6/7 [00:00<00:00, 398.86it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 435.35it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 406.93it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 401.50it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 396.17it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_proportion_of_unique_values_to_be_between:duplicate_values_in_column] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/7 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/7 [00:00<?, ?it/s]Calculating Metrics:  29%|       | 2/7 [00:00<00:00, 3013.15it/s]Calculating Metrics:  29%|       | 2/7 [00:00<00:00, 509.57it/s] Calculating Metrics:  43%|     | 3/7 [00:00<00:00, 693.35it/s]Calculating Metrics:  43%|     | 3/7 [00:00<00:00, 421.06it/s]Calculating Metrics:  71%|  | 5/7 [00:00<00:00, 577.44it/s]Calculating Metrics:  71%|  | 5/7 [00:00<00:00, 459.27it/s]Calculating Metrics:  86%| | 6/7 [00:00<00:00, 515.64it/s]Calculating Metrics:  86%| | 6/7 [00:00<00:00, 452.18it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 498.72it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 465.83it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 462.57it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 458.59it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_proportion_of_unique_values_to_be_between:null_max_duplicate_and_null_values] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/7 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/7 [00:00<?, ?it/s]Calculating Metrics:  29%|       | 2/7 [00:00<00:00, 2720.04it/s]Calculating Metrics:  29%|       | 2/7 [00:00<00:00, 528.12it/s] Calculating Metrics:  43%|     | 3/7 [00:00<00:00, 722.49it/s]Calculating Metrics:  43%|     | 3/7 [00:00<00:00, 436.15it/s]Calculating Metrics:  71%|  | 5/7 [00:00<00:00, 590.86it/s]Calculating Metrics:  71%|  | 5/7 [00:00<00:00, 453.87it/s]Calculating Metrics:  86%| | 6/7 [00:00<00:00, 511.28it/s]Calculating Metrics:  86%| | 6/7 [00:00<00:00, 452.75it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 500.60it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 467.44it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 464.31it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 460.37it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_proportion_of_unique_values_to_be_between:vacuously_true_null_min_and_max] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/7 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/7 [00:00<?, ?it/s]Calculating Metrics:  29%|       | 2/7 [00:00<00:00, 3071.63it/s]Calculating Metrics:  29%|       | 2/7 [00:00<00:00, 550.80it/s] Calculating Metrics:  43%|     | 3/7 [00:00<00:00, 740.87it/s]Calculating Metrics:  43%|     | 3/7 [00:00<00:00, 437.94it/s]Calculating Metrics:  71%|  | 5/7 [00:00<00:00, 597.65it/s]Calculating Metrics:  71%|  | 5/7 [00:00<00:00, 469.42it/s]Calculating Metrics:  86%| | 6/7 [00:00<00:00, 528.54it/s]Calculating Metrics:  86%| | 6/7 [00:00<00:00, 464.93it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 512.92it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 477.26it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 473.83it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 469.35it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:basic_positive_test] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3090.87it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1113.58it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1399.81it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 977.54it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 930.21it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 831.58it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 813.16it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 792.54it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:positive_test_with_null_values_in_column] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3200.54it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1122.97it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1411.91it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 986.51it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 903.75it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 809.87it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 792.54it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 772.82it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:positive_test_with_duplicate_values_in_column] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3320.91it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1142.71it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1335.62it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 938.88it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 893.21it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 799.68it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 782.59it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 763.05it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:positive_test_duplicate_and_null_values] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 2728.89it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1042.71it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1319.79it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 935.74it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 907.22it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 807.92it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 789.89it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 770.13it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:basic_negative_test_no_set_intersection] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3120.76it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1114.17it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1401.22it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 978.76it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 955.80it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 850.90it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 832.16it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 811.20it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:negative_test_some_set_intersection] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3153.61it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1118.63it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1409.69it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 986.82it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 966.65it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 859.84it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 840.67it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 819.00it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:negative_test_with_null_values_in_column] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3296.11it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1135.28it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1426.80it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 994.38it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 901.76it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 801.63it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 783.25it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 763.26it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:negative_test_with_duplicate_values_in_column] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3200.54it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1022.63it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1278.23it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 914.66it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 878.16it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 786.63it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 770.13it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 751.47it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:negative_test_duplicate_and_null_values] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3057.07it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1102.46it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1388.23it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 976.56it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 949.90it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 847.08it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 828.63it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 807.37it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:positive_test_string_values] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 2009.73it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 668.41it/s] Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 838.64it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 494.63it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 471.35it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 426.89it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 419.33it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 411.06it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:negative_test_string_values] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1550.57it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 490.94it/s] Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 632.91it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 466.28it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 453.46it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 411.87it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 404.66it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 396.78it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:basic_positive_test_case_date_set] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 3007.75it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1100.72it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 1319.93it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 929.66it/s] Calculating Metrics: 100%|| 4/4 [00:00<00:00, 855.46it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 769.84it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 753.86it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 729.41it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:basic_negative_test_case_date_set] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1959.04it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 99.55it/s]  Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 137.41it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 126.04it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 150.22it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 144.99it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 143.78it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 142.51it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:basic_positive_test_case_datetime_set] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1883.39it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 614.28it/s] Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 771.86it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 164.75it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 189.03it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 180.44it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 178.37it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 172.84it/s]
_ test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:basic_negative_test_case_datetime_set] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 1787.47it/s]Calculating Metrics:  50%|     | 2/4 [00:00<00:00, 734.75it/s] Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 911.28it/s]Calculating Metrics:  75%|  | 3/4 [00:00<00:00, 598.70it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 522.67it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 487.03it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 480.31it/s]Calculating Metrics: 100%|| 4/4 [00:00<00:00, 472.64it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_stdev_to_be_between:basic_positive_test] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:  18%|        | 2/11 [00:00<00:00, 1526.59it/s]Calculating Metrics:  18%|        | 2/11 [00:00<00:00, 73.23it/s]  Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 133.01it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 70.11it/s] Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 82.60it/s]Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 73.85it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 82.01it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 67.27it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 67.27it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 67.27it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 67.27it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 67.27it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 67.27it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 67.27it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 67.27it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 67.27it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 62.06it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_stdev_to_be_between:vacuously_true] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:  18%|        | 2/11 [00:00<00:00, 1611.64it/s]Calculating Metrics:  18%|        | 2/11 [00:00<00:00, 72.52it/s]  Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 134.30it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 75.72it/s] Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 87.57it/s]Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 69.10it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 86.90it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 72.41it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 72.41it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 72.41it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 72.41it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 72.41it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 72.41it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 72.41it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 72.41it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 72.41it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 68.76it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_stdev_to_be_between:positive_test__exact_min_and_max] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:  18%|        | 2/11 [00:00<00:00, 1567.67it/s]Calculating Metrics:  18%|        | 2/11 [00:00<00:00, 82.93it/s]  Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 151.74it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 62.94it/s] Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 90.84it/s]Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 72.16it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 90.63it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 84.40it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 92.41it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 78.34it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 78.34it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 78.34it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 78.34it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 78.34it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 78.34it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 78.34it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 75.08it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_stdev_to_be_between:basic_negative_test] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:  18%|        | 2/11 [00:00<00:00, 175.60it/s]Calculating Metrics:  18%|        | 2/11 [00:00<00:00, 55.65it/s] Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 103.28it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 77.31it/s] Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 110.87it/s]Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 72.28it/s] Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 84.59it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 78.58it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 78.58it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 78.58it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 78.58it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 78.58it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 78.58it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 78.58it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 78.58it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 78.58it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 74.18it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_stdev_to_be_between:positive_zero_stdev_exact_min_and_max] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:  18%|        | 2/11 [00:00<00:00, 1465.26it/s]Calculating Metrics:  18%|        | 2/11 [00:00<00:00, 152.91it/s] Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 226.51it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 114.54it/s]Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 160.60it/s]Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 127.43it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 152.55it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 126.09it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 134.11it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 113.26it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 121.25it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 111.23it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 114.64it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 109.19it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 109.19it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 109.19it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 108.46it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_stdev_to_be_between:positive_test_null_max_exact_min] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:  18%|        | 2/11 [00:00<00:00, 1585.15it/s]Calculating Metrics:  18%|        | 2/11 [00:00<00:00, 195.95it/s] Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 322.27it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 178.56it/s]Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 245.57it/s]Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 182.58it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 211.41it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 181.18it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 192.81it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 172.86it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 184.20it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 171.38it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 179.76it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 170.46it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 169.82it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 169.22it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_stdev_to_be_between:positive_test_null_min_exact_max] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:  18%|        | 2/11 [00:00<00:00, 1562.42it/s]Calculating Metrics:  18%|        | 2/11 [00:00<00:00, 204.25it/s] Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 339.13it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 191.15it/s]Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 259.75it/s]Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 194.68it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 225.25it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 199.81it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 213.33it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 196.36it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 210.94it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 195.95it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 205.74it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 194.70it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 194.10it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 193.58it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_stdev_to_be_between:negative_test_null_max] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:  18%|        | 2/11 [00:00<00:00, 2186.24it/s]Calculating Metrics:  18%|        | 2/11 [00:00<00:00, 212.72it/s] Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 366.74it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 211.48it/s]Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 291.54it/s]Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 221.94it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 257.48it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 226.21it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 239.10it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 217.45it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 231.41it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 216.96it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 226.61it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 218.05it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 217.47it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 216.86it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_stdev_to_be_between:negative_test_null_min] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:  18%|        | 2/11 [00:00<00:00, 2134.51it/s]Calculating Metrics:  18%|        | 2/11 [00:00<00:00, 306.75it/s] Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 505.93it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 295.53it/s]Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 400.16it/s]Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 307.69it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 364.08it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 308.59it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 327.44it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 294.91it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 314.95it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 291.36it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 302.25it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 287.99it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 287.12it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 286.11it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_stdev_to_be_between:positive_test_missing_value_in_column_complete_result_format] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:  18%|        | 2/11 [00:00<00:00, 2309.64it/s]Calculating Metrics:  18%|        | 2/11 [00:00<00:00, 308.64it/s] Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 509.76it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 305.58it/s]Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 415.81it/s]Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 318.61it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 374.85it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 322.03it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 340.41it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 305.20it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 325.91it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 302.06it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 311.57it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 296.61it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 295.72it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 294.63it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_be_in_set:basic_positive_test] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/5 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/5 [00:00<?, ?it/s]Calculating Metrics:  40%|      | 2/5 [00:00<00:00, 2444.95it/s]Calculating Metrics:  40%|      | 2/5 [00:00<00:00, 857.99it/s] Calculating Metrics:  80%|  | 4/5 [00:00<00:00, 993.56it/s]Calculating Metrics:  80%|  | 4/5 [00:00<00:00, 790.97it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 730.56it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 672.31it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 662.25it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 650.72it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_be_in_set:vacuously_true_universal_set] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/5 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/5 [00:00<?, ?it/s]Calculating Metrics:  40%|      | 2/5 [00:00<00:00, 2706.88it/s]Calculating Metrics:  40%|      | 2/5 [00:00<00:00, 864.72it/s] Calculating Metrics:  80%|  | 4/5 [00:00<00:00, 1112.40it/s]Calculating Metrics:  80%|  | 4/5 [00:00<00:00, 865.07it/s] Calculating Metrics: 100%|| 5/5 [00:00<00:00, 829.08it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 756.33it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 743.72it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 729.19it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_be_in_set:positive_test_with_null_values_in_column] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/5 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/5 [00:00<?, ?it/s]Calculating Metrics:  40%|      | 2/5 [00:00<00:00, 2777.68it/s]Calculating Metrics:  40%|      | 2/5 [00:00<00:00, 950.12it/s] Calculating Metrics:  80%|  | 4/5 [00:00<00:00, 1122.37it/s]Calculating Metrics:  80%|  | 4/5 [00:00<00:00, 869.20it/s] Calculating Metrics: 100%|| 5/5 [00:00<00:00, 799.22it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 731.73it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 719.95it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 706.61it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_be_in_set:positive_test_with_duplicate_values_in_column] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/5 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/5 [00:00<?, ?it/s]Calculating Metrics:  40%|      | 2/5 [00:00<00:00, 2607.59it/s]Calculating Metrics:  40%|      | 2/5 [00:00<00:00, 926.41it/s] Calculating Metrics:  80%|  | 4/5 [00:00<00:00, 1181.74it/s]Calculating Metrics:  80%|  | 4/5 [00:00<00:00, 907.07it/s] Calculating Metrics: 100%|| 5/5 [00:00<00:00, 815.12it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 744.17it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 731.76it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 717.88it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_be_in_set:positive_test_duplicate_and_null_values] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/5 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/5 [00:00<?, ?it/s]Calculating Metrics:  40%|      | 2/5 [00:00<00:00, 2698.17it/s]Calculating Metrics:  40%|      | 2/5 [00:00<00:00, 937.17it/s] Calculating Metrics:  80%|  | 4/5 [00:00<00:00, 1156.33it/s]Calculating Metrics:  80%|  | 4/5 [00:00<00:00, 888.48it/s] Calculating Metrics: 100%|| 5/5 [00:00<00:00, 804.74it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 733.76it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 721.59it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 707.90it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_be_in_set:basic_negative_test_no_set_intersection] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/5 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/5 [00:00<?, ?it/s]Calculating Metrics:  40%|      | 2/5 [00:00<00:00, 2746.76it/s]Calculating Metrics:  40%|      | 2/5 [00:00<00:00, 941.59it/s] Calculating Metrics:  80%|  | 4/5 [00:00<00:00, 1126.14it/s]Calculating Metrics:  80%|  | 4/5 [00:00<00:00, 868.61it/s] Calculating Metrics: 100%|| 5/5 [00:00<00:00, 830.03it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 754.13it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 740.18it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 725.78it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_be_in_set:negative_test_some_set_intersection_and_extra] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/5 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/5 [00:00<?, ?it/s]Calculating Metrics:  40%|      | 2/5 [00:00<00:00, 2755.78it/s]Calculating Metrics:  40%|      | 2/5 [00:00<00:00, 941.69it/s] Calculating Metrics:  80%|  | 4/5 [00:00<00:00, 1166.54it/s]Calculating Metrics:  80%|  | 4/5 [00:00<00:00, 897.27it/s] Calculating Metrics: 100%|| 5/5 [00:00<00:00, 846.04it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 770.42it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 757.34it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 742.41it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_be_in_set:negative_test_with_null_values_in_column] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/5 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/5 [00:00<?, ?it/s]Calculating Metrics:  40%|      | 2/5 [00:00<00:00, 2659.67it/s]Calculating Metrics:  40%|      | 2/5 [00:00<00:00, 934.14it/s] Calculating Metrics:  80%|  | 4/5 [00:00<00:00, 1189.11it/s]Calculating Metrics:  80%|  | 4/5 [00:00<00:00, 893.88it/s] Calculating Metrics: 100%|| 5/5 [00:00<00:00, 853.13it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 776.41it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 763.24it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 748.07it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_be_in_set:negative_test_with_duplicate_values_in_column] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/5 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/5 [00:00<?, ?it/s]Calculating Metrics:  40%|      | 2/5 [00:00<00:00, 2754.88it/s]Calculating Metrics:  40%|      | 2/5 [00:00<00:00, 939.37it/s] Calculating Metrics:  80%|  | 4/5 [00:00<00:00, 1187.94it/s]Calculating Metrics:  80%|  | 4/5 [00:00<00:00, 908.05it/s] Calculating Metrics: 100%|| 5/5 [00:00<00:00, 861.78it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 783.57it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 770.16it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 755.02it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_be_in_set:negative_test_duplicate_and_null_values] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/5 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/5 [00:00<?, ?it/s]Calculating Metrics:  40%|      | 2/5 [00:00<00:00, 2663.90it/s]Calculating Metrics:  40%|      | 2/5 [00:00<00:00, 936.44it/s] Calculating Metrics:  80%|  | 4/5 [00:00<00:00, 1197.94it/s]Calculating Metrics:  80%|  | 4/5 [00:00<00:00, 917.64it/s] Calculating Metrics: 100%|| 5/5 [00:00<00:00, 878.76it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 797.97it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 784.19it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 768.75it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_most_common_value_to_be_in_set:negative_test_tie_for_most_common_with_missing_values_and_complete_result_format] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 2724.46it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 703.21it/s] Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 895.21it/s]Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 642.68it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 634.35it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 546.92it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 585.31it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 544.07it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 538.69it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 532.52it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_most_common_value_to_be_in_set:negative_test__tie_for_most_common__full_value_set__ties_okay__false] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 2444.95it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 683.72it/s] Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 944.03it/s]Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 666.87it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 673.76it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 577.23it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 613.74it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 568.44it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 562.59it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 555.65it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_most_common_value_to_be_in_set:positive_test__tie_for_most_common__ties_okay__true] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 2573.98it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 689.68it/s] Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 968.27it/s]Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 680.26it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 687.30it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 583.37it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 619.59it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 566.95it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 560.02it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 552.74it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_most_common_value_to_be_in_set:positive_test__tie_for_most_common_but_test_for_last_value__ties_okay__true] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 2519.10it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 687.53it/s] Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 944.72it/s]Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 666.79it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 662.52it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 567.03it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 573.79it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 505.90it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 498.42it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 489.76it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_most_common_value_to_be_in_set:negative_test__tie_for_most_common__value_set_does_not_match__ties_okay__false] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 1897.45it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 621.15it/s] Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 772.18it/s]Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 414.33it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 408.93it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 344.38it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 361.25it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 299.06it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 295.74it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 292.61it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_most_common_value_to_be_in_set:negative_test__tie_for_most_common__value_set_does_not_match__ties_okay__true] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 1248.49it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 307.88it/s] Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 444.25it/s]Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 327.76it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 341.27it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 294.07it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 317.97it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 297.36it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 294.93it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 292.04it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_most_common_value_to_be_in_set:positive_test_string_values_value_set_contains_more_than_actual_mode_list] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 1566.21it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 326.91it/s] Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 470.32it/s]Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 332.51it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 328.13it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 283.51it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 304.74it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 283.14it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 280.40it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 277.35it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_most_common_value_to_be_in_set:negative_test_string_values_value_set_contains_more_than_actual_mode_list] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 1639.04it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 391.31it/s] Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 548.01it/s]Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 320.00it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 333.28it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 289.18it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 311.65it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 266.58it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 263.94it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 252.14it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_quantile_values_to_be_between:basic_positive_test_extremes] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/5 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/5 [00:00<?, ?it/s]Calculating Metrics:  40%|      | 2/5 [00:00<00:00, 1351.26it/s]Calculating Metrics:  40%|      | 2/5 [00:00<00:00, 471.59it/s] Calculating Metrics:  80%|  | 4/5 [00:00<00:00, 574.05it/s]Calculating Metrics:  80%|  | 4/5 [00:00<00:00, 446.23it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 371.45it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 344.88it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 340.37it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 335.30it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_quantile_values_to_be_between:basic_positive_test_normal_quantiles] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/5 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/5 [00:00<?, ?it/s]Calculating Metrics:  40%|      | 2/5 [00:00<00:00, 1623.18it/s]Calculating Metrics:  40%|      | 2/5 [00:00<00:00, 519.74it/s] Calculating Metrics:  80%|  | 4/5 [00:00<00:00, 664.34it/s]Calculating Metrics:  80%|  | 4/5 [00:00<00:00, 500.24it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 322.31it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 299.74it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 296.28it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 292.50it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_quantile_values_to_be_between:basic_positive_test_uneven_spacing] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/5 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/5 [00:00<?, ?it/s]Calculating Metrics:  40%|      | 2/5 [00:00<00:00, 1577.40it/s]Calculating Metrics:  40%|      | 2/5 [00:00<00:00, 352.98it/s] Calculating Metrics:  80%|  | 4/5 [00:00<00:00, 496.09it/s]Calculating Metrics:  80%|  | 4/5 [00:00<00:00, 390.69it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 254.64it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 240.04it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 237.63it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 235.05it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_quantile_values_to_be_between:basic_negative_test_normal_quantiles_wrong_distribution] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/5 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/5 [00:00<?, ?it/s]Calculating Metrics:  40%|      | 2/5 [00:00<00:00, 1552.87it/s]Calculating Metrics:  40%|      | 2/5 [00:00<00:00, 324.51it/s] Calculating Metrics:  80%|  | 4/5 [00:00<00:00, 478.30it/s]Calculating Metrics:  80%|  | 4/5 [00:00<00:00, 389.11it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 280.14it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 263.74it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 261.18it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 258.34it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_max_to_be_between:basic_positive_test_case] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 1164.11it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 374.52it/s] Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 489.77it/s]Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 358.52it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 401.54it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 342.37it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 341.69it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 320.39it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 317.98it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 315.54it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_max_to_be_between:basic_negative_test_case] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 2043.01it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 423.47it/s] Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 584.29it/s]Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 437.36it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 493.25it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 435.55it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 454.31it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 409.98it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 403.12it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 398.70it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_max_to_be_between:test_case_with_result_format_summary_also_verifies_that_max_value_is_inclusive] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 2384.48it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 710.00it/s] Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 973.95it/s]Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 697.97it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 777.76it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 650.38it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 669.57it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 620.49it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 613.50it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 605.40it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_max_to_be_between:test_case_with_only_a_lower_bound_and_a_missing_value] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 2424.45it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 669.59it/s] Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 894.26it/s]Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 649.57it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 727.37it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 622.36it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 634.52it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 589.63it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 583.20it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 575.77it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_max_to_be_between:negative_test_case_with_only_a_lower_bound] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 1954.48it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 674.71it/s] Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 891.22it/s]Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 657.98it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 737.21it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 621.34it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 642.31it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 596.95it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 590.43it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 582.81it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_max_to_be_between:datetime_sqlite] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 2372.34it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 718.14it/s] Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 984.98it/s]Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 708.59it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 788.64it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 656.78it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 652.23it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 598.13it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 590.37it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 582.23it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_max_to_be_between:datetime_with_evaluation_parameter_sqlite] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 2490.68it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 734.49it/s] Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 787.40it/s]Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 595.95it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 666.31it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 576.90it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 592.12it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 552.54it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 546.80it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 540.16it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_max_to_be_between:test_empty_column_should_be_false_no_observed_value_with_which_to_compare] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 2451.38it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 702.33it/s] Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 899.68it/s]Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 649.15it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 722.33it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 617.30it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 618.43it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 564.98it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 558.00it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 550.82it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_mean_to_be_between:simple_mean_positive_range] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 2409.83it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 699.28it/s] Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 883.38it/s]Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 656.05it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 724.93it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 621.89it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 606.00it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 564.81it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 558.92it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 552.08it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_mean_to_be_between:simple_mean_negative_range] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 2207.53it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 717.10it/s] Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 973.72it/s]Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 704.98it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 757.23it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 639.06it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 651.83it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 605.02it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 598.33it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 590.66it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_mean_to_be_between:simple_mean_positive_exact_match0] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 2299.51it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 722.84it/s] Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 991.85it/s]Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 712.80it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 781.03it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 663.51it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 654.25it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 606.86it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 596.86it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 586.41it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_mean_to_be_between:simple_mean_negative_exact_match] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 2181.13it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 684.23it/s] Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 951.31it/s]Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 690.14it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 759.65it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 646.57it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 640.14it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 594.30it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 587.62it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 579.87it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_mean_to_be_between:simple_mean_positive_exact_match1] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 2398.12it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 724.91it/s] Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 985.68it/s]Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 697.60it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 757.01it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 645.42it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 631.18it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 585.20it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 578.66it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 571.06it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_mean_to_be_between:simple_mean_negative_range_match] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 2490.68it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 740.52it/s] Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 1016.49it/s]Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 731.26it/s] Calculating Metrics:  83%| | 5/6 [00:00<00:00, 799.86it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 666.31it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 664.60it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 615.38it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 608.27it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 600.13it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_mean_to_be_between:simple_mean_includes_null] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 2439.26it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 726.79it/s] Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 990.86it/s]Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 717.34it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 787.78it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 656.86it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 620.87it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 577.20it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 570.94it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 563.75it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_mean_to_be_between:vacuously_true_missing_min_and_max] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 2525.17it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 721.23it/s] Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 966.65it/s]Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 700.28it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 768.27it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 653.42it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 664.81it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 616.01it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 609.02it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 600.90it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_mean_to_be_between:coerced_types_true_false_values] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 2432.89it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 736.36it/s] Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 948.29it/s]Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 688.13it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 758.27it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 644.66it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 612.81it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 569.58it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 563.49it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 556.48it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_mean_to_be_between:coerced_types_true_false_and_null] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 2593.88it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 751.67it/s] Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 1019.95it/s]Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 725.72it/s] Calculating Metrics:  83%| | 5/6 [00:00<00:00, 793.02it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 669.27it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 656.90it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 609.39it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 602.49it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 594.66it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_mean_to_be_between:test_empty_column_should_be_false_no_observed_value_with_which_to_compare] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 2667.28it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 761.91it/s] Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 990.10it/s]Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 716.09it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 788.28it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 667.82it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 646.49it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 600.67it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 594.07it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 586.57it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_equal_set:basic_positive_test] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/5 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/5 [00:00<?, ?it/s]Calculating Metrics:  40%|      | 2/5 [00:00<00:00, 2694.70it/s]Calculating Metrics:  40%|      | 2/5 [00:00<00:00, 939.79it/s] Calculating Metrics:  80%|  | 4/5 [00:00<00:00, 1135.36it/s]Calculating Metrics:  80%|  | 4/5 [00:00<00:00, 880.05it/s] Calculating Metrics: 100%|| 5/5 [00:00<00:00, 797.79it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 729.90it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 718.47it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 705.40it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_equal_set:positive_test_with_null_values_in_column] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/5 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/5 [00:00<?, ?it/s]Calculating Metrics:  40%|      | 2/5 [00:00<00:00, 2898.62it/s]Calculating Metrics:  40%|      | 2/5 [00:00<00:00, 968.55it/s] Calculating Metrics:  80%|  | 4/5 [00:00<00:00, 1244.14it/s]Calculating Metrics:  80%|  | 4/5 [00:00<00:00, 922.53it/s] Calculating Metrics: 100%|| 5/5 [00:00<00:00, 834.72it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 760.80it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 748.07it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 733.68it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_equal_set:positive_test_with_duplicate_values_in_column] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/5 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/5 [00:00<?, ?it/s]Calculating Metrics:  40%|      | 2/5 [00:00<00:00, 2181.13it/s]Calculating Metrics:  40%|      | 2/5 [00:00<00:00, 867.31it/s] Calculating Metrics:  80%|  | 4/5 [00:00<00:00, 1150.78it/s]Calculating Metrics:  80%|  | 4/5 [00:00<00:00, 869.96it/s] Calculating Metrics: 100%|| 5/5 [00:00<00:00, 672.88it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 595.11it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 583.45it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 570.59it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_equal_set:positive_test_duplicate_and_null_values] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/5 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/5 [00:00<?, ?it/s]Calculating Metrics:  40%|      | 2/5 [00:00<00:00, 2503.31it/s]Calculating Metrics:  40%|      | 2/5 [00:00<00:00, 911.21it/s] Calculating Metrics:  80%|  | 4/5 [00:00<00:00, 1112.03it/s]Calculating Metrics:  80%|  | 4/5 [00:00<00:00, 856.55it/s] Calculating Metrics: 100%|| 5/5 [00:00<00:00, 780.86it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 715.73it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 704.40it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 691.38it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_equal_set:basic_negative_test_set_contained] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/5 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/5 [00:00<?, ?it/s]Calculating Metrics:  40%|      | 2/5 [00:00<00:00, 2637.93it/s]Calculating Metrics:  40%|      | 2/5 [00:00<00:00, 940.32it/s] Calculating Metrics:  80%|  | 4/5 [00:00<00:00, 1195.47it/s]Calculating Metrics:  80%|  | 4/5 [00:00<00:00, 917.44it/s] Calculating Metrics: 100%|| 5/5 [00:00<00:00, 870.15it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 791.02it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 777.59it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 762.18it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_equal_set:negative_test_some_set_intersection] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/5 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/5 [00:00<?, ?it/s]Calculating Metrics:  40%|      | 2/5 [00:00<00:00, 2472.33it/s]Calculating Metrics:  40%|      | 2/5 [00:00<00:00, 849.22it/s] Calculating Metrics:  80%|  | 4/5 [00:00<00:00, 1074.15it/s]Calculating Metrics:  80%|  | 4/5 [00:00<00:00, 821.89it/s] Calculating Metrics: 100%|| 5/5 [00:00<00:00, 760.69it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 696.29it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 685.23it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 672.51it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_equal_set:negative_test_with_null_values_in_column] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/5 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/5 [00:00<?, ?it/s]Calculating Metrics:  40%|      | 2/5 [00:00<00:00, 2563.76it/s]Calculating Metrics:  40%|      | 2/5 [00:00<00:00, 929.69it/s] Calculating Metrics:  80%|  | 4/5 [00:00<00:00, 1181.66it/s]Calculating Metrics:  80%|  | 4/5 [00:00<00:00, 896.65it/s] Calculating Metrics: 100%|| 5/5 [00:00<00:00, 786.54it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 718.69it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 706.92it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 693.39it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_equal_set:negative_test_with_duplicate_values_in_column] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/5 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/5 [00:00<?, ?it/s]Calculating Metrics:  40%|      | 2/5 [00:00<00:00, 2638.76it/s]Calculating Metrics:  40%|      | 2/5 [00:00<00:00, 860.99it/s] Calculating Metrics:  80%|  | 4/5 [00:00<00:00, 1028.77it/s]Calculating Metrics:  80%|  | 4/5 [00:00<00:00, 791.75it/s] Calculating Metrics: 100%|| 5/5 [00:00<00:00, 754.13it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 692.70it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 681.93it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 669.33it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_equal_set:negative_test_duplicate_and_null_values] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/5 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/5 [00:00<?, ?it/s]Calculating Metrics:  40%|      | 2/5 [00:00<00:00, 2347.12it/s]Calculating Metrics:  40%|      | 2/5 [00:00<00:00, 886.93it/s] Calculating Metrics:  80%|  | 4/5 [00:00<00:00, 1142.78it/s]Calculating Metrics:  80%|  | 4/5 [00:00<00:00, 883.20it/s] Calculating Metrics: 100%|| 5/5 [00:00<00:00, 848.02it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 772.80it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 759.98it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 745.02it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_sum_to_be_between:basic_positive_test_case] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 2250.16it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 711.80it/s] Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 929.85it/s]Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 668.23it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 747.06it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 637.53it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 649.16it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 596.06it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 588.47it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 580.61it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_sum_to_be_between:basic_negative_test_case] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 2105.57it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 661.15it/s] Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 935.24it/s]Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 687.42it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 768.89it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 653.77it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 676.68it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 626.44it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 619.27it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 611.06it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_sum_to_be_between:test_case_with_result_format_summary] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 2584.29it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 748.85it/s] Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 1032.51it/s]Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 739.38it/s] Calculating Metrics:  83%| | 5/6 [00:00<00:00, 821.57it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 693.48it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 713.78it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 658.69it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 650.85it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 641.94it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_sum_to_be_between:test_case_with_only_a_lower_bound_and_a_missing_value] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 2422.35it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 699.05it/s] Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 903.17it/s]Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 664.15it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 742.72it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 635.50it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 643.38it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 592.01it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 584.53it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 576.72it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_sum_to_be_between:negative_test_case_with_only_a_lower_bound] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 2468.69it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 736.10it/s] Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 1012.93it/s]Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 724.66it/s] Calculating Metrics:  83%| | 5/6 [00:00<00:00, 805.02it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 679.61it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 699.23it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 645.38it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 637.76it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 628.86it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_sum_to_be_between:negative_test_case_with_only_a_max] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 2723.57it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 757.23it/s] Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 1045.37it/s]Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 743.18it/s] Calculating Metrics:  83%| | 5/6 [00:00<00:00, 825.36it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 695.50it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 680.80it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 630.11it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 622.92it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 614.63it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_sum_to_be_between:raise_valueerror_with_both_max_and_min_are_missing] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 2577.94it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 741.57it/s] Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 1013.42it/s]Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 718.54it/s] Calculating Metrics:  83%| | 5/6 [00:00<00:00, 798.46it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 674.78it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 694.19it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 639.93it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 632.37it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 623.77it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_unique_value_count_to_be_between:basic_positive_test] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 2580.32it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 736.36it/s] Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 964.26it/s]Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 698.79it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 778.34it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 659.71it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 653.81it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 602.23it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 594.35it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 585.99it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_unique_value_count_to_be_between:positive_test_with_null_values_in_column] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 2522.13it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 739.15it/s] Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 958.53it/s]Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 698.32it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 779.06it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 660.42it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 658.69it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 610.63it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 600.85it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 591.79it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_unique_value_count_to_be_between:null_min_duplicate_values_in_column] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 2597.90it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 756.75it/s] Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 1036.59it/s]Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 740.62it/s] Calculating Metrics:  83%| | 5/6 [00:00<00:00, 820.51it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 691.67it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 685.74it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 633.33it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 625.78it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 617.35it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_unique_value_count_to_be_between:null_max_duplicate_and_null_values] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 2541.23it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 740.19it/s] Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 1003.72it/s]Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 720.18it/s] Calculating Metrics:  83%| | 5/6 [00:00<00:00, 796.28it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 659.79it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 642.53it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 596.60it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 589.96it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 582.35it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_unique_value_count_to_be_between:vacuously_true_null_min_and_max] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 2510.06it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 741.31it/s] Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 1012.99it/s]Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 726.48it/s] Calculating Metrics:  83%| | 5/6 [00:00<00:00, 805.95it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 672.16it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 668.68it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 619.85it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 612.87it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 604.90it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_median_to_be_between:positive_test_min_equal_max] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 2554.39it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 471.80it/s] Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 702.00it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 442.87it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 510.16it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 397.36it/s]Calculating Metrics:  67%|   | 6/9 [00:00<00:00, 446.92it/s]Calculating Metrics:  67%|   | 6/9 [00:00<00:00, 381.93it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 399.72it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 360.06it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 403.37it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 373.78it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 380.80it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 363.09it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 361.46it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 359.54it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_median_to_be_between:positive_test_null_min] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 2778.60it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 478.47it/s] Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 743.11it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 471.43it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 543.78it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 419.83it/s]Calculating Metrics:  67%|   | 6/9 [00:00<00:00, 472.07it/s]Calculating Metrics:  67%|   | 6/9 [00:00<00:00, 400.81it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 428.19it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 385.61it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 432.14it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 398.39it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 423.79it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 401.68it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 399.68it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 397.28it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_median_to_be_between:positive_test_null_max] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 2706.88it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 475.73it/s] Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 734.62it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 466.10it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 532.08it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 412.27it/s]Calculating Metrics:  67%|   | 6/9 [00:00<00:00, 463.64it/s]Calculating Metrics:  67%|   | 6/9 [00:00<00:00, 368.14it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 373.02it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 316.47it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 350.91it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 307.63it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 320.78it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 274.41it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 272.23it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 270.21it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_median_to_be_between:negative_test_min_equal_max] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 1588.75it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 177.15it/s] Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 287.57it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 138.97it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 165.46it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 140.82it/s]Calculating Metrics:  67%|   | 6/9 [00:00<00:00, 161.56it/s]Calculating Metrics:  67%|   | 6/9 [00:00<00:00, 144.69it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 156.67it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 145.58it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 163.96it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 154.18it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 165.24it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 158.37it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 157.75it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 157.09it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_median_to_be_between:negative_test_null_min] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 2448.51it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 468.82it/s] Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 722.28it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 447.93it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 514.10it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 402.84it/s]Calculating Metrics:  67%|   | 6/9 [00:00<00:00, 453.93it/s]Calculating Metrics:  67%|   | 6/9 [00:00<00:00, 389.64it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 415.21it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 373.30it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 417.99it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 384.12it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 409.31it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 384.42it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 382.18it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 379.80it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_median_to_be_between:negative_test_null_max] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 2311.55it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 466.84it/s] Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 717.19it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 459.61it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 525.75it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 408.96it/s]Calculating Metrics:  67%|   | 6/9 [00:00<00:00, 460.00it/s]Calculating Metrics:  67%|   | 6/9 [00:00<00:00, 393.57it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 420.09it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 379.44it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 425.39it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 392.73it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 419.52it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 398.35it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 396.42it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 394.13it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_median_to_be_between:positive_test_missing_value_in_column_exact_min_and_max] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 2416.07it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 468.93it/s] Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 723.84it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 442.48it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 494.56it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 309.73it/s]Calculating Metrics:  67%|   | 6/9 [00:00<00:00, 166.86it/s]Calculating Metrics:  67%|   | 6/9 [00:00<00:00, 150.26it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 166.35it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 159.19it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 180.40it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 174.08it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 190.13it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 185.56it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 185.13it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 184.61it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_median_to_be_between:negative_test_missing_value_in_column_complete_result_format] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 2591.48it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 474.42it/s] Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 733.56it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 468.34it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 539.96it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 418.20it/s]Calculating Metrics:  67%|   | 6/9 [00:00<00:00, 470.19it/s]Calculating Metrics:  67%|   | 6/9 [00:00<00:00, 400.37it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 427.15it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 384.68it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 430.99it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 397.28it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 423.81it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 402.13it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 400.05it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 397.58it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_median_to_be_between:vacuously_true_both_min_and_max_null] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 2660.52it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 477.79it/s] Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 739.64it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 468.83it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 540.66it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 418.24it/s]Calculating Metrics:  67%|   | 6/9 [00:00<00:00, 470.04it/s]Calculating Metrics:  67%|   | 6/9 [00:00<00:00, 400.86it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 428.03it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 385.47it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 431.85it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 397.91it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 424.87it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 403.19it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 401.19it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 398.85it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_median_to_be_between:test_empty_column_should_be_false_no_observed_value_with_which_to_compare] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 2754.88it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 479.27it/s] Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 684.42it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 444.92it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 515.30it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 401.25it/s]Calculating Metrics:  67%|   | 6/9 [00:00<00:00, 452.58it/s]Calculating Metrics:  67%|   | 6/9 [00:00<00:00, 387.82it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 407.49it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 369.27it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 414.07it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 383.05it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 416.78it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 396.05it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 394.18it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 391.97it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_min_to_be_between:basic_positive_test_case] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 2535.09it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 717.40it/s] Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 927.89it/s]Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 678.09it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 758.19it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 645.83it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 640.22it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 594.66it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 588.19it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 580.79it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_min_to_be_between:negative_test_case_with_max_value_none] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 2328.23it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 720.18it/s] Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 999.24it/s]Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 719.81it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 802.15it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 677.97it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 699.15it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 645.64it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 638.16it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 629.60it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_min_to_be_between:test_case_with_result_format_summary_also_verifies_that_max_value_is_inclusive] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 2833.03it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 767.77it/s] Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 1001.51it/s]Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 719.71it/s] Calculating Metrics:  83%| | 5/6 [00:00<00:00, 803.08it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 677.51it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 699.38it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 644.90it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 637.29it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 628.74it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_min_to_be_between:test_case_with_only_a_lower_bound_and_a_missing_value] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 2852.30it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 772.72it/s] Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 1069.43it/s]Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 754.81it/s] Calculating Metrics:  83%| | 5/6 [00:00<00:00, 838.19it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 701.83it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 704.94it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 650.46it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 642.94it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 634.30it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_min_to_be_between:negative_test_case_with_only_a_lower_bound] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 2764.87it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 769.74it/s] Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 1053.91it/s]Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 744.99it/s] Calculating Metrics:  83%| | 5/6 [00:00<00:00, 827.25it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 694.81it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 714.45it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 658.39it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 650.67it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 641.84it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_min_to_be_between:test_on_a_series_with_mostly_nulls] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 1403.48it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 388.79it/s] Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 538.15it/s]Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 389.67it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 450.45it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 402.57it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 396.67it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 365.23it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 361.23it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 356.76it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_min_to_be_between:negative_test_case_with_only_a_max] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 1616.93it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 351.87it/s] Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 492.85it/s]Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 369.48it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 419.29it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 357.88it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 362.95it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 338.39it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 335.27it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 331.73it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_min_to_be_between:raise_valueerror_with_both_max_and_min_are_missing] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 1612.57it/s]Calculating Metrics:  33%|      | 2/6 [00:00<00:00, 454.94it/s] Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 688.35it/s]Calculating Metrics:  67%|   | 4/6 [00:00<00:00, 520.97it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 537.51it/s]Calculating Metrics:  83%| | 5/6 [00:00<00:00, 435.16it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 430.48it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 393.54it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 388.75it/s]Calculating Metrics: 100%|| 6/6 [00:00<00:00, 383.73it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_proportion_of_unique_values_to_be_between:basic_positive_test] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2378.40it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 356.95it/s] Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 532.19it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 338.24it/s]Calculating Metrics:  60%|    | 6/10 [00:00<00:00, 457.35it/s]Calculating Metrics:  60%|    | 6/10 [00:00<00:00, 361.66it/s]Calculating Metrics:  80%|  | 8/10 [00:00<00:00, 423.07it/s]Calculating Metrics:  80%|  | 8/10 [00:00<00:00, 372.44it/s]Calculating Metrics:  90%| | 9/10 [00:00<00:00, 387.46it/s]Calculating Metrics:  90%| | 9/10 [00:00<00:00, 355.79it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 383.60it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 362.81it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 361.38it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 359.58it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_proportion_of_unique_values_to_be_between:positive_test_with_null_values_in_column] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2462.89it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 348.68it/s] Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 563.77it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 351.00it/s]Calculating Metrics:  60%|    | 6/10 [00:00<00:00, 473.56it/s]Calculating Metrics:  60%|    | 6/10 [00:00<00:00, 367.42it/s]Calculating Metrics:  80%|  | 8/10 [00:00<00:00, 428.79it/s]Calculating Metrics:  80%|  | 8/10 [00:00<00:00, 377.73it/s]Calculating Metrics:  90%| | 9/10 [00:00<00:00, 388.25it/s]Calculating Metrics:  90%| | 9/10 [00:00<00:00, 356.72it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 382.25it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 361.58it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 360.04it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 358.23it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_proportion_of_unique_values_to_be_between:duplicate_values_in_column] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 1888.48it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 294.81it/s] Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 485.73it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 314.37it/s]Calculating Metrics:  60%|    | 6/10 [00:00<00:00, 421.61it/s]Calculating Metrics:  60%|    | 6/10 [00:00<00:00, 336.36it/s]Calculating Metrics:  80%|  | 8/10 [00:00<00:00, 389.41it/s]Calculating Metrics:  80%|  | 8/10 [00:00<00:00, 344.38it/s]Calculating Metrics:  90%| | 9/10 [00:00<00:00, 351.23it/s]Calculating Metrics:  90%| | 9/10 [00:00<00:00, 323.98it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 349.44it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 331.90it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 330.61it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 329.09it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_proportion_of_unique_values_to_be_between:null_max_duplicate_and_null_values] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2299.51it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 303.35it/s] Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 496.59it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 321.19it/s]Calculating Metrics:  60%|    | 6/10 [00:00<00:00, 428.11it/s]Calculating Metrics:  60%|    | 6/10 [00:00<00:00, 337.90it/s]Calculating Metrics:  80%|  | 8/10 [00:00<00:00, 392.85it/s]Calculating Metrics:  80%|  | 8/10 [00:00<00:00, 347.33it/s]Calculating Metrics:  90%| | 9/10 [00:00<00:00, 355.92it/s]Calculating Metrics:  90%| | 9/10 [00:00<00:00, 326.51it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 351.71it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 333.43it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 331.89it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 330.28it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_proportion_of_unique_values_to_be_between:vacuously_true_null_min_and_max] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2404.30it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 359.27it/s] Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 573.72it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 353.32it/s]Calculating Metrics:  60%|    | 6/10 [00:00<00:00, 473.04it/s]Calculating Metrics:  60%|    | 6/10 [00:00<00:00, 368.37it/s]Calculating Metrics:  80%|  | 8/10 [00:00<00:00, 428.77it/s]Calculating Metrics:  80%|  | 8/10 [00:00<00:00, 371.57it/s]Calculating Metrics:  90%| | 9/10 [00:00<00:00, 386.20it/s]Calculating Metrics:  90%| | 9/10 [00:00<00:00, 353.62it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 380.68it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 359.98it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 358.18it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 356.33it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:basic_positive_test] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/5 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/5 [00:00<?, ?it/s]Calculating Metrics:  40%|      | 2/5 [00:00<00:00, 1669.71it/s]Calculating Metrics:  40%|      | 2/5 [00:00<00:00, 468.93it/s] Calculating Metrics:  80%|  | 4/5 [00:00<00:00, 604.67it/s]Calculating Metrics:  80%|  | 4/5 [00:00<00:00, 516.33it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 511.30it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 480.59it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 474.96it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 468.73it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:positive_test_with_null_values_in_column] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/5 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/5 [00:00<?, ?it/s]Calculating Metrics:  40%|      | 2/5 [00:00<00:00, 1757.14it/s]Calculating Metrics:  40%|      | 2/5 [00:00<00:00, 780.63it/s] Calculating Metrics:  80%|  | 4/5 [00:00<00:00, 999.48it/s]Calculating Metrics:  80%|  | 4/5 [00:00<00:00, 789.85it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 723.26it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 664.71it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 654.26it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 642.49it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:positive_test_with_duplicate_values_in_column] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/5 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/5 [00:00<?, ?it/s]Calculating Metrics:  40%|      | 2/5 [00:00<00:00, 1984.53it/s]Calculating Metrics:  40%|      | 2/5 [00:00<00:00, 728.87it/s] Calculating Metrics:  80%|  | 4/5 [00:00<00:00, 922.94it/s]Calculating Metrics:  80%|  | 4/5 [00:00<00:00, 697.25it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 630.68it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 585.14it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 577.11it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 568.20it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:positive_test_duplicate_and_null_values] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/5 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/5 [00:00<?, ?it/s]Calculating Metrics:  40%|      | 2/5 [00:00<00:00, 1656.85it/s]Calculating Metrics:  40%|      | 2/5 [00:00<00:00, 737.72it/s] Calculating Metrics:  80%|  | 4/5 [00:00<00:00, 969.50it/s]Calculating Metrics:  80%|  | 4/5 [00:00<00:00, 737.59it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 659.27it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 604.82it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 595.73it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 585.83it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:basic_negative_test_no_set_intersection] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/5 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/5 [00:00<?, ?it/s]Calculating Metrics:  40%|      | 2/5 [00:00<00:00, 1869.12it/s]Calculating Metrics:  40%|      | 2/5 [00:00<00:00, 732.05it/s] Calculating Metrics:  80%|  | 4/5 [00:00<00:00, 874.31it/s]Calculating Metrics:  80%|  | 4/5 [00:00<00:00, 706.08it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 699.00it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 645.42it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 635.89it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 624.77it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:negative_test_some_set_intersection] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/5 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/5 [00:00<?, ?it/s]Calculating Metrics:  40%|      | 2/5 [00:00<00:00, 2352.39it/s]Calculating Metrics:  40%|      | 2/5 [00:00<00:00, 884.50it/s] Calculating Metrics:  80%|  | 4/5 [00:00<00:00, 1121.02it/s]Calculating Metrics:  80%|  | 4/5 [00:00<00:00, 871.05it/s] Calculating Metrics: 100%|| 5/5 [00:00<00:00, 826.43it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 753.10it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 740.62it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 726.09it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:negative_test_with_null_values_in_column] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/5 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/5 [00:00<?, ?it/s]Calculating Metrics:  40%|      | 2/5 [00:00<00:00, 2270.26it/s]Calculating Metrics:  40%|      | 2/5 [00:00<00:00, 828.26it/s] Calculating Metrics:  80%|  | 4/5 [00:00<00:00, 1017.60it/s]Calculating Metrics:  80%|  | 4/5 [00:00<00:00, 776.29it/s] Calculating Metrics: 100%|| 5/5 [00:00<00:00, 660.33it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 584.88it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 569.03it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 557.80it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:negative_test_with_duplicate_values_in_column] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/5 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/5 [00:00<?, ?it/s]Calculating Metrics:  40%|      | 2/5 [00:00<00:00, 2307.10it/s]Calculating Metrics:  40%|      | 2/5 [00:00<00:00, 774.57it/s] Calculating Metrics:  80%|  | 4/5 [00:00<00:00, 993.56it/s]Calculating Metrics:  80%|  | 4/5 [00:00<00:00, 788.81it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 762.66it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 699.80it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 688.81it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 676.15it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:negative_test_duplicate_and_null_values] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/5 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/5 [00:00<?, ?it/s]Calculating Metrics:  40%|      | 2/5 [00:00<00:00, 2357.68it/s]Calculating Metrics:  40%|      | 2/5 [00:00<00:00, 894.40it/s] Calculating Metrics:  80%|  | 4/5 [00:00<00:00, 1121.32it/s]Calculating Metrics:  80%|  | 4/5 [00:00<00:00, 869.56it/s] Calculating Metrics: 100%|| 5/5 [00:00<00:00, 830.82it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 757.34it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 744.57it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 729.60it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:positive_test_string_values] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/5 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/5 [00:00<?, ?it/s]Calculating Metrics:  40%|      | 2/5 [00:00<00:00, 2381.10it/s]Calculating Metrics:  40%|      | 2/5 [00:00<00:00, 880.69it/s] Calculating Metrics:  80%|  | 4/5 [00:00<00:00, 1114.84it/s]Calculating Metrics:  80%|  | 4/5 [00:00<00:00, 862.45it/s] Calculating Metrics: 100%|| 5/5 [00:00<00:00, 768.64it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 703.15it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 691.76it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 678.71it/s]
_ test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:negative_test_string_values] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/5 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/5 [00:00<?, ?it/s]Calculating Metrics:  40%|      | 2/5 [00:00<00:00, 2453.53it/s]Calculating Metrics:  40%|      | 2/5 [00:00<00:00, 911.90it/s] Calculating Metrics:  80%|  | 4/5 [00:00<00:00, 924.01it/s]Calculating Metrics:  80%|  | 4/5 [00:00<00:00, 744.73it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 739.32it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 679.99it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 669.89it/s]Calculating Metrics: 100%|| 5/5 [00:00<00:00, 658.05it/s]
_ test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:discrete_baseline_categorical_fixed_partition] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/7 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/7 [00:00<?, ?it/s]Calculating Metrics:  29%|       | 2/7 [00:00<00:00, 3394.82it/s]Calculating Metrics:  29%|       | 2/7 [00:00<00:00, 981.81it/s] Calculating Metrics:  43%|     | 3/7 [00:00<00:00, 1305.01it/s]Calculating Metrics:  43%|     | 3/7 [00:00<00:00, 836.35it/s] Calculating Metrics:  71%|  | 5/7 [00:00<00:00, 963.76it/s]Calculating Metrics:  71%|  | 5/7 [00:00<00:00, 822.51it/s]Calculating Metrics:  86%| | 6/7 [00:00<00:00, 918.13it/s]Calculating Metrics:  86%| | 6/7 [00:00<00:00, 838.47it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 943.78it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 881.29it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 869.98it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 856.48it/s]
_ test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:discrete_categorical_fixed_alternate_partition] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/7 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/7 [00:00<?, ?it/s]Calculating Metrics:  29%|       | 2/7 [00:00<00:00, 3651.98it/s]Calculating Metrics:  29%|       | 2/7 [00:00<00:00, 999.60it/s] Calculating Metrics:  43%|     | 3/7 [00:00<00:00, 1318.27it/s]Calculating Metrics:  43%|     | 3/7 [00:00<00:00, 837.08it/s] Calculating Metrics:  71%|  | 5/7 [00:00<00:00, 972.39it/s]Calculating Metrics:  71%|  | 5/7 [00:00<00:00, 824.81it/s]Calculating Metrics:  86%| | 6/7 [00:00<00:00, 919.27it/s]Calculating Metrics:  86%| | 6/7 [00:00<00:00, 838.94it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 943.54it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 880.31it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 868.93it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 855.33it/s]
_ test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:internal_holdout_with_categorical_partition] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/7 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/7 [00:00<?, ?it/s]Calculating Metrics:  29%|       | 2/7 [00:00<00:00, 3760.02it/s]Calculating Metrics:  29%|       | 2/7 [00:00<00:00, 999.95it/s] Calculating Metrics:  43%|     | 3/7 [00:00<00:00, 1276.03it/s]Calculating Metrics:  43%|     | 3/7 [00:00<00:00, 815.70it/s] Calculating Metrics:  71%|  | 5/7 [00:00<00:00, 953.99it/s]Calculating Metrics:  71%|  | 5/7 [00:00<00:00, 804.74it/s]Calculating Metrics:  86%| | 6/7 [00:00<00:00, 896.31it/s]Calculating Metrics:  86%| | 6/7 [00:00<00:00, 819.33it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 922.03it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 861.43it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 850.65it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 837.11it/s]
_ test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:holdout_0_1] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/7 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/7 [00:00<?, ?it/s]Calculating Metrics:  29%|       | 2/7 [00:00<00:00, 3407.23it/s]Calculating Metrics:  29%|       | 2/7 [00:00<00:00, 978.61it/s] Calculating Metrics:  43%|     | 3/7 [00:00<00:00, 1296.54it/s]Calculating Metrics:  43%|     | 3/7 [00:00<00:00, 832.42it/s] Calculating Metrics:  71%|  | 5/7 [00:00<00:00, 983.70it/s]Calculating Metrics:  71%|  | 5/7 [00:00<00:00, 836.69it/s]Calculating Metrics:  86%| | 6/7 [00:00<00:00, 932.86it/s]Calculating Metrics:  86%| | 6/7 [00:00<00:00, 838.94it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 939.85it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 877.08it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 865.60it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 851.81it/s]
_ test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:holdout_0_05] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/7 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/7 [00:00<?, ?it/s]Calculating Metrics:  29%|       | 2/7 [00:00<00:00, 2915.75it/s]Calculating Metrics:  29%|       | 2/7 [00:00<00:00, 923.04it/s] Calculating Metrics:  43%|     | 3/7 [00:00<00:00, 1230.48it/s]Calculating Metrics:  43%|     | 3/7 [00:00<00:00, 802.38it/s] Calculating Metrics:  71%|  | 5/7 [00:00<00:00, 957.69it/s]Calculating Metrics:  71%|  | 5/7 [00:00<00:00, 801.94it/s]Calculating Metrics:  86%| | 6/7 [00:00<00:00, 889.82it/s]Calculating Metrics:  86%| | 6/7 [00:00<00:00, 806.80it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 905.31it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 845.82it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 834.64it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 821.03it/s]
_ test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:missing_vals_no_holdout] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/7 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/7 [00:00<?, ?it/s]Calculating Metrics:  29%|       | 2/7 [00:00<00:00, 3495.25it/s]Calculating Metrics:  29%|       | 2/7 [00:00<00:00, 973.61it/s] Calculating Metrics:  43%|     | 3/7 [00:00<00:00, 1236.04it/s]Calculating Metrics:  43%|     | 3/7 [00:00<00:00, 767.44it/s] Calculating Metrics:  71%|  | 5/7 [00:00<00:00, 871.05it/s]Calculating Metrics:  71%|  | 5/7 [00:00<00:00, 748.26it/s]Calculating Metrics:  86%| | 6/7 [00:00<00:00, 838.22it/s]Calculating Metrics:  86%| | 6/7 [00:00<00:00, 770.21it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 868.05it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 813.84it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 803.95it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 791.93it/s]
_ test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:norm_0_1_auto_explicit_infinite_endpoints] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 3039.90it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 1215.92it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 1397.54it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 956.95it/s] Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 1041.84it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 894.83it/s] Calculating Metrics:  89%| | 8/9 [00:00<00:00, 965.62it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 878.16it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 959.72it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 890.03it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 880.64it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 869.41it/s]
_ test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:norm_0_1_auto_inf_partition_test_tail_weights] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 3233.85it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 1304.20it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 1497.97it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 1009.46it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 1052.79it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 899.62it/s] Calculating Metrics:  89%| | 8/9 [00:00<00:00, 968.89it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 880.76it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 962.17it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 892.41it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 883.03it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 871.94it/s]
_ test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:norm_0_1_auto_inf_partition_should_fail_with_no_holdout] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 3390.02it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 1336.40it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 1531.44it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 1019.62it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 1106.01it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 939.70it/s] Calculating Metrics:  89%| | 8/9 [00:00<00:00, 1009.10it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 914.39it/s] Calculating Metrics: 100%|| 9/9 [00:00<00:00, 997.69it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 923.27it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 913.24it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 901.08it/s]
_ test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:norm_0_1_auto_inf_partition_null_threshold_should_always_succeed] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 1451.82it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 626.58it/s] Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 712.66it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 463.87it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 505.16it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 436.38it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 469.46it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 405.39it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 441.11it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 410.87it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 405.39it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 400.27it/s]
_ test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:norm_0_1_auto_inf_partition_null_threshold_and_partition_object_supports_profiling] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/8 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/8 [00:00<?, ?it/s]Calculating Metrics:  25%|       | 2/8 [00:00<00:00, 1666.72it/s]Calculating Metrics:  25%|       | 2/8 [00:00<00:00, 331.13it/s] Calculating Metrics:  38%|      | 3/8 [00:00<00:00, 448.91it/s]Calculating Metrics:  38%|      | 3/8 [00:00<00:00, 252.00it/s]Calculating Metrics:  62%|   | 5/8 [00:00<00:00, 286.81it/s]Calculating Metrics:  62%|   | 5/8 [00:00<00:00, 240.38it/s]Calculating Metrics:  75%|  | 6/8 [00:00<00:00, 247.82it/s]Calculating Metrics:  75%|  | 6/8 [00:00<00:00, 220.76it/s]Calculating Metrics:  88%| | 7/8 [00:00<00:00, 250.42it/s]Calculating Metrics:  88%| | 7/8 [00:00<00:00, 229.56it/s]Calculating Metrics: 100%|| 8/8 [00:00<00:00, 247.62it/s]Calculating Metrics: 100%|| 8/8 [00:00<00:00, 234.80it/s]Calculating Metrics: 100%|| 8/8 [00:00<00:00, 233.05it/s]Calculating Metrics: 100%|| 8/8 [00:00<00:00, 231.25it/s]
Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 2424.45it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 243.94it/s] Calculating Metrics:  45%|     | 5/11 [00:00<00:00, 295.88it/s]Calculating Metrics:  45%|     | 5/11 [00:00<00:00, 225.95it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 291.69it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 255.80it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 278.98it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 262.03it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 288.62it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 272.33it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 292.53it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 283.86it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 283.03it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 282.02it/s]
Calculating Metrics:   0%|          | 0/8 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/8 [00:00<?, ?it/s]Calculating Metrics:  25%|       | 2/8 [00:00<00:00, 1690.57it/s]Calculating Metrics:  25%|       | 2/8 [00:00<00:00, 542.00it/s] Calculating Metrics:  38%|      | 3/8 [00:00<00:00, 737.09it/s]Calculating Metrics:  38%|      | 3/8 [00:00<00:00, 449.78it/s]Calculating Metrics:  62%|   | 5/8 [00:00<00:00, 503.23it/s]Calculating Metrics:  62%|   | 5/8 [00:00<00:00, 425.17it/s]Calculating Metrics:  75%|  | 6/8 [00:00<00:00, 487.05it/s]Calculating Metrics:  75%|  | 6/8 [00:00<00:00, 437.06it/s]Calculating Metrics:  88%| | 7/8 [00:00<00:00, 499.57it/s]Calculating Metrics:  88%| | 7/8 [00:00<00:00, 458.11it/s]Calculating Metrics: 100%|| 8/8 [00:00<00:00, 497.45it/s]Calculating Metrics: 100%|| 8/8 [00:00<00:00, 469.54it/s]Calculating Metrics: 100%|| 8/8 [00:00<00:00, 465.85it/s]Calculating Metrics: 100%|| 8/8 [00:00<00:00, 462.03it/s]
_ test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:norm_0_1_auto_inf_partition_tail_weights_should_fail_with_no_internal_holdout] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 2987.40it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 1013.97it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 1172.84it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 802.31it/s] Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 885.30it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 775.29it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 842.38it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 775.20it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 849.70it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 794.91it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 787.55it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 778.55it/s]
_ test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:positive_norm_0_1_auto_partition] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 3110.92it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 1166.22it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 1335.09it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 927.49it/s] Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 1016.59it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 873.40it/s] Calculating Metrics:  89%| | 8/9 [00:00<00:00, 941.83it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 857.56it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 936.83it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 870.35it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 861.25it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 850.12it/s]
_ test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:positive_norm_0_1_uniform_partition] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 3328.15it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 1390.34it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 1587.43it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 1070.69it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 1163.38it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 991.66it/s] Calculating Metrics:  89%| | 8/9 [00:00<00:00, 1064.11it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 965.85it/s] Calculating Metrics: 100%|| 9/9 [00:00<00:00, 1052.52it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 976.05it/s] Calculating Metrics: 100%|| 9/9 [00:00<00:00, 964.85it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 951.38it/s]
_ test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:positive_norm_0_1_ntile_partition] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 3169.70it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 1361.01it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 1556.67it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 1063.41it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 1126.68it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 961.68it/s] Calculating Metrics:  89%| | 8/9 [00:00<00:00, 1031.33it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 935.89it/s] Calculating Metrics: 100%|| 9/9 [00:00<00:00, 1018.91it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 946.99it/s] Calculating Metrics: 100%|| 9/9 [00:00<00:00, 936.23it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 918.73it/s]
_ test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:positive_norm_0_1_kde_partition] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 3188.98it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 1346.27it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 1538.86it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 1051.26it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 1142.82it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 973.58it/s] Calculating Metrics:  89%| | 8/9 [00:00<00:00, 1044.66it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 948.51it/s] Calculating Metrics: 100%|| 9/9 [00:00<00:00, 1033.50it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 958.14it/s] Calculating Metrics: 100%|| 9/9 [00:00<00:00, 947.13it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 934.44it/s]
_ test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:negative_norm_1_1_column_norm_0_1_auto_partition] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 2910.69it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 1200.09it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 1368.27it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 923.86it/s] Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 1019.34it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 878.28it/s] Calculating Metrics:  89%| | 8/9 [00:00<00:00, 948.75it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 863.91it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 944.47it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 877.61it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 868.47it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 857.38it/s]
_ test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:negative_norm_1_1_column_norm_0_1_uniform_partition] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 3149.47it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 1365.67it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 1560.61it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 1066.82it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 1149.03it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 979.72it/s] Calculating Metrics:  89%| | 8/9 [00:00<00:00, 1051.14it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 954.91it/s] Calculating Metrics: 100%|| 9/9 [00:00<00:00, 1040.83it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 934.07it/s] Calculating Metrics: 100%|| 9/9 [00:00<00:00, 920.63it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 907.64it/s]
_ test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:negative_norm_1_1_column_norm_0_1_ntile_partition] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 2906.66it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 1306.74it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 1499.25it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 1038.19it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 1122.89it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 958.76it/s] Calculating Metrics:  89%| | 8/9 [00:00<00:00, 1028.93it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 926.25it/s] Calculating Metrics: 100%|| 9/9 [00:00<00:00, 1008.52it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 936.62it/s] Calculating Metrics: 100%|| 9/9 [00:00<00:00, 925.94it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 913.13it/s]
_ test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:negative_norm_1_1_column_norm_0_1_kde_partition] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 2867.41it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 1217.24it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 1391.15it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 976.33it/s] Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 1071.46it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 922.72it/s] Calculating Metrics:  89%| | 8/9 [00:00<00:00, 993.79it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 906.39it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 988.99it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 920.50it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 910.38it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 898.29it/s]
_ test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:positive_bimodal_auto_partition] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 2493.64it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 1174.79it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 1344.16it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 953.81it/s] Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 980.96it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 849.44it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 917.24it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 842.21it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 913.64it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 851.00it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 841.91it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 831.49it/s]
_ test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:negative_bimodal_column_norm_0_1_auto_partition] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 2965.74it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 1224.70it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 1391.24it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 958.61it/s] Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 1041.51it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 862.06it/s] Calculating Metrics:  89%| | 8/9 [00:00<00:00, 928.07it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 846.56it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 925.17it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 859.12it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 850.12it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 839.48it/s]
_ test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:negative_bimodal_column_norm_0_1_uniform_partition] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 3142.39it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 1341.43it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 1527.20it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 1037.12it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 1103.93it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 944.27it/s] Calculating Metrics:  89%| | 8/9 [00:00<00:00, 1015.11it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 924.75it/s] Calculating Metrics: 100%|| 9/9 [00:00<00:00, 1008.87it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 938.18it/s] Calculating Metrics: 100%|| 9/9 [00:00<00:00, 927.94it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 915.39it/s]
_ test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_lower_inf_bound] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 2859.10it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 1315.76it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 1492.95it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 1013.95it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 1078.90it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 916.44it/s] Calculating Metrics:  89%| | 8/9 [00:00<00:00, 985.56it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 905.90it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 989.22it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 925.80it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 915.83it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 903.86it/s]
_ test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_lower_inf_bound_tail_weights] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 3466.37it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 1351.91it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 1535.25it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 1075.52it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 1181.49it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 1013.64it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 1085.94it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 990.39it/s] Calculating Metrics: 100%|| 9/9 [00:00<00:00, 1077.73it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 1003.93it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 992.21it/s] Calculating Metrics: 100%|| 9/9 [00:00<00:00, 978.17it/s]
_ test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_upper_inf_bound] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 3101.15it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 1394.61it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 1590.20it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 1095.75it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 1162.59it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 990.22it/s] Calculating Metrics:  89%| | 8/9 [00:00<00:00, 1059.03it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 950.77it/s] Calculating Metrics: 100%|| 9/9 [00:00<00:00, 1030.79it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 955.52it/s] Calculating Metrics: 100%|| 9/9 [00:00<00:00, 943.98it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 930.41it/s]
_ test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_upper_inf_bound_tail_weights] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 2851.33it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 1336.08it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 1525.42it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 1066.38it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 1178.88it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 1005.93it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 1077.60it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 982.33it/s] Calculating Metrics: 100%|| 9/9 [00:00<00:00, 1069.13it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 994.93it/s] Calculating Metrics: 100%|| 9/9 [00:00<00:00, 983.09it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 969.11it/s]
_ test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_lower_and_upper_inf_bounds0] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 3050.96it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 1363.78it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 1550.80it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 1078.67it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 1131.59it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 968.31it/s] Calculating Metrics:  89%| | 8/9 [00:00<00:00, 1038.26it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 947.73it/s] Calculating Metrics: 100%|| 9/9 [00:00<00:00, 1033.05it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 962.27it/s] Calculating Metrics: 100%|| 9/9 [00:00<00:00, 951.26it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 938.16it/s]
_ test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_lower_and_upper_inf_bounds1] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 3460.65it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 1456.23it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 1655.60it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 1132.80it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 1229.13it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 1046.82it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 1119.19it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 1015.35it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 1102.28it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 1022.97it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 1010.78it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 996.69it/s]
_ test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:tail_weight_holdout_is_not_defined_for_partitions_already_extending_to_inifinity] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 3445.72it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 1458.25it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 1658.48it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 1128.90it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 1224.00it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 1039.96it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 1111.59it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 1009.22it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 1097.70it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 1018.67it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 1005.48it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 990.75it/s]
_ test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:tail_weight_holdout_is_not_defined_for_partitions_already_extending_to_inifinity_tail_weight] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 3328.15it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 1461.43it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 1660.06it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 1138.46it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 1245.34it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 1060.62it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 1134.40it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 1031.84it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 1122.61it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 1042.87it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 1030.46it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 1015.93it/s]
_ test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:too_big_tail_weight] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 3600.26it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 1500.78it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 1702.92it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 1153.93it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 1245.71it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 1061.24it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 1134.44it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 1031.17it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 1121.21it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 1041.06it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 1028.55it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 1013.39it/s]
_ test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:too_big_internal_weight] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 3381.14it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 1365.22it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 1548.97it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 1079.73it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 1169.40it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 1004.01it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 1076.70it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 983.77it/s] Calculating Metrics: 100%|| 9/9 [00:00<00:00, 1071.95it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 999.23it/s] Calculating Metrics: 100%|| 9/9 [00:00<00:00, 987.82it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 974.04it/s]
_ test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_undefined_infinite_kl_divergence0] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/7 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/7 [00:00<?, ?it/s]Calculating Metrics:  29%|       | 2/7 [00:00<00:00, 3736.57it/s]Calculating Metrics:  29%|       | 2/7 [00:00<00:00, 1004.86it/s]Calculating Metrics:  43%|     | 3/7 [00:00<00:00, 1330.82it/s]Calculating Metrics:  43%|     | 3/7 [00:00<00:00, 849.57it/s] Calculating Metrics:  71%|  | 5/7 [00:00<00:00, 1006.60it/s]Calculating Metrics:  71%|  | 5/7 [00:00<00:00, 853.65it/s] Calculating Metrics:  86%| | 6/7 [00:00<00:00, 950.98it/s]Calculating Metrics:  86%| | 6/7 [00:00<00:00, 865.64it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 973.16it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 906.57it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 894.66it/s]Calculating Metrics: 100%|| 7/7 [00:00<00:00, 880.71it/s]
_ test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_undefined_infinite_kl_divergence1] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 3090.87it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 1398.10it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 1596.86it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 1102.78it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 1207.49it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 1030.00it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 1102.06it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 1001.83it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 1090.63it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 1013.61it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 1001.64it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 987.26it/s]
_ test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_undefined_infinite_kl_divergence_bins_do_not_cover_all_data] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 3294.82it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 1433.22it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 1632.02it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 1115.39it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 1216.14it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 1032.32it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 1103.29it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 1003.03it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 1065.99it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 980.41it/s] Calculating Metrics: 100%|| 9/9 [00:00<00:00, 966.70it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 952.79it/s]
_ test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_return_partitions_should_have_tail_weights] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 2861.54it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 1314.01it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 1499.68it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 1052.63it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 1156.09it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 991.09it/s] Calculating Metrics:  89%| | 8/9 [00:00<00:00, 1063.26it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 968.41it/s] Calculating Metrics: 100%|| 9/9 [00:00<00:00, 1054.88it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 981.58it/s] Calculating Metrics: 100%|| 9/9 [00:00<00:00, 969.73it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 956.22it/s]
_ test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_tail_weights_return_partitions_should_have_tail_weights] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 3336.09it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 1453.08it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 1652.86it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 1131.52it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 1234.60it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 1049.66it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 1122.52it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 1019.77it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 1109.77it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 1031.30it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 1019.02it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 1004.38it/s]
_ test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_bounded_endpoints_empty_tail_weights_in_return] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 3625.94it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 1497.43it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 1700.03it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 1148.05it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 1249.74it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 1062.04it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 1133.90it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 1028.93it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 1117.98it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 1037.57it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 1025.28it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 1010.68it/s]
_ test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_bounded_endpoints_observed_with_tail_weight_infinite_kl_divergence] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 3390.02it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 1458.76it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 1660.06it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 1134.52it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 1231.29it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 1048.05it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 1089.18it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 929.36it/s] Calculating Metrics: 100%|| 9/9 [00:00<00:00, 994.04it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 889.69it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 875.39it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 858.78it/s]
_ test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_infinite_endpoints_non_zero_tail_hold_out] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 1795.31it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 283.95it/s] Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 346.40it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 315.26it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 405.44it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 380.46it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 419.88it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 403.51it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 442.95it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 426.23it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 423.67it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 419.52it/s]
_ test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_upper_infinite_endpoint_non_zero_tail_hold_out] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 3162.53it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 1229.28it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 1389.39it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 989.55it/s] Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 1089.83it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 940.64it/s] Calculating Metrics:  89%| | 8/9 [00:00<00:00, 1011.28it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 925.54it/s] Calculating Metrics: 100%|| 9/9 [00:00<00:00, 1009.89it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 942.45it/s] Calculating Metrics: 100%|| 9/9 [00:00<00:00, 931.19it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 918.39it/s]
_ test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_lower_infinite_endpoint_non_zero_tail_hold_out] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 2645.41it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 1210.30it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 1386.55it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 994.62it/s] Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 1095.45it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 944.15it/s] Calculating Metrics:  89%| | 8/9 [00:00<00:00, 1014.43it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 928.59it/s] Calculating Metrics: 100%|| 9/9 [00:00<00:00, 1012.46it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 944.78it/s] Calculating Metrics: 100%|| 9/9 [00:00<00:00, 934.19it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 921.44it/s]
_ test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_bounded_endpoints_non_zero_tail_hold_out] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 3068.25it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 1351.91it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 1535.70it/s]Calculating Metrics:  56%|    | 5/9 [00:00<00:00, 1065.25it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 1157.46it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 993.20it/s] Calculating Metrics:  89%| | 8/9 [00:00<00:00, 1062.32it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 934.38it/s] Calculating Metrics: 100%|| 9/9 [00:00<00:00, 1014.45it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 946.39it/s] Calculating Metrics: 100%|| 9/9 [00:00<00:00, 934.88it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 921.87it/s]
_ test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:discrete_baseline_categorical_fixed_partition] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 2642.08it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 725.66it/s] Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 963.82it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 677.24it/s]Calculating Metrics:  67%|   | 6/9 [00:00<00:00, 740.91it/s]Calculating Metrics:  67%|   | 6/9 [00:00<00:00, 635.71it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 695.75it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 631.07it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 631.35it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 594.08it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 654.50it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 623.96it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 619.45it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 613.87it/s]
_ test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:discrete_categorical_fixed_alternate_partition] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 2976.79it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 756.75it/s] Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 1084.36it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 735.29it/s] Calculating Metrics:  67%|   | 6/9 [00:00<00:00, 831.02it/s]Calculating Metrics:  67%|   | 6/9 [00:00<00:00, 702.17it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 765.70it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 687.90it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 684.59it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 640.73it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 705.23it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 669.80it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 664.56it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 658.14it/s]
_ test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:internal_holdout_with_categorical_partition] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 2563.76it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 705.99it/s] Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 1008.31it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 701.15it/s] Calculating Metrics:  67%|   | 6/9 [00:00<00:00, 799.88it/s]Calculating Metrics:  67%|   | 6/9 [00:00<00:00, 680.19it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 743.09it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 669.16it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 679.58it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 636.63it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 700.93it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 666.02it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 660.51it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 653.26it/s]
_ test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:holdout_0_1] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 2666.44it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 689.40it/s] Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 878.16it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 631.32it/s]Calculating Metrics:  67%|   | 6/9 [00:00<00:00, 721.93it/s]Calculating Metrics:  67%|   | 6/9 [00:00<00:00, 621.26it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 665.52it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 605.49it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 613.51it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 577.37it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 636.54it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 603.27it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 597.65it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 591.88it/s]
_ test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:holdout_0_05] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 2894.62it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 755.66it/s] Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 1084.36it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 737.49it/s] Calculating Metrics:  67%|   | 6/9 [00:00<00:00, 864.06it/s]Calculating Metrics:  67%|   | 6/9 [00:00<00:00, 726.14it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 790.55it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 708.38it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 727.03it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 677.17it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 744.24it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 704.57it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 698.71it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 691.47it/s]
_ test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:missing_vals_no_holdout] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 2857.16it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 757.92it/s] Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 1077.53it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 733.56it/s] Calculating Metrics:  67%|   | 6/9 [00:00<00:00, 846.88it/s]Calculating Metrics:  67%|   | 6/9 [00:00<00:00, 712.91it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 776.31it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 697.56it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 697.10it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 651.73it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 716.89it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 680.53it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 675.17it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 668.59it/s]
_ test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:norm_0_1_auto_explicit_infinite_endpoints] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 872.04it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 361.93it/s]Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 454.76it/s]Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 346.87it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 109.58it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 106.10it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 118.24it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 116.30it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 125.59it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 123.56it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 135.39it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 133.78it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 133.57it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 133.33it/s]
_ test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:norm_0_1_auto_inf_partition_test_tail_weights] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 1983.12it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 895.26it/s] Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 1085.01it/s]Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 785.65it/s] Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 339.73it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 318.17it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 349.71it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 333.66it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 353.68it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 341.53it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 372.06it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 361.26it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 359.96it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 358.37it/s]
_ test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:norm_0_1_auto_inf_partition_should_fail_with_no_holdout] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 1909.11it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 883.34it/s] Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 1079.71it/s]Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 750.84it/s] Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 387.56it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 343.62it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 371.56it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 351.44it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 370.41it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 353.37it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 384.33it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 372.57it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 371.12it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 369.39it/s]
_ test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:norm_0_1_auto_inf_partition_null_threshold_should_always_succeed] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 1733.18it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 843.33it/s] Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 1037.89it/s]Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 759.40it/s] Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 419.72it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 387.13it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 423.05it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 398.42it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 418.81it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 401.68it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 436.85it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 421.88it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 419.78it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 417.62it/s]
_ test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:norm_0_1_auto_inf_partition_tail_weights_should_fail_with_no_internal_holdout] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 1736.05it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 776.08it/s] Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 930.21it/s]Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 692.34it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 345.84it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 322.81it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 352.56it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 335.79it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 353.69it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 341.03it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 371.32it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 360.49it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 359.17it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 357.56it/s]
_ test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:positive_norm_0_1_auto_partition] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 1885.72it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 818.00it/s] Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 994.19it/s]Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 678.73it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 408.75it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 375.78it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 410.10it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 388.00it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 407.36it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 391.08it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 425.42it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 409.94it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 407.80it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 405.60it/s]
_ test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:positive_norm_0_1_uniform_partition] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 1960.87it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 938.74it/s] Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 1126.74it/s]Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 816.54it/s] Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 531.81it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 482.36it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 522.92it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 488.76it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 505.71it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 481.78it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 522.57it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 500.25it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 496.68it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 493.34it/s]
_ test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:positive_norm_0_1_ntile_partition] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 1868.91it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 920.81it/s] Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 1108.82it/s]Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 813.77it/s] Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 631.60it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 563.54it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 607.37it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 561.30it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 574.21it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 544.28it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 589.28it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 564.13it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 560.93it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 556.99it/s]
_ test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:positive_norm_0_1_kde_partition] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 1650.81it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 858.21it/s] Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 1058.81it/s]Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 787.61it/s] Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 652.21it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 580.73it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 626.92it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 578.82it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 596.66it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 564.85it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 611.69it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 584.58it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 581.13it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 576.92it/s]
_ test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:negative_norm_1_1_column_norm_0_1_auto_partition] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 1432.73it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 768.36it/s] Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 945.48it/s]Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 706.89it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 330.31it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 309.43it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 339.59it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 322.98it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 337.63it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 326.43it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 355.76it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 345.99it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 344.81it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 343.37it/s]
_ test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:negative_norm_1_1_column_norm_0_1_uniform_partition] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 1795.31it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 863.34it/s] Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 989.14it/s]Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 731.35it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 501.19it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 456.03it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 493.63it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 462.79it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 474.70it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 448.09it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 482.73it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 455.17it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 451.93it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 448.19it/s]
_ test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:negative_norm_1_1_column_norm_0_1_ntile_partition] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 1457.87it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 712.02it/s] Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 852.79it/s]Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 644.14it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 485.70it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 441.99it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 469.90it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 440.75it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 458.53it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 438.93it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 476.81it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 460.16it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 458.05it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 455.47it/s]
_ test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:negative_norm_1_1_column_norm_0_1_kde_partition] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 1804.78it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 864.63it/s] Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 1038.07it/s]Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 772.60it/s] Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 631.05it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 558.65it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 599.16it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 554.05it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 565.86it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 536.34it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 580.72it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 556.11it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 552.90it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 548.88it/s]
_ test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:positive_bimodal_auto_partition] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 1414.84it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 791.45it/s] Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 980.55it/s]Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 739.56it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 521.38it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 474.04it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 515.00it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 473.18it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 479.62it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 458.11it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 497.24it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 479.26it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 476.95it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 474.16it/s]
_ test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:negative_bimodal_column_norm_0_1_auto_partition] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 1907.59it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 879.49it/s] Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 1057.08it/s]Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 770.92it/s] Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 327.86it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 307.49it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 337.66it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 322.57it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 341.59it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 328.96it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 358.20it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 348.10it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 346.84it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 345.35it/s]
_ test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:negative_bimodal_column_norm_0_1_uniform_partition] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 1451.44it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 801.93it/s] Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 991.29it/s]Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 747.12it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 531.13it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 482.40it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 523.63it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 489.77it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 504.83it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 481.45it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 522.37it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 502.75it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 500.21it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 497.13it/s]
_ test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_lower_inf_bound] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 1336.08it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 771.47it/s] Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 884.97it/s]Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 684.77it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 646.21it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 572.33it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 615.60it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 569.88it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 570.81it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 542.21it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 587.05it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 563.36it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 560.11it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 556.09it/s]
_ test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_lower_inf_bound_tail_weights] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 1811.60it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 915.09it/s] Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 1111.27it/s]Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 828.80it/s] Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 775.70it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 682.64it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 732.47it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 671.79it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 687.41it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 648.21it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 700.41it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 668.37it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 664.05it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 658.79it/s]
_ test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_upper_inf_bound] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 1530.21it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 844.39it/s] Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 1044.23it/s]Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 786.87it/s] Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 663.73it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 592.21it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 638.70it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 590.40it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 597.12it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 565.96it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 612.65it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 587.20it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 583.65it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 579.47it/s]
_ test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_upper_inf_bound_tail_weights] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 1608.40it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 854.37it/s] Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 1042.41it/s]Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 775.60it/s] Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 699.44it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 619.59it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 666.37it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 614.63it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 631.00it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 597.23it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 645.96it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 618.05it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 614.29it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 609.66it/s]
_ test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_lower_and_upper_inf_bounds0] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 1412.46it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 808.07it/s] Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 962.00it/s]Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 737.18it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 648.98it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 569.64it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 612.42it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 568.29it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 576.31it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 547.53it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 592.96it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 568.71it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 565.46it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 561.54it/s]
_ test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_lower_and_upper_inf_bounds1] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 1402.07it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 805.32it/s] Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 1003.02it/s]Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 761.63it/s] Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 727.81it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 639.14it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 683.12it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 627.53it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 634.32it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 598.45it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 646.15it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 617.15it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 612.85it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 607.88it/s]
_ test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:tail_weight_holdout_is_not_defined_for_partitions_already_extending_to_inifinity] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 1849.34it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 798.72it/s] Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 922.37it/s]Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 694.77it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 630.27it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 554.98it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 590.40it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 548.75it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 566.86it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 539.31it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 584.39it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 555.61it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 551.85it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 547.92it/s]
_ test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:tail_weight_holdout_is_not_defined_for_partitions_already_extending_to_inifinity_tail_weight] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 2012.14it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 815.66it/s] Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 989.46it/s]Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 758.26it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 802.89it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 702.12it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 750.95it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 686.77it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 697.05it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 656.51it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 709.22it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 675.93it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 671.51it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 666.06it/s]
_ test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:too_big_tail_weight] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 2042.76it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 964.48it/s] Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 1117.29it/s]Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 826.65it/s] Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 834.38it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 726.99it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 771.45it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 687.49it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 691.98it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 651.33it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 700.72it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 666.54it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 661.81it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 656.16it/s]
_ test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:too_big_internal_weight] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 2239.35it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 1040.25it/s]Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 1245.28it/s]Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 902.52it/s] Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 933.13it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 801.51it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 852.91it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 771.66it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 782.96it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 732.49it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 789.70it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 748.44it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 742.99it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 736.42it/s]
_ test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_undefined_infinite_kl_divergence0] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 2608.40it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 721.54it/s] Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 972.31it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 677.65it/s]Calculating Metrics:  67%|   | 6/9 [00:00<00:00, 734.49it/s]Calculating Metrics:  67%|   | 6/9 [00:00<00:00, 628.88it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 687.83it/s]Calculating Metrics:  78%|  | 7/9 [00:00<00:00, 625.00it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 627.76it/s]Calculating Metrics:  89%| | 8/9 [00:00<00:00, 589.97it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 650.20it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 619.76it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 615.23it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 609.55it/s]
_ test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_undefined_infinite_kl_divergence1] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 1228.11it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 622.00it/s] Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 744.88it/s]Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 553.30it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 462.78it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 415.80it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 448.90it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 423.71it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 434.42it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 417.02it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 452.98it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 438.84it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 436.89it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 434.44it/s]
_ test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_undefined_infinite_kl_divergence_bins_do_not_cover_all_data] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 1871.62it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 939.16it/s] Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 1051.51it/s]Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 785.33it/s] Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 720.13it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 634.97it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 681.75it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 627.65it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 641.23it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 605.06it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 653.83it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 624.89it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 621.04it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 616.21it/s]
_ test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_return_partitions_should_have_tail_weights] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 1398.57it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 776.08it/s] Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 969.59it/s]Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 720.28it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 658.21it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 588.57it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 635.59it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 588.50it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 589.31it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 553.10it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 597.92it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 571.45it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 567.54it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 563.34it/s]
_ test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_tail_weights_return_partitions_should_have_tail_weights] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 1582.31it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 778.24it/s] Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 908.42it/s]Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 685.42it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 633.62it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 268.51it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 278.66it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 269.32it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 288.12it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 280.84it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 306.47it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 300.00it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 299.11it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 298.01it/s]
_ test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_bounded_endpoints_empty_tail_weights_in_return] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 1934.20it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 860.77it/s] Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 992.38it/s]Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 732.14it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 562.66it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 501.22it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 539.47it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 504.17it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 519.70it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 493.49it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 534.21it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 514.67it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 511.82it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 508.43it/s]
_ test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_bounded_endpoints_observed_with_tail_weight_infinite_kl_divergence] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 1918.71it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 941.22it/s] Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 1083.47it/s]Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 767.37it/s] Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 648.88it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 574.64it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 611.80it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 566.59it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 576.08it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 546.48it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 590.90it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 566.84it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 563.59it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 559.52it/s]
_ test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_infinite_endpoints_non_zero_tail_hold_out] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 2031.39it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 977.98it/s] Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 1178.29it/s]Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 855.40it/s] Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 779.34it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 680.78it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 716.16it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 619.28it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 624.53it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 586.40it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 632.95it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 601.45it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 596.40it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 591.34it/s]
_ test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_upper_infinite_endpoint_non_zero_tail_hold_out] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 1863.10it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 805.98it/s] Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 924.09it/s]Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 691.56it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 494.31it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 417.73it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 435.50it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 401.32it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 407.83it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 388.23it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 419.50it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 405.78it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 403.61it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 401.34it/s]
_ test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_lower_infinite_endpoint_non_zero_tail_hold_out] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 1876.23it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 686.38it/s] Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 775.62it/s]Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 570.78it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 483.56it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 421.12it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 446.23it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 407.85it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 421.89it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 405.73it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 440.85it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 426.87it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 424.38it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 420.87it/s]
_ test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_bounded_endpoints_non_zero_tail_hold_out] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/11 [00:00<?, ?it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 2089.84it/s]Calculating Metrics:  36%|      | 4/11 [00:00<00:00, 971.35it/s] Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 1150.07it/s]Calculating Metrics:  55%|    | 6/11 [00:00<00:00, 798.10it/s] Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 762.48it/s]Calculating Metrics:  73%|  | 8/11 [00:00<00:00, 671.13it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 720.16it/s]Calculating Metrics:  82%| | 9/11 [00:00<00:00, 661.23it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 676.50it/s]Calculating Metrics:  91%| | 10/11 [00:00<00:00, 638.66it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 690.27it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 658.84it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 654.64it/s]Calculating Metrics: 100%|| 11/11 [00:00<00:00, 649.43it/s]
_ test_case_runner_v3_api[pandas/other_expectations/expect_table_row_count_to_equal:basic_positive_case] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 3104.59it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1971.93it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1630.76it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1351.26it/s]
_ test_case_runner_v3_api[pandas/other_expectations/expect_table_row_count_to_equal:basic_negative_case_upper_error] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 3066.01it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1941.81it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1607.63it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1334.92it/s]
_ test_case_runner_v3_api[pandas/other_expectations/expect_table_row_count_to_equal:basic_negative_case_lower_error] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 3204.20it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 2007.80it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1657.83it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1371.58it/s]
_ test_case_runner_v3_api[pandas/other_expectations/expect_table_row_count_to_equal:basic_negative_case_kwargs_args] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 3151.24it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1987.82it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1641.61it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1358.70it/s]
_ test_case_runner_v3_api[pandas/other_expectations/expect_column_to_exist:basic_positive_test] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 1842.03it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 1053.85it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1523.26it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1296.34it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1212.75it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1124.33it/s]
_ test_case_runner_v3_api[pandas/other_expectations/expect_column_to_exist:basic_negative_test] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 2145.42it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 1140.38it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1621.93it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1361.35it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1269.85it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1176.52it/s]
_ test_case_runner_v3_api[pandas/other_expectations/expect_column_to_exist:positive_test_with_column_order] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 2087.76it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 1126.59it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1592.67it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1340.68it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1251.66it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1156.09it/s]
_ test_case_runner_v3_api[pandas/other_expectations/expect_column_to_exist:column_exists_but_wrong_index] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 1572.67it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 944.45it/s] Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1399.50it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1202.67it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1129.32it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1049.36it/s]
_ test_case_runner_v3_api[pandas/other_expectations/expect_table_row_count_to_be_between:basic_positive_test] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 3088.59it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1957.21it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1626.33it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1346.05it/s]
_ test_case_runner_v3_api[pandas/other_expectations/expect_table_row_count_to_be_between:vacuously_true] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 3146.51it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1984.06it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1639.68it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1362.67it/s]
_ test_case_runner_v3_api[pandas/other_expectations/expect_table_row_count_to_be_between:basic_negative_test] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 2857.16it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1855.89it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1550.57it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1296.94it/s]
_ test_case_runner_v3_api[pandas/other_expectations/expect_table_row_count_to_be_between:positive_test_with_null_min_value] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 3125.41it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1945.41it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1607.63it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1333.22it/s]
_ test_case_runner_v3_api[pandas/other_expectations/expect_table_row_count_to_be_between:test_error_handling_for_min_greater_than_max] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 3165.51it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1988.76it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1637.12it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1349.52it/s]
_ test_case_runner_v3_api[pandas/other_expectations/expect_table_row_count_to_be_between:positive_test_with_null_min] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 3196.88it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 2000.14it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1653.25it/s]Calculating Metrics: 100%|| 1/1 [00:00<00:00, 1368.01it/s]
_ test_case_runner_v3_api[pandas/other_expectations/expect_table_columns_to_match_ordered_list:basic_positive_test] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 1251.66it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 828.10it/s] Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1278.95it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1112.55it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1051.07it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 983.89it/s]
_ test_case_runner_v3_api[pandas/other_expectations/expect_table_columns_to_match_ordered_list:negative_test_column_is_missing] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 1683.78it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 997.93it/s] Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1471.43it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1258.61it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1146.14it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1059.30it/s]
_ test_case_runner_v3_api[pandas/other_expectations/expect_table_columns_to_match_ordered_list:negative_test_column_is_misnamed] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 2058.05it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 1129.93it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1619.42it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1366.89it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1276.22it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1180.66it/s]
_ test_case_runner_v3_api[pandas/other_expectations/expect_table_columns_to_match_ordered_list:negative_test_columns_are_right_but_ordering_wrong] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 2079.48it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 1133.90it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1620.99it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1370.02it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1277.97it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1179.33it/s]
_ test_case_runner_v3_api[pandas/other_expectations/expect_table_columns_to_match_ordered_list:negative_test_extra_column] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 1963.63it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 1092.84it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1569.72it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1334.07it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1247.56it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1155.30it/s]
_ test_case_runner_v3_api[pandas/other_expectations/expect_table_columns_to_match_ordered_list:null_list_provides_vacuously_true_expectation] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 2174.34it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 1168.33it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1657.17it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1395.78it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1302.17it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1205.78it/s]
_ test_case_runner_v3_api[pandas/other_expectations/expect_table_column_count_to_be_between:basic_positive_test] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/3 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/3 [00:00<?, ?it/s]Calculating Metrics:  33%|      | 1/3 [00:00<00:00, 1890.18it/s]Calculating Metrics:  33%|      | 1/3 [00:00<00:00, 888.06it/s] Calculating Metrics:  67%|   | 2/3 [00:00<00:00, 1353.22it/s]Calculating Metrics:  67%|   | 2/3 [00:00<00:00, 990.16it/s] Calculating Metrics: 100%|| 3/3 [00:00<00:00, 1218.09it/s]Calculating Metrics: 100%|| 3/3 [00:00<00:00, 1089.34it/s]Calculating Metrics: 100%|| 3/3 [00:00<00:00, 1047.44it/s]Calculating Metrics: 100%|| 3/3 [00:00<00:00, 997.38it/s]
_ test_case_runner_v3_api[pandas/other_expectations/expect_table_column_count_to_be_between:vacuously_true] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/3 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/3 [00:00<?, ?it/s]Calculating Metrics:  33%|      | 1/3 [00:00<00:00, 1426.15it/s]Calculating Metrics:  33%|      | 1/3 [00:00<00:00, 724.03it/s] Calculating Metrics:  67%|   | 2/3 [00:00<00:00, 1131.15it/s]Calculating Metrics:  67%|   | 2/3 [00:00<00:00, 796.49it/s] Calculating Metrics: 100%|| 3/3 [00:00<00:00, 1017.21it/s]Calculating Metrics: 100%|| 3/3 [00:00<00:00, 924.19it/s] Calculating Metrics: 100%|| 3/3 [00:00<00:00, 893.36it/s]Calculating Metrics: 100%|| 3/3 [00:00<00:00, 857.85it/s]
_ test_case_runner_v3_api[pandas/other_expectations/expect_table_column_count_to_be_between:basic_negative_test] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/3 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/3 [00:00<?, ?it/s]Calculating Metrics:  33%|      | 1/3 [00:00<00:00, 2021.35it/s]Calculating Metrics:  33%|      | 1/3 [00:00<00:00, 907.66it/s] Calculating Metrics:  67%|   | 2/3 [00:00<00:00, 1374.73it/s]Calculating Metrics:  67%|   | 2/3 [00:00<00:00, 1060.51it/s]Calculating Metrics: 100%|| 3/3 [00:00<00:00, 1344.90it/s]Calculating Metrics: 100%|| 3/3 [00:00<00:00, 1197.69it/s]Calculating Metrics: 100%|| 3/3 [00:00<00:00, 1149.54it/s]Calculating Metrics: 100%|| 3/3 [00:00<00:00, 1094.93it/s]
_ test_case_runner_v3_api[pandas/other_expectations/expect_table_column_count_to_be_between:positive_test_with_null_min_value] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/3 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/3 [00:00<?, ?it/s]Calculating Metrics:  33%|      | 1/3 [00:00<00:00, 1594.79it/s]Calculating Metrics:  33%|      | 1/3 [00:00<00:00, 740.65it/s] Calculating Metrics:  67%|   | 2/3 [00:00<00:00, 1157.37it/s]Calculating Metrics:  67%|   | 2/3 [00:00<00:00, 928.05it/s] Calculating Metrics: 100%|| 3/3 [00:00<00:00, 1203.30it/s]Calculating Metrics: 100%|| 3/3 [00:00<00:00, 1084.55it/s]Calculating Metrics: 100%|| 3/3 [00:00<00:00, 1045.27it/s]Calculating Metrics: 100%|| 3/3 [00:00<00:00, 999.91it/s]
_ test_case_runner_v3_api[pandas/other_expectations/expect_table_column_count_to_be_between:test_error_handling_for_max_lt_min] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/3 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/3 [00:00<?, ?it/s]Calculating Metrics:  33%|      | 1/3 [00:00<00:00, 2041.02it/s]Calculating Metrics:  33%|      | 1/3 [00:00<00:00, 864.45it/s] Calculating Metrics:  67%|   | 2/3 [00:00<00:00, 1297.14it/s]Calculating Metrics:  67%|   | 2/3 [00:00<00:00, 1009.58it/s]Calculating Metrics: 100%|| 3/3 [00:00<00:00, 1288.57it/s]Calculating Metrics: 100%|| 3/3 [00:00<00:00, 1151.12it/s]Calculating Metrics: 100%|| 3/3 [00:00<00:00, 1106.19it/s]Calculating Metrics: 100%|| 3/3 [00:00<00:00, 1054.91it/s]
_ test_case_runner_v3_api[pandas/other_expectations/expect_table_column_count_to_be_between:positive_test_with_null_min] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/3 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/3 [00:00<?, ?it/s]Calculating Metrics:  33%|      | 1/3 [00:00<00:00, 2075.36it/s]Calculating Metrics:  33%|      | 1/3 [00:00<00:00, 925.89it/s] Calculating Metrics:  67%|   | 2/3 [00:00<00:00, 1394.61it/s]Calculating Metrics:  67%|   | 2/3 [00:00<00:00, 1070.66it/s]Calculating Metrics: 100%|| 3/3 [00:00<00:00, 1358.11it/s]Calculating Metrics: 100%|| 3/3 [00:00<00:00, 1201.92it/s]Calculating Metrics: 100%|| 3/3 [00:00<00:00, 1150.28it/s]Calculating Metrics: 100%|| 3/3 [00:00<00:00, 1093.31it/s]
_ test_case_runner_v3_api[pandas/other_expectations/expect_table_columns_to_match_set:basic_positive_test_exact_match_true] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 1911.72it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 1076.29it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1549.14it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1133.90it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1063.33it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 993.09it/s]
_ test_case_runner_v3_api[pandas/other_expectations/expect_table_columns_to_match_set:basic_positive_test_exact_match_false] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 2032.12it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 1117.29it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1589.96it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1345.84it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1257.10it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1163.47it/s]
_ test_case_runner_v3_api[pandas/other_expectations/expect_table_columns_to_match_set:negative_test_column_is_missing_exact_match_true] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 2020.38it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 1106.09it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1536.09it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1155.30it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1047.14it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 968.55it/s]
_ test_case_runner_v3_api[pandas/other_expectations/expect_table_columns_to_match_set:positive_test_column_is_missing_exact_match_false] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 2045.00it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 1113.43it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1596.01it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1351.26it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1263.34it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1170.12it/s]
_ test_case_runner_v3_api[pandas/other_expectations/expect_table_columns_to_match_set:negative_test_column_is_misnamed_exact_match_true] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 2213.35it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 1179.50it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1665.40it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1400.67it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1306.43it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1208.38it/s]
_ test_case_runner_v3_api[pandas/other_expectations/expect_table_columns_to_match_set:negative_test_column_is_misnamed_exact_match_false] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 2169.84it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 1158.97it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1531.61it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1203.53it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1107.99it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1023.00it/s]
_ test_case_runner_v3_api[pandas/other_expectations/expect_table_columns_to_match_set:positive_test_columns_are_right_but_ordering_wrong_exact_match_true] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 2015.52it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 1120.87it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1606.09it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1360.46it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1272.16it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1177.02it/s]
_ test_case_runner_v3_api[pandas/other_expectations/expect_table_columns_to_match_set:positive_test_columns_are_right_but_ordering_wrong_exact_match_false] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 1526.31it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 921.62it/s] Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1305.21it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1108.58it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1044.79it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 971.35it/s]
_ test_case_runner_v3_api[pandas/other_expectations/expect_table_columns_to_match_set:negative_test_extra_column_exact_match_true] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 1387.01it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 758.19it/s] Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1129.17it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 976.56it/s] Calculating Metrics: 100%|| 2/2 [00:00<00:00, 924.16it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 855.72it/s]
_ test_case_runner_v3_api[pandas/other_expectations/expect_table_columns_to_match_set:negative_test_extra_column_exact_match_false] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 2012.62it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 1113.43it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1598.74it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1354.09it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1266.59it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1173.07it/s]
_ test_case_runner_v3_api[pandas/other_expectations/expect_table_columns_to_match_set:negative_test_null_set_exact_match_true] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 2183.40it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 1158.65it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1651.63it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1387.23it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1295.34it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1200.60it/s]
_ test_case_runner_v3_api[pandas/other_expectations/expect_table_columns_to_match_set:positive_test_vacuously_true_null_set_exact_match_false] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 2136.68it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 1158.65it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1655.54it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1397.64it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1305.21it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1209.08it/s]
_ test_case_runner_v3_api[pandas/other_expectations/expect_table_column_count_to_equal:basic_positive_case] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/3 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/3 [00:00<?, ?it/s]Calculating Metrics:  33%|      | 1/3 [00:00<00:00, 1694.67it/s]Calculating Metrics:  33%|      | 1/3 [00:00<00:00, 829.24it/s] Calculating Metrics:  67%|   | 2/3 [00:00<00:00, 1274.67it/s]Calculating Metrics:  67%|   | 2/3 [00:00<00:00, 998.88it/s] Calculating Metrics: 100%|| 3/3 [00:00<00:00, 1279.79it/s]Calculating Metrics: 100%|| 3/3 [00:00<00:00, 1144.11it/s]Calculating Metrics: 100%|| 3/3 [00:00<00:00, 1100.10it/s]Calculating Metrics: 100%|| 3/3 [00:00<00:00, 1048.58it/s]
_ test_case_runner_v3_api[pandas/other_expectations/expect_table_column_count_to_equal:basic_negative_case_upper_error] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/3 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/3 [00:00<?, ?it/s]Calculating Metrics:  33%|      | 1/3 [00:00<00:00, 1960.87it/s]Calculating Metrics:  33%|      | 1/3 [00:00<00:00, 887.31it/s] Calculating Metrics:  67%|   | 2/3 [00:00<00:00, 1334.07it/s]Calculating Metrics:  67%|   | 2/3 [00:00<00:00, 1034.61it/s]Calculating Metrics: 100%|| 3/3 [00:00<00:00, 1314.69it/s]Calculating Metrics: 100%|| 3/3 [00:00<00:00, 1172.79it/s]Calculating Metrics: 100%|| 3/3 [00:00<00:00, 1126.19it/s]Calculating Metrics: 100%|| 3/3 [00:00<00:00, 1073.35it/s]
_ test_case_runner_v3_api[pandas/other_expectations/expect_table_column_count_to_equal:basic_negative_case_lower_error] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/3 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/3 [00:00<?, ?it/s]Calculating Metrics:  33%|      | 1/3 [00:00<00:00, 2016.49it/s]Calculating Metrics:  33%|      | 1/3 [00:00<00:00, 907.66it/s] Calculating Metrics:  67%|   | 2/3 [00:00<00:00, 1366.45it/s]Calculating Metrics:  67%|   | 2/3 [00:00<00:00, 1054.91it/s]Calculating Metrics: 100%|| 3/3 [00:00<00:00, 1335.20it/s]Calculating Metrics: 100%|| 3/3 [00:00<00:00, 1186.28it/s]Calculating Metrics: 100%|| 3/3 [00:00<00:00, 1138.52it/s]Calculating Metrics: 100%|| 3/3 [00:00<00:00, 1083.52it/s]
_ test_case_runner_v3_api[pandas/other_expectations/expect_table_column_count_to_equal:basic_negative_case_kwargs_args] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/3 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/3 [00:00<?, ?it/s]Calculating Metrics:  33%|      | 1/3 [00:00<00:00, 2065.14it/s]Calculating Metrics:  33%|      | 1/3 [00:00<00:00, 918.19it/s] Calculating Metrics:  67%|   | 2/3 [00:00<00:00, 1384.03it/s]Calculating Metrics:  67%|   | 2/3 [00:00<00:00, 1067.25it/s]Calculating Metrics: 100%|| 3/3 [00:00<00:00, 1353.15it/s]Calculating Metrics: 100%|| 3/3 [00:00<00:00, 1202.84it/s]Calculating Metrics: 100%|| 3/3 [00:00<00:00, 1154.29it/s]Calculating Metrics: 100%|| 3/3 [00:00<00:00, 1098.85it/s]
_ test_case_runner_v3_api[sqlite/other_expectations/expect_table_row_count_to_equal:basic_positive_case] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 2906.66it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 1364.45it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 921.62it/s] Calculating Metrics: 100%|| 2/2 [00:00<00:00, 821.69it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 764.27it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 720.24it/s]
_ test_case_runner_v3_api[sqlite/other_expectations/expect_table_row_count_to_equal:basic_negative_case_upper_error] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 2841.67it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 1309.08it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1038.32it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 914.49it/s] Calculating Metrics: 100%|| 2/2 [00:00<00:00, 868.03it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 820.00it/s]
_ test_case_runner_v3_api[sqlite/other_expectations/expect_table_row_count_to_equal:basic_negative_case_lower_error] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 2859.10it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 1340.89it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1085.76it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 952.93it/s] Calculating Metrics: 100%|| 2/2 [00:00<00:00, 904.53it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 852.59it/s]
_ test_case_runner_v3_api[sqlite/other_expectations/expect_table_row_count_to_equal:basic_negative_case_kwargs_args] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 1851.79it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 823.70it/s] Calculating Metrics: 100%|| 2/2 [00:00<00:00, 604.58it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 527.59it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 501.38it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 470.03it/s]
_ test_case_runner_v3_api[sqlite/other_expectations/expect_column_to_exist:basic_positive_test] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 1443.33it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 901.81it/s] Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1356.06it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1173.72it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1106.24it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1030.41it/s]
_ test_case_runner_v3_api[sqlite/other_expectations/expect_column_to_exist:basic_negative_test] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 1650.00it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 985.27it/s] Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1456.61it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1249.98it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1173.56it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1091.13it/s]
_ test_case_runner_v3_api[sqlite/other_expectations/expect_column_to_exist:positive_test_with_column_order] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 1410.32it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 832.04it/s] Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1254.65it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1089.43it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1029.40it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 962.55it/s]
_ test_case_runner_v3_api[sqlite/other_expectations/expect_column_to_exist:column_exists_but_wrong_index] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 1340.46it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 841.05it/s] Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1265.82it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1098.85it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1036.27it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 960.67it/s]
_ test_case_runner_v3_api[sqlite/other_expectations/expect_table_row_count_to_be_between:basic_positive_test] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 2763.05it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 1310.31it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 832.62it/s] Calculating Metrics: 100%|| 2/2 [00:00<00:00, 698.82it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 657.67it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 614.64it/s]
_ test_case_runner_v3_api[sqlite/other_expectations/expect_table_row_count_to_be_between:vacuously_true] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 2716.52it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 1301.77it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 879.03it/s] Calculating Metrics: 100%|| 2/2 [00:00<00:00, 784.94it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 751.53it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 714.78it/s]
_ test_case_runner_v3_api[sqlite/other_expectations/expect_table_row_count_to_be_between:basic_negative_test] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 2761.23it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 1321.04it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1048.71it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 917.89it/s] Calculating Metrics: 100%|| 2/2 [00:00<00:00, 873.36it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 824.76it/s]
_ test_case_runner_v3_api[sqlite/other_expectations/expect_table_row_count_to_be_between:positive_test_with_null_min_value] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 2444.23it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 1228.20it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 988.17it/s] Calculating Metrics: 100%|| 2/2 [00:00<00:00, 868.84it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 828.10it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 783.40it/s]
_ test_case_runner_v3_api[sqlite/other_expectations/expect_table_row_count_to_be_between:test_error_handling_for_min_greater_than_max] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 2597.09it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 1271.77it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1047.66it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 921.52it/s] Calculating Metrics: 100%|| 2/2 [00:00<00:00, 876.64it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 828.10it/s]
_ test_case_runner_v3_api[sqlite/other_expectations/expect_table_row_count_to_be_between:positive_test_with_null_min] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 2763.05it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 1310.31it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1069.43it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 939.37it/s] Calculating Metrics: 100%|| 2/2 [00:00<00:00, 893.64it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 843.16it/s]
_ test_case_runner_v3_api[sqlite/other_expectations/expect_table_columns_to_match_ordered_list:basic_positive_test] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 1260.69it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 816.33it/s] Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1249.98it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1093.41it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1032.95it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 939.27it/s]
_ test_case_runner_v3_api[sqlite/other_expectations/expect_table_columns_to_match_ordered_list:negative_test_column_is_missing] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 641.04it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 437.82it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 685.85it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 622.67it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 590.83it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 554.80it/s]
_ test_case_runner_v3_api[sqlite/other_expectations/expect_table_columns_to_match_ordered_list:negative_test_column_is_misnamed] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 1390.68it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 727.67it/s] Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1119.08it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 988.06it/s] Calculating Metrics: 100%|| 2/2 [00:00<00:00, 938.85it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 883.38it/s]
_ test_case_runner_v3_api[sqlite/other_expectations/expect_table_columns_to_match_ordered_list:negative_test_columns_are_right_but_ordering_wrong] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 1633.93it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 976.56it/s] Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1445.07it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1240.73it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1160.73it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1075.88it/s]
_ test_case_runner_v3_api[sqlite/other_expectations/expect_table_columns_to_match_ordered_list:negative_test_extra_column] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 1207.69it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 808.46it/s] Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1251.66it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1094.12it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1035.12it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 970.79it/s]
_ test_case_runner_v3_api[sqlite/other_expectations/expect_table_columns_to_match_ordered_list:null_list_provides_vacuously_true_expectation] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 1696.04it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 1008.25it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1479.47it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1266.01it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1187.68it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1105.66it/s]
_ test_case_runner_v3_api[sqlite/other_expectations/expect_table_column_count_to_be_between:basic_positive_test] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/3 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/3 [00:00<?, ?it/s]Calculating Metrics:  33%|      | 1/3 [00:00<00:00, 1625.70it/s]Calculating Metrics:  33%|      | 1/3 [00:00<00:00, 824.51it/s] Calculating Metrics:  67%|   | 2/3 [00:00<00:00, 1279.53it/s]Calculating Metrics:  67%|   | 2/3 [00:00<00:00, 1007.52it/s]Calculating Metrics: 100%|| 3/3 [00:00<00:00, 1291.48it/s]Calculating Metrics: 100%|| 3/3 [00:00<00:00, 1156.09it/s]Calculating Metrics: 100%|| 3/3 [00:00<00:00, 1112.35it/s]Calculating Metrics: 100%|| 3/3 [00:00<00:00, 1064.18it/s]
_ test_case_runner_v3_api[sqlite/other_expectations/expect_table_column_count_to_be_between:vacuously_true] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/3 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/3 [00:00<?, ?it/s]Calculating Metrics:  33%|      | 1/3 [00:00<00:00, 1795.51it/s]Calculating Metrics:  33%|      | 1/3 [00:00<00:00, 872.54it/s] Calculating Metrics:  67%|   | 2/3 [00:00<00:00, 1337.04it/s]Calculating Metrics:  67%|   | 2/3 [00:00<00:00, 1041.67it/s]Calculating Metrics: 100%|| 3/3 [00:00<00:00, 1328.15it/s]Calculating Metrics: 100%|| 3/3 [00:00<00:00, 1184.83it/s]Calculating Metrics: 100%|| 3/3 [00:00<00:00, 1139.45it/s]Calculating Metrics: 100%|| 3/3 [00:00<00:00, 1088.96it/s]
_ test_case_runner_v3_api[sqlite/other_expectations/expect_table_column_count_to_be_between:basic_negative_test] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/3 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/3 [00:00<?, ?it/s]Calculating Metrics:  33%|      | 1/3 [00:00<00:00, 1485.76it/s]Calculating Metrics:  33%|      | 1/3 [00:00<00:00, 716.36it/s] Calculating Metrics:  67%|   | 2/3 [00:00<00:00, 1119.68it/s]Calculating Metrics:  67%|   | 2/3 [00:00<00:00, 853.54it/s] Calculating Metrics: 100%|| 3/3 [00:00<00:00, 1103.38it/s]Calculating Metrics: 100%|| 3/3 [00:00<00:00, 999.99it/s] Calculating Metrics: 100%|| 3/3 [00:00<00:00, 950.59it/s]Calculating Metrics: 100%|| 3/3 [00:00<00:00, 903.88it/s]
_ test_case_runner_v3_api[sqlite/other_expectations/expect_table_column_count_to_be_between:positive_test_with_null_min_value] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/3 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/3 [00:00<?, ?it/s]Calculating Metrics:  33%|      | 1/3 [00:00<00:00, 1362.67it/s]Calculating Metrics:  33%|      | 1/3 [00:00<00:00, 664.39it/s] Calculating Metrics:  67%|   | 2/3 [00:00<00:00, 912.90it/s]Calculating Metrics:  67%|   | 2/3 [00:00<00:00, 707.48it/s]Calculating Metrics: 100%|| 3/3 [00:00<00:00, 876.19it/s]Calculating Metrics: 100%|| 3/3 [00:00<00:00, 782.91it/s]Calculating Metrics: 100%|| 3/3 [00:00<00:00, 755.50it/s]Calculating Metrics: 100%|| 3/3 [00:00<00:00, 728.85it/s]
_ test_case_runner_v3_api[sqlite/other_expectations/expect_table_column_count_to_be_between:test_error_handling_for_max_lt_min] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/3 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/3 [00:00<?, ?it/s]Calculating Metrics:  33%|      | 1/3 [00:00<00:00, 1272.16it/s]Calculating Metrics:  33%|      | 1/3 [00:00<00:00, 698.70it/s] Calculating Metrics:  67%|   | 2/3 [00:00<00:00, 1109.16it/s]Calculating Metrics:  67%|   | 2/3 [00:00<00:00, 887.68it/s] Calculating Metrics: 100%|| 3/3 [00:00<00:00, 1154.29it/s]Calculating Metrics: 100%|| 3/3 [00:00<00:00, 1029.45it/s]Calculating Metrics: 100%|| 3/3 [00:00<00:00, 992.97it/s] Calculating Metrics: 100%|| 3/3 [00:00<00:00, 950.23it/s]
_ test_case_runner_v3_api[sqlite/other_expectations/expect_table_column_count_to_be_between:positive_test_with_null_min] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/3 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/3 [00:00<?, ?it/s]Calculating Metrics:  33%|      | 1/3 [00:00<00:00, 1430.53it/s]Calculating Metrics:  33%|      | 1/3 [00:00<00:00, 654.85it/s] Calculating Metrics:  67%|   | 2/3 [00:00<00:00, 1044.92it/s]Calculating Metrics:  67%|   | 2/3 [00:00<00:00, 851.38it/s] Calculating Metrics: 100%|| 3/3 [00:00<00:00, 1113.93it/s]Calculating Metrics: 100%|| 3/3 [00:00<00:00, 1011.49it/s]Calculating Metrics: 100%|| 3/3 [00:00<00:00, 977.24it/s] Calculating Metrics: 100%|| 3/3 [00:00<00:00, 938.11it/s]
_ test_case_runner_v3_api[sqlite/other_expectations/expect_table_columns_to_match_set:basic_positive_test_exact_match_true] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 1486.29it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 926.92it/s] Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1386.09it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1141.15it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1074.77it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1004.62it/s]
_ test_case_runner_v3_api[sqlite/other_expectations/expect_table_columns_to_match_set:basic_positive_test_exact_match_false] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 1579.18it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 781.21it/s] Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1086.19it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 953.58it/s] Calculating Metrics: 100%|| 2/2 [00:00<00:00, 905.31it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 822.65it/s]
_ test_case_runner_v3_api[sqlite/other_expectations/expect_table_columns_to_match_set:negative_test_column_is_missing_exact_match_true] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 826.46it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 575.03it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 938.95it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 845.63it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 809.40it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 768.33it/s]
_ test_case_runner_v3_api[sqlite/other_expectations/expect_table_columns_to_match_set:positive_test_column_is_missing_exact_match_false] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 1664.41it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 933.73it/s] Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1318.34it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1106.24it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1040.51it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 973.72it/s]
_ test_case_runner_v3_api[sqlite/other_expectations/expect_table_columns_to_match_set:negative_test_column_is_misnamed_exact_match_true] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 1709.87it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 1012.38it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1497.16it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1280.31it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1201.98it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1119.38it/s]
_ test_case_runner_v3_api[sqlite/other_expectations/expect_table_columns_to_match_set:negative_test_column_is_misnamed_exact_match_false] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 1880.01it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 1074.09it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1563.87it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1328.99it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1243.68it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1155.30it/s]
_ test_case_runner_v3_api[sqlite/other_expectations/expect_table_columns_to_match_set:positive_test_columns_are_right_but_ordering_wrong_exact_match_true] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 1776.49it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 1034.10it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1518.30it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1294.54it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1214.16it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1128.56it/s]
_ test_case_runner_v3_api[sqlite/other_expectations/expect_table_columns_to_match_set:positive_test_columns_are_right_but_ordering_wrong_exact_match_false] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 1533.57it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 928.56it/s] Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1388.84it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1194.79it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1123.42it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1046.48it/s]
_ test_case_runner_v3_api[sqlite/other_expectations/expect_table_columns_to_match_set:negative_test_extra_column_exact_match_true] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 1623.81it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 969.11it/s] Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1421.56it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1220.34it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1147.40it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1068.88it/s]
_ test_case_runner_v3_api[sqlite/other_expectations/expect_table_columns_to_match_set:negative_test_extra_column_exact_match_false] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 1494.76it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 918.19it/s] Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1256.16it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1055.97it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 960.12it/s] Calculating Metrics: 100%|| 2/2 [00:00<00:00, 883.76it/s]
_ test_case_runner_v3_api[sqlite/other_expectations/expect_table_columns_to_match_set:negative_test_null_set_exact_match_true] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 1595.40it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 956.95it/s] Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1404.66it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1201.46it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1128.87it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1049.89it/s]
_ test_case_runner_v3_api[sqlite/other_expectations/expect_table_columns_to_match_set:positive_test_vacuously_true_null_set_exact_match_false] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 1655.21it/s]Calculating Metrics:  50%|     | 1/2 [00:00<00:00, 986.20it/s] Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1458.63it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1247.56it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1170.29it/s]Calculating Metrics: 100%|| 2/2 [00:00<00:00, 1088.72it/s]
_ test_case_runner_v3_api[sqlite/other_expectations/expect_table_column_count_to_equal:basic_positive_case] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/3 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/3 [00:00<?, ?it/s]Calculating Metrics:  33%|      | 1/3 [00:00<00:00, 1604.55it/s]Calculating Metrics:  33%|      | 1/3 [00:00<00:00, 818.24it/s] Calculating Metrics:  67%|   | 2/3 [00:00<00:00, 1266.59it/s]Calculating Metrics:  67%|   | 2/3 [00:00<00:00, 901.61it/s] Calculating Metrics: 100%|| 3/3 [00:00<00:00, 1126.49it/s]Calculating Metrics: 100%|| 3/3 [00:00<00:00, 1014.18it/s]Calculating Metrics: 100%|| 3/3 [00:00<00:00, 977.77it/s] Calculating Metrics: 100%|| 3/3 [00:00<00:00, 936.02it/s]
_ test_case_runner_v3_api[sqlite/other_expectations/expect_table_column_count_to_equal:basic_negative_case_upper_error] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/3 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/3 [00:00<?, ?it/s]Calculating Metrics:  33%|      | 1/3 [00:00<00:00, 1223.90it/s]Calculating Metrics:  33%|      | 1/3 [00:00<00:00, 705.76it/s] Calculating Metrics:  67%|   | 2/3 [00:00<00:00, 1127.35it/s]Calculating Metrics:  67%|   | 2/3 [00:00<00:00, 907.07it/s] Calculating Metrics: 100%|| 3/3 [00:00<00:00, 1175.53it/s]Calculating Metrics: 100%|| 3/3 [00:00<00:00, 1062.39it/s]Calculating Metrics: 100%|| 3/3 [00:00<00:00, 1024.92it/s]Calculating Metrics: 100%|| 3/3 [00:00<00:00, 982.66it/s]
_ test_case_runner_v3_api[sqlite/other_expectations/expect_table_column_count_to_equal:basic_negative_case_lower_error] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/3 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/3 [00:00<?, ?it/s]Calculating Metrics:  33%|      | 1/3 [00:00<00:00, 1620.67it/s]Calculating Metrics:  33%|      | 1/3 [00:00<00:00, 821.61it/s] Calculating Metrics:  67%|   | 2/3 [00:00<00:00, 1264.87it/s]Calculating Metrics:  67%|   | 2/3 [00:00<00:00, 994.03it/s] Calculating Metrics: 100%|| 3/3 [00:00<00:00, 1273.32it/s]Calculating Metrics: 100%|| 3/3 [00:00<00:00, 1138.00it/s]Calculating Metrics: 100%|| 3/3 [00:00<00:00, 1095.31it/s]Calculating Metrics: 100%|| 3/3 [00:00<00:00, 1045.27it/s]
_ test_case_runner_v3_api[sqlite/other_expectations/expect_table_column_count_to_equal:basic_negative_case_kwargs_args] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/3 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/3 [00:00<?, ?it/s]Calculating Metrics:  33%|      | 1/3 [00:00<00:00, 1678.39it/s]Calculating Metrics:  33%|      | 1/3 [00:00<00:00, 590.00it/s] Calculating Metrics:  67%|   | 2/3 [00:00<00:00, 950.23it/s]Calculating Metrics:  67%|   | 2/3 [00:00<00:00, 739.15it/s]Calculating Metrics: 100%|| 3/3 [00:00<00:00, 973.46it/s]Calculating Metrics: 100%|| 3/3 [00:00<00:00, 890.76it/s]Calculating Metrics: 100%|| 3/3 [00:00<00:00, 863.62it/s]Calculating Metrics: 100%|| 3/3 [00:00<00:00, 831.32it/s]
_ test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_compound_columns_to_be_unique:mostly_default_successful_expectation] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 2691.24it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 332.16it/s] Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 461.74it/s]Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 248.65it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 255.31it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 200.62it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 298.08it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 282.63it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 281.54it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 280.34it/s]
_ test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_compound_columns_to_be_unique:mostly_default_fails_expectation] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 2936.16it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 352.73it/s] Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 494.88it/s]Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 269.08it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 276.19it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 214.81it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 320.84it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 301.36it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 299.64it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 298.19it/s]
_ test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_compound_columns_to_be_unique:mostly_set_successful_expectation] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 2966.27it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 357.25it/s] Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 503.24it/s]Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 278.86it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 275.38it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 210.79it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 304.70it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 287.61it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 286.45it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 285.12it/s]
_ test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_compound_columns_to_be_unique:mostly_set_fails_expectation] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 3044.87it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 353.73it/s] Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 496.68it/s]Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 272.36it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 279.96it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 212.43it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 307.37it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 289.62it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 288.25it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 286.91it/s]
_ test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_compound_columns_to_be_unique:basic_test_ignore_if_all_are_missing_the_default_behavior] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 2886.65it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 359.84it/s] Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 506.23it/s]Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 283.93it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 290.97it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 224.23it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 347.13it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 326.28it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 324.89it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 323.28it/s]
_ test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_compound_columns_to_be_unique:basic_test_ignore_if_any_are_missing] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 3002.37it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 352.79it/s] Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 496.68it/s]Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 279.87it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 291.88it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 224.81it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 342.24it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 322.07it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 320.73it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 319.15it/s]
_ test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_compound_columns_to_be_unique:row_condition_with_ignore_if_any_are_missing] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 451.07it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 257.97it/s]Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 372.95it/s]Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 268.55it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 259.17it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 220.14it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 281.09it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 271.18it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 270.25it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 269.16it/s]
_ test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_compound_columns_to_be_unique:unexpected_values_with_unexpected_index_list] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 3043.76it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 348.61it/s] Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 487.88it/s]Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 276.62it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 282.34it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 216.50it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 306.78it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 290.47it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 289.39it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 288.17it/s]
_ test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_compound_columns_to_be_unique:unexpected_values_without_unexpected_index_list] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 2971.52it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 354.17it/s] Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 498.75it/s]Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 279.09it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 279.66it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 216.20it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 304.24it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 275.46it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 273.57it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 271.79it/s]
_ test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_compound_columns_to_be_unique:unexpected_values_exact_match_out_without_unexpected_index_list] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 1888.48it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 251.42it/s] Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 350.38it/s]Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 77.84it/s] Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 95.13it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 86.52it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 157.70it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 153.19it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 152.89it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 152.53it/s]
_ test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_select_column_values_to_be_unique_within_record:mostly_default_successful_expectation] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 2958.94it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 356.57it/s] Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 502.95it/s]Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 281.56it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 283.23it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 219.71it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 329.59it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 310.66it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 309.39it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 307.90it/s]
_ test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_select_column_values_to_be_unique_within_record:mostly_default_fails_expectation] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 3067.13it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 338.76it/s] Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 476.64it/s]Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 269.30it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 261.73it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 205.85it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 300.42it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 280.23it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 278.99it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 277.74it/s]
_ test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_select_column_values_to_be_unique_within_record:mostly_set_successful_expectation] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 3048.19it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 354.59it/s] Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 499.24it/s]Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 279.33it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 280.32it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 218.55it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 323.86it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 305.72it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 304.48it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 303.06it/s]
_ test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_select_column_values_to_be_unique_within_record:mostly_set_fails_expectation] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 2804.62it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 346.92it/s] Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 488.28it/s]Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 277.60it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 280.31it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 218.29it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 325.50it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 307.28it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 306.09it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 304.70it/s]
_ test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_select_column_values_to_be_unique_within_record:basic_test_ignore_if_all_are_missing_the_default_behavior] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 2869.86it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 349.41it/s] Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 492.60it/s]Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 278.09it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 278.41it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 216.39it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 342.62it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 322.34it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 320.97it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 319.42it/s]
_ test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_select_column_values_to_be_unique_within_record:basic_test_ignore_if_any_are_missing] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 2958.94it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 356.07it/s] Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 502.17it/s]Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 281.08it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 273.80it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 213.81it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 322.13it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 303.77it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 302.46it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 301.07it/s]
_ test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_select_column_values_to_be_unique_within_record:unexpected_values] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 3077.26it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 359.44it/s] Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 506.50it/s]Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 283.12it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 273.65it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 210.64it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 303.13it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 286.65it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 285.50it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 284.28it/s]
_ test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_select_column_values_to_be_unique_within_record:unexpected_values_exact_match_out_without_unexpected_index_list] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 2789.69it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 347.28it/s] Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 486.86it/s]Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 276.17it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 271.06it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 212.39it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 310.65it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 293.97it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 292.86it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 291.57it/s]
_ test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_multicolumn_sum_to_equal:mostly_default_successful_expectation] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 2975.74it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 318.83it/s] Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 452.22it/s]Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 249.93it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 266.65it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 202.11it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 309.78it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 289.69it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 288.44it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 287.13it/s]
_ test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_multicolumn_sum_to_equal:mostly_default_fails_expectation] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 3003.44it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 311.00it/s] Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 440.15it/s]Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 245.72it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 259.05it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 198.71it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 298.39it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 279.96it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 278.82it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 277.58it/s]
_ test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_multicolumn_sum_to_equal:mostly_set_successful_expectation] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 3042.66it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 318.83it/s] Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 450.79it/s]Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 236.48it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 249.92it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 180.95it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 281.66it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 264.49it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 263.35it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 262.27it/s]
_ test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_multicolumn_sum_to_equal:mostly_set_fails_expectation] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 2985.27it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 310.37it/s] Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 438.02it/s]Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 245.08it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 260.66it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 199.47it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 302.54it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 284.13it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 283.07it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 281.86it/s]
_ test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_multicolumn_sum_to_equal:basic_positive_test] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 2944.40it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 305.20it/s] Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 431.90it/s]Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 242.95it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 258.98it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 193.40it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 291.04it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 273.70it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 272.68it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 271.53it/s]
_ test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_multicolumn_sum_to_equal:basic_positive_test_more_than_2_columns] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 2398.12it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 287.48it/s] Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 406.07it/s]Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 231.38it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 246.02it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 189.90it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 293.46it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 275.72it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 274.68it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 273.54it/s]
_ test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_multicolumn_sum_to_equal:row_condition_with_ignore_if_any_are_missing] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 318.63it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 192.55it/s]Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 280.01it/s]Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 207.37it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 199.79it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 169.55it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 207.87it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 201.17it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 200.50it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 199.72it/s]
_ test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_multicolumn_sum_to_equal:basic_negative_test] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 2968.37it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 315.02it/s] Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 443.86it/s]Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 230.93it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 247.11it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 166.56it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 251.28it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 238.15it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 237.35it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 236.47it/s]
_ test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_multicolumn_sum_to_equal:negative_test_with_ignore_if_any_are_missing] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 2897.62it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 315.85it/s] Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 446.28it/s]Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 245.52it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 256.36it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 196.26it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 282.07it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 263.41it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 261.83it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 260.69it/s]
_ test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_multicolumn_sum_to_equal:negative_test_different_value] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 3062.65it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 306.09it/s] Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 435.03it/s]Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 239.41it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 257.88it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 195.32it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 290.96it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 272.98it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 272.01it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 270.90it/s]
_ test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_select_column_values_to_be_unique_within_record:mostly_default_successful_expectation] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2307.73it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 316.97it/s] Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 493.90it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 284.84it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 326.55it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 255.82it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 342.21it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 321.66it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 320.22it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 318.70it/s]
_ test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_select_column_values_to_be_unique_within_record:mostly_default_fails_expectation] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2451.38it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 336.26it/s] Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 550.38it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 331.35it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 378.30it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 288.09it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 383.44it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 359.86it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 358.36it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 356.61it/s]
_ test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_select_column_values_to_be_unique_within_record:mostly_set_successful_expectation] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 1675.04it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 314.51it/s] Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 521.86it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 322.30it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 370.16it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 284.12it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 424.85it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 396.56it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 394.68it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 392.45it/s]
_ test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_select_column_values_to_be_unique_within_record:mostly_set_fails_expectation] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2424.45it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 319.64it/s] Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 526.03it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 323.02it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 368.87it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 278.49it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 396.35it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 370.71it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 369.02it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 367.09it/s]
_ test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_select_column_values_to_be_unique_within_record:basic_test_ignore_if_all_are_missing_the_default_behavior] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2190.24it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 323.46it/s] Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 483.60it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 303.46it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 346.91it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 265.58it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 347.17it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 327.24it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 325.94it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 324.45it/s]
_ test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_select_column_values_to_be_unique_within_record:basic_test_ignore_if_any_are_missing] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2009.73it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 302.51it/s] Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 489.82it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 301.52it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 343.12it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 264.93it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 354.45it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 333.53it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 332.08it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 330.49it/s]
_ test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_select_column_values_to_be_unique_within_record:unexpected_values] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2288.22it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 323.83it/s] Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 533.83it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 320.20it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 363.45it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 245.33it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 330.07it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 312.36it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 311.21it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 309.89it/s]
_ test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_select_column_values_to_be_unique_within_record:unexpected_values_exact_match_out_with_index_list_pandas_v3_api] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2391.96it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 337.45it/s] Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 554.95it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 333.45it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 381.10it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 289.85it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 424.14it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 395.60it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 393.79it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 391.69it/s]
_ test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_select_column_values_to_be_unique_within_record:unexpected_values_exact_match_out_no_index_list] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2074.85it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 323.72it/s] Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 531.77it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 310.97it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 340.00it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 250.78it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 369.41it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 347.08it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 345.59it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 343.90it/s]
_ test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_select_column_values_to_be_unique_within_record:unexpected_values_exact_match_out_without_unexpected_index_list] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2132.34it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 298.16it/s] Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 491.47it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 299.16it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 334.18it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 258.80it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 374.54it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 346.96it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 344.80it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 342.05it/s]
_ test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_multicolumn_sum_to_equal:mostly_default_successful_expectation] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 1619.42it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 272.96it/s] Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 444.04it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 260.89it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 291.29it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 223.70it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 315.18it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 295.19it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 293.82it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 292.51it/s]
_ test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_multicolumn_sum_to_equal:mostly_default_fails_expectation] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 1808.28it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 280.12it/s] Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 467.89it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 281.21it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 315.48it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 239.57it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 333.72it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 312.65it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 311.44it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 310.07it/s]
_ test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_multicolumn_sum_to_equal:mostly_set_successful_expectation] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2447.09it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 294.50it/s] Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 412.32it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 256.89it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 296.75it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 224.62it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 341.94it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 312.19it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 310.42it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 308.89it/s]
_ test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_multicolumn_sum_to_equal:mostly_set_fails_expectation] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2207.53it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 271.51it/s] Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 446.18it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 250.14it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 288.83it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 222.98it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 332.99it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 311.96it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 310.75it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 309.41it/s]
_ test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_multicolumn_sum_to_equal:basic_positive_test] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2285.72it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 249.25it/s] Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 400.08it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 253.15it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 288.42it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 220.34it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 304.17it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 286.40it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 284.79it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 283.49it/s]
_ test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_multicolumn_sum_to_equal:basic_positive_test_more_than_2_columns] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 1647.41it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 272.36it/s] Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 461.14it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 278.92it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 321.66it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 244.62it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 338.42it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 316.67it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 315.52it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 314.14it/s]
_ test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_multicolumn_sum_to_equal:basic_negative_test] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2389.92it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 297.05it/s] Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 496.10it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 291.30it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 334.99it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 253.64it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 342.80it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 320.77it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 319.48it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 318.07it/s]
_ test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_multicolumn_sum_to_equal:negative_test_with_ignore_if_any_are_missing] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2312.19it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 248.82it/s] Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 400.08it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 250.74it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 286.27it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 211.42it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 295.14it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 277.39it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 276.33it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 275.22it/s]
_ test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_multicolumn_sum_to_equal:negative_test_different_value] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2275.19it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 268.06it/s] Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 450.81it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 267.49it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 309.60it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 233.47it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 324.28it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 303.06it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 301.88it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 300.58it/s]
_ test_case_runner_v3_api[pandas/column_pair_map_expectations/expect_column_pair_values_to_be_equal:trivial_case:_x__x] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 2864.96it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 327.12it/s] Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 447.42it/s]Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 232.25it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 253.34it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 197.10it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 288.98it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 273.51it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 272.35it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 271.16it/s]
_ test_case_runner_v3_api[pandas/column_pair_map_expectations/expect_column_pair_values_to_be_equal:basic_negative_example_compare_number_to_text] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 2988.46it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 368.39it/s] Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 518.28it/s]Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 253.31it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 262.15it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 174.12it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 253.90it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 233.97it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 232.67it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 231.38it/s]
_ test_case_runner_v3_api[pandas/column_pair_map_expectations/expect_column_pair_values_to_be_equal:basic_negative_example_compare_numbers] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 2259.86it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 263.92it/s] Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 363.37it/s]Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 219.72it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 243.23it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 188.64it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 283.81it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 268.00it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 266.49it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 265.29it/s]
_ test_case_runner_v3_api[pandas/column_pair_map_expectations/expect_column_pair_values_to_be_equal:positive_example_with_mostly_compare_number_to_text] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 2937.19it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 367.52it/s] Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 513.44it/s]Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 290.39it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 324.57it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 246.08it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 371.12it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 347.47it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 345.37it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 343.52it/s]
_ test_case_runner_v3_api[pandas/column_pair_map_expectations/expect_column_pair_values_to_be_equal:positive_example_with_mostly_compare_numbers] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 3059.30it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 372.31it/s] Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 524.22it/s]Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 293.25it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 319.04it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 243.25it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 350.43it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 329.52it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 327.98it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 326.35it/s]
_ test_case_runner_v3_api[pandas/column_pair_map_expectations/expect_column_pair_values_to_be_equal:positive_example_with_mismatched_null_values_and_ignore_row_if__either_value_is_missing_compare_number_to_text] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 3096.57it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 376.91it/s] Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 528.34it/s]Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 296.24it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 325.68it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 247.20it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 355.73it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 333.35it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 331.57it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 329.81it/s]
_ test_case_runner_v3_api[pandas/column_pair_map_expectations/expect_column_pair_values_to_be_equal:positive_example_with_mismatched_null_values_and_ignore_row_if__either_value_is_missing_compare_numbers] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 3048.19it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 321.91it/s] Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 452.90it/s]Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 255.76it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 286.66it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 224.00it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 316.36it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 298.67it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 296.41it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 294.75it/s]
_ test_case_runner_v3_api[pandas/column_pair_map_expectations/expect_column_pair_values_to_be_equal:a_negative_example_with_mismatched_null_values_and_ignore_row_if__both_values_are_missing_set_explicitly] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 2981.03it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 328.24it/s] Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 461.18it/s]Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 271.20it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 292.06it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 226.14it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 293.12it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 278.47it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 277.48it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 276.34it/s]
_ test_case_runner_v3_api[pandas/column_pair_map_expectations/expect_column_pair_values_to_be_equal:a_negative_example_with_mismatched_null_values_and_ignore_row_if__both_values_are_missing_set_by_default] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 1857.12it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 206.38it/s] Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 296.53it/s]Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 184.76it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 206.55it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 165.94it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 240.02it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 227.72it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 226.63it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 225.53it/s]
_ test_case_runner_v3_api[pandas/column_pair_map_expectations/expect_column_pair_values_to_be_equal:a_negative_example] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 1722.51it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 160.57it/s] Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 228.38it/s]Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 140.12it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 161.87it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 136.48it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 217.45it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 206.07it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 205.31it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 204.64it/s]
_ test_case_runner_v3_api[pandas/column_pair_map_expectations/expect_column_pair_values_to_be_equal:a_positive_example_with_mostly] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 2457.12it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 359.46it/s] Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 505.05it/s]Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 276.57it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 295.03it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 228.65it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 296.14it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 279.87it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 278.63it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 277.38it/s]
_ test_case_runner_v3_api[pandas/column_pair_map_expectations/expect_column_pair_values_to_be_equal:a_positive_example_with_ignore_row_if__either_value_is_missing] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 3067.13it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 344.94it/s] Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 483.08it/s]Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 281.45it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 302.66it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 233.49it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 323.86it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 306.22it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 304.98it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 303.58it/s]
_ test_case_runner_v3_api[pandas/column_pair_map_expectations/expect_column_pair_values_to_be_in_set:basic_positive_test_without_nulls] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 3464.46it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 498.83it/s] Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 631.13it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 356.95it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 349.31it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 267.75it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 358.11it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 334.60it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 333.21it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 331.72it/s]
_ test_case_runner_v3_api[pandas/column_pair_map_expectations/expect_column_pair_values_to_be_in_set:positive_test_with_nulls_and_ignore_row_if_either_value_is_missing] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 4201.31it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 577.38it/s] Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 720.61it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 397.46it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 392.17it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 303.14it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 412.32it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 386.01it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 384.29it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 382.29it/s]
_ test_case_runner_v3_api[pandas/column_pair_map_expectations/expect_column_pair_values_to_be_in_set:negative_test_with_nulls] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 4266.84it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 599.39it/s] Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 758.57it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 423.28it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 398.98it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 307.71it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 285.48it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 263.97it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 262.58it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 261.06it/s]
_ test_case_runner_v3_api[pandas/column_pair_map_expectations/expect_column_pair_values_to_be_in_set:another_positive_test_with_nulls] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 1319.79it/s]Calculating Metrics:  30%|       | 3/10 [00:00<00:00, 105.23it/s] Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 137.53it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 100.04it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 109.71it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 95.11it/s] Calculating Metrics: 100%|| 10/10 [00:00<00:00, 99.70it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 99.70it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 99.70it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 99.70it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 96.26it/s]
_ test_case_runner_v3_api[pandas/column_pair_map_expectations/expect_column_pair_values_A_to_be_greater_than_B:basic_positive_test] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 207.53it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 70.21it/s] Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 93.50it/s]Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 70.46it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 86.10it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 69.20it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 124.19it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 116.94it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 116.57it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 116.26it/s]
_ test_case_runner_v3_api[pandas/column_pair_map_expectations/expect_column_pair_values_A_to_be_greater_than_B:basic_positive_test_with_missing_values_and_ignore_row_if__either_value_is_missing] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 1848.53it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 178.32it/s] Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 251.22it/s]Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 125.07it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 146.16it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 94.60it/s] Calculating Metrics: 100%|| 9/9 [00:00<00:00, 129.93it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 121.48it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 121.05it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 120.65it/s]
_ test_case_runner_v3_api[pandas/column_pair_map_expectations/expect_column_pair_values_A_to_be_greater_than_B:test_ties] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 1736.41it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 149.35it/s] Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 216.16it/s]Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 86.14it/s] Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 102.10it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 75.76it/s] Calculating Metrics: 100%|| 9/9 [00:00<00:00, 119.65it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 112.28it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 110.95it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 110.57it/s]
_ test_case_runner_v3_api[pandas/column_pair_map_expectations/expect_column_pair_values_A_to_be_greater_than_B:test_ties_with_or_equal] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 718.94it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 120.73it/s]Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 173.64it/s]Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 99.61it/s] Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 118.69it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 76.60it/s] Calculating Metrics: 100%|| 9/9 [00:00<00:00, 127.15it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 116.67it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 115.74it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 115.38it/s]
_ test_case_runner_v3_api[pandas/column_pair_map_expectations/expect_column_pair_values_A_to_be_greater_than_B:test_parse_strings_as_datetimes_and_mostly] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 1924.88it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 109.06it/s] Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 157.94it/s]Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 89.69it/s] Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 98.19it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 71.07it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 110.77it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 105.17it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 104.87it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 104.61it/s]
_ test_case_runner_v3_api[pandas/column_pair_map_expectations/expect_column_pair_values_A_to_be_greater_than_B:test_mostly] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/9 [00:00<?, ?it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 1921.35it/s]Calculating Metrics:  22%|       | 2/9 [00:00<00:00, 131.66it/s] Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 188.71it/s]Calculating Metrics:  33%|      | 3/9 [00:00<00:00, 106.37it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 123.76it/s]Calculating Metrics:  44%|     | 4/9 [00:00<00:00, 95.97it/s] Calculating Metrics: 100%|| 9/9 [00:00<00:00, 156.84it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 149.96it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 149.56it/s]Calculating Metrics: 100%|| 9/9 [00:00<00:00, 149.20it/s]
_ test_case_runner_v3_api[sqlite/column_pair_map_expectations/expect_column_pair_values_to_be_equal:trivial_case:_x__x] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 1440.85it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 197.91it/s] Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 332.23it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 228.97it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 263.20it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 205.45it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 284.36it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 271.39it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 270.38it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 269.36it/s]
_ test_case_runner_v3_api[sqlite/column_pair_map_expectations/expect_column_pair_values_to_be_equal:basic_negative_example_compare_numbers] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2320.50it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 343.70it/s] Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 540.47it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 305.22it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 348.91it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 269.70it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 330.41it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 307.85it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 305.60it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 303.56it/s]
_ test_case_runner_v3_api[sqlite/column_pair_map_expectations/expect_column_pair_values_to_be_equal:positive_example_with_mostly_compare_numbers] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 1574.73it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 194.78it/s] Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 308.50it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 192.24it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 220.32it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 167.43it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 261.31it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 247.44it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 246.46it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 245.58it/s]
_ test_case_runner_v3_api[sqlite/column_pair_map_expectations/expect_column_pair_values_to_be_equal:positive_example_with_mismatched_null_values_and_ignore_row_if__either_value_is_missing_compare_numbers] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2336.01it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 346.91it/s] Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 564.17it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 343.46it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 391.14it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 298.97it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 392.14it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 367.94it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 366.14it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 364.28it/s]
_ test_case_runner_v3_api[sqlite/column_pair_map_expectations/expect_column_pair_values_to_be_equal:a_negative_example_with_mismatched_null_values_and_ignore_row_if__both_values_are_missing_set_explicitly] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2341.88it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 329.33it/s] Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 535.91it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 332.23it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 378.94it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 291.70it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 357.72it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 334.17it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 331.20it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 328.78it/s]
_ test_case_runner_v3_api[sqlite/column_pair_map_expectations/expect_column_pair_values_to_be_equal:a_negative_example_with_mismatched_null_values_and_ignore_row_if__both_values_are_missing_set_by_default] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 1888.48it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 308.78it/s] Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 507.75it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 318.93it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 357.35it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 272.24it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 401.67it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 376.70it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 375.01it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 371.90it/s]
_ test_case_runner_v3_api[sqlite/column_pair_map_expectations/expect_column_pair_values_to_be_equal:a_negative_example] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2392.64it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 340.38it/s] Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 554.71it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 337.87it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 386.17it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 294.57it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 421.34it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 391.04it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 388.62it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 386.40it/s]
_ test_case_runner_v3_api[sqlite/column_pair_map_expectations/expect_column_pair_values_to_be_equal:a_positive_example_with_mostly] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2381.10it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 342.87it/s] Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 560.94it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 340.81it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 390.23it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 297.69it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 422.04it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 391.53it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 389.24it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 386.28it/s]
_ test_case_runner_v3_api[sqlite/column_pair_map_expectations/expect_column_pair_values_to_be_equal:a_positive_example_with_ignore_row_if__either_value_is_missing] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2412.60it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 339.51it/s] Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 553.41it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 340.40it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 390.47it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 294.43it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 387.66it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 364.51it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 362.91it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 361.18it/s]
_ test_case_runner_v3_api[sqlite/column_pair_map_expectations/expect_column_pair_values_to_be_in_set:basic_positive_test_without_nulls] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/12 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/12 [00:00<?, ?it/s]Calculating Metrics:  25%|       | 3/12 [00:00<00:00, 2068.88it/s]Calculating Metrics:  25%|       | 3/12 [00:00<00:00, 438.67it/s] Calculating Metrics:  50%|     | 6/12 [00:00<00:00, 678.96it/s]Calculating Metrics:  50%|     | 6/12 [00:00<00:00, 421.86it/s]Calculating Metrics:  58%|    | 7/12 [00:00<00:00, 435.81it/s]Calculating Metrics:  58%|    | 7/12 [00:00<00:00, 342.07it/s]Calculating Metrics: 100%|| 12/12 [00:00<00:00, 368.49it/s]Calculating Metrics: 100%|| 12/12 [00:00<00:00, 345.32it/s]Calculating Metrics: 100%|| 12/12 [00:00<00:00, 343.85it/s]Calculating Metrics: 100%|| 12/12 [00:00<00:00, 342.44it/s]
_ test_case_runner_v3_api[sqlite/column_pair_map_expectations/expect_column_pair_values_to_be_in_set:positive_test_with_nulls_and_ignore_row_if_either_value_is_missing] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/12 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/12 [00:00<?, ?it/s]Calculating Metrics:  25%|       | 3/12 [00:00<00:00, 3167.90it/s]Calculating Metrics:  25%|       | 3/12 [00:00<00:00, 437.32it/s] Calculating Metrics:  50%|     | 6/12 [00:00<00:00, 655.82it/s]Calculating Metrics:  50%|     | 6/12 [00:00<00:00, 428.11it/s]Calculating Metrics:  58%|    | 7/12 [00:00<00:00, 445.32it/s]Calculating Metrics:  58%|    | 7/12 [00:00<00:00, 356.31it/s]Calculating Metrics: 100%|| 12/12 [00:00<00:00, 401.54it/s]Calculating Metrics: 100%|| 12/12 [00:00<00:00, 379.30it/s]Calculating Metrics: 100%|| 12/12 [00:00<00:00, 377.80it/s]Calculating Metrics: 100%|| 12/12 [00:00<00:00, 376.17it/s]
_ test_case_runner_v3_api[sqlite/column_pair_map_expectations/expect_column_pair_values_to_be_in_set:negative_test_with_nulls] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/12 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/12 [00:00<?, ?it/s]Calculating Metrics:  25%|       | 3/12 [00:00<00:00, 3274.24it/s]Calculating Metrics:  25%|       | 3/12 [00:00<00:00, 521.46it/s] Calculating Metrics:  50%|     | 6/12 [00:00<00:00, 728.05it/s]Calculating Metrics:  50%|     | 6/12 [00:00<00:00, 475.50it/s]Calculating Metrics:  58%|    | 7/12 [00:00<00:00, 500.93it/s]Calculating Metrics:  58%|    | 7/12 [00:00<00:00, 385.57it/s]Calculating Metrics: 100%|| 12/12 [00:00<00:00, 411.89it/s]Calculating Metrics: 100%|| 12/12 [00:00<00:00, 381.63it/s]Calculating Metrics: 100%|| 12/12 [00:00<00:00, 378.66it/s]Calculating Metrics: 100%|| 12/12 [00:00<00:00, 376.81it/s]
_ test_case_runner_v3_api[sqlite/column_pair_map_expectations/expect_column_pair_values_to_be_in_set:another_positive_test_with_nulls] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/12 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/12 [00:00<?, ?it/s]Calculating Metrics:  25%|       | 3/12 [00:00<00:00, 3265.74it/s]Calculating Metrics:  25%|       | 3/12 [00:00<00:00, 546.37it/s] Calculating Metrics:  50%|     | 6/12 [00:00<00:00, 788.35it/s]Calculating Metrics:  50%|     | 6/12 [00:00<00:00, 509.69it/s]Calculating Metrics:  58%|    | 7/12 [00:00<00:00, 529.75it/s]Calculating Metrics:  58%|    | 7/12 [00:00<00:00, 399.25it/s]Calculating Metrics: 100%|| 12/12 [00:00<00:00, 443.63it/s]Calculating Metrics: 100%|| 12/12 [00:00<00:00, 417.76it/s]Calculating Metrics: 100%|| 12/12 [00:00<00:00, 416.04it/s]Calculating Metrics: 100%|| 12/12 [00:00<00:00, 414.06it/s]
_ test_case_runner_v3_api[sqlite/column_pair_map_expectations/expect_column_pair_values_A_to_be_greater_than_B:basic_positive_test] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2290.72it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 236.80it/s] Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 381.25it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 224.14it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 263.16it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 193.57it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 277.78it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 259.73it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 258.94it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 258.05it/s]
_ test_case_runner_v3_api[sqlite/column_pair_map_expectations/expect_column_pair_values_A_to_be_greater_than_B:basic_positive_test_with_missing_values_and_ignore_row_if__either_value_is_missing] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 1691.59it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 226.27it/s] Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 392.11it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 231.63it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 270.50it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 203.72it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 289.60it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 269.05it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 268.07it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 267.07it/s]
_ test_case_runner_v3_api[sqlite/column_pair_map_expectations/expect_column_pair_values_A_to_be_greater_than_B:test_ties] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2386.52it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 248.17it/s] Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 429.78it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 247.97it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 291.12it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 216.38it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 314.08it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 291.23it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 290.22it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 289.06it/s]
_ test_case_runner_v3_api[sqlite/column_pair_map_expectations/expect_column_pair_values_A_to_be_greater_than_B:test_ties_with_or_equal] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2227.46it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 267.03it/s] Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 457.51it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 264.50it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 307.84it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 231.05it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 332.07it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 309.00it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 307.91it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 306.65it/s]
_ test_case_runner_v3_api[sqlite/column_pair_map_expectations/expect_column_pair_values_A_to_be_greater_than_B:test_mostly] _
----------------------------- Captured stderr call -----------------------------
Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 2385.84it/s]Calculating Metrics:  20%|        | 2/10 [00:00<00:00, 234.27it/s] Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 405.34it/s]Calculating Metrics:  40%|      | 4/10 [00:00<00:00, 234.20it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 274.36it/s]Calculating Metrics:  50%|     | 5/10 [00:00<00:00, 207.57it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 301.49it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 280.30it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 279.41it/s]Calculating Metrics: 100%|| 10/10 [00:00<00:00, 278.37it/s]
=========================== short test summary info ============================
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/multi_table_expectations/expect_table_row_count_to_equal_other_table:basic_positive]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/multi_table_expectations/expect_table_row_count_to_equal_other_table:basic_negative]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_lengths_to_equal:positive_test_string_one_character_length]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_lengths_to_equal:negative_test_string_value_is_1_too_high]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_lengths_to_equal:positive_test_with_missing_value_in_column_mostly]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_lengths_to_equal:negative_one_length_too_small]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_lengths_to_equal:positive_one_length_too_small_mostly]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_lengths_to_equal:test_conditional_expectation_passes]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_lengths_to_equal:test_conditional_expectation_fails]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_lengths_to_equal:test_conditional_expectation_parser_errors]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:basic_positive_now_test]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:basic_negative_now_test]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:basic_positive_now_timedelta_test]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:basic_negative_now_timedelta_test]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:basic_positive_datetime_test]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:basic_negative_datetime_test]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_json_parseable:basic_positive_test]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_json_parseable:positive_test_with_nulls]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_json_parseable:negative_test_integers]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_json_parseable:negative_test_string_only]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_json_parseable:negative_test_null_only]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:basic_positive_test_with_timestamps_tz_informed]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:basic_negative_test_with_timestamps_tz_informed]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_be_null:basic_positive_case_complete_result_format]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_be_null:negative_all_missing_values_pandas]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_be_null:positive_mostly_pandas]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_be_null:negative_no_mostly_one_missing_pandas]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_be_null:negative_mostly]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_be_null:positive_case_with_mostly_and_no_unexpected_values]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_be_null:negative_case_with_75percent_null_values_no_mostly]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_regex_list:basic_positive_test]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_regex_list:positive_test_with_multiple_regexes]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_regex_list:basic_negative_test]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_regex_list:negative_test_with_more_string-ish_strings]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_regex_list:positive_test_with_match_on__any]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_regex_list:positive_test_column_name_has_space_and_match_on__any]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_z_scores_to_be_less_than:basic_successful_test]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_z_scores_to_be_less_than:basic_unsuccessful_test]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_z_scores_to_be_less_than:basic_test_with_outlier]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_z_scores_to_be_less_than:basic_test_mostly_zero]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_z_scores_to_be_less_than:basic_test_with_missing]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:basic_positive_test0]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:another_basic_positive_test0]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:basic_positive_test_with_timestamps0]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:missing_min_value0]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:null_min_value0]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:missing_max_value0]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:null_max_value0]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:basic_negative_test0]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:another_negative_test0]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:basic_negative_test_with_timestamps0]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:positive_test_with_result_format__boolean_only0]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:another_positive_test_with_result_format__boolean_only0]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:negative_test_with_result_format__boolean_only0]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:another_negative_test_with_result_format__boolean_only0]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:positive_test_with_mostly0]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:2nd_positive_test_with_mostly0]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:3rd_positive_test_with_mostly0]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:negative_test_with_mostly0]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:error:_improperly_mixed_types0]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:error:_improperly_mixed_types_again0]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:error:_improperly_mixed_types_once_more0]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:error:_missing_both_min_value_and_max_value0]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:negative_test_to_verify_that_the_denominator_for_mostly_works_with_missing_values0]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:positive_test_to_verify_that_the_denominator_for_mostly_works_with_missing_values0]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:error_on_string-to-int_comparisons0]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:test_min_value_is_greater_than_max_value0]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:test_allow_cross_type_comparisons0]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:test_allow_cross_type_comparisons_again0]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:test_strict_min_failure0]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:test_strict_min_success0]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:test_strict_max_failure0]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:test_strict_max_success0]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:test_conditional_expectation_passes0]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:test_conditional_expectation_fails0]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:test_conditional_expectation_parser_errors0]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_regex:negative_test_insufficient_mostly_and_one_non_matching_value]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_regex:negative_test_insufficient_mostly_and_one_non_matching_value_summary_output]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_regex:positive_test_exact_mostly_w_one_non_matching_value]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_regex:positive_test_column_name_has_space]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_regex:positive_test_sufficient_mostly_w_one_non_matching_value]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_regex:negative_test_one_missing_value_and_insufficent_mostly]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_regex:positive_test_one_missing_value_and_exact_mostly]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_regex:positive_test_one_missing_value_and_sufficent_mostly]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_regex:positive_test_all_missing_values]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_regex:positive_test_all_missing_values_mostly]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_regex:positive_test_empty_regex]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_regex:positive_test_more_complicated_regex]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_regex:positive_test_match_characters_not_at_the_beginning_of_string]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:basic_positive_test1]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:another_basic_positive_test1]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:basic_positive_test_with_timestamps1]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:missing_min_value1]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:null_min_value1]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:missing_max_value1]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:null_max_value1]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:basic_negative_test1]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:another_negative_test1]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:basic_negative_test_with_timestamps1]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:positive_test_with_result_format__boolean_only1]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:another_positive_test_with_result_format__boolean_only1]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:negative_test_with_result_format__boolean_only1]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:another_negative_test_with_result_format__boolean_only1]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:positive_test_with_mostly1]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:2nd_positive_test_with_mostly1]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:3rd_positive_test_with_mostly1]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:negative_test_with_mostly1]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:error:_improperly_mixed_types1]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:error:_improperly_mixed_types_again1]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:error:_improperly_mixed_types_once_more1]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:error:_missing_both_min_value_and_max_value1]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:negative_test_to_verify_that_the_denominator_for_mostly_works_with_missing_values1]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:positive_test_to_verify_that_the_denominator_for_mostly_works_with_missing_values1]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:error_on_string-to-int_comparisons1]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:test_min_value_is_greater_than_max_value1]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:test_allow_cross_type_comparisons1]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:test_allow_cross_type_comparisons_again1]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:test_strict_min_failure1]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:test_strict_min_success1]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:test_strict_max_failure1]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:test_strict_max_success1]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:test_conditional_expectation_passes1]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:test_conditional_expectation_fails1]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_between:test_conditional_expectation_parser_errors1]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_be_in_set:basic_positive_test_case_single_value_not_in_column]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_be_in_set:negative_test_case_include_one_existing_column_value]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_be_in_set:positive_empty_values_set]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_be_in_set:basic_negative_strings_set_all_character_values]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_be_in_set:positive_test_strings_set_extra_value_in_column]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_be_in_set:negative_test_float_set_two_out_of_three_column_values_included_mostly]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_be_in_set:negative_test_float_set_two_out_of_three_column_values_included_mostly_summary_output]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_be_in_set:positive_test_float_set_two_out_of_three_column_values_included_mostly]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_be_in_set:positive_test_values_set_is_null]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_be_in_set:raise_typeerror_when_values_set_is_missing]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_of_type:basic_python_int_positive_test]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_of_type:negative_test_python_ints_are_not_string]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_of_type:positive_test_pandas_floats]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_of_type:positive_test_pandas_strings]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_of_type:negative_test_python_floats_are_not_python_bools]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_of_type:dtype_object_and_type_object_still_has_aggregate_semantics]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_of_type:dtype_object_and_type_object_still_has_aggregate_semantics_object_underscore]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_of_type:dtype_object_and_type_object_still_has_aggregate_semantics_big_o]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_of_type:positive_pandas_datetime_no_timezone]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_of_type:positive_pandas_datetime_with_timezone]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_of_type:negative_pandas_datetime_with_timezone]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_of_type:negative_pandas_datetime_expected_int]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_in_set:basic_positive_test_case_number_set]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_in_set:vacuously_true_empty_value_set]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_in_set:negative_test_case_exclude_existing_column_value]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_in_set:negative_empty_values_set]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_in_set:basic_positive_strings_set]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_in_set:negative_test_strings_set_extra_value_in_column]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_in_set:negative_test_numbers_set_no_matching_values]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_in_set:positive_test_float_set]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_in_set:negative_test_float_set]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_in_set:test_conditional_expectation_passes]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_in_set:test_conditional_expectation_fails]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_in_set:test_conditional_expectation_parser_errors]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_in_set:test_empty_column_should_be_vacuously_true]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_in_set:basic_positive_test_case_datetime_set]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_in_set:basic_negative_test_case_datetime_set]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_decreasing:positive_test_with_mostly]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_decreasing:basic_negative_test]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_decreasing:basic_negative_test_with_strictly]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_decreasing:basic_positive_test]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_decreasing:test_empty_column_should_be_vacuously_true]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_match_regex:negative_test_insufficient_mostly_and_one_non_matching_value]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_match_regex:positive_test_exact_mostly_w_one_non_matching_value]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_match_regex:positive_test_sufficient_mostly_w_one_non_matching_value]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_match_regex:negative_test_one_missing_value_and_insufficent_mostly]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_match_regex:positive_test_one_missing_value_no_exceptions]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_match_regex:positive_test_all_missing_values]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_match_regex:positive_test_all_missing_values_mostly]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_match_regex:negative_test_empty_regex]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_match_regex:negative_test_match_characters_not_at_the_beginning_of_string_exact_mostly]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_dateutil_parseable:positive_test]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_dateutil_parseable:positive_test_with_nulls]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_dateutil_parseable:negative_test]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_dateutil_parseable:test_raising_exception_for_wrong_input_data_type]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_match_regex_list:basic_positive_test]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_match_regex_list:positive_test_with_multiple_regexes]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_match_regex_list:basic_negative_test]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_not_match_regex_list:negative_test_with_more_string-ish_strings]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_increasing:basic_positive_test]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_increasing:2nd_basic_positive_test]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_increasing:positive_test_with_strictly]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_increasing:basic_negative_test]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_increasing:positive_test_with_parse_strings_as_datetimes]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_increasing:positive_test_with_interspersed_nulls]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_increasing:negative_test_with_interspersed_nulls]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_lengths_to_be_between:positive_test_exact_min_and_max]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_lengths_to_be_between:negative_test_matching_min_max_too_small]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_lengths_to_be_between:negative_test_matching_max_min_too_large]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_lengths_to_be_between:positive_test_with_null_min_value]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_lengths_to_be_between:positive_test_with_null_max_value]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_lengths_to_be_between:negative_test_with_max_lt_min]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_lengths_to_be_between:positive_test_with_missing_value_in_column]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_lengths_to_be_between:test_error_handling_for_non_int_min_value]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_lengths_to_be_between:test_error_handling_for_non_int_max_value]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_lengths_to_be_between:test_error_handling_for_both_null_max_and_min_values]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_lengths_to_be_between:test_error_handling_values_are_integers]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_lengths_to_be_between:test_conditional_expectation_passes]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_lengths_to_be_between:test_conditional_expectation_fails]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_value_lengths_to_be_between:test_conditional_expectation_parser_errors]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_strftime_format:simple_positive_test]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_strftime_format:negative_test_wrong_format]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_strftime_format:positive_test_w_nulls]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_strftime_format:positive_test_w_mostly]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_strftime_format:simple_negative_test]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_strftime_format:negative_test_out_of_bounds_value_for_month]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_strftime_format:negative_test_iso8601]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_strftime_format:test_raising_exception_for_wrong_input_data_type]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_strftime_format:test_raising_exception_for_wrong_format]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_unique:basic_positive_test_case]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_unique:basic_negative_case_all_non_unique_character_values]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_unique:multi_type_column_contains_2_and_quoted_2_suppressed_for_sqalchemy]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_unique:positive_case_using_mostly]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_unique:negative_case_using_mostly]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_unique:positive_case_multiple_null_values]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_unique:negative_case_non_unique_numeric_values]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_unique:positive_case_all_null_values]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_unique:negative_multiple_duplicate_values]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_json_schema:basic_positive_test]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_json_schema:positive_test_with_a_more_complex_schema]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_match_json_schema:basic_negative_test]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_null:basic_positive_case_basic_result_format]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_null:negative_no_missing_values]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_null:positive_mostly]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_null:negative_mostly]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_null:positive_case_with_mostly_and_no_unexpected_values]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_null:negative_case_with_75percent_non_null_values_no_mostly]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_in_type_list:positive_test_pandas_integer_column]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_in_type_list:negative_test_pandas_float_values_are_not_strings]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_in_type_list:positive_test_float_values]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_in_type_list:positive_test_string_values]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_in_type_list:positive_test_boolean_values]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_in_type_list:positive_test_string_and_int_values]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_in_type_list:negative_test_string_and_int_values_summary_output]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_in_type_list:negative_test_string_and_int_values_complete_output]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_map_expectations/expect_column_values_to_be_in_type_list:positive_test_placeholder_expectation]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_value_lengths_to_equal:positive_test_string_one_character_length]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_value_lengths_to_equal:negative_test_string_value_is_1_too_high]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_value_lengths_to_equal:positive_test_with_missing_value_in_column_mostly]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_value_lengths_to_equal:negative_one_length_too_small]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_value_lengths_to_equal:positive_one_length_too_small_mostly]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:basic_positive_now_test]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:basic_positive_now_timedelta_test]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:basic_positive_datetime_test]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:basic_positive_test_with_timestamps_tz_informed]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_be_null:basic_positive_case_complete_result_format]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_be_null:negative_mostly]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_be_null:positive_case_with_mostly_and_no_unexpected_values]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_be_null:negative_case_with_75percent_null_values_no_mostly]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_value_z_scores_to_be_less_than:basic_successful_test]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_value_z_scores_to_be_less_than:basic_unsuccessful_test]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_value_z_scores_to_be_less_than:basic_test_with_outlier]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_value_z_scores_to_be_less_than:basic_test_mostly_zero]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_value_z_scores_to_be_less_than:basic_test_with_missing]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:basic_positive_test0]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:another_basic_positive_test0]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:basic_positive_test_with_timestamps0]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:missing_min_value0]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:null_min_value0]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:missing_max_value0]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:null_max_value0]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:basic_negative_test0]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:another_negative_test0]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:positive_test_with_result_format__boolean_only0]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:another_positive_test_with_result_format__boolean_only0]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:negative_test_with_result_format__boolean_only0]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:another_negative_test_with_result_format__boolean_only0]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:positive_test_with_mostly0]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:2nd_positive_test_with_mostly0]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:3rd_positive_test_with_mostly0]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:negative_test_with_mostly0]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:error:_improperly_mixed_types0]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:error:_improperly_mixed_types_again0]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:error:_improperly_mixed_types_once_more0]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:error:_missing_both_min_value_and_max_value0]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:negative_test_to_verify_that_the_denominator_for_mostly_works_with_missing_values0]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:positive_test_to_verify_that_the_denominator_for_mostly_works_with_missing_values0]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:error_on_string-to-int_comparisons0]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:test_min_value_is_greater_than_max_value0]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:test_strict_min_failure0]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:test_strict_min_success0]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:test_strict_max_failure0]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:test_strict_max_success0]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:basic_positive_test1]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:another_basic_positive_test1]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:basic_positive_test_with_timestamps1]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:missing_min_value1]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:null_min_value1]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:missing_max_value1]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:null_max_value1]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:basic_negative_test1]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:another_negative_test1]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:positive_test_with_result_format__boolean_only1]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:another_positive_test_with_result_format__boolean_only1]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:negative_test_with_result_format__boolean_only1]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:another_negative_test_with_result_format__boolean_only1]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:positive_test_with_mostly1]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:2nd_positive_test_with_mostly1]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:3rd_positive_test_with_mostly1]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:negative_test_with_mostly1]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:error:_improperly_mixed_types1]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:error:_improperly_mixed_types_again1]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:error:_improperly_mixed_types_once_more1]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:error:_missing_both_min_value_and_max_value1]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:negative_test_to_verify_that_the_denominator_for_mostly_works_with_missing_values1]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:positive_test_to_verify_that_the_denominator_for_mostly_works_with_missing_values1]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:error_on_string-to-int_comparisons1]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:test_min_value_is_greater_than_max_value1]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:test_strict_min_failure1]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:test_strict_min_success1]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:test_strict_max_failure1]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:test_strict_max_success1]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_be_in_set:basic_positive_test_case_single_value_not_in_column]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_be_in_set:negative_test_case_include_one_existing_column_value]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_be_in_set:positive_empty_values_set]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_be_in_set:basic_negative_strings_set_all_character_values]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_be_in_set:positive_test_strings_set_extra_value_in_column]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_be_in_set:negative_test_float_set_two_out_of_three_column_values_included_mostly]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_be_in_set:positive_test_float_set_two_out_of_three_column_values_included_mostly]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_be_in_set:positive_test_values_set_is_null]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_be_in_set:raise_typeerror_when_values_set_is_missing]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_of_type:basic_sqlalchemy_int_positive_test]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_of_type:negative_sqlite_integer_is_not_varchar]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_of_type:positive_test_sql_non_postgres_floats]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_of_type:positive_test_sql_varchar]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_of_type:negative_test_sqlalchemy_floats_are_not_boolean]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_in_set:basic_positive_test_case_number_set]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_in_set:vacuously_true_empty_value_set]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_in_set:negative_test_case_exclude_existing_column_value]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_in_set:negative_empty_values_set]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_in_set:basic_positive_strings_set]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_in_set:negative_test_strings_set_extra_value_in_column]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_in_set:negative_test_numbers_set_no_matching_values]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_in_set:positive_test_float_set]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_in_set:negative_test_float_set]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_in_set:test_empty_column_should_be_vacuously_true]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_match_like_pattern_list:basic_positive_test]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_match_like_pattern_list:positive_test_with_multiple_like_patternes]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_match_like_pattern:positive_test_one_missing_value_no_exceptions]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_match_like_pattern:positive_test_all_missing_values]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_match_like_pattern:positive_test_all_missing_values_mostly]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_like_pattern:positive_test_all_missing_values]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_like_pattern:positive_test_all_missing_values_mostly]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_value_lengths_to_be_between:positive_test_exact_min_and_max]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_value_lengths_to_be_between:negative_test_matching_min_max_too_small]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_value_lengths_to_be_between:negative_test_matching_max_min_too_large]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_value_lengths_to_be_between:positive_test_with_null_min_value]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_value_lengths_to_be_between:positive_test_with_null_max_value]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_value_lengths_to_be_between:negative_test_with_max_lt_min]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_value_lengths_to_be_between:positive_test_with_missing_value_in_column]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_value_lengths_to_be_between:test_error_handling_for_non_int_min_value]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_value_lengths_to_be_between:test_error_handling_for_non_int_max_value]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_value_lengths_to_be_between:test_error_handling_for_both_null_max_and_min_values]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_value_lengths_to_be_between:test_error_handling_values_are_integers]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_like_pattern_list:basic_positive_test]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_like_pattern_list:positive_test_with_multiple_like_patternes]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_like_pattern_list:positive_test_with_match_on__any]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_like_pattern_list:positive_test_column_name_has_space_and_match_on__any]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_unique:basic_positive_test_case]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_unique:basic_negative_case_all_non_unique_character_values]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_unique:positive_case_using_mostly]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_unique:negative_case_using_mostly]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_unique:positive_case_multiple_null_values]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_unique:negative_case_non_unique_numeric_values]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_unique:positive_case_all_null_values]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_unique:negative_multiple_duplicate_values]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_null:basic_positive_case_basic_result_format]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_null:negative_no_missing_values]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_null:positive_mostly]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_null:negative_mostly]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_null:positive_case_with_mostly_and_no_unexpected_values]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_null:negative_case_with_75percent_non_null_values_no_mostly]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_in_type_list:positive_test_sqlalchemy_integer_column]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_in_type_list:negative_test_sqlalchemy_float_values_are_not_text]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_in_type_list:positive_test_float_values]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_in_type_list:positive_test_text_values]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_in_type_list:positive_test_boolean_values]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_in_type_list:positive_test_text_and_integer_values]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_in_type_list:positive_test_placeholder_expectation]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_stdev_to_be_between:basic_positive_test]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_stdev_to_be_between:vacuously_true]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_stdev_to_be_between:positive_test__exact_min_and_max]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_stdev_to_be_between:basic_negative_test]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_stdev_to_be_between:positive_zero_stdev_exact_min_and_max]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_stdev_to_be_between:positive_test_null_max_exact_min]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_stdev_to_be_between:positive_test_null_min_exact_max]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_stdev_to_be_between:negative_test_null_max]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_stdev_to_be_between:negative_test_null_min]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_stdev_to_be_between:positive_test_missing_value_in_column_complete_result_format]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_be_in_set:basic_positive_test]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_be_in_set:vacuously_true_universal_set]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_be_in_set:positive_test_with_null_values_in_column]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_be_in_set:positive_test_with_duplicate_values_in_column]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_be_in_set:positive_test_duplicate_and_null_values]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_be_in_set:basic_negative_test_no_set_intersection]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_be_in_set:negative_test_some_set_intersection_and_extra]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_be_in_set:negative_test_with_null_values_in_column]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_be_in_set:negative_test_with_duplicate_values_in_column]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_be_in_set:negative_test_duplicate_and_null_values]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_most_common_value_to_be_in_set:negative_test_tie_for_most_common_with_missing_values_and_complete_result_format]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_most_common_value_to_be_in_set:negative_test__tie_for_most_common__full_value_set__ties_okay__false]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_most_common_value_to_be_in_set:positive_test__tie_for_most_common__ties_okay__true]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_most_common_value_to_be_in_set:positive_test__tie_for_most_common_but_test_for_last_value__ties_okay__true]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_most_common_value_to_be_in_set:negative_test__tie_for_most_common__value_set_does_not_match__ties_okay__false]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_most_common_value_to_be_in_set:negative_test__tie_for_most_common__value_set_does_not_match__ties_okay__true]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_most_common_value_to_be_in_set:positive_test_string_values_value_set_contains_more_than_actual_mode_list]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_most_common_value_to_be_in_set:negative_test_string_values_value_set_contains_more_than_actual_mode_list]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_quantile_values_to_be_between:basic_positive_test_extremes]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_quantile_values_to_be_between:basic_positive_test_normal_quantiles]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_quantile_values_to_be_between:basic_positive_test_uneven_spacing]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_quantile_values_to_be_between:basic_negative_test_normal_quantiles_wrong_distribution]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_quantile_values_to_be_between:basic_negative_test_disordered_quantile_ranges]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_max_to_be_between:basic_positive_test_case]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_max_to_be_between:basic_negative_test_case]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_max_to_be_between:test_case_with_result_format_summary_also_verifies_that_max_value_is_inclusive]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_max_to_be_between:test_case_with_only_a_lower_bound_and_a_missing_value]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_max_to_be_between:negative_test_case_with_only_a_lower_bound]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_max_to_be_between:datetime_except_sqlite]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_max_to_be_between:datetime_with_evaluation_parameter_except_sqlite]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_max_to_be_between:test_empty_column_should_be_false_no_observed_value_with_which_to_compare]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_mean_to_be_between:simple_mean_positive_range]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_mean_to_be_between:simple_mean_negative_range]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_mean_to_be_between:simple_mean_positive_exact_match0]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_mean_to_be_between:simple_mean_negative_exact_match]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_mean_to_be_between:simple_mean_positive_exact_match1]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_mean_to_be_between:simple_mean_negative_range_match]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_mean_to_be_between:simple_mean_includes_null]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_mean_to_be_between:vacuously_true_missing_min_and_max]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_mean_to_be_between:type_mismatch_null_observed_value]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_mean_to_be_between:coerced_types_true_false_values]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_mean_to_be_between:coerced_types_true_false_and_null]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_mean_to_be_between:catch_exceptions___non_number_min_value]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_mean_to_be_between:catch_exceptions___non_number_max_value]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_mean_to_be_between:test_empty_column_should_be_false_no_observed_value_with_which_to_compare]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_equal_set:basic_positive_test]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_equal_set:positive_test_with_null_values_in_column]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_equal_set:positive_test_with_duplicate_values_in_column]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_equal_set:positive_test_duplicate_and_null_values]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_equal_set:basic_negative_test_set_contained]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_equal_set:negative_test_some_set_intersection]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_equal_set:negative_test_with_null_values_in_column]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_equal_set:negative_test_with_duplicate_values_in_column]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_equal_set:negative_test_duplicate_and_null_values]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_sum_to_be_between:basic_positive_test_case]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_sum_to_be_between:basic_negative_test_case]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_sum_to_be_between:test_case_with_result_format_summary]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_sum_to_be_between:test_case_with_only_a_lower_bound_and_a_missing_value]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_sum_to_be_between:negative_test_case_with_only_a_lower_bound]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_sum_to_be_between:negative_test_case_with_only_a_max]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_sum_to_be_between:raise_valueerror_with_both_max_and_min_are_missing]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_unique_value_count_to_be_between:basic_positive_test]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_unique_value_count_to_be_between:positive_test_with_null_values_in_column]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_unique_value_count_to_be_between:null_min_duplicate_values_in_column]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_unique_value_count_to_be_between:null_max_duplicate_and_null_values]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_unique_value_count_to_be_between:vacuously_true_null_min_and_max]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_median_to_be_between:positive_test_min_equal_max]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_median_to_be_between:positive_test_null_min]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_median_to_be_between:positive_test_null_max]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_median_to_be_between:negative_test_min_equal_max]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_median_to_be_between:negative_test_null_min]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_median_to_be_between:negative_test_null_max]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_median_to_be_between:positive_test_missing_value_in_column_exact_min_and_max]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_median_to_be_between:negative_test_missing_value_in_column_complete_result_format]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_median_to_be_between:vacuously_true_both_min_and_max_null]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_median_to_be_between:test_empty_column_should_be_false_no_observed_value_with_which_to_compare]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_min_to_be_between:basic_positive_test_case]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_min_to_be_between:negative_test_case_with_max_value_none]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_min_to_be_between:test_case_with_result_format_summary_also_verifies_that_max_value_is_inclusive]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_min_to_be_between:test_case_with_only_a_lower_bound_and_a_missing_value]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_min_to_be_between:negative_test_case_with_only_a_lower_bound]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_min_to_be_between:test_on_a_series_with_mostly_nulls]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_min_to_be_between:negative_test_case_with_only_a_max]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_min_to_be_between:raise_valueerror_with_both_max_and_min_are_missing]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_proportion_of_unique_values_to_be_between:basic_positive_test]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_proportion_of_unique_values_to_be_between:positive_test_with_null_values_in_column]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_proportion_of_unique_values_to_be_between:duplicate_values_in_column]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_proportion_of_unique_values_to_be_between:null_max_duplicate_and_null_values]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_proportion_of_unique_values_to_be_between:vacuously_true_null_min_and_max]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:basic_positive_test]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:positive_test_with_null_values_in_column]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:positive_test_with_duplicate_values_in_column]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:positive_test_duplicate_and_null_values]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:basic_negative_test_no_set_intersection]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:negative_test_some_set_intersection]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:negative_test_with_null_values_in_column]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:negative_test_with_duplicate_values_in_column]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:negative_test_duplicate_and_null_values]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:positive_test_string_values]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:negative_test_string_values]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:basic_positive_test_case_date_set]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:basic_negative_test_case_date_set]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:basic_positive_test_case_datetime_set]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:basic_negative_test_case_datetime_set]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_stdev_to_be_between:basic_positive_test]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_stdev_to_be_between:vacuously_true]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_stdev_to_be_between:positive_test__exact_min_and_max]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_stdev_to_be_between:basic_negative_test]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_stdev_to_be_between:positive_zero_stdev_exact_min_and_max]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_stdev_to_be_between:positive_test_null_max_exact_min]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_stdev_to_be_between:positive_test_null_min_exact_max]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_stdev_to_be_between:negative_test_null_max]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_stdev_to_be_between:negative_test_null_min]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_stdev_to_be_between:positive_test_missing_value_in_column_complete_result_format]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_be_in_set:basic_positive_test]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_be_in_set:vacuously_true_universal_set]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_be_in_set:positive_test_with_null_values_in_column]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_be_in_set:positive_test_with_duplicate_values_in_column]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_be_in_set:positive_test_duplicate_and_null_values]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_be_in_set:basic_negative_test_no_set_intersection]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_be_in_set:negative_test_some_set_intersection_and_extra]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_be_in_set:negative_test_with_null_values_in_column]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_be_in_set:negative_test_with_duplicate_values_in_column]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_be_in_set:negative_test_duplicate_and_null_values]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_most_common_value_to_be_in_set:negative_test_tie_for_most_common_with_missing_values_and_complete_result_format]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_most_common_value_to_be_in_set:negative_test__tie_for_most_common__full_value_set__ties_okay__false]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_most_common_value_to_be_in_set:positive_test__tie_for_most_common__ties_okay__true]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_most_common_value_to_be_in_set:positive_test__tie_for_most_common_but_test_for_last_value__ties_okay__true]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_most_common_value_to_be_in_set:negative_test__tie_for_most_common__value_set_does_not_match__ties_okay__false]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_most_common_value_to_be_in_set:negative_test__tie_for_most_common__value_set_does_not_match__ties_okay__true]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_most_common_value_to_be_in_set:positive_test_string_values_value_set_contains_more_than_actual_mode_list]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_most_common_value_to_be_in_set:negative_test_string_values_value_set_contains_more_than_actual_mode_list]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_quantile_values_to_be_between:basic_positive_test_extremes]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_quantile_values_to_be_between:basic_positive_test_normal_quantiles]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_quantile_values_to_be_between:basic_positive_test_uneven_spacing]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_quantile_values_to_be_between:basic_negative_test_normal_quantiles_wrong_distribution]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_quantile_values_to_be_between:basic_negative_test_disordered_quantile_ranges]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_max_to_be_between:basic_positive_test_case]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_max_to_be_between:basic_negative_test_case]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_max_to_be_between:test_case_with_result_format_summary_also_verifies_that_max_value_is_inclusive]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_max_to_be_between:test_case_with_only_a_lower_bound_and_a_missing_value]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_max_to_be_between:negative_test_case_with_only_a_lower_bound]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_max_to_be_between:datetime_sqlite]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_max_to_be_between:datetime_with_evaluation_parameter_sqlite]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_max_to_be_between:test_empty_column_should_be_false_no_observed_value_with_which_to_compare]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_mean_to_be_between:simple_mean_positive_range]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_mean_to_be_between:simple_mean_negative_range]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_mean_to_be_between:simple_mean_positive_exact_match0]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_mean_to_be_between:simple_mean_negative_exact_match]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_mean_to_be_between:simple_mean_positive_exact_match1]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_mean_to_be_between:simple_mean_negative_range_match]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_mean_to_be_between:simple_mean_includes_null]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_mean_to_be_between:vacuously_true_missing_min_and_max]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_mean_to_be_between:coerced_types_true_false_values]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_mean_to_be_between:coerced_types_true_false_and_null]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_mean_to_be_between:catch_exceptions___non_number_min_value]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_mean_to_be_between:catch_exceptions___non_number_max_value]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_mean_to_be_between:test_empty_column_should_be_false_no_observed_value_with_which_to_compare]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_equal_set:basic_positive_test]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_equal_set:positive_test_with_null_values_in_column]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_equal_set:positive_test_with_duplicate_values_in_column]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_equal_set:positive_test_duplicate_and_null_values]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_equal_set:basic_negative_test_set_contained]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_equal_set:negative_test_some_set_intersection]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_equal_set:negative_test_with_null_values_in_column]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_equal_set:negative_test_with_duplicate_values_in_column]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_equal_set:negative_test_duplicate_and_null_values]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_sum_to_be_between:basic_positive_test_case]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_sum_to_be_between:basic_negative_test_case]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_sum_to_be_between:test_case_with_result_format_summary]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_sum_to_be_between:test_case_with_only_a_lower_bound_and_a_missing_value]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_sum_to_be_between:negative_test_case_with_only_a_lower_bound]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_sum_to_be_between:negative_test_case_with_only_a_max]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_sum_to_be_between:raise_valueerror_with_both_max_and_min_are_missing]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_unique_value_count_to_be_between:basic_positive_test]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_unique_value_count_to_be_between:positive_test_with_null_values_in_column]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_unique_value_count_to_be_between:null_min_duplicate_values_in_column]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_unique_value_count_to_be_between:null_max_duplicate_and_null_values]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_unique_value_count_to_be_between:vacuously_true_null_min_and_max]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_median_to_be_between:positive_test_min_equal_max]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_median_to_be_between:positive_test_null_min]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_median_to_be_between:positive_test_null_max]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_median_to_be_between:negative_test_min_equal_max]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_median_to_be_between:negative_test_null_min]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_median_to_be_between:negative_test_null_max]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_median_to_be_between:positive_test_missing_value_in_column_exact_min_and_max]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_median_to_be_between:negative_test_missing_value_in_column_complete_result_format]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_median_to_be_between:vacuously_true_both_min_and_max_null]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_median_to_be_between:test_empty_column_should_be_false_no_observed_value_with_which_to_compare]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_min_to_be_between:basic_positive_test_case]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_min_to_be_between:negative_test_case_with_max_value_none]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_min_to_be_between:test_case_with_result_format_summary_also_verifies_that_max_value_is_inclusive]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_min_to_be_between:test_case_with_only_a_lower_bound_and_a_missing_value]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_min_to_be_between:negative_test_case_with_only_a_lower_bound]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_min_to_be_between:test_on_a_series_with_mostly_nulls]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_min_to_be_between:negative_test_case_with_only_a_max]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_min_to_be_between:raise_valueerror_with_both_max_and_min_are_missing]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_proportion_of_unique_values_to_be_between:basic_positive_test]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_proportion_of_unique_values_to_be_between:positive_test_with_null_values_in_column]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_proportion_of_unique_values_to_be_between:duplicate_values_in_column]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_proportion_of_unique_values_to_be_between:null_max_duplicate_and_null_values]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_proportion_of_unique_values_to_be_between:vacuously_true_null_min_and_max]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:basic_positive_test]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:positive_test_with_null_values_in_column]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:positive_test_with_duplicate_values_in_column]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:positive_test_duplicate_and_null_values]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:basic_negative_test_no_set_intersection]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:negative_test_some_set_intersection]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:negative_test_with_null_values_in_column]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:negative_test_with_duplicate_values_in_column]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:negative_test_duplicate_and_null_values]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:positive_test_string_values]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_aggregate_expectations/expect_column_distinct_values_to_contain_set:negative_test_string_values]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:discrete_baseline_categorical_fixed_partition]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:discrete_categorical_fixed_alternate_partition]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:internal_holdout_with_categorical_partition]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:holdout_0_1]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:holdout_0_05]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:missing_vals_no_holdout]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:norm_0_1_auto_explicit_infinite_endpoints]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:norm_0_1_auto_inf_partition_test_tail_weights]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:norm_0_1_auto_inf_partition_should_fail_with_no_holdout]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:norm_0_1_auto_inf_partition_null_threshold_should_always_succeed]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:norm_0_1_auto_inf_partition_null_threshold_and_partition_object_supports_profiling]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:norm_0_1_auto_inf_partition_tail_weights_should_fail_with_no_internal_holdout]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:positive_norm_0_1_auto_partition]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:positive_norm_0_1_uniform_partition]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:positive_norm_0_1_ntile_partition]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:positive_norm_0_1_kde_partition]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:negative_norm_1_1_column_norm_0_1_auto_partition]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:negative_norm_1_1_column_norm_0_1_uniform_partition]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:negative_norm_1_1_column_norm_0_1_ntile_partition]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:negative_norm_1_1_column_norm_0_1_kde_partition]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:positive_bimodal_auto_partition]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:negative_bimodal_column_norm_0_1_auto_partition]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:negative_bimodal_column_norm_0_1_uniform_partition]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_lower_inf_bound]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_lower_inf_bound_tail_weights]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_upper_inf_bound]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_upper_inf_bound_tail_weights]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_lower_and_upper_inf_bounds0]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_lower_and_upper_inf_bounds1]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:tail_weight_holdout_is_not_defined_for_partitions_already_extending_to_inifinity]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:tail_weight_holdout_is_not_defined_for_partitions_already_extending_to_inifinity_tail_weight]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:empty_partition]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:too_big_tail_weight]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:too_big_internal_weight]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_undefined_infinite_kl_divergence0]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_undefined_infinite_kl_divergence1]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_undefined_infinite_kl_divergence_bins_do_not_cover_all_data]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_return_partitions_should_have_tail_weights]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_tail_weights_return_partitions_should_have_tail_weights]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_bounded_endpoints_empty_tail_weights_in_return]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_bounded_endpoints_observed_with_tail_weight_infinite_kl_divergence]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_infinite_endpoints_non_zero_tail_hold_out]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_upper_infinite_endpoint_non_zero_tail_hold_out]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_lower_infinite_endpoint_non_zero_tail_hold_out]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_bounded_endpoints_non_zero_tail_hold_out]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:discrete_baseline_categorical_fixed_partition]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:discrete_categorical_fixed_alternate_partition]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:internal_holdout_with_categorical_partition]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:holdout_0_1]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:holdout_0_05]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:missing_vals_no_holdout]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:norm_0_1_auto_explicit_infinite_endpoints]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:norm_0_1_auto_inf_partition_test_tail_weights]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:norm_0_1_auto_inf_partition_should_fail_with_no_holdout]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:norm_0_1_auto_inf_partition_null_threshold_should_always_succeed]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:norm_0_1_auto_inf_partition_tail_weights_should_fail_with_no_internal_holdout]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:positive_norm_0_1_auto_partition]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:positive_norm_0_1_uniform_partition]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:positive_norm_0_1_ntile_partition]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:positive_norm_0_1_kde_partition]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:negative_norm_1_1_column_norm_0_1_auto_partition]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:negative_norm_1_1_column_norm_0_1_uniform_partition]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:negative_norm_1_1_column_norm_0_1_ntile_partition]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:negative_norm_1_1_column_norm_0_1_kde_partition]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:positive_bimodal_auto_partition]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:negative_bimodal_column_norm_0_1_auto_partition]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:negative_bimodal_column_norm_0_1_uniform_partition]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_lower_inf_bound]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_lower_inf_bound_tail_weights]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_upper_inf_bound]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_upper_inf_bound_tail_weights]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_lower_and_upper_inf_bounds0]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_lower_and_upper_inf_bounds1]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:tail_weight_holdout_is_not_defined_for_partitions_already_extending_to_inifinity]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:tail_weight_holdout_is_not_defined_for_partitions_already_extending_to_inifinity_tail_weight]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:empty_partition]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:too_big_tail_weight]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:too_big_internal_weight]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_undefined_infinite_kl_divergence0]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_undefined_infinite_kl_divergence1]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_undefined_infinite_kl_divergence_bins_do_not_cover_all_data]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_return_partitions_should_have_tail_weights]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_tail_weights_return_partitions_should_have_tail_weights]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_bounded_endpoints_empty_tail_weights_in_return]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_bounded_endpoints_observed_with_tail_weight_infinite_kl_divergence]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_infinite_endpoints_non_zero_tail_hold_out]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_upper_infinite_endpoint_non_zero_tail_hold_out]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_lower_infinite_endpoint_non_zero_tail_hold_out]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_distributional_expectations/expect_column_kl_divergence_to_be_less_than:manual_partition_bounded_endpoints_non_zero_tail_hold_out]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_row_count_to_equal:basic_positive_case]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_row_count_to_equal:basic_negative_case_upper_error]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_row_count_to_equal:basic_negative_case_lower_error]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_row_count_to_equal:basic_negative_case_kwargs_args]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_row_count_to_equal:invalid_arguments_throws_exception]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_column_to_exist:basic_positive_test]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_column_to_exist:basic_negative_test]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_column_to_exist:positive_test_with_column_order]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_column_to_exist:column_exists_but_wrong_index]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_row_count_to_be_between:basic_positive_test]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_row_count_to_be_between:vacuously_true]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_row_count_to_be_between:basic_negative_test]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_row_count_to_be_between:positive_test_with_null_min_value]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_row_count_to_be_between:test_error_handling_for_min_greater_than_max]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_row_count_to_be_between:positive_test_with_null_min]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_row_count_to_be_between:test_error_handling_for_non_int_min_value]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_row_count_to_be_between:test_error_handling_for_non_int_max_value]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_columns_to_match_ordered_list:basic_positive_test]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_columns_to_match_ordered_list:negative_test_column_is_missing]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_columns_to_match_ordered_list:negative_test_column_is_misnamed]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_columns_to_match_ordered_list:negative_test_columns_are_right_but_ordering_wrong]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_columns_to_match_ordered_list:negative_test_extra_column]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_columns_to_match_ordered_list:null_list_provides_vacuously_true_expectation]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_column_count_to_be_between:basic_positive_test]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_column_count_to_be_between:vacuously_true]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_column_count_to_be_between:basic_negative_test]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_column_count_to_be_between:positive_test_with_null_min_value]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_column_count_to_be_between:test_error_handling_for_max_lt_min]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_column_count_to_be_between:positive_test_with_null_min]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_column_count_to_be_between:test_error_handling_for_non_int_min_value]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_column_count_to_be_between:test_error_handling_for_non_int_max_value]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_columns_to_match_set:basic_positive_test_exact_match_true]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_columns_to_match_set:basic_positive_test_exact_match_false]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_columns_to_match_set:negative_test_column_is_missing_exact_match_true]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_columns_to_match_set:positive_test_column_is_missing_exact_match_false]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_columns_to_match_set:negative_test_column_is_misnamed_exact_match_true]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_columns_to_match_set:negative_test_column_is_misnamed_exact_match_false]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_columns_to_match_set:positive_test_columns_are_right_but_ordering_wrong_exact_match_true]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_columns_to_match_set:positive_test_columns_are_right_but_ordering_wrong_exact_match_false]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_columns_to_match_set:negative_test_extra_column_exact_match_true]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_columns_to_match_set:negative_test_extra_column_exact_match_false]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_columns_to_match_set:negative_test_null_set_exact_match_true]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_columns_to_match_set:positive_test_vacuously_true_null_set_exact_match_false]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_column_count_to_equal:basic_positive_case]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_column_count_to_equal:basic_negative_case_upper_error]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_column_count_to_equal:basic_negative_case_lower_error]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_column_count_to_equal:basic_negative_case_kwargs_args]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/other_expectations/expect_table_column_count_to_equal:invalid_arguments_throws_exception]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_row_count_to_equal:basic_positive_case]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_row_count_to_equal:basic_negative_case_upper_error]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_row_count_to_equal:basic_negative_case_lower_error]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_row_count_to_equal:basic_negative_case_kwargs_args]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_row_count_to_equal:invalid_arguments_throws_exception]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_column_to_exist:basic_positive_test]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_column_to_exist:basic_negative_test]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_column_to_exist:positive_test_with_column_order]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_column_to_exist:column_exists_but_wrong_index]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_row_count_to_be_between:basic_positive_test]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_row_count_to_be_between:vacuously_true]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_row_count_to_be_between:basic_negative_test]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_row_count_to_be_between:positive_test_with_null_min_value]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_row_count_to_be_between:test_error_handling_for_min_greater_than_max]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_row_count_to_be_between:positive_test_with_null_min]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_row_count_to_be_between:test_error_handling_for_non_int_min_value]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_row_count_to_be_between:test_error_handling_for_non_int_max_value]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_columns_to_match_ordered_list:basic_positive_test]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_columns_to_match_ordered_list:negative_test_column_is_missing]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_columns_to_match_ordered_list:negative_test_column_is_misnamed]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_columns_to_match_ordered_list:negative_test_columns_are_right_but_ordering_wrong]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_columns_to_match_ordered_list:negative_test_extra_column]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_columns_to_match_ordered_list:null_list_provides_vacuously_true_expectation]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_column_count_to_be_between:basic_positive_test]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_column_count_to_be_between:vacuously_true]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_column_count_to_be_between:basic_negative_test]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_column_count_to_be_between:positive_test_with_null_min_value]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_column_count_to_be_between:test_error_handling_for_max_lt_min]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_column_count_to_be_between:positive_test_with_null_min]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_column_count_to_be_between:test_error_handling_for_non_int_min_value]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_column_count_to_be_between:test_error_handling_for_non_int_max_value]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_columns_to_match_set:basic_positive_test_exact_match_true]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_columns_to_match_set:basic_positive_test_exact_match_false]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_columns_to_match_set:negative_test_column_is_missing_exact_match_true]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_columns_to_match_set:positive_test_column_is_missing_exact_match_false]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_columns_to_match_set:negative_test_column_is_misnamed_exact_match_true]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_columns_to_match_set:negative_test_column_is_misnamed_exact_match_false]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_columns_to_match_set:positive_test_columns_are_right_but_ordering_wrong_exact_match_true]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_columns_to_match_set:positive_test_columns_are_right_but_ordering_wrong_exact_match_false]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_columns_to_match_set:negative_test_extra_column_exact_match_true]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_columns_to_match_set:negative_test_extra_column_exact_match_false]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_columns_to_match_set:negative_test_null_set_exact_match_true]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_columns_to_match_set:positive_test_vacuously_true_null_set_exact_match_false]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_column_count_to_equal:basic_positive_case]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_column_count_to_equal:basic_negative_case_upper_error]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_column_count_to_equal:basic_negative_case_lower_error]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_column_count_to_equal:basic_negative_case_kwargs_args]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/other_expectations/expect_table_column_count_to_equal:invalid_arguments_throws_exception]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_compound_columns_to_be_unique:mostly_default_successful_expectation]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_compound_columns_to_be_unique:mostly_default_fails_expectation]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_compound_columns_to_be_unique:mostly_set_successful_expectation]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_compound_columns_to_be_unique:mostly_set_fails_expectation]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_compound_columns_to_be_unique:mostly_set_incorrectly]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_compound_columns_to_be_unique:basic_test_ignore_if_all_are_missing_the_default_behavior]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_compound_columns_to_be_unique:basic_test_ignore_if_any_are_missing]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_compound_columns_to_be_unique:row_condition_with_ignore_if_any_are_missing]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_compound_columns_to_be_unique:unexpected_values_with_unexpected_index_list]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_compound_columns_to_be_unique:unexpected_values_without_unexpected_index_list]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_compound_columns_to_be_unique:unexpected_values_exact_match_out_without_unexpected_index_list]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_select_column_values_to_be_unique_within_record:mostly_default_successful_expectation]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_select_column_values_to_be_unique_within_record:mostly_default_fails_expectation]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_select_column_values_to_be_unique_within_record:mostly_set_successful_expectation]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_select_column_values_to_be_unique_within_record:mostly_set_fails_expectation]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_select_column_values_to_be_unique_within_record:mostly_set_incorrectly]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_select_column_values_to_be_unique_within_record:basic_test_ignore_if_all_are_missing_the_default_behavior]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_select_column_values_to_be_unique_within_record:basic_test_ignore_if_any_are_missing]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_select_column_values_to_be_unique_within_record:unexpected_values]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_select_column_values_to_be_unique_within_record:unexpected_values_exact_match_out_without_unexpected_index_list]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_multicolumn_sum_to_equal:mostly_default_successful_expectation]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_multicolumn_sum_to_equal:mostly_default_fails_expectation]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_multicolumn_sum_to_equal:mostly_set_successful_expectation]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_multicolumn_sum_to_equal:mostly_set_fails_expectation]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_multicolumn_sum_to_equal:mostly_set_incorrectly]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_multicolumn_sum_to_equal:basic_positive_test]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_multicolumn_sum_to_equal:basic_positive_test_more_than_2_columns]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_multicolumn_sum_to_equal:row_condition_with_ignore_if_any_are_missing]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_multicolumn_sum_to_equal:basic_negative_test]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_multicolumn_sum_to_equal:negative_test_with_ignore_if_any_are_missing]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/multicolumn_map_expectations/expect_multicolumn_sum_to_equal:negative_test_different_value]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_compound_columns_to_be_unique:mostly_set_incorrectly]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_select_column_values_to_be_unique_within_record:mostly_default_successful_expectation]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_select_column_values_to_be_unique_within_record:mostly_default_fails_expectation]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_select_column_values_to_be_unique_within_record:mostly_set_successful_expectation]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_select_column_values_to_be_unique_within_record:mostly_set_fails_expectation]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_select_column_values_to_be_unique_within_record:mostly_set_incorrectly]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_select_column_values_to_be_unique_within_record:basic_test_ignore_if_all_are_missing_the_default_behavior]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_select_column_values_to_be_unique_within_record:basic_test_ignore_if_any_are_missing]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_select_column_values_to_be_unique_within_record:unexpected_values]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_select_column_values_to_be_unique_within_record:unexpected_values_exact_match_out_with_index_list_pandas_v3_api]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_select_column_values_to_be_unique_within_record:unexpected_values_exact_match_out_no_index_list]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_select_column_values_to_be_unique_within_record:unexpected_values_exact_match_out_without_unexpected_index_list]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_multicolumn_sum_to_equal:mostly_default_successful_expectation]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_multicolumn_sum_to_equal:mostly_default_fails_expectation]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_multicolumn_sum_to_equal:mostly_set_successful_expectation]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_multicolumn_sum_to_equal:mostly_set_fails_expectation]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_multicolumn_sum_to_equal:mostly_set_incorrectly]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_multicolumn_sum_to_equal:basic_positive_test]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_multicolumn_sum_to_equal:basic_positive_test_more_than_2_columns]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_multicolumn_sum_to_equal:basic_negative_test]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_multicolumn_sum_to_equal:negative_test_with_ignore_if_any_are_missing]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_multicolumn_sum_to_equal:negative_test_different_value]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_pair_map_expectations/expect_column_pair_values_to_be_equal:trivial_case:_x__x]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_pair_map_expectations/expect_column_pair_values_to_be_equal:basic_negative_example_compare_number_to_text]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_pair_map_expectations/expect_column_pair_values_to_be_equal:basic_negative_example_compare_numbers]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_pair_map_expectations/expect_column_pair_values_to_be_equal:positive_example_with_mostly_compare_number_to_text]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_pair_map_expectations/expect_column_pair_values_to_be_equal:positive_example_with_mostly_compare_numbers]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_pair_map_expectations/expect_column_pair_values_to_be_equal:positive_example_with_mismatched_null_values_and_ignore_row_if__either_value_is_missing_compare_number_to_text]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_pair_map_expectations/expect_column_pair_values_to_be_equal:positive_example_with_mismatched_null_values_and_ignore_row_if__either_value_is_missing_compare_numbers]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_pair_map_expectations/expect_column_pair_values_to_be_equal:a_negative_example_with_mismatched_null_values_and_ignore_row_if__both_values_are_missing_set_explicitly]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_pair_map_expectations/expect_column_pair_values_to_be_equal:a_negative_example_with_mismatched_null_values_and_ignore_row_if__both_values_are_missing_set_by_default]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_pair_map_expectations/expect_column_pair_values_to_be_equal:a_negative_example]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_pair_map_expectations/expect_column_pair_values_to_be_equal:a_positive_example_with_mostly]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_pair_map_expectations/expect_column_pair_values_to_be_equal:a_positive_example_with_ignore_row_if__either_value_is_missing]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_pair_map_expectations/expect_column_pair_values_to_be_in_set:basic_positive_test_without_nulls]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_pair_map_expectations/expect_column_pair_values_to_be_in_set:positive_test_with_nulls_and_ignore_row_if_either_value_is_missing]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_pair_map_expectations/expect_column_pair_values_to_be_in_set:negative_test_with_nulls]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_pair_map_expectations/expect_column_pair_values_to_be_in_set:another_positive_test_with_nulls]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_pair_map_expectations/expect_column_pair_values_A_to_be_greater_than_B:basic_positive_test]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_pair_map_expectations/expect_column_pair_values_A_to_be_greater_than_B:basic_positive_test_with_missing_values_and_ignore_row_if__either_value_is_missing]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_pair_map_expectations/expect_column_pair_values_A_to_be_greater_than_B:test_ties]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_pair_map_expectations/expect_column_pair_values_A_to_be_greater_than_B:test_ties_with_or_equal]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_pair_map_expectations/expect_column_pair_values_A_to_be_greater_than_B:test_parse_strings_as_datetimes_and_mostly]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[pandas/column_pair_map_expectations/expect_column_pair_values_A_to_be_greater_than_B:test_mostly]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_pair_map_expectations/expect_column_pair_values_to_be_equal:trivial_case:_x__x]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_pair_map_expectations/expect_column_pair_values_to_be_equal:basic_negative_example_compare_numbers]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_pair_map_expectations/expect_column_pair_values_to_be_equal:positive_example_with_mostly_compare_numbers]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_pair_map_expectations/expect_column_pair_values_to_be_equal:positive_example_with_mismatched_null_values_and_ignore_row_if__either_value_is_missing_compare_numbers]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_pair_map_expectations/expect_column_pair_values_to_be_equal:a_negative_example_with_mismatched_null_values_and_ignore_row_if__both_values_are_missing_set_explicitly]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_pair_map_expectations/expect_column_pair_values_to_be_equal:a_negative_example_with_mismatched_null_values_and_ignore_row_if__both_values_are_missing_set_by_default]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_pair_map_expectations/expect_column_pair_values_to_be_equal:a_negative_example]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_pair_map_expectations/expect_column_pair_values_to_be_equal:a_positive_example_with_mostly]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_pair_map_expectations/expect_column_pair_values_to_be_equal:a_positive_example_with_ignore_row_if__either_value_is_missing]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_pair_map_expectations/expect_column_pair_values_to_be_in_set:basic_positive_test_without_nulls]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_pair_map_expectations/expect_column_pair_values_to_be_in_set:positive_test_with_nulls_and_ignore_row_if_either_value_is_missing]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_pair_map_expectations/expect_column_pair_values_to_be_in_set:negative_test_with_nulls]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_pair_map_expectations/expect_column_pair_values_to_be_in_set:another_positive_test_with_nulls]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_pair_map_expectations/expect_column_pair_values_A_to_be_greater_than_B:basic_positive_test]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_pair_map_expectations/expect_column_pair_values_A_to_be_greater_than_B:basic_positive_test_with_missing_values_and_ignore_row_if__either_value_is_missing]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_pair_map_expectations/expect_column_pair_values_A_to_be_greater_than_B:test_ties]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_pair_map_expectations/expect_column_pair_values_A_to_be_greater_than_B:test_ties_with_or_equal]
PASSED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_pair_map_expectations/expect_column_pair_values_A_to_be_greater_than_B:test_mostly]
SKIPPED [190] tests/test_definitions/test_expectations_v3_api.py:415: Skipped
FAILED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:basic_negative_now_test]
FAILED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:basic_negative_now_timedelta_test]
FAILED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:basic_negative_datetime_test]
FAILED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:basic_negative_test_with_timestamps_tz_informed]
FAILED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:basic_negative_test_with_timestamps0]
FAILED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_be_between:basic_negative_test_with_timestamps1]
FAILED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_match_like_pattern_list:negative_test_with_more_string-ish_strings]
FAILED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_match_like_pattern_list:basic_negative_test]
FAILED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_match_like_pattern:negative_test_insufficient_mostly_and_one_non_matching_value]
FAILED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_match_like_pattern:positive_test_exact_mostly_w_one_non_matching_value]
FAILED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_match_like_pattern:positive_test_sufficient_mostly_w_one_non_matching_value]
FAILED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_match_like_pattern:negative_test_one_missing_value_and_insufficent_mostly]
FAILED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_not_match_like_pattern:negative_test_match_characters_not_at_the_beginning_of_string_exact_mostly]
FAILED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_like_pattern:negative_test_insufficient_mostly_and_one_non_matching_value]
FAILED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_like_pattern:positive_test_exact_mostly_w_one_non_matching_value]
FAILED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_like_pattern:positive_test_column_name_has_space]
FAILED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_like_pattern:positive_test_sufficient_mostly_w_one_non_matching_value]
FAILED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_like_pattern:negative_test_one_missing_value_and_insufficent_mostly]
FAILED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_like_pattern:positive_test_one_missing_value_and_exact_mostly]
FAILED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_like_pattern:positive_test_one_missing_value_and_sufficent_mostly]
FAILED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_like_pattern:positive_test_match_characters_not_at_the_beginning_of_string]
FAILED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_like_pattern_list:basic_negative_test]
FAILED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/column_map_expectations/expect_column_values_to_match_like_pattern_list:negative_test_with_more_string-ish_strings]
FAILED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_compound_columns_to_be_unique:mostly_default_successful_expectation]
FAILED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_compound_columns_to_be_unique:mostly_default_fails_expectation]
FAILED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_compound_columns_to_be_unique:mostly_set_successful_expectation]
FAILED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_compound_columns_to_be_unique:mostly_set_fails_expectation]
FAILED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_compound_columns_to_be_unique:basic_test_ignore_if_all_are_missing_the_default_behavior]
FAILED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_compound_columns_to_be_unique:basic_test_ignore_if_any_are_missing]
FAILED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_compound_columns_to_be_unique:unexpected_values_without_unexpected_index_list]
FAILED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_compound_columns_to_be_unique:unexpected_values_exact_match_out_with_unexpected_index_list_pandas_v3]
FAILED tests/test_definitions/test_expectations_v3_api.py::test_case_runner_v3_api[sqlite/multicolumn_map_expectations/expect_compound_columns_to_be_unique:unexpected_values_exact_match_out_without_unexpected_index_list]
===== 32 failed, 884 passed, 190 skipped, 48 warnings in 87.99s (0:01:27) ======
