{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f0a5264-b003-4101-862f-45653f2aed1b",
   "metadata": {},
   "source": [
    "# How to write multi-batch `BatchRequest` - `InferredAsset` Example for Spark\n",
    "\n",
    "* A `BatchRequest` facilitates the return of one or more `batch(es)` of data from a configured `Datasource`. To find more about `Batches`, please refer to the [related documentation](https://docs.greatexpectations.io/docs/guides/connecting_to_your_data/how_to_get_one_or_more_batches_of_data_from_a_configured_datasource#1-construct-a-batchrequest). \n",
    "* A `BatchRequest` can return 0 or more Batches of data depending on the underlying data, and how it is configured. This guide will help you configure `BatchRequests` to return multiple batches, which can be used by\n",
    "   1. Self-Initializing Expectations to estimate parameters\n",
    "   2. DataAssistants to profile your data and create and Expectation suite with self-intialized parameters.\n",
    "   \n",
    "* Note : Multi-batch BatchRequests are not supported in `RuntimeDataConnector`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4462320-d76e-492c-96fb-f0ff8f788851",
   "metadata": {},
   "source": [
    "## FileSystem Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e04726",
   "metadata": {},
   "source": [
    "### Example Directory\n",
    "\n",
    "Imagine we have a directory of 12 csv files, each corresponding to 1 month of Taxi rider data\n",
    "\n",
    "```\n",
    "yellow_tripdata_sample_2020-01.csv\n",
    "yellow_tripdata_sample_2020-02.csv\n",
    "yellow_tripdata_sample_2020-03.csv\n",
    "yellow_tripdata_sample_2020-04.csv\n",
    "yellow_tripdata_sample_2020-05.csv\n",
    "yellow_tripdata_sample_2020-06.csv\n",
    "yellow_tripdata_sample_2020-07.csv\n",
    "yellow_tripdata_sample_2020-08.csv\n",
    "yellow_tripdata_sample_2020-09.csv\n",
    "yellow_tripdata_sample_2020-10.csv\n",
    "yellow_tripdata_sample_2020-11.csv\n",
    "yellow_tripdata_sample_2020-12.csv\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee54886b-4f88-46d9-9afe-dfd8bb061e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import great_expectations as gx\n",
    "from ruamel import yaml\n",
    "from great_expectations.core.batch import BatchRequest\n",
    "from great_expectations.core.util import get_or_create_spark_application\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c9b4ce-9448-44d3-9546-4373ff90d991",
   "metadata": {},
   "source": [
    "* Some additional imports for `Pyspark`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580f5875-3a04-41f5-a507-bf1620cc7e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "try:\n",
    "    from pyspark.sql import SparkSession\n",
    "except ImportError:\n",
    "    logger.debug(\n",
    "        \"Unable to load spark context; install optional spark dependency for support.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a2eb4f",
   "metadata": {},
   "source": [
    "* Load `DataContext`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b1854b-2a75-422e-83bb-5509d868e0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_context: gx.DataContext = gx.get_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49515697-83a2-432d-8b74-33e2f01db72c",
   "metadata": {},
   "source": [
    "### `InferredAssetDataConnector` Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df19a29c",
   "metadata": {},
   "source": [
    "* Add `Datasource` named `taxi_multi_batch_inferred_datasource` with two `InferredAssetDataConnectors`. A key difference is in the `pattern` they use to build the `data_asset_name`. Depending on which `group_names` are used, we can either create a data Asset with a single batch (corresponding to 1 csv file) or a data Asset with 12 batches (corresponding to 12 csv files for 2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7a8284",
   "metadata": {},
   "source": [
    "* The first DataConnector is called `inferred_data_connector_single_batch_asset`, which takes the entire file name  (`(.*)`), and maps it to the `data_asset_name` group.\n",
    "    * For the directory , we get 12 Data Assets, with 1 Batch each.\n",
    "    * This can be seen in the output of `test_yaml_config()`, which shows the 12 data assets, with 1 Batch each. \n",
    "    \n",
    "    * Here is the output: \n",
    "    \n",
    "    ```\t\n",
    "    Available data_asset_names (3 of 12):\n",
    "\t\tyellow_tripdata_sample_2020-01 (1 of 1): ['yellow_tripdata_sample_2020-01.csv']\n",
    "\t\tyellow_tripdata_sample_2020-02 (1 of 1): ['yellow_tripdata_sample_2020-02.csv']\n",
    "\t\tyellow_tripdata_sample_2020-03 (1 of 1): ['yellow_tripdata_sample_2020-03.csv']\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0852b21a",
   "metadata": {},
   "source": [
    "* A second DataConnector is called `inferred_data_connector_multi_batch_asset`\n",
    "    * It takes `(yellow_tripdata_sample_2020)` and maps it to the `data_asset_name` group, and matches the month (`(\\\\d.*)`) as the second group (`month`). \n",
    "    * In the case of the files in our directory, we will return a single data asset named `yellow_tripdata_sample_2020`, with each of the 12 months corresponding to Batches for the asset. \n",
    "    * This can be seen in the output of `test_yaml_config()`, which shows 3 of the 12 Batches corresponding to `yellow_tripdata_sample_2020`\n",
    "    * Here is the output:\n",
    " ```\n",
    " Available data_asset_names (1 of 1):\n",
    "       yellow_tripdata_sample_2020 (3 of 12): ['yellow_tripdata_sample_2020-01.csv', 'yellow_tripdata_sample_2020-02.csv', 'yellow_tripdata_sample_2020-03.csv']\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60d62a9-4a39-4c88-9308-67fccb540229",
   "metadata": {},
   "source": [
    "* Both DataConnectors also specify `batch_spec_passthrough` parameters. These allow backend-specific `reader_options` to be passed through to the actual reader method, in this case `spark.read.csv()` which are passed into the `SparkDFExecutionEngine`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84150f65-bbd6-4b45-95ab-9590a29f116a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path: str = \"../../../../test_sets/taxi_yellow_tripdata_samples/samples_2020\"\n",
    "\n",
    "datasource_config = {\n",
    "    \"name\": \"taxi_multi_batch_inferred_datasource\",\n",
    "    \"class_name\": \"Datasource\",\n",
    "    \"module_name\": \"great_expectations.datasource\",\n",
    "    \"execution_engine\": {\n",
    "        \"module_name\": \"great_expectations.execution_engine\",\n",
    "        \"class_name\": \"SparkDFExecutionEngine\",\n",
    "    },\n",
    "    \"data_connectors\": {\n",
    "        \"inferred_data_connector_single_batch_asset\": {\n",
    "            \"class_name\": \"InferredAssetFilesystemDataConnector\",\n",
    "            \"base_directory\": data_path,\n",
    "            \"default_regex\": {\n",
    "                \"group_names\": [\"data_asset_name\"],\n",
    "                \"pattern\": \"(.*)\\\\.csv\",\n",
    "            },\n",
    "            \"batch_spec_passthrough\": {\n",
    "                \"reader_method\": \"csv\",\n",
    "                \"reader_options\": {\n",
    "                    \"header\": True,\n",
    "                    \"inferSchema\": True,\n",
    "                },\n",
    "            },\n",
    "        },\n",
    "        \"inferred_data_connector_multi_batch_asset\": {\n",
    "            \"class_name\": \"InferredAssetFilesystemDataConnector\",\n",
    "            \"base_directory\": data_path,\n",
    "            \"default_regex\": {\n",
    "                \"group_names\": [\"data_asset_name\", \"month\"],\n",
    "                \"pattern\": \"(yellow_tripdata_sample_2020)-(\\\\d.*)\\\\.csv\",\n",
    "            },\n",
    "            \"batch_spec_passthrough\": {\n",
    "                \"reader_method\": \"csv\",\n",
    "                \"reader_options\": {\n",
    "                    \"header\": True,\n",
    "                    \"inferSchema\": True,\n",
    "                },\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "data_context.test_yaml_config(yaml.dump(datasource_config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7636ffff-0ddc-48fd-a4cf-f8e139a5e36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_datasource only if it doesn't already exist in our configuration\n",
    "try:\n",
    "    data_context.get_datasource(datasource_config[\"name\"])\n",
    "except ValueError:\n",
    "    data_context.add_datasource(**datasource_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438146be",
   "metadata": {},
   "source": [
    "## BatchRequest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117cdb0d",
   "metadata": {},
   "source": [
    "* Depending on which `DataConnector` you send a `BatchRequest` to, you will retrieve a different number of `Batches`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bc9c59",
   "metadata": {},
   "source": [
    "* Single Batch returned by `inferred_data_connector_single_batch_asset` DataConnector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0453cd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_batch_batch_request: BatchRequest = BatchRequest(\n",
    "    datasource_name=\"taxi_multi_batch_inferred_datasource\",\n",
    "    data_connector_name=\"inferred_data_connector_single_batch_asset\",\n",
    "    data_asset_name=\"yellow_tripdata_sample_2020-01\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35df7084",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_list = data_context.get_batch_list(batch_request=single_batch_batch_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e74a05-3fd1-4e47-9105-b721dbcf3516",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7f4fa5",
   "metadata": {},
   "source": [
    "* Multi Batch returned by `inferred_data_connector_multi_batch_asset` DataConnector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32dbac9-af5d-4677-98f9-f098ef091b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_batch_batch_request: BatchRequest = BatchRequest(\n",
    "    datasource_name=\"taxi_multi_batch_inferred_datasource\",\n",
    "    data_connector_name=\"inferred_data_connector_multi_batch_asset\",\n",
    "    data_asset_name=\"yellow_tripdata_sample_2020\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a284bfd-00aa-4068-bc09-71c6dea627e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_batch_batch_list = data_context.get_batch_list(\n",
    "    batch_request=multi_batch_batch_request\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf3e1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_batch_batch_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790746ee",
   "metadata": {},
   "source": [
    "* You can also get a single Batch from a multi-batch DataConnector by passing in `data_connector_query`. Index `-1` will return the most recent (month = `12`) batch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16612bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_batch_batch_request_from_multi: BatchRequest = BatchRequest(\n",
    "    datasource_name=\"taxi_multi_batch_inferred_datasource\",\n",
    "    data_connector_name=\"inferred_data_connector_multi_batch_asset\",\n",
    "    data_asset_name=\"yellow_tripdata_sample_2020\",\n",
    "    data_connector_query={\"index\": -1},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef1b6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_list = data_context.get_batch_list(\n",
    "    batch_request=single_batch_batch_request_from_multi\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c857607",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229815cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_list[0].to_dict()  # 'batch_identifiers': {'month': '12'}},"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907a6ef5",
   "metadata": {},
   "source": [
    "# Using auto-initializing `Expectations` to generate parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efe9c76",
   "metadata": {},
   "source": [
    "* We will generate a `Validator` using our `multi_batch_batch_list`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847ce4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_batch_batch_list = data_context.get_batch_list(\n",
    "    batch_request=multi_batch_batch_request\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1eca55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_suite = data_context.add_expectation_suite(\n",
    "    expectation_suite_name=\"example_inferred_suite\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852deba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "validator = data_context.get_validator_using_batch_list(\n",
    "    batch_list=multi_batch_batch_list, expectation_suite=example_suite\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee01a0e9",
   "metadata": {},
   "source": [
    "* When you run methods on the validator, it will typically run on the most recent batch (index `-1`), even if the Validator has access to a longer Batch list. For example, notice that the `pickup_datetime` and `dropoff_datetime` below are all associated with December, indicating that it is with the most recent Batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fe8b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "validator.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be66602",
   "metadata": {},
   "source": [
    "### Typical Workflow\n",
    "* A `batch_list` becomes really useful when you are calculating parameters for auto-initializing Expectations, as they us a `RuleBasedProfiler` under-the-hood to calculate parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdef9ad7",
   "metadata": {},
   "source": [
    "* Here is an example running `expect_column_median_to_be_between()` by \"guessing\" at the `min_value` and `max_value`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b524a2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "validator.expect_column_median_to_be_between(\n",
    "    column=\"trip_distance\", min_value=0, max_value=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18d096f",
   "metadata": {},
   "source": [
    "* The observed value for the most recent batch (December/2020) is going to be `1.61`, which means the Expectation fails"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5016d8",
   "metadata": {},
   "source": [
    "* Now we run the same expectation again, but this time with `auto=True`. This means the `median` values are going to calculated across the `batch_list` associated with the `Validator` (ie 12 Batches for 2020), which gives the min value of `1.6` and the max value of `1.92`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd821c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "validator.expect_column_median_to_be_between(column=\"trip_distance\", auto=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a6c277",
   "metadata": {},
   "source": [
    "* The `auto=True` will also automatically run the Expectation against the most recent Batch (which has an observed value of `1.61`) and the Expectation will pass. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b8b938",
   "metadata": {},
   "source": [
    "* You can now save the `ExpectationSuite`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba880ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "validator.save_expectation_suite()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7ec631",
   "metadata": {},
   "source": [
    "### Running the `ExpectationSuite` against single `Batch`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477381f5",
   "metadata": {},
   "source": [
    "* Now the ExpectationSuite can be used to validate single batches using a Checkpoint. As before, we can use `data_connector_query` to specify the batch that we would like to run the `Checkpoint` on, but the recommended way would be to use the `batch_identifier` parameter, where we have set `month` to `01` to specify the January 2020 batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747dea95",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_batch_batch_request: BatchRequest = BatchRequest(\n",
    "    datasource_name=\"taxi_multi_batch_inferred_datasource\",\n",
    "    data_connector_name=\"inferred_data_connector_multi_batch_asset\",\n",
    "    data_asset_name=\"yellow_tripdata_sample_2020\",\n",
    "    # data_connector_query={\n",
    "    #    \"index\": 0 # this one will correspond to Jan 2020\n",
    "    # }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d392e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_config = {\n",
    "    \"name\": \"my_checkpoint\",\n",
    "    \"config_version\": 1,\n",
    "    \"class_name\": \"SimpleCheckpoint\",\n",
    "    \"validations\": [\n",
    "        {\n",
    "            \"batch_request\": multi_batch_batch_request,\n",
    "            \"expectation_suite_name\": \"example_inferred_suite\",\n",
    "            \"batch_identifiers\": {\"month\": \"01\"},  # batch_identifier month is set to 01\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "data_context.add_checkpoint(**checkpoint_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3269dfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = data_context.run_checkpoint(checkpoint_name=\"my_checkpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6234082",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.success"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
