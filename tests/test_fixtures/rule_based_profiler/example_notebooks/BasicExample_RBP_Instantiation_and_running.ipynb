{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Build a `RuleBasedProfiler`\n",
    "* This Notebook will demonstrate the steps we need to take to generate a simple `RuleBasedProfiler` by initializing the components in memory.\n",
    "\n",
    "* We will start from a new Great Expectations Data Context (ie `great_expectations` folder after running `great_expectations init`), and begin by adding the Datasource, and progressively adding more components\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/work/Development/ENVs/bugbash/lib/python3.8/site-packages/snowflake/connector/options.py:94: UserWarning: You have an incompatible version of 'pyarrow' installed (7.0.0), please install a version that adheres to: 'pyarrow<3.1.0,>=3.0.0; extra == \"pandas\"'\n",
      "  warn_incompatible_dep(\n"
     ]
    }
   ],
   "source": [
    "import great_expectations as ge\n",
    "from ruamel import yaml\n",
    "\n",
    "from great_expectations.core.batch import BatchRequest\n",
    "from great_expectations.core import ExpectationSuite\n",
    "\n",
    "from great_expectations.rule_based_profiler.rule.rule import Rule\n",
    "from great_expectations.rule_based_profiler.rule_based_profiler import RuleBasedProfiler\n",
    "\n",
    "from great_expectations.rule_based_profiler.domain_builder import (\n",
    "    DomainBuilder,\n",
    "    ColumnDomainBuilder,\n",
    ")\n",
    "from great_expectations.rule_based_profiler.parameter_builder import (\n",
    "    MetricMultiBatchParameterBuilder,\n",
    ")\n",
    "from great_expectations.rule_based_profiler.expectation_configuration_builder import (\n",
    "    DefaultExpectationConfigurationBuilder,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_context: ge.DataContext = ge.get_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up: Adding `taxi_data` `Datasource`\n",
    "* Add `taxi_data` as a new `Datasource`\n",
    "* We are using an `InferredAssetFilesystemDataConnector` to connect to data in the `test_sets/taxi_yellow_tripdata_samples` folder and get one `DataAsset` (`yellow_tripdata_sample_2018`) that has 12 Batches (1 Batch/month)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to instantiate class from config...\n",
      "\tInstantiating as a Datasource, since class_name is Datasource\n",
      "\tSuccessfully instantiated Datasource\n",
      "\n",
      "\n",
      "ExecutionEngine class name: PandasExecutionEngine\n",
      "Data Connectors:\n",
      "\tdefault_inferred_data_connector_name : InferredAssetFilesystemDataConnector\n",
      "\n",
      "\tAvailable data_asset_names (1 of 1):\n",
      "\t\tyellow_tripdata_sample_2018 (3 of 12): ['yellow_tripdata_sample_2018-01.csv', 'yellow_tripdata_sample_2018-02.csv', 'yellow_tripdata_sample_2018-03.csv']\n",
      "\n",
      "\tUnmatched data_references (3 of 29):['.DS_Store', 'first_3_files', 'random_subsamples']\n",
      "\n",
      "\tdefault_inferred_data_connector_name_all_years : InferredAssetFilesystemDataConnector\n",
      "\n",
      "\tAvailable data_asset_names (1 of 1):\n",
      "\t\tyellow_tripdata_sample (3 of 36): ['yellow_tripdata_sample_2018-01.csv', 'yellow_tripdata_sample_2018-02.csv', 'yellow_tripdata_sample_2018-03.csv']\n",
      "\n",
      "\tUnmatched data_references (3 of 5):['.DS_Store', 'first_3_files', 'random_subsamples']\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<great_expectations.datasource.new_datasource.Datasource at 0x7f8bd944fdf0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path: str = \"../../../../test_sets/taxi_yellow_tripdata_samples\"\n",
    "\n",
    "datasource_config = {\n",
    "    \"name\": \"taxi_multi_batch_datasource\",\n",
    "    \"class_name\": \"Datasource\",\n",
    "    \"module_name\": \"great_expectations.datasource\",\n",
    "    \"execution_engine\": {\n",
    "        \"module_name\": \"great_expectations.execution_engine\",\n",
    "        \"class_name\": \"PandasExecutionEngine\",\n",
    "    },\n",
    "    \"data_connectors\": {\n",
    "        \"default_inferred_data_connector_name\": {\n",
    "            \"class_name\": \"InferredAssetFilesystemDataConnector\",\n",
    "            \"base_directory\": data_path,\n",
    "            \"default_regex\": {\n",
    "                \"group_names\": [\"data_asset_name\", \"month\"],\n",
    "                \"pattern\": \"(yellow_tripdata_sample_2018)-(\\\\d.*)\\\\.csv\",\n",
    "            },\n",
    "        },\n",
    "        \"default_inferred_data_connector_name_all_years\": {\n",
    "            \"class_name\": \"InferredAssetFilesystemDataConnector\",\n",
    "            \"base_directory\": data_path,\n",
    "            \"default_regex\": {\n",
    "                \"group_names\": [\"data_asset_name\", \"year\", \"month\"],\n",
    "                \"pattern\": \"(yellow_tripdata_sample)_(\\\\d.*)-(\\\\d.*)\\\\.csv\",\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "data_context.test_yaml_config(yaml.dump(datasource_config))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_datasource only if it doesn't already exist in our configuration\n",
    "try:\n",
    "    data_context.get_datasource(datasource_config[\"name\"])\n",
    "except ValueError:\n",
    "    data_context.add_datasource(**datasource_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BatchRequests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In this example, we will be using two `BatchRequests` using our `Datasource`. \n",
    "   * `single_batch_batch_request` : which gives the most recent (December) data from the 2018 `taxi_data` dataset. \n",
    "   * `multi_batch_batch_request`: which gives all 12 Batches of data from the 2018 `taxi_data` datataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_batch_batch_request: BatchRequest = BatchRequest(\n",
    "    datasource_name=\"taxi_multi_batch_datasource\",\n",
    "    data_connector_name=\"default_inferred_data_connector_name\",\n",
    "    data_asset_name=\"yellow_tripdata_sample_2018\",\n",
    "    data_connector_query={\"index\": -1},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_batch_batch_request: BatchRequest = BatchRequest(\n",
    "    datasource_name=\"taxi_multi_batch_datasource\",\n",
    "    data_connector_name=\"default_inferred_data_connector_name\",\n",
    "    data_asset_name=\"yellow_tripdata_sample_2018\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1:  `RuleBasedProfiler` with just a `DomainBuilder` and `ExpectationConfigurationBuilder`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a `DomainBuilder`\n",
    "\n",
    "In the process of building a `RuleBasedProfiler`, one of the first components we want to build/test\n",
    "is a `DomainBuilder`, which returns the Domains (tables, columns, set of columns, etc) that the our resulting `Expectations` will be run on. In our example, the `DomainBuilder` will output a list of columns that follow a certain pattern, namely have `'_amount'` in their suffix. To this end we will be using a `ColumnDomainBuilder` which allows you to choose columns based on their suffix, name, or semantic type (like numeric or string) and our `DomainBuilder` will output a list of 4 columns : `fare_amount`, `tip_amount`, `tolls_amount` and `total_amount`.\n",
    "\n",
    "The `RuleBasedProfiler` also contains additional `DomainBuilders` that allow you to do more sophisticated filtering on your data. \n",
    "\n",
    "These include:\n",
    " * `CategoricalColumnDomainBuilder`: which allows you to choose columns based on their cardinality (number of unique values).\n",
    " * `MapMetricColumnDomainBuilder`: which allows you to choose columns based on Map Metrics, which give a yes/no answer for individual values or rows. \n",
    "\n",
    "In addition, there are `DomainBuilders` that do not perform any additional filtering, but are required by the Expectations that are being built by the `RuleBasedProfiler`. \n",
    " * `TableDomainBuilder`:  Outputs Table Domain, which is required by `Expectations` that act on tables, like (`expect_table_row_count_to_equal`, or `expect_table_columns_to_match_set`). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `ColumnDomainBuilder`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "914f6711ae3449e280bb22d8970d6fb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5f4ca9463f04efe92d61c7ca765c6f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "domain_builder: DomainBuilder = ColumnDomainBuilder(\n",
    "    data_context=data_context,\n",
    "    batch_request=single_batch_batch_request,\n",
    "    include_column_name_suffixes=[\"_amount\"],\n",
    ")\n",
    "domains: list = domain_builder.get_domains()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert that the domains we get are the ones we expect\n",
    "assert len(domains) == 4\n",
    "assert domains == [\n",
    "    {\"domain_type\": \"column\", \"domain_kwargs\": {\"column\": \"fare_amount\"}},\n",
    "    {\"domain_type\": \"column\", \"domain_kwargs\": {\"column\": \"tip_amount\"}},\n",
    "    {\"domain_type\": \"column\", \"domain_kwargs\": {\"column\": \"tolls_amount\"}},\n",
    "    {\"domain_type\": \"column\", \"domain_kwargs\": {\"column\": \"total_amount\"}},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To continue our example, we will continue building a `RuleBasedProfiler` using our `ColumnDomainBuilder`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build `Rule`\n",
    "* The first `Rule` that we build will output `expect_column_values_to_not_be_null` because it does not take in  additional information other than Domain. We will add `ParameterBuilders` in a subsequent example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_expectation_configuration_builder = DefaultExpectationConfigurationBuilder(\n",
    "    expectation_type=\"expect_column_values_to_not_be_null\",\n",
    "    column=\"$domain.domain_kwargs.column\", # Get the column from domain_kwargs that are retrieved from the DomainBuilder\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_rule: Rule = Rule(\n",
    "    name=\"rule_with_no_parameters\",\n",
    "    domain_builder=domain_builder,\n",
    "    expectation_configuration_builders=[default_expectation_configuration_builder],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create `RuleBasedProfiler` and add `Rule`\n",
    "* We create a simple `RuleBasedProfiler` and add the `Rule` that we added in the previous step is added to the Profiler. When we run the Profiler, the output is an `ExpectationSuite` with 4 `Expectations`, which we expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from great_expectations.core import ExpectationSuite\n",
    "from great_expectations.rule_based_profiler.rule_based_profiler import RuleBasedProfiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_rbp: RuleBasedProfiler = RuleBasedProfiler(\n",
    "    name=\"my_simple_rbp\", data_context=data_context, config_version=1.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_rbp.add_rule(rule=simple_rule)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "268d6045f375449aaa12b7f162d386a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2643583d651407193d168b954348e0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res: ExpectationSuite = my_rbp.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(res.expectations) == 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{\"meta\": {}, \"expectation_type\": \"expect_column_values_to_not_be_null\", \"kwargs\": {\"column\": \"fare_amount\"}},\n",
       " {\"meta\": {}, \"expectation_type\": \"expect_column_values_to_not_be_null\", \"kwargs\": {\"column\": \"tip_amount\"}},\n",
       " {\"meta\": {}, \"expectation_type\": \"expect_column_values_to_not_be_null\", \"kwargs\": {\"column\": \"tolls_amount\"}},\n",
       " {\"meta\": {}, \"expectation_type\": \"expect_column_values_to_not_be_null\", \"kwargs\": {\"column\": \"total_amount\"}}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.expectations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected our simple `RuleBasedProfiler` will output an `ExpectationSuite` with 4 `Expectations`, one for each of our 4 columns. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2: `RuleBasedProfiler` with `DomainBuilder`, `ParameterBuilder` `ExpectationConfigurationBuilder`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a DomainBuilder\n",
    "* Using the same `ColumnDomainBuilder` from our previous example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dab4d56e7c14e3d8e18897a45bd3357",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a856b6cced544923a4a94172aba6bb6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "domain_builder: DomainBuilder = ColumnDomainBuilder(\n",
    "    data_context=data_context,\n",
    "    batch_request=single_batch_batch_request,\n",
    "    include_column_name_suffixes=[\"_amount\"],\n",
    ")\n",
    "domains: list = domain_builder.get_domains()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{\n",
       "   \"domain_type\": \"column\",\n",
       "   \"domain_kwargs\": {\n",
       "     \"column\": \"fare_amount\"\n",
       "   }\n",
       " },\n",
       " {\n",
       "   \"domain_type\": \"column\",\n",
       "   \"domain_kwargs\": {\n",
       "     \"column\": \"tip_amount\"\n",
       "   }\n",
       " },\n",
       " {\n",
       "   \"domain_type\": \"column\",\n",
       "   \"domain_kwargs\": {\n",
       "     \"column\": \"tolls_amount\"\n",
       "   }\n",
       " },\n",
       " {\n",
       "   \"domain_type\": \"column\",\n",
       "   \"domain_kwargs\": {\n",
       "     \"column\": \"total_amount\"\n",
       "   }\n",
       " }]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a `ParameterBuilder`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ParameterBuilders` help calcluate \"reasonable\" parameters for Expectations based on data that is specified by a `BatchRequest`.\n",
    "\n",
    "The largest categories include: \n",
    "- `metric_multi_batch_parameter_builder`: Which is able to calculate a numeric Metric (like `column.min`) across multiple Batches (or just one Batch).\n",
    "- `value_set_multi_batch_parameter_builder`: Which is able to build a value set across multiple Batches (or just one Batch). \n",
    "\n",
    "In some cases, there is a better way to build a value set using regex or dates. \n",
    "- `regex_pattern_string_parameter_builder`: Which contains a set of default regex patterns and builds a value set of the best-matching patterns. Users are also able to pass in new patterns as a parameter. \n",
    "- `simple_date_format_string_parameter_builder`: Which contains a set of default datetime-format patterns and builds a value set of the best-matching patterns. Users are also able to pass in new patterns as a parameter. \n",
    "\n",
    "Across multiple-Batches, we can build more-sophisticated parameters by using sampling methods. \n",
    "- `numeric_range_multi_batch_parameter_builder`: Which is able to provide range estimations across Batches using sampling methods. For instance, if we expect a table's `row_count` to change between Batches, we could calculate the min / max values of row_count by using the `NumericMetricRangeMultiBatchParameterBuilder`. These parameters could then be used by `ExpectTableRowCountToBeBetween`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our example we will be using a `MetricMultiBatchParameterBuilder` to estimate the `column.min` Metric for the 4 columns defined by our Domain Builder. These are passed in as `metric_domain_kwargs` and are accessible using the fully qualified parameter `$domain.domain_kwargs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_range_parameter_builder: MetricMultiBatchParameterBuilder = (\n",
    "    MetricMultiBatchParameterBuilder(\n",
    "        data_context=data_context,\n",
    "        batch_request=single_batch_batch_request,\n",
    "        metric_name=\"column.min\",\n",
    "        metric_domain_kwargs=\"$domain.domain_kwargs\",  # domain kwarg values are accessible using fully qualified parameters\n",
    "        name=\"my_column_min\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build an ExpectationConfigurationBuilder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ExpectationConfigurationBuilder` is being built for `expect_column_values_to_be_greater_than` which will use the `column.min` values that are calculated using the `ParameterBuilder`. These are now accessible using the fully qualified parameter `$parameter.my_column_min.value[-1]`.  The `[-1]` indicates that we will use the min value from the latest Batch (the only `Batch` in this case since our `BatchRequest` only returns a single `Batch`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_builder: DefaultExpectationConfigurationBuilder = (\n",
    "    DefaultExpectationConfigurationBuilder(\n",
    "        expectation_type=\"expect_column_values_to_be_greater_than\",\n",
    "        value=\"$parameter.my_column_min.value[-1]\", # the parameter is accessible using a fully qualified parameter\n",
    "        column=\"$domain.domain_kwargs.column\", # domain kwarg values are accessible using fully qualified parameters\n",
    "        name=\"my_column_min\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a `Rule`, `RuleBasedProfiler`, and run "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we build a rule with our `ParameterBuilder`, `DomainBuilder` and `ExpectationConfigurationBuilder`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_rule: Rule = Rule(\n",
    "    name=\"rule_with_parameters\",\n",
    "    domain_builder=domain_builder,\n",
    "    parameter_builders=[numeric_range_parameter_builder],\n",
    "    expectation_configuration_builders=[config_builder],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_rbp = RuleBasedProfiler(name=\"my_rbp\", data_context=data_context\n",
    "                           , config_version=1.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the `Rule` to our `RuleBasedProfiler` and run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_rbp.add_rule(rule=simple_rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb64332ce9a941d9b075096c3077db94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2406a8f00756488ba7174a1b907a097a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "798306e4fead4a2db81354685ebb4318",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6983e4d4ae524825b89c556a4c417624",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eee132ee6a4a4daab47f27032599ad85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "175c6789a73e427594c863d506c271b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res: ExpectationSuite = my_rbp.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(res.expectations) == 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{\"meta\": {}, \"expectation_type\": \"expect_column_values_to_be_greater_than\", \"kwargs\": {\"name\": \"my_column_min\", \"value\": -80.0, \"column\": \"fare_amount\"}},\n",
       " {\"meta\": {}, \"expectation_type\": \"expect_column_values_to_be_greater_than\", \"kwargs\": {\"name\": \"my_column_min\", \"value\": 0.0, \"column\": \"tip_amount\"}},\n",
       " {\"meta\": {}, \"expectation_type\": \"expect_column_values_to_be_greater_than\", \"kwargs\": {\"name\": \"my_column_min\", \"value\": 0.0, \"column\": \"tolls_amount\"}},\n",
       " {\"meta\": {}, \"expectation_type\": \"expect_column_values_to_be_greater_than\", \"kwargs\": {\"name\": \"my_column_min\", \"value\": -80.3, \"column\": \"total_amount\"}}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.expectations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting `ExpectationSuite` now contain values (`-80.0`, `0.0` etc) that were calculated from the Batch of data defined by the `BatchRequest`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 3: `RuleBasedProfiler` with multiple `ParameterBuilders`, `ExpectationConfigurationBuilders` and  `Variables`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The third example is more complex, using multiple batches, multiple `ParameterBuilders`, `ExpectationConfigurationBuilders` and also introducing the use of `variables`.\n",
    "\n",
    "The goal of this example is to build a `RuleBasedProfiler` that outputs an `ExpectationSuite` containing 2 Expectation types\n",
    "- `expect_column_min_to_be_between` : Defined as \"Expect the column minimum to be between a min and max value\".\n",
    "- `expect_column_max_to_be_between` : Defined as \"Expect the column maxmimum to be between a min and max value\".\n",
    "\n",
    "for 2 columns in our `taxi_data` dataset\n",
    "- `fare_amount` \n",
    "- `tip_amount`\n",
    "\n",
    "with the `min_value` and `max_value` parameters for each of the Expectations estimated over 12 Batches of `taxi_data`, for a total of 4 Expectations.\n",
    "\n",
    "To estimate the parameters, we will be using a `NumericMetricRangeMultiBatchParameterBuilder`, which is able to provide range estimations across Batches using sampling methods.  We will also be using a `variables` dictionary to share defined variables across Rule components like `DomainBuilders`, `ParameterBuilders` and `ExpectationConfigurationBuilders`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiating `variables` dictionary\n",
    "\n",
    "`RuleBasedProfilers` allow for the definition of variables, which can be shared across Rules and Rule components. When building a complex `RuleBasedProfiler` with multiple Rules or components, using variables will help you keep track of values without having to input them multiple times.\n",
    "\n",
    "Once loaded into the `RuleBasedProfiler` configuration, the variables are accessible using the fully qualified variable name `$variables.[key_in_variables_dictionary]`, similar to how domain kwarg values and parameter values are accessible using a fully qualified name that begins with `$`.\n",
    "\n",
    "In the example below, the `estimator_name` is accessible using `$variables.estimator_name`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables: dict = {\n",
    "    \"multi_batch_batch_request\": multi_batch_batch_request,\n",
    "    \"estimator_name\": \"bootstrap\",\n",
    "    \"false_positive_rate\": 5.0e-2, \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiating `RuleBasedProfiler` with `variables`\n",
    "\n",
    "Pass the `variables` dictionary into the `RuleBasedProfiler` constructor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_rbp = RuleBasedProfiler(name=\"my_complex_rbp\", data_context=data_context, variables=variables, config_version=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiating `ColumnDomainBuilder`\n",
    "\n",
    "The `ColumnDomainBuilder` is instantiated using column names `tip_amount` and `fare_amount`. The BatchRequest is passed in as a `$variable`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from great_expectations.rule_based_profiler.domain_builder import ColumnDomainBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_builder: DomainBuilder = ColumnDomainBuilder(\n",
    "    data_context=data_context,\n",
    "    batch_request=\"$variables.multi_batch_batch_request\",\n",
    "    include_column_names=[\"tip_amount\", \"fare_amount\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiating `ParameterBuilders`\n",
    "\n",
    "Our Rule will contain 2 `NumericMetricRangeMultiBatchParameterBuilders`, one for each of our 2 Expectation types. One will be estimating the Parameter values for the `column.min` Metric, and the other will be estimating Parameter values for the `column.max` Metric.  `metric_domain_kwargs` are passed in from our DomainBuilder using `$domain.domain_kwargs`.\n",
    "\n",
    "Also note the use of 3 Variables we defined above: \n",
    "\n",
    "- `$variables.estimator_name`: This is `\"oneshot\"` in our case. \n",
    "- `$variables.false_positive_rate`: This is `5.0e-2` or 5% in our case.\n",
    "- `$variables.multi_batch_batch_request`: This the `multi_batch_batch_request`, which gives all 12 Batches of data from the 2018 taxi_data datataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from great_expectations.rule_based_profiler.parameter_builder import NumericMetricRangeMultiBatchParameterBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_range_parameter_builder: NumericMetricRangeMultiBatchParameterBuilder = NumericMetricRangeMultiBatchParameterBuilder(\n",
    "    name=\"min_range_parameter_builder\",\n",
    "    metric_name=\"column.min\",\n",
    "    metric_domain_kwargs=\"$domain.domain_kwargs\",\n",
    "    false_positive_rate='$variables.false_positive_rate',\n",
    "    estimator=\"$variables.estimator_name\",\n",
    "    batch_request=\"$variables.multi_batch_batch_request\",\n",
    "    data_context=data_context,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_range_parameter_builder: NumericMetricRangeMultiBatchParameterBuilder = NumericMetricRangeMultiBatchParameterBuilder(\n",
    "    name=\"max_range_parameter_builder\",\n",
    "    metric_name=\"column.max\",\n",
    "    metric_domain_kwargs=\"$domain.domain_kwargs\",\n",
    "    false_positive_rate=\"$variables.false_positive_rate\",\n",
    "    estimator=\"$variables.estimator_name\",\n",
    "    batch_request=\"$variables.multi_batch_batch_request\",\n",
    "    data_context=data_context,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiating `ExpectationConfigurationBuilders`\n",
    "\n",
    "Our Rule will contain 2 `ExpectationConfigurationBuilders`, one for each of our 2 Expectation types: \n",
    "\n",
    "- `expect_column_min_to_be_between`\n",
    "- `expect_column_max_to_be_between`\n",
    "\n",
    "The Expectations are both `ColumnExpectations`, so the `column` parameter will be accessed from the Domain kwargs using `$domain.domain_kwargs.column`. \n",
    "\n",
    "The Expectations also take in a `min_value` and `max_value` parameter, which our `NumericMetricRangeMultiBatchParameterBuilders` are estimating. For `expect_column_min_to_be_between`, these estimated values are accessible using\n",
    "\n",
    "- `$parameter.min_range_parameter_builder.value[0]` for the `min_value`, with `min_range_parameter_builder` being the name of our ParameterBuilder that estimates the `column.min` metric.\n",
    "- `$parameter.min_range.value[1]` for the `max_value`.\n",
    "\n",
    "The equivalent `$parameter` for `expect_column_max_to_be_between` would be `$parameter.max_range.value[0]` and `$parameter.max_range_parameter_builder.value[1]` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "expect_column_min: DefaultExpectationConfigurationBuilder = DefaultExpectationConfigurationBuilder(\n",
    "    expectation_type=\"expect_column_min_to_be_between\",\n",
    "    column=\"$domain.domain_kwargs.column\",\n",
    "    min_value=\"$parameter.min_range_parameter_builder.value[0]\",\n",
    "    max_value=\"$parameter.min_range_parameter_builder.value[1]\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "expect_column_max: DefaultExpectationConfigurationBuilder = DefaultExpectationConfigurationBuilder(\n",
    "    expectation_type=\"expect_column_max_to_be_between\",\n",
    "    column=\"$domain.domain_kwargs.column\", \n",
    "    min_value=\"$parameter.max_range_parameter_builder.value[0]\",\n",
    "    max_value=\"$parameter.max_range_parameter_builder.value[1]\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiating `RuleBasedProfiler` and Running"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We instantiate a Rule with our `DomainBuilder`, `ParameterBuilders` and `ExpectationConfigurationBuilders` and load into our `RuleBasedProfiler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "more_complex_rule: Rule = Rule(\n",
    "    name=\"rule_with_parameters\",\n",
    "    domain_builder=domain_builder,\n",
    "    parameter_builders=[min_range_parameter_builder, max_range_parameter_builder],\n",
    "    expectation_configuration_builders=[expect_column_min, expect_column_max],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_rbp.add_rule(rule=more_complex_rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7168332f1bb48658a5079b1fa69a9fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59e9161c5c864658aa04e9d84221970d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "788bbfcfc1cd403283ff26a483a5eb8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/work/Development/great_expectations/great_expectations/rule_based_profiler/helpers/util.py:587: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if bootstrap_upper_quantile_bias / bootstrap_upper_quantile_standard_error <= 0.25:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5255612fae124e4c8d5ee9c51664c1d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "692e6b7c62e1493797d5f53c0ff00e59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b244d7e2850b4e0da1bbd055916ac2d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res: ExpectationSuite = my_rbp.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{\"meta\": {}, \"expectation_type\": \"expect_column_min_to_be_between\", \"kwargs\": {\"max_value\": 0.0, \"min_value\": -1.66025, \"column\": \"tip_amount\"}},\n",
       " {\"meta\": {}, \"expectation_type\": \"expect_column_max_to_be_between\", \"kwargs\": {\"max_value\": 157.344489649, \"min_value\": 34.4595, \"column\": \"tip_amount\"}},\n",
       " {\"meta\": {}, \"expectation_type\": \"expect_column_min_to_be_between\", \"kwargs\": {\"max_value\": -4.325420542, \"min_value\": -94.5, \"column\": \"fare_amount\"}},\n",
       " {\"meta\": {}, \"expectation_type\": \"expect_column_max_to_be_between\", \"kwargs\": {\"max_value\": 235678.589018902, \"min_value\": 167.375, \"column\": \"fare_amount\"}}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.expectations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the resulting ExpectationSuite contains our minimum and maximum values, with `tip_amount` ranging from `$-2.16` to `$195.05` (a generous tip), and `fare_amount` ranging from `$-98.90` (a refund) to `$405,904.54` (a very very long trip)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Appendix\n",
    "\n",
    "* Here we have additional example configuration of `DomainBuilder` and `ParameterBuilders` that were not included in the previous 3 Examples. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `DomainBuilders`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `ColumnDomainBuilder`\n",
    "This `DomainBuilder` outputs column Domains, which are required by `ColumnExpectations` like (`expect_column_median_to_be_between`). There are a few ways that the `ColumnDomainBuilder` can be used. \n",
    "\n",
    "1. In the simplest usecase, the `ColumnDomainBuilder` can output all columns in the dataset as a Domain, or include/exclude columns if you already know which ones you would like. Column suffixes (like `_amount`) can be used to select columns of interest, as we saw in our examples above.\n",
    "3. The `ColumnDomainBuilder` also allows you to choose columns based on their semantic types (such as numeric, or text).\n",
    "\n",
    "    - Semantic types are defined as an Enum object called SemanticDomainTypes, which can be found here : https://github.com/great-expectations/great_expectations/blob/develop/great_expectations/rule_based_profiler/types/domain.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from great_expectations.rule_based_profiler.domain_builder import ColumnDomainBuilder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the simplest usecase, the `ColumnDomainBuilder` can output all of the columns in `yellow_tripdata_sample_2018`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46585d22d4e748a28e15d702e703046b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbda77a6fc844be88ba89bad61c8dcd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "domain_builder: DomainBuilder = ColumnDomainBuilder(\n",
    "    data_context=data_context,\n",
    "    batch_request=single_batch_batch_request,\n",
    ")\n",
    "domains: list = domain_builder.get_domains()\n",
    "assert len(domains) == 18 # all columns in yellow_tripdata_sample_2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns can also be included or excluded by name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f037b56a27c3429faa219e813627e3be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a10e4842a4449e1a9738578c3321f40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{\n",
       "   \"domain_type\": \"column\",\n",
       "   \"domain_kwargs\": {\n",
       "     \"column\": \"vendor_id\"\n",
       "   }\n",
       " }]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domain_builder: DomainBuilder = ColumnDomainBuilder(\n",
    "    data_context=data_context,\n",
    "    batch_request=single_batch_batch_request,\n",
    "    include_column_names=[\"vendor_id\"]\n",
    ")\n",
    "domains: list = domain_builder.get_domains()\n",
    "domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faa90cb8b55b4051916551b82c539e9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1318216b37714570b0212711343bf4a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "domain_builder: DomainBuilder = ColumnDomainBuilder(\n",
    "    data_context=data_context,\n",
    "    batch_request=single_batch_batch_request,\n",
    "    exclude_column_names=[\"vendor_id\"]\n",
    ")\n",
    "domains: list = domain_builder.get_domains()\n",
    "assert len(domains) == 17 # all columns in yellow_tripdata_sample_2018 with vendor_id excluded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As described above, the `ColumnDomainBuilder` also allows you to choose columns based on their semantic types (such as numeric, or text). This is passed in as part of the `include_semantic_types` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_builder: DomainBuilder = ColumnDomainBuilder(\n",
    "    batch_request=single_batch_batch_request,\n",
    "    data_context=data_context,\n",
    "    include_semantic_types=['numeric']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81ddfa0e1d1b43c5a667e9c862480b08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86c55bf7a80b4418a8cc300af1c5eccc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "domains: list = domain_builder.get_domains()\n",
    "assert len(domains) == 15 # columns in yellow_trip_data_sample_2018 that are numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `TableDomainBuilder`\n",
    "This `DomainBuilder` outputs table `Domains`, which is required by `Expectations` that act on tables, like (`expect_table_row_count_to_equal`, or `expect_table_columns_to_match_set`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from great_expectations.rule_based_profiler.domain_builder import TableDomainBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{\n",
       "   \"domain_type\": \"table\"\n",
       " }]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domain_builder: DomainBuilder = TableDomainBuilder(\n",
    "    data_context=data_context,\n",
    "    batch_request=single_batch_batch_request,\n",
    ")\n",
    "domains: list = domain_builder.get_domains()\n",
    "domains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `MapMetricColumnDomainBuilder`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This `DomainBuilder` allows you to choose columns based on Map Metrics, which give a yes/no answer for individual values or rows. In this example, we use the Map Metrics `column_values.nonnull` to filter out a column that was all `None` from `taxi_data`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from great_expectations.rule_based_profiler.domain_builder import MapMetricColumnDomainBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed14697e589d4a0483080e9800031fab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0664bb3dac0d4ad9bb3ae06d3a1b301c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45bff5b50d7e4c229ad32a0ccc9ec5e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df14e53da5d6462b997c673209168c2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domain_builder: DomainBuilder = MapMetricColumnDomainBuilder(\n",
    "    data_context=data_context,\n",
    "    batch_request=single_batch_batch_request,\n",
    "    map_metric_name=\"column_values.nonnull\"\n",
    ")\n",
    "domains: list = domain_builder.get_domains()\n",
    "len(domains) == 17 # filtered 1 column that was all None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `CategoricalColumnDomainBuilder`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This `DomainBuilder` allows you to choose columns based on their cardinality (number of unique values).The `CategoricalColumnDomainBuilder` will take in various `limit_modes` for cardinality, and in this example we are only interested in columns that have \"very_few\" (less than 10) unique values. For a full of valid modes, along with the associated values, please refer to the `CardinalityLimitMode` enum in:\n",
    "\n",
    "https://github.com/great-expectations/great_expectations/blob/develop/great_expectations/rule_based_profiler/helpers/cardinality_checker.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from great_expectations.rule_based_profiler.domain_builder import CategoricalColumnDomainBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_builder: DomainBuilder = CategoricalColumnDomainBuilder(\n",
    "    batch_request=single_batch_batch_request,\n",
    "    data_context=data_context,\n",
    "    limit_mode=\"very_few\", # VERY_FEW = 10 or less\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc4fcfc3918547efbe19235c54ff6854",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9e6e7c0191a42ce9cfaa8bd5f33c26d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11f88c3971ed4633ae21c78f414f6900",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "domains: list = domain_builder.get_domains()\n",
    "assert len(domains) == 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `ParameterBuilders`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ParameterBuilders` work under the hood by populating a `ParameterContainer`, which can also be shared by multiple `ParameterBuilders`. It requires a Domain, and `metric_name`, with `domain_kwargs` accessible from the `DomainBuilder` using the fully qualified parameter `$domain.domain_kwargs`.\n",
    "\n",
    "For the sake of simplicity, we will define a `Domain` object directly using the `Domain()` constructor, and pass in a column name within `domain_kwargs`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from great_expectations.rule_based_profiler.types.domain import Domain\n",
    "from great_expectations.execution_engine.execution_engine import MetricDomainTypes\n",
    "from great_expectations.rule_based_profiler.types import ParameterContainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain: Domain = Domain(domain_type=MetricDomainTypes.COLUMN, domain_kwargs = {'column': 'total_amount'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `MetricMultiBatchParameterBuilder`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `MetricMultiBatchParameterBuilder` computes a Metric on data from one or more batches. It takes `domain_kwargs`, `value_kwargs`, and `metric_name` as arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from great_expectations.rule_based_profiler.parameter_builder import MetricMultiBatchParameterBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_range_parameter_builder: MetricMultiBatchParameterBuilder = (\n",
    "    MetricMultiBatchParameterBuilder(\n",
    "        data_context=data_context,\n",
    "        batch_request=multi_batch_batch_request, # we are passing in our multi_batch_batch_request here\n",
    "        metric_name=\"column.min\",\n",
    "        metric_domain_kwargs=domain.domain_kwargs,\n",
    "        name=\"my_column_min\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_container: ParameterContainer = ParameterContainer(parameter_nodes=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10f7dfe4cb1a4980b5c6fe8216ea6a9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameter': {'parameter': {'my_column_min': {'value': [-19.8, -57.3, -6.8, -63.06, -11.8, -6.8, -30.6, -16.8, -4.3, -100.8, -12.8, -80.3], 'details': {'metric_configuration': {'metric_name': 'column.min', 'domain_kwargs': {'column': 'total_amount'}, 'metric_value_kwargs': None, 'metric_dependencies': None}, 'num_batches': 12}}}}}\n"
     ]
    }
   ],
   "source": [
    "numeric_range_parameter_builder.build_parameters(domain=domain, parameter_container=parameter_container)\n",
    "# we check the parameter container\n",
    "print(parameter_container.parameter_nodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-100.8"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(parameter_container.parameter_nodes[\"parameter\"][\"parameter\"][\"my_column_min\"][\"value\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`my_column_min[value]` now contains a list of 12 values, which are the minimum values the `total_amount` column for each of the 12 Batches associated with 2018 `taxi_data` data. If we were to use the values in a `ExpectationConfigurationBuilder`, it would be accessible through the fully-qualified parameter: `$parameter.my_column_min.value`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `ValueSetMultiBatchParameterBuilder`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `ValueSetMultiBatchParameterBuilder` is able to build a value set across multiple Batches (or just one Batch). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from great_expectations.rule_based_profiler.parameter_builder import ValueSetMultiBatchParameterBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain: Domain = Domain(domain_type=MetricDomainTypes.COLUMN, domain_kwargs = {'column': 'vendor_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating a new parameter container, since it can contain the results of more than one ParmeterBuilder. \n",
    "parameter_container: ParameterContainer = ParameterContainer(parameter_nodes=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_set_parameter_builder: ValueSetMultiBatchParameterBuilder = (\n",
    "    ValueSetMultiBatchParameterBuilder(\n",
    "        data_context=data_context,\n",
    "        batch_request= multi_batch_batch_request,\n",
    "        metric_domain_kwargs=domain.domain_kwargs,\n",
    "        name=\"my_value_set\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45162a33b7964fbbba4c5dd4bbfc0623",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "value_set_parameter_builder.build_parameters(\n",
    "    parameter_container=parameter_container,\n",
    "    domain=domain,\n",
    "    parameters = {domain.id: parameter_container}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameter': {'parameter': {'my_value_set': {'value': [1, 2, 4], 'details': {'metric_configuration': {'metric_name': 'column.distinct_values', 'domain_kwargs': {'column': 'vendor_id'}, 'metric_value_kwargs': None, 'metric_dependencies': None}, 'num_batches': 12}}}}}\n"
     ]
    }
   ],
   "source": [
    "print(parameter_container.parameter_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`my_value_set[value]` now contains a list of 3 values, which is a list of all unique `vendor_ids` across 12 Batches in the 2018 `taxi_data` dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `RegexPatternStringParameterBuilder`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `RegexPatternStringParameterBuilder` contains a set of default regex patterns and builds a value set of the best-matching patterns. Users are also able to pass in new patterns as a parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from great_expectations.rule_based_profiler.parameter_builder import RegexPatternStringParameterBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain: Domain = Domain(domain_type=MetricDomainTypes.COLUMN, domain_kwargs = {'column': 'vendor_id'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `vendor_id` is a single integer. Let's see if our default patterns can match it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_container: ParameterContainer = ParameterContainer(parameter_nodes=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_parameter_builder: RegexPatternStringParameterBuilder = (\n",
    "    RegexPatternStringParameterBuilder(\n",
    "        data_context=data_context,\n",
    "        batch_request=single_batch_batch_request,\n",
    "        metric_domain_kwargs=domain.domain_kwargs,\n",
    "        name=\"my_regex_set\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67333da46bf0491ab1fa8d5680211a39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2121d8227a664beea7d7d836500308d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/work/Development/great_expectations/great_expectations/expectations/metrics/column_map_metrics/column_values_match_regex.py:23: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  return column.astype(str).str.contains(regex)\n"
     ]
    }
   ],
   "source": [
    "regex_parameter_builder.build_parameters(\n",
    "    parameter_container=parameter_container,\n",
    "    domain=domain,\n",
    "    parameters = {domain.id: parameter_container}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameter': {'parameter': {'my_regex_set': {'value': [], 'details': {'evaluated_regexes': {'^\\\\s+/': 0.0, '\\\\s+/$': 0.0, '\\\\b[0-9a-fA-F]{8}\\\\b-[0-9a-fA-F]{4}-[0-5][0-9a-fA-F]{3}-[089ab][0-9a-fA-F]{3}-\\\\b[0-9a-fA-F]{12}\\\\b ': 0.0, '/https?:\\\\/\\\\/(www\\\\.)?[-a-zA-Z0-9@:%._\\\\+~#=]{2,256}\\\\.[a-z]{2,6}\\\\b([-a-zA-Z0-9@:%_\\\\+.~#()?&//=]*)/': 0.0, '/\\\\d+/': 0.0, '/[A-Za-z0-9\\\\.,;:!?()\\\\\"\\'%\\\\-]+/': 0.0, '/<\\\\/?(?:p|a|b|img)(?: \\\\/)?>/': 0.0, '/-?\\\\d+/': 0.0, '/-?\\\\d+(\\\\.\\\\d*)?/': 0.0, '/(?:[A-Fa-f0-9]){0,4}(?: ?:? ?(?:[A-Fa-f0-9]){0,4}){0,7}/': 0.0, '/(?:25[0-5]|2[0-4]\\\\d|[01]\\\\d{2}|\\\\d{1,2})(?:.(?:25[0-5]|2[0-4]\\\\d|[01]\\\\d{2}|\\\\d{1,2})){3}/': 0.0}, 'threshold': 1.0}}}}}\n"
     ]
    }
   ],
   "source": [
    "print(parameter_container.parameter_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Looks like `my_regex_set[value]` is an empty list. This means that none of the `evaluated_regexes` matched our domain. Let's try the same thing again, but this time with a regex that will match our `vendor_id` column. `^\\\\d{1}$` and `^\\\\d{2}$` which will match 1 or 2 digit integers anchored at the beginning and end of the string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_parameter_builder: RegexPatternStringParameterBuilder = (\n",
    "    RegexPatternStringParameterBuilder(\n",
    "        data_context=data_context,\n",
    "        batch_request=single_batch_batch_request,\n",
    "        metric_domain_kwargs=domain.domain_kwargs,\n",
    "        candidate_regexes=[\"^\\\\d{1}$\"],\n",
    "        name=\"my_regex_set\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65dc09ad5b23468e8cc61037ffb2c186",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5fea7bc30ba4d6b80b164775bbab26c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "regex_parameter_builder.build_parameters(\n",
    "    parameter_container=parameter_container,\n",
    "    domain=domain,\n",
    "    parameters = {domain.id: parameter_container}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameter': {'parameter': {'my_regex_set': {'value': ['^\\\\d{1}$'], 'details': {'evaluated_regexes': {'^\\\\d{1}$': 1.0}, 'threshold': 1.0}}}}}\n"
     ]
    }
   ],
   "source": [
    "print(parameter_container.parameter_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now `my_regex_set[value]` contains `^\\\\d{1}$`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `SimpleDateFormatStringParameterBuilder`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `SimpleDateFormatStringParameterBuilder` contains a set of default Datetime format patterns and builds a value set of the best-matching patterns. Users are also able to pass in new patterns as a parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from great_expectations.rule_based_profiler.parameter_builder import SimpleDateFormatStringParameterBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain: Domain = Domain(domain_type=MetricDomainTypes.COLUMN, domain_kwargs = {'column': 'pickup_datetime'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_container: ParameterContainer = ParameterContainer(parameter_nodes=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_date_format_string_parameter_builder: SimpleDateFormatStringParameterBuilder = (\n",
    "    SimpleDateFormatStringParameterBuilder(\n",
    "        data_context=data_context,\n",
    "        batch_request=single_batch_batch_request,\n",
    "        metric_domain_kwargs=domain.domain_kwargs,\n",
    "        name=\"my_value_set\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ec3800f1b4c4144b829af3f16c3f2e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "419a5e33934b4e27a09b3919a873133b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/121 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "simple_date_format_string_parameter_builder.build_parameters(\n",
    "    parameter_container=parameter_container,\n",
    "    domain=domain,\n",
    "    parameters = {domain.id: parameter_container}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameter': {'parameter': {'my_value_set': {'value': '%Y-%m-%d %H:%M:%S', 'details': {'success_ratio': 1.0, 'candidate_strings': ['%H:%M:%S', '%H:%M:%S,%f', '%H:%M:%S.%f', '%Y %b %d %H:%M:%S.%f', '%Y %b %d %H:%M:%S.%f %Z', '%Y %b %d %H:%M:%S.%f*%Z', '%Y%m%d %H:%M:%S.%f', '%Y-%m-%d', '%Y-%m-%d %H:%M:%S', '%Y-%m-%d %H:%M:%S %z', '%Y-%m-%d %H:%M:%S%z', '%Y-%m-%d %H:%M:%S,%f', '%Y-%m-%d %H:%M:%S,%f%z', '%Y-%m-%d %H:%M:%S.%f', '%Y-%m-%d %H:%M:%S.%f%z', \"%Y-%m-%d'T'%H:%M:%S\", \"%Y-%m-%d'T'%H:%M:%S%z\", \"%Y-%m-%d'T'%H:%M:%S'%z'\", \"%Y-%m-%d'T'%H:%M:%S.%f\", \"%Y-%m-%d'T'%H:%M:%S.%f'%z'\", '%Y-%m-%d*%H:%M:%S', '%Y-%m-%d*%H:%M:%S:%f', '%Y-%m-%dT%z', '%Y/%m/%d', '%Y/%m/%d*%H:%M:%S', '%b %d %H:%M:%S', '%b %d %H:%M:%S %Y', '%b %d %H:%M:%S %z', '%b %d %H:%M:%S %z %Y', '%b %d %Y %H:%M:%S', '%b %d, %Y %H:%M:%S %p', '%d %b %Y %H:%M:%S', '%d %b %Y %H:%M:%S*%f', '%d-%b-%Y %H:%M:%S', '%d-%b-%Y %H:%M:%S.%f', '%d-%m-%Y', '%d/%b %H:%M:%S,%f', '%d/%b/%Y %H:%M:%S', '%d/%b/%Y:%H:%M:%S', '%d/%b/%Y:%H:%M:%S %z', '%d/%m/%Y', '%m%d_%H:%M:%S', '%m%d_%H:%M:%S.%f', '%m-%d-%Y', '%m/%d/%Y', '%m/%d/%Y %H:%M:%S %p', '%m/%d/%Y %H:%M:%S %p:%f', '%m/%d/%Y %H:%M:%S %z', '%m/%d/%Y*%H:%M:%S', '%m/%d/%Y*%H:%M:%S*%f', '%m/%d/%y %H:%M:%S %z', '%m/%d/%y*%H:%M:%S', '%y%m%d %H:%M:%S', '%y-%m-%d', '%y-%m-%d %H:%M:%S', '%y-%m-%d %H:%M:%S,%f', '%y-%m-%d %H:%M:%S,%f %z', '%y/%m/%d', '%y/%m/%d %H:%M:%S']}}}}}\n"
     ]
    }
   ],
   "source": [
    "print(parameter_container.parameter_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'%Y-%m-%d %H:%M:%S'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameter_container.parameter_nodes[\"parameter\"][\"parameter\"][\"my_value_set\"][\"value\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result contains our matching `datetime` pattern, which is `'%Y-%m-%d %H:%M:%S'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `NumericMetricRangeMultiBatchParameterBuilder`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `NumericMetricRangeMultiBatchParameterBuilder` is able to provide range estimations across Batches using sampling methods. For instance, if we expect a table's row_count to change between Batches, we could calculate the min / max values of row_count by using the `NumericMetricRangeMultiBatchParameterBuilder`. These parameters could then be used by `Expectations` that take in ranges, like `ExpectTableRowCountToBeBetween`, or `ExpectColumnValuesToBeBetween`.\n",
    "\n",
    "In this example, we will be taking a single Metric, `column.mean` and calculating it for a single column, `total_amount`. The parameter we will be building is the column mean-range, which are the min-max values of the `total_amount` column across random samples of 12 Batches of the 2018 `taxi_data` dataaset. \n",
    "\n",
    "We will also be passing in specifications for estimator, namely `bootstrap` sampling with a false-positive rate of less than 0.01. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from great_expectations.rule_based_profiler.parameter_builder import NumericMetricRangeMultiBatchParameterBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain: Domain = Domain(domain_type=MetricDomainTypes.COLUMN, domain_kwargs = {'column': 'total_amount'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_metric_range_parameter_builder: NumericMetricRangeMultiBatchParameterBuilder = NumericMetricRangeMultiBatchParameterBuilder(\n",
    "    name=\"column_mean_range\",\n",
    "    metric_name=\"column.mean\",\n",
    "    estimator=\"bootstrap\",\n",
    "    metric_domain_kwargs=domain.domain_kwargs,\n",
    "    false_positive_rate=1.0e-2,\n",
    "    round_decimals=0,\n",
    "    data_context=data_context,\n",
    "    batch_request=multi_batch_batch_request,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_container: ParameterContainer = ParameterContainer(parameter_nodes=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dfb74f1f12245d1b3d852ba200339c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "numeric_metric_range_parameter_builder.build_parameters(\n",
    "    parameter_container=parameter_container,\n",
    "    domain=domain,\n",
    "    parameters = {domain.id: parameter_container}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'parameter': {'parameter': {'column_mean_range': {'value': [16.0, 44.0], 'details': {'metric_configuration': {'metric_name': 'column.mean', 'domain_kwargs': {'column': 'total_amount'}, 'metric_value_kwargs': None, 'metric_dependencies': None}, 'num_batches': 12}}}}}\n"
     ]
    }
   ],
   "source": [
    "print(parameter_container.parameter_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, the mean value range for the `total_amount` column is `16.0` to `44.0`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Clean-up Directory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As part of running this notebook, the `RuleBasedProfiler` will create a number of ExpectationSuite configurations in the `great_expectations/expectations/tmp` directory. Optionally run the following cell to clean up the directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import shutil\n",
    "# clean up Expectations directory after running tests\n",
    "#shutil.rmtree(\"great_expectations/expectations/tmp\")\n",
    "#os.remove(\"great_expectations/expectations/.ge_store_backend_id\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
