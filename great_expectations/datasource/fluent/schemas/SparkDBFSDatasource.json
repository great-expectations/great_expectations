{
    "title": "SparkDBFSDatasource",
    "description": "--Public API--Spark based Datasource for DataBricks File System (DBFS) based data assets.",
    "type": "object",
    "properties": {
        "type": {
            "title": "Type",
            "default": "spark_dbfs",
            "enum": [
                "spark_dbfs"
            ],
            "type": "string"
        },
        "name": {
            "title": "Name",
            "type": "string"
        },
        "id": {
            "title": "Id",
            "description": "Datasource id",
            "type": "string",
            "format": "uuid"
        },
        "assets": {
            "title": "Assets",
            "default": {},
            "type": "object",
            "additionalProperties": {
                "$ref": "#/definitions/_FilePathDataAsset"
            }
        },
        "base_directory": {
            "title": "Base Directory",
            "type": "string",
            "format": "path"
        },
        "data_context_root_directory": {
            "title": "Data Context Root Directory",
            "type": "string",
            "format": "path"
        }
    },
    "required": [
        "name",
        "base_directory"
    ],
    "additionalProperties": false,
    "definitions": {
        "Sorter": {
            "title": "Sorter",
            "type": "object",
            "properties": {
                "key": {
                    "title": "Key",
                    "type": "string"
                },
                "reverse": {
                    "title": "Reverse",
                    "default": false,
                    "type": "boolean"
                }
            },
            "required": [
                "key"
            ]
        },
        "_FilePathDataAsset": {
            "title": "_FilePathDataAsset",
            "description": "Base model for most fluent datasource related pydantic models.\n\nAdds yaml dumping and parsing methods.\n\nExtra fields are not allowed.\n\nSerialization methods default to `exclude_unset = True` to prevent serializing\nconfigs full of mostly unset default values.\nAlso prevents passing along unset kwargs to BatchSpec.\nhttps://docs.pydantic.dev/usage/exporting_models/",
            "type": "object",
            "properties": {
                "name": {
                    "title": "Name",
                    "type": "string"
                },
                "type": {
                    "title": "Type",
                    "type": "string"
                },
                "id": {
                    "title": "Id",
                    "description": "DataAsset id",
                    "type": "string",
                    "format": "uuid"
                },
                "order_by": {
                    "title": "Order By",
                    "type": "array",
                    "items": {
                        "$ref": "#/definitions/Sorter"
                    }
                },
                "batching_regex": {
                    "title": "Batching Regex",
                    "type": "string",
                    "format": "regex"
                }
            },
            "required": [
                "name",
                "type",
                "batching_regex"
            ]
        }
    }
}
