{
    "title": "SparkAzureBlobStorageDatasource",
    "description": "--Public API--",
    "type": "object",
    "properties": {
        "type": {
            "title": "Type",
            "default": "spark_abs",
            "enum": [
                "spark_abs"
            ],
            "type": "string"
        },
        "name": {
            "title": "Name",
            "type": "string"
        },
        "id": {
            "title": "Id",
            "description": "Datasource id",
            "type": "string",
            "format": "uuid"
        },
        "assets": {
            "title": "Assets",
            "default": [],
            "type": "array",
            "items": {
                "$ref": "#/definitions/_FilePathDataAsset"
            }
        },
        "azure_options": {
            "title": "Azure Options",
            "default": {},
            "type": "object",
            "additionalProperties": {
                "anyOf": [
                    {
                        "type": "string",
                        "writeOnly": true,
                        "format": "password"
                    },
                    {}
                ]
            }
        }
    },
    "required": [
        "name"
    ],
    "additionalProperties": false,
    "definitions": {
        "Sorter": {
            "title": "Sorter",
            "type": "object",
            "properties": {
                "key": {
                    "title": "Key",
                    "type": "string"
                },
                "reverse": {
                    "title": "Reverse",
                    "default": false,
                    "type": "boolean"
                }
            },
            "required": [
                "key"
            ]
        },
        "_FilePathDataAsset": {
            "title": "_FilePathDataAsset",
            "description": "Base model for most fluent datasource related pydantic models.\n\nAdds yaml dumping and parsing methods.\n\nExtra fields are not allowed.\n\nSerialization methods default to `exclude_unset = True` to prevent serializing\nconfigs full of mostly unset default values.\nAlso prevents passing along unset kwargs to BatchSpec.\nhttps://docs.pydantic.dev/usage/exporting_models/",
            "type": "object",
            "properties": {
                "name": {
                    "title": "Name",
                    "type": "string"
                },
                "type": {
                    "title": "Type",
                    "type": "string"
                },
                "id": {
                    "title": "Id",
                    "description": "DataAsset id",
                    "type": "string",
                    "format": "uuid"
                },
                "order_by": {
                    "title": "Order By",
                    "type": "array",
                    "items": {
                        "$ref": "#/definitions/Sorter"
                    }
                },
                "batch_metadata": {
                    "title": "Batch Metadata",
                    "type": "object"
                },
                "batching_regex": {
                    "title": "Batching Regex",
                    "default": ".*",
                    "type": "string",
                    "format": "regex"
                },
                "connect_options": {
                    "title": "Connect Options",
                    "description": "Optional filesystem specific advanced parameters for connecting to data assets",
                    "type": "object"
                }
            },
            "required": [
                "name",
                "type"
            ]
        }
    }
}
